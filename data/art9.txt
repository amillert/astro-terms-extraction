ABSTRACT Photometric redshift estimation algorithms are often based on representative data from observational campaigns. Data-drivenmethods of this type are subject to a number of potential deficiencies, such as sample bias and incompleteness. Motivated by theseconsiderations, we propose using physically motivated synthetic spectral energy distributions in redshift estimation. In addition,the synthetic data would have to span a domain in colour-redshift space concordant with that of the targeted observationalsurveys. With a matched distribution and realistically modelled synthetic data in hand, a suitable regression algorithm can beappropriately trained; we use a mixture density network for this purpose. We also perform a zero-point re-calibration to reduce thesystematic differences between noise-free synthetic data and the (unavoidably) noisy observational data sets. This new redshiftestimation framework,-, demonstrates superior accuracy over a wide range of redshifts compared to baseline modelstrained on oservational data alone. Approaches using realistic synthetic data sets can therefore greatly mitigate the reliance onexpensive spectroscopic follow-up for the next generation of photometric surveys.Key words: methods: statistical – galaxies: distances and redshifts – galaxies: statistics
Ongoing and near-future photometric surveys such as the Dark En-ergy Survey (DES, Abbott et al. 2005), the Kilo-Degree Survey(KiDS, de Jong et al. 2013), the Hyper Suprime-Cam Survey (HSC, Aihara et al. 2018a , b), Euclid ( Laureĳs et al. 2011), the Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST, Abell et al. 2009), and the Roman Space Telescope ( Green et al. 2012) encounter several hurdles that were not faced by previous, more shallow, sur-veys such as the Sloan Digital Sky Survey (SDSS, York et al. 2000).As galaxy catalogues continue to be substantially larger in size andfainter in magnitude, spectroscopic follow-ups to obtain confirma-tion of galactic properties become prohibitively expensive (Newman et al . 2015a ; Stanford et al. 2021). This necessitates alternatives to spectroscopic follow-ups via synthetic modeling, using a combina-tion of stellar population synthesis (SPS) models and star formationhistories (SFHs) from parametric models (eg, Alsing et al . 2020),semi-analytic models (eg, Pacifici et al . 2012), or hybrid approachescombining empirical and semi-analytic models (eg, LSST Dark En- ergy Science Collaboration (LSST DESC) et al. 2021). Photometric redshift estimation of individual galaxies typicallyrelies upon data either in the form of Spectral Energy Distributions(SED) templates for matching (Fernández-Soto et al. 1999 ; Benítez 2000a), or as training sets for machine learning algorithms ( Firth ★ E-mail:nramachandra@anl.gov et al . 2003). The supervised learning algorithms are designed to find a mapping between sets of dependent variables based on a trainingset with input-target examples. In an ideal case, these algorithms canpredict outputs (like galaxy redshifts) for combinations of input vari-ables (like galaxy colours) never previously encountered, thereforegeneralizing training data to unseen situations. However, in a morerealistic situation, supervised learning algorithms inherit biases pre-sented in the training data. Therefore, to prevent these biases, it ismandatory to optimise supervised learning models using trainingsets encompassing all cases expected to be found in the envisagedapplication scenario.The majority of machine learning (ML) algorithms designed toinfer photometric redshifts use observational photometric data fortraining (Carrasco Kind & Brunner 2013a , 2014 ; Graff et al . 2014; Almosallam et al. 2016a ; Almosallam et al. 2016b ; Cavuoti et al.2016 ; Sadeh et al. 2016 ; Graham et al. 2018 ; Fadikar et al. 2021). This approach is not ideal, however, because spectroscopic surveyscan only estimate redshifts at the bright end of sources detectedby photometric surveys, given their significantly slower observingspeeds. Furthermore, aiming to reduce the level of star-galaxy mis-classification, most spectroscopic surveys incorporate strict selectioncriteria on colour space that result in not being able to observe somegalaxy types. Taken together, these issues may lead to unrealisticpredictions for galaxy types, especially faint galaxies with uncom-mon properties. One approach to overcome biases originating from © 2021 The Authors arXiv:2111.12118v1 [astro-ph.CO] 23 Nov 2021
Page 2
2Ramachandra et al. incomplete observations is to employ stellar population synthesismodels to generate more complete training data sets.The viability of stellar population synthesis modelling in photo-metric redshift estimation is currently explored in template fittingcodes. For instance, Hernán-Caballero et al. (2021) use the stel-lar population synthesis code(Boquien et al. 2019) withdelayed-exponential star formation histories to create templates, andthen introduce these in a customized version of the template-fittingcode(Arnouts et al. 1999) to compute photometric redshiftsfor galaxies of the miniJPAS survey (Bonoli et al. 2021), which ob-served ≃ 1 deg 2 of the northern sky using the 56 narrow-band filtersof the J-PAS survey (Benitez et al. 2014). A similar approach isalso utilized in the COSMOS-2020 (Weaver et al. 2021) catalogueor the PAUS survey (Alarcon et al. 2021), where log-normal starformation histories are used to create 17 generated synthetic SEDsfrom Flexible Stellar Population Synthesis (, Conroy et al. 2009 ; Conroy & Gunn 2010). These are also utilized in the template fitting code(Brammer et al. 2008) to estimate the redshift. Both theseapproaches, while demonstrating the usefulness of synthetic SEDs,also highlight the need for more realistic galaxy formation models inthe future surveys of LSST, Euclid and SPHEREx (Doré et al. 2014).Furthermore, expanding the template set to include more realisticand diverse galaxy formation physics often leads to an unaffordableincrease in compute time for current and future surveys.Another issue with photometric redshift estimation is that the map-ping is not an injective function, due to the relatively sparse inputdimension, resulting in degeneracies. Hence a simple point-estimatefor a galaxy's “photo-z” is less desirable than a probability distri-bution function (PDF) that is conditioned on the observed photo-metric colours, ie, (|) (Mandelbaum et al. 2008 ; Almosallam et al . 2016b ; Benítez 2000b ; Izbicki et al . 2017 ; Carrasco Kind &Brunner 2013b), and possibly other properties, such as morphology and galaxy clustering. However, a full Bayesian posterior estimationof (|) may not be practically feasible with traditional statisticalapproaches. This is primarily due to nontrivial issues with scalingthe inference problem to billions of galaxies. Despite having a ro-bust forward model and massive parallelization abilities, obtainingfull redshift posteriors for individual galaxies is still prohibitivelyexpensive.Artificial neural networks could be used as inference machinesas alternatives to traditional posterior estimation techniques, by sam-pling over the model parameters of network weights and biases (Neal 2012). However, the numerical expense of sampling over a large num- ber of model parameters can be numerically expensive, as is the casewith deep neural networks. Consequently, neural networks employ-ing Bayesian inference techniques for robust uncertainty estimates(Mackay 1995 ; Gal 2016 ; Wenzel et al. 2020) are an active field ofresearch.It should also be noted that for photometric redshift estimationand downstream analyses, a simpler conditional density estimatorthat quantifies the uncertainty in the predictions with respect to thedata-prior suffices for most purposes. Approximating the likelihoodsusing parameterized models could further reduce the computationalexpense. This could provide the much-needed scalability to billionsof galaxies, whilst providing robust uncertainty estimations for red-shift predictions. Hence we adopt this approach in our photomet-ric redshift estimation by approximating the conditional distribution (|) using a mixture of Gaussian distributions. Our redshift esti-mation algorithm-is constructed with both the above consider-ations: the synthesis of physically modelled mock photometric data,and adaptation of synthetic data in a probabilistic framework that isscalable to a large number of galaxies. In this paper, we show thatwith robust physical modelling and meticulous sampling, we mayachieve high levels of accuracy in photo-z estimation over a baselineof observation-based training.The methodology described above is a hybrid approach thatbridges aspects of both ML and template methods of photomet-ric redshift estimation. The ML interpretation is straightforward –weights of a neural network are optimized to learn the mapping be-tween broad-band photometry and redshifts. From a template-fittingmethods perspective,-is built upon complex empirical star for-mation histories (SFHs) and SEDs, and these are approximated usingan interpolation technique. This novel combination makes-apowerful framework for predicting galactic redshifts.The paper is organized as follows. The process of creating thesynthetic galaxy colours is introduced in Section 2.1. Details of thedata from the photometric surveys of SDSS, VIPERS and DEEP2 aredescribed in Section 2.2. In Section 3 we explain the probabilisticmachine learning algorithm used for computing the redshift PDF,given galaxy colours. We also introduce zero-point adjustments per-formed to reduce the systematic differences between synthetic andobserved colours. In Section 4, we demonstrate the advantage ofusing synthetically-trained photometric redshift estimation against abaseline training scheme of using survey data for training. We discussour findings and summarize the major results in Section 5 .Throughout this work, we use extinction-corrected magnitudes inthe AB system and Planck 2015 cosmological parameters (Planck Collaboration et al. 2014): Ω m = 0.314, Ω Λ = 0.686, Ω b = 0.049, 8 = 0.83, ℎ 0 = 0.67, and s = 0.96.2 TRAINING AND VALIDATION DATAWe begin with the curation of the training and validation data usedthroughout this paper. In contrast to the traditional machine learningframeworks, the testing or validation set is different from the train-ing data. That is, the-training is entirely carried out with thesynthetic data, and'out-of-set' data is used for benchmarking. In thissection, we begin by presenting the process of modelling synthetictraining data from stellar population synthesis codes. Next, we tabu-late the observational galaxy samples used for validating the photo- algorithm introduced in Section 3.2.2.1 Synthetic spectral energy distributionsModelling galaxy SEDs is a long-standing problem in astronomydue to the dependence of the light of a galaxy on several propertiesand their correlations, such as star formation history, metallicity, dusttype and abundance, and gas properties. The most common approachto predict galaxy SEDs is by using stellar population synthesis (SPS)models, which rely upon stellar evolution theory to produce precisegalaxy spectral energy distributions in the ultraviolet, optical, andinfrared ranges (for a review see Conroy 2013). Throughout thiswork, we generate galaxy colours using the SPS model(Conroy et al . 2009 ; Conroy & Gunn 2010) together with its python interface (Foreman-Mackey et al. 2014), which include a plethora of parame-ters controlling galaxy properties. Our strategy is to produce syntheticgalaxy photometry approximately spanning the same region of thecolour space as galaxies from observations (see Section 2.2).Producing synthetic colours representative of the colours of theobserved galaxies is challenging due to the large diversity of proper-ties influencing colours. For example, Pacifici et al. (2015) show thatprecise modelling of star formation histories, metallicity enrichment MNRAS 000 , 1– 14 (2021)
Page 3
Synthetic spectra for redshift estimation: SYTH-Z3 histories, dust attenuation, and nebular emission is necessary to pro-duce colours covering the same region of the colour space as observedgalaxies. Among these properties, the star formation history presentsthe strongest influence on broadband colours (eg, Chaves-Montero & Hearin 2020). The two main approaches for modelling SFHs are parametric functional forms and star formation rates tabulated at aset of cosmic times. Sufficiently flexible parametric models captureSFHs predicted by simulations with reasonable precision (Simha et al . 2014 ; Diemer et al. 2017) and accommodate episodic bursts of star formation or other transient features. But simple models mayfail to do so entirely (Lower et al. 2020). Another crucial concern ofthe parametric models is that they may produce SFHs that are notphysically motivated.Motivated by the above issues, we use SFHs predicted by galaxyformation models to produce physically-motivated colours. Themain drawback of this approach is that the results become model-dependent. To alleviate this problem, we draw SFHs from two modelsthat reproduce a broad range of summary statistics of galaxy popula-tions but follow completely different approaches to simulate galaxies.The first is the empirical model(Behroozi et al. 2019), which simulates galaxies using a set of scaling relations be- tween galaxy and halo properties. We generateSFHs by running the publicly available version of the code1 onmerger trees identified in the Bolshoi-Planck simulation with Rock-star and Consistent trees (Behroozi et al. 2013a, b ; Klypin et al. 2016 ; Rodríguez-Puebla et al. 2016) up to redshift = 0 and 1. The sec- ond is based on the cosmological hydrodynamical simulation Illus-tris TNG (Marinacci et al. 2018 ; Naiman et al. 2018 ; Nelson et al. 2018a ; Pillepich et al . 2018 ; Springel et al . 2018), which models the joint evolution of dark matter, gas, stars, and supermassive blackholes by incorporating a comprehensive galaxy formation modelwith radiative gas cooling, star formation, galactic winds, and AGNfeedback. In particular, we draw IllustrisTNG SFHs from the largesthydrodynamical simulation of the suite, TNG300-3 (Nelson et al. 2018b). Due to the non-parametric nature of SFHs drawn from-and IllustrisTNG, it is challenging to select a setof SFHs representative of a whole galaxy population. To facilitatethis process, we label each SFH by the maximum mass ever attainedby its host halo, peak , and the slope of the host halo mass accretionhistory, MAH . It is natural to use peak because galaxies hosted bymore massive haloes present larger masses, reach the peak of their SFH at higher redshift, and become quenched at earlier times (eg, Chaves-Montero & Hearin 2020). We use MAH because this param- eter captures the dependence of galaxy properties on the assemblyhistory of its host halo; for example, at fixed halo mass, the galaxieswith a steeper slope reach the peak of their SFH at higher redshiftand become quenched at earlier times (Montero-Dorta et al. 2021).We also model the impact of three other galaxy properties influ-encing colours: metallicity, dust attenuation, and nebular emission.We use a time-independent parameter to model the stellar and gasmetallicity, ISM and ISM to specify the dust attenuation of lightcoming from stars younger and older than 10 Myr (Charlot & Fall 2000), respectively, and log 10 to set the logarithm of zero-ageionization at the Strömgren radius. Therefore, our model presents sixfree parameters: and log 10 are defined at 22 and 7 values ​​withinthe ranges ∈ [0.0002, 0.03] and log 10 ∈ [−4, −1] respectively, and ISM are continuous to within the intervals ∈ [1, 4] and ISM ∈ [0, 1.5], and peak and MAH vary to within the ranges 1 https://bitbucket.org/pbehroozi/universemachine/ predicted byand IllustrisTNG. We note that wealso use a Chabrier initial mass function (Chabrier 2003) to predictcolours.To produce galaxy colours, we begin by sampling the model pa-rameters according to a Latin hypercube design (McKay et al. 1979)defined by the priors specified above. To reduce the impact of short-term star formation fluctuations on colours, we compute the averageof the 20 SFHs with closest peak and MAH to the sampled values.Note that the resulting SFHs are more representative of the coloursof galaxy populations (Chaves-Montero & Hearin 2021). Then, weuseto generate colours at 50 randomly selected redshifts from = 0.002 to 1.25 for each combination of model parameters. In thismanner, we end up producing synthetic colours for∼200 000 differentgalaxies. In Appendix A, we compare the spectral energy distributionof some of these galaxies and that of galaxies from observations.2.2 Data from observationsThe standard approach to evaluate the quality of photometric red-shifts is to use spectroscopic redshift estimates as ground truth,which is motivated by the much better precision of spectroscopicredshifts relative to photometric redshifts. Nonetheless, the precisionof spectroscopic redshifts decreases significantly for low signal-to-noise sources; consequently, this technique may lead to catastrophicredshift solutions for faint sources. In this section, we describe themain properties of the galaxies with secure spectroscopic redshiftestimates that are used to validate our methodology.In order to benchmark-with a broadly representative sam-ple of galaxies with spectroscopic redshifts and broadband photom-etry, we collate publicly available spectroscopic sources from theSloan Digital Sky Survey (SDSS, York et al. 2000 ; Eisenstein et al. 2011 ; Blanton et al. 2017), the VIMOS Public Extragalactic Redshift Survey (VIPERS, Scodeggio et al. 2018), and the DEEP2 RedshiftSurvey (DEEP2, Newman et al. 2013 ; Matthews et al. 2013). Wedetail the properties of each of the samples below, having tabulatedthe primary statistics in Table 1.(i) SDSS: This sample comprises the 1,911,919 galaxies fromthe SDSS database2 presenting the spectroscopic redshifts with pre-cision superior to Δ spec = 0.003, extinction-corrected -band mag-nitude brighter than 20 mag, -band magnitude error smaller than0.1 mag, and clean photometry in all bands. For these sources, weuse extinction-corrected magnitudes from the public database. Thesegalaxies present redshifts typically smaller than spec = 0.6.(ii) VIPERS: We select the 40,718 galaxies from the secondpublic data release of the VIPERS survey3 with secure redshifts.VIPERS galaxies present redshifts slightly larger than the SDSSgalaxies, but typically smaller than spec = 1.(iii) DEEP2: We use the 13,163 galaxies from the fourth data re-lease of DEEP24 with spectroscopic redshifts. These galaxies presentredshifts covering approximately the same redshift range as VIPERS galaxies
 MODELLING AND FRAMEWORKUnlike the majority of ML-based photo-z estimation codes, ourframework is trained on noiseless, simulated data. The discrepancyin training and testing samples requires calibrations and validationsbeyond standard training and hold-out testing routines. In this sec-tion, we describe the major components in the-framework thataim to address these concerns: experimental design and synthesis oftraining data, construction and training of the probabilistic mappingalgorithm, and survey-specific systematic offset corrections.3.1 Colour distribution of observational and synthetic galaxiesThe architecture of data-driven ML methods, eg, artificial neuralnetworks, is usually agnostic to the underlying physics. Only thetraining data includes the intrinsic information about the input andtarget distributions, and the underlying relationships between them.Thus any incorrect modelling or biases in the training data willbe learned by the network. This is particularly important when thetraining data is created using simulations – the assumptions in thesynthetic modelling may create intractable biases in the estimations.In our work, the mixture density network (MDN) learns the infor-mation about mapping between the colours and redshift entirely fromthe training data. Since the broadband colours for training-aresynthetically generated via the steps prescribed in Section 2.1, thevalidity of synthetic data has to be meticulously checked. Primarily,the coverage of synthetic data has to be compared to that of ob-servational samples. In the colour-redshift space, if the distributiontraining set does not significantly overlap with that of the observa-tional data, the resulting extrapolation is highly prone to biases in theredshift estimations.In Figure 1, we display the distribution of colours and spectro-scopic redshifts (−, −, −, −, -band, spec ) projectedonto 2D slices. The first, second, and third panels show the colourdistribution of observed and synthetic data at 0.0 < spec <0.3,0.3 < spec <0.7, and 0.7 < spec <1.0, respectively. We find thatthe distribution of SDSS colours spans the same region of the colourspace as that of synthetic colours for the first redshift bin but notfor the higher redshift bin of 0.7 < spec <1.0. This is because theSDSS low-redshift sample is primarily a magnitude-limited sample,while at intermediate and high redshift the survey only observed redand bright galaxies. In fact, we can see that the distribution of SDSScolours in the second redshift bin agrees with just the distribution ofcolours for the reddest synthetic galaxies.In the third redshift bin 0.7 < spec <1.0, we can readily see thatSDSS galaxies present, on an average, redder colours than DEEP2galaxies. The red colours of SDSS galaxies are once again explainedby the flux limit selection, which at higher redshifts preferentiallyselects luminous red galaxies. DEEP2 selects much fainter galaxies(up to ∼ 24), with a particular colour selection that targets galaxieswith> 0.7, yielding a different colour distribution with a largerpopulation of blue galaxies. Furthermore, we can see that the dis-tribution of galaxy colours for observed data is more extended thanfor the case of synthetic data. This is simply because we producenoiseless synthetic colours and observed colours suffer from signifi-cant photometric uncertainties, especially for faint galaxies. Possiblesystematic errors by training on such noiseless data may require cor-rections (as explained in Section 3.3) and calibrations (as explainedin Section 4.1) when adapting to real observations.We can also see that synthetic galaxies span the same region of thecolour-redshift space as observed galaxies, which strongly suggeststhat our methodology produces synthetic colours representative ofthe observed colours of spectroscopic galaxies. This, in conjunctionwith physically motivated information regarding the colour-redshiftcorrelation in the training set would enable an ML model to learnthe associated mapping. Furthermore, given that observed data fromdifferent surveys do not span the same region of the colour space,an ML-model trained on one survey may not be apt for inferringredshifts from another. With a training prior different from that oftesting colour-redshift space, the mapping learned could be inher-ently biased, and a leading order zero-point correction would notsufficiently correct for the discrepancy. On the other hand, syntheticdata overlaps substantially with all observed data, ensuring that asingle model trained on the synthetic data may satisfactorily estimate 

photometric redshifts, independently of which survey is used for theinference.3.2 The probabilistic neural network algorithmThe mapping of broad-band filter values ​​to photometric redshift iscomplicated due to multiple factors. Primarily, degeneracies arise inthe redshift prediction due to the presence of multiple clusters in thecolour space C. This results in non-Gaussian posteriors for photo-metric redshifts ( phot | ∈ C), which is typically ignored in 2 op-timization schemes in template fitting or regression neural networks.In order to capture multi-modal information within the inferencepipeline, one may explicitly include a hard clustering method (likek-means clustering) to separate the whole galaxy sample sub-typesand then perform regression analysis within individual subtypes. Al-ternatively, one can also perform soft clustering for determining aprobability of association of a given datapoint with a specific sub-type, and perform regression without separate training models.
When the MDN measurements are marginalised over the observa-tional measurement error, the ( phot |) is broader. We investigatethis by running 1000 MDN evaluations per galaxy, where the inputcolours are drawn from Gaussian distributions corresponding to theSDSS photometric error ( ie we use Equation 5). Figure 3 showsthe broadening of the photo-z PDF due to averaging over the 1000conditional density measurements, before (blue shaded region) andafter (red shaded lines) the zero-point correction.Once the systematic offsets are corrected using the zero-point cor-rections, the pre-marginalized PDF output of the MDN representsthe epistemic uncertainty and is described via the distribution of theweights of the neural network. Epistemic uncertainties are usuallymodel dependent, ie, they can be reduced by an optimal training pro-cess or a better statistical model. Due to the tight sampling of trainingdata points and near-optimal training of the MDN, the epistemic un-certainty is highly minimized, as demonstrated in Figure 3. Next, thePDF obtained by marginalizing over the observational colours (afterzero-point correction) represents the aleatoric uncertainty, arisingfrom the inherent colour variability. The stochasticity in the predic-tion is limited by the quality of the observational photometry, andcannot be improved by a better training scheme or a more flexible neural network.
Marginalization over the observed photometricerrors results in a wider broadening for the faint SDSS object in thelower panel. In Figure 5, the effect of obtaining less confident predic-tions with fainter redshifts is demonstrated for all the galaxies in ourtesting sample. For the SDSS, VIPERS and DEEP2 surveys, the widthof marginalized ( phot |) increases with larger i-band magnitudes.In other words, the aleatoric uncertainty of the redshift predictionincreases with increasing magnitude. On the other hand, the corre-sponding width of the MDN density estimates is both smaller, androughly consistent across varying brightness of the galaxies. Thispre-marginalization ( phot |) includes the uncertainty due to thetraining data prior. That is, the width is primarily due to the limita-tions in the training process, the information loss due to the smallnumber of broad bands, and their colour-redshift degeneracies in thelimited number of bands. However, the MDN output alone does notcapture the effect of measurement error in the surveys.The process of zero-point calibration implemented within the-framework (from Section 3.3) involves an assessment ofmodel uncertainty using the noisy galaxy samples and a consequentupdating of the redshift prediction model. This inverse uncertaintyquantification is often neglected in machine learning regression al-gorithms; most prediction codes instead quantify the forward uncer-tainty propagation (ie, the influence on the outputs from the para-metric variability in the input space) by assessing the mean, variance,or the distribution of outputs. An alternative to zero point calibrationis a bias correction, where a discrepancy function can be determined based on spectroscopic redshift values ​​for a small number of obser-vational data points. Within the current-framework, we onlyperform the parameter calibration. However, the bias correction maybe applied independently, or in combination with the calibration.Hence, the-framework has a two-fold treatment of the un-certainties. First, it provides an inverse assessment of uncertainty andcalibration in the input space, to account for the systematic offsetsbetween the trained MDN model and true photometric redshift map-ping. Second, it includes a forward uncertainty propagation, identi-fying the sources of both aleatoric and epistemic uncertainties in the redshift estimates.
evelopment of such a synthetic-data based photometric red-shift estimation framework requires meticulous experimental design,where both modelling of synthetic SEDs (shown in Figure A1) andtheir colour-redshift distribution (in Figure 1) has to match with theobservational surveys. Once a surrogate model for mapping pho-tometry to redshifts is trained, systematic offsets in the predictioncan be corrected (Figure 4) via a calibration technique inspired bytemplate-fitting algorithms.Utilizing this framework, we have demonstrated, using Figure 7,that for a choice of inference method with uncertainty quantifica-tion, physical modelling of synthetic data can outperform purelyobservation-based training. This work motivates the development ofrobustness requirements for synthetic forward modelling efforts anderror propagation modelling in the context of upcoming astronomicalsurveys.The spectroscopic observational campaigns are expensive, whichresults in restricted coverage over sky area or over faint objects. Asa result, such samples are incomplete and prone to selection effects,which lead to biased training for ML techniques. On the other hand,template-based methods usually rely on simple libraries, as physi-cally realistic galaxy SED models quickly become too computation-ally costly. In this paper, we provide a bridge between these worlds byusing a set of realistic synthetic templates based on SFHs from state-of-art hydrodynamical simulations and empirical galaxy formationmodels, together with a probabilistic neural network framework toestimate fast galaxy redshifts conditioned on LSST-like photometry.Each individual component of-(in Section 3 can be re-placed, say, by a more realistic template library, with a better MLalgorithm, or a higher-order offset mitigation technique. However,the principles of designing such a framework – the meticulous ex-perimental design, a physical forward model for synthesizing galaxycolours, usage of uncertainty quantifiable ML models, and marginal-ization of estimates over stochastic measurements of observationalcolours – remain the same.Investigation into synthetic galaxy models, simulations and real-istic galaxy mock catalogues are crucial for astronomical studies inthe near future. Stage IV dark energy surveys like Euclid and RomanSpace Telescope would require about 5000 spectroscopic observa-tions to enable photometric calibrations (Stanford et al. 2021). Train-ing and calibration for surveys like the Rubin Observatory's LSSTmay require an even higher number (about 30,000) of spectroscopicobjects over roughly 15 widely separated regions (Newman et al. 2015b). Larger, more complete samples reaching the faintest objects would be required to reduce the scatter in photometric redshift esti-mates. Our approach of synthetic data creation circumvents the needfor the highly expensive spectroscopic follow-up surveys needed forphoto-z calibration. In addition, it also avoids the issue of trainingwith existing observational data that are neither representative norcomplete.In addition, quantification of error propagation is increasingly im-portant for future sky surveys that probe faint galaxies with broadphotometric bands. Degeneracies resulting from the limited numberof filters results in both biased estimations of redshift, and catas-trophic outliers in the predictions. With the Gaussian mixture modelwe have employed in-, followed by the marginalization over MNRAS 000 , 1– 14 (2021)
Page 12
12Ramachandra et al. observational errors, we are able to model complex photo-z PDFs,two of which are shown in Figure 3. Incorporating the mixture modelsnot only allows for modelling arbitrary prediction posteriors that arenot simple Gaussian distributions but also accounts for degeneracyin the colour-redshift space.The possible offsets in the predictions of the MDN can be tracedto the lack of modelling of the observational processes, such as thePSF response. This offset is specific to synthetic training models,and calibration in the input space is necessary to ensure an unbiasedredshift estimation via the-framework. Stringent requirementof unbiased redshift estimation in weak lensing studies (Ma et al. 2006) necessitates such an offset-mitigation treatment. Finally, the computational expense of photometric redshift esti-mation is also worth noting. Classical template fitting codes can takeover 1 second per object. In comparison, MDN prediction takes lessthan 0.02 milliseconds per galaxy with a single NVIDIA V100 Ten-sor Core GPU. This speed-up is reached because the input colourscan be passed to the trained network in arbitrarily large batches (onlylimited by the device memory). In the context of LSST and Euclid,where photometric data of billions of galaxies are expected, this levelof robustness is required for most photometric analyses.Next, we discuss the limitations of the-technique, whichare applicable to a broader family of photometric redshift estimationcodes that rely on synthetic SED templates:• One possible shortcoming of our synthetic data creation is thattheor IllustrisTNG models may not generateSFHs representative enough for all galaxies from the observations.To solve this problem, new approaches to model the galaxy-halo con-nection that brings together the advantages of SFH parametric andempirical models (Alarcon et al. 2021, in prep.) are currently beinginvestigated. Furthermore, the development of surrogate SPS modelsbased on such empirical models to speed up the generation of galaxyphotometry (Hearin et al. 2021, in prep.) is also underway.• Another notable issue with approaches that may use syntheticdata is that the template library may not be representative of thegalaxies from the observations. That is, the templates may not becompatible with any survey galaxy SED. We believe our approachof using ML circumvents this issue by learning the overall map-ping, rather than the individual one-on-one matching of galaxies.Regardless, the validity of the synthetic templates used in-isensured only up to redshift of spec ≈ 1 (see Appendix A). Extensivebenchmarking of synthetic templates will be necessary to broadenthe scope of-, where proper scoring rules or other evaluationmetrics would be required.• In addition, one should also ensure that the synthetic-trained MLmodel does not extrapolate in the colour-redshift space of the obser-vational surveys. The black-box nature of over-parameterised statis-tical models (eg, deep neural networks) renders the interpretabilityof the mapping exceedingly difficult whilst extrapolating. Within thisstudy, we have only applied limiting constraints on our data to ensureoverlap between synthetic and observed colours. However, agree-ment of training and testing data distributions in a higher-dimensionalspace needs to be investigated.• Finally, our treatment for dealing with photometric errors in-volves large numbers of draws in the colour space, followed by av-eraging over PDFs from the MDN. The plain estimations of MDN(with zero-point calibration) are much faster, and provide mean red-shift predictions with associated epistemic uncertainties, but not theeffect of observational errors. The effect of aleatoric uncertaintybecomes increasingly important in fainter galaxies. This trade-offbetween inference speed and accounting for all the prediction errorscan be challenging while scaling the model to billions of galaxies.We are currently exploring models based on these requirements, in-cluding adaptability to high-performance computing resources, andML techniques of transfer learning and Bayesian neural networks.This work facilitates exploration into multiple research avenues.In this work, we have only discussed the synthetic data correspond-ing to 5 (broad) bands. Detailed analyses with various numbers ofbands (for example, 5 LSST colours, 40 narrow bands of PAUS,56 narrow bands from J-PAS, or 101 SPHEREx channels) are easilypossible. Investigations of correlations between individual bands andtheir effects on photometric redshift estimation can help in designing future surveys. Second, ML inference algorithms can be designed specifically for cross-matched catalogues using synthetic data. Inreal observational surveys, obtaining a pristine cross-matched sam-ple depends on sky coverage, resolution, and sensitivity of individualsurveys. This is prone to multiple cross-matches for single sourcesand mismatches. However, the synthetic SEDs will only have to beconvolved with filter transmission curves of different telescopes inorder to get perfectly matched galaxies. Third, synthetic colours alsoenable the possibility of inferring star formation rates, metallicitiesand other galactic parameters. A nonlinear mapping between thesegalactic properties and photometric colours can be machine-learnedsince the synthetic data involves these parameters as inputs. Suchsynthetic forward models are highly valuable if the computationalexpense is reduced considerably. The above analyses are under active development and will be presented in the near future.