Sinkhorn Distributionally Robust Optimization
Jie Wang
School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA 30332, jwang3163@gatech.edu
Rui Gao
Department of Information, Risk, and Operations Management, University of Texas at Austin, Austin, TX 78712,
rui.gao@mccombs.utexas.edu
Yao Xie
School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA 30332, yao.xie@isye.gatech.edu
We study distributionally robust optimization with Sinkorn distanceâ€”a variant of Wasserstein distance based on
entropic regularization. We derive convex programming dual reformulations when the nominal distribution is an
empirical distribution and a general distribution, respectively. Compared with Wasserstein DRO, it is computationally
tractable for a larger class of loss functions, and its worst-case distribution is more reasonable. To solve the dual
reformulation, we propose an efficient batch gradient descent with a bisection search algorithm. Finally, we provide
various numerical examples using both synthetic and real data to demonstrate its competitive performance.
Key words: Wasserstein distributionally robust optimization, Sinkhorn distance, Duality theory
1. Introduction
Decision-making problems under uncertainty have broad applications in operations research, machine
learning, engineering, and economics. When the data involves uncertainty due to measurement error,
insufficient sample size, contamination, and anomalies, or model misspecification, distributionally
robust optimization (DRO) is a promising approach to data-driven optimization, by seeking a minimax
robust optimal decision that minimizes the expected loss under the most adverse distribution within
a given set of relevant distributions, called ambiguity set. It provides a principled framework to
produce a solution with more promising out-of-sample performance than the traditional sample average
approximation (SAA) method for stochastic programming [86]. We refer to [81] for a recent survey on
DRO.
At the core of DRO is the choice of the ambiguity set. Ideally, a good ambiguity set should take
account of the properties of practical applications while maintaining the computational tractability
of resulted DRO formulation; and it should be rich enough to contain all distributions relevant to
the decision-making but, at the same time, should not include unnecessary distributions that lead
to overly conservative decisions. Various DRO formulations have been proposed in the literature.
Among them, the ambiguity set based on Wasserstein distance has recently received much attention
[104, 67, 17, 46]. The Wasserstein distance incorporates the geometry of sample space, and thereby
is suitable for comparing distributions with non-overlapping supports and hedging against data
perturbations [46]. Nice statistical performance guarantees have been established for Wasserstein
DRO both asymptotically [16, 19, 18], non-asymptotically [44, 24, 84], and empirically in a variety of
applications in operations research [13, 30, 87, 73, 88, 100], machine learning [85, 25, 66, 14, 72, 93],
stochastic control [106, 1, 91, 38, 107, 99], etc; see [61] and references therein for more discussions.
We also provide a more detailed literature survey by the end of this section.
On the other hand, the current Wasserstein DRO framework is not without limitation. First, from the
computational efficiency perspective, the tractability of Wasserstein DRO is usually available only under
somewhat stringent conditions on the loss function, as its dual formulation involves a subproblem that
requires the global supremum of some regularized loss function over the sample space. In particular,
for 1-Wasserstein DRO, a convex reformulation is only known when the loss function can be expressed
1
arXiv:2109.11926v1 [math.OC] 24 Sep 2021
2
as a pointwise maximum of finitely many concave functions [67] and efficient first-order algorithm is
proposed only for special loss functions such as logistic loss [62]; and for 2-Wasserstein DRO, efficient
first-order algorithms have been developed only for smooth loss functions and sufficiently small radius
(or equivalently, sufficiently large Lagrangian multiplier) so that the involved subproblem becomes
strongly convex [89, 20, 63, 26]. Second, from the modeling perspective, for data-driven Wasserstein
DRO in which the nominal distribution is finitely supported (usually the empirical distribution),
the worst-case distribution is shown to be a discrete distribution [46], despite that the underlying
true distribution in many practical applications may well be continuous. This raises the concern of
whether Wasserstein DRO hedges the right family of distribution and whether it causes potentially
over-conservative performance.
To address these potential issues while maintaining the advantages of Wasserstein DRO, in this
paper, we propose Sinkhorn DRO, which hedges against distributions that are close to some nominal
distribution in Sinkhorn distance [35]. The Sinkhorn distance can be viewed as a smoothed Wasserstein
distance, defined as the cheapest transport cost between two distributions associated with an optimal
transport problem with entropic regularization (see Definition 1 in Section 2). As far as we know, this
paper is the first to study the DRO formulation using the Sinkhorn distance. Our main contributions
are summarized as follows.
(I) We derive a strong duality reformulation for Sinkhorn DRO (Theorem 1), both when the
nominal distribution is a data-driven empirical distribution (Section 3.2) and when the nominal
distribution is any arbitrary distribution (Section 3.3). The Sinkhorn dual objective smooths
the maximization subproblem in the Wasserstein dual objective, and converges to Wasserstein
dual objective as the entropic regularization parameter goes to zero (Remark 3). Moreover, the
dual objective of Sinkhorn DRO is upper bounded by that of the KL-divergence DRO with the
nominal distribution being a kernel density estimator (Remark 4).
(II) As a byproduct of our duality proof, we characterize the worst-case distribution of the Sinkhorn
DRO (Remark 5), which is absolutely continuous with respect to some reference measure such
as Lebesgue or counting measure. Compared with Wasserstein DRO, the worst-case distribution
of Sinkhorn DRO is not necessarily finitely supported even when the nominal distribution is a
finitely supported distribution. This indicates that Sinkhorn DRO is a more flexible modeling
choice for many applications.
(III) On the algorithmic aspect, we propose a computationally efficient first-order method for solving
the Sinkhorn DRO problem (Section 4), based on batch gradient descent and bisection search.
Its convergence guarantees are also developed. Compared with Wasserstein DRO, the dual
problem of Sinkhorn DRO is computationally tractable for any measurable loss functions.
(IV) We provide experiments (Section 5) to validate the performance of the proposed Sinkhorn
DRO model in the context of newsvendor problem, mean-risk portfolio optimization, and
semi-supervised learning, using both synthetic and real data sets. Numerical results demonstrate
its superior out-of-sample performances compared with several benchmarks including SAA,
Wasserstein DRO, and KL-divergence DRO.
Related Literature
On DRO Models Construction of ambiguity sets plays a key role in the performance of DRO models.
Generally, there are two ways to construct ambiguity sets in literature. First, ambiguity sets can be
defined using descriptive statistics, such as the support information [11], moment conditions [83,
36, 52, 112, 103, 29, 12], shape constraints [80, 94], marginal distributions [43, 69, 2, 39]. Second, a
more recently popular approach that makes full use of the available data is to consider distributions
within a pre-specified statistical distance from a nominal distribution, usually chosen as the empirical
distribution of samples. Commonly used statistical distances used in literature include ğœ™-divergence [57,
10, 102, 9, 41], Wasserstein distance [78, 104, 67, 110, 17, 46, 28, 105], and maximum mean discrepancy
3
[92, 111]. Our proposed Sinkhorn DRO can be viewed as a variant of Wasserstein DRO. In the
literature on Wasserstein DRO, besides the computational tractability, its regularization effects and
statistical inference have also be investigated. In particular, it has been shown that Wasserstein DRO is
asymptotically equivalent to a statistical learning problem with variation regularization [45, 16, 84],
and when the radius is chosen properly, the worst-case loss of Wasserstein DRO serves as an upper
confidence bound on the true loss [16, 19, 44, 18] . Other variants of Wasserstein DRO have been
explored, by combining with other information such as moment information [48, 96] and marginal
distributions [47, 42].
Finally, we remark that a recent work [42] on distributionally robust optimization with given
marginals share a somewhat similar spirit as our work. They start from a dual formulation and propose
to replace its supremum subproblem with a smooth penalization, and then dualize the dual problem to
obtain a primal problem that penalizes the entropy of the distribution. The main differences between
their formulation and ours are that: (i) we do not impose marginal distribution constraints in the
primal formulation; (ii) our entropic regularization is on the transport plan (joint distribution) between
the nominal distribution and a candidate distribution in the ambiguity set, but their entropic penalty
is imposed only on the candidate distributions in the ambiguity set; (iii) our dual formulation smooths
the supremum subproblem by log-exp-sum function, which is not covered in their considered family of
penalizations.
On Sinkhorn Distance Sinkhorn distance [35] is proposed to improve the computational complexity of Wasserstein distance by regularizing the original mass transportation problem with relative
entropy penalty on the transport mapping. In particular, this distance can be computed from its dual
form by optimizing two blocks of decision variables alternatively, which only requires simple matrixvector products and therefore significantly improves the computation speed [77]. Such an approach
first aroused in the areas of economics and survey statistics [60, 109, 37, 7], and its convergence
analysis is attributed to the mathematician Sinkhorn [90], which gives the name of Sinkhorn distance.
A recent work [3] further designs an accelerated algorithm to compute Sinkhorn distance in near-linear
time. Using Sinkhorn distance other than Wasserstein distance has been demonstrated to be beneficial
because of lower computational cost in various applications, including domain adaptations [32, 33, 31],
generative modeling [50, 76, 65, 75], dimensionality reduction [64, 97, 98, 58], etc. To the best of
our knowledge, the study of Sinkhorn distance for distributionally robust optimization is new in the
literature.
The rest of the paper is organized as follows. In Section 2, we describe the main formulation for
the Sinkhorn DRO model. In Section 3, we develop its strong dual reformulation. In Section 4, we
propose a first-order optimization algorithm that solves the reformulation efficiently. We report several
numerical results in Section 5, and conclude the paper in Section 6. All omitted proofs can be found in
Appendix.
2. Model Setup
Notation. Assume that the logarithm function log is taken with base ğ‘’. For a positive integer ğ‘,
we write [ğ‘] for {1, 2, . . . , ğ‘}. For a measurable set Z, denote by M(Z) the set of measures (not
necessarily probability measures) on Z, and P(Z) the set of probability measures on Z. Given a
probability distribution â„™ and a measure ğœ‡, we denote supp(â„™) the support of â„™, and write â„™  ğœ‡
if â„™ is absolutely continuous with respect to ğœ‡. For a given element ğ‘¥, denote by ğ›¿ğ‘¥ the one-point
probability distribution supported on {ğ‘¥}. Denote â„™ âŠ— â„š as the product measure of two probability
distributions â„™ and â„š. Denote by Proj1#ğ›¾ and Proj2#ğ›¾ the first and the second marginal distributions
of ğ›¾, respectively. For a given set ğ´, define the characteristic function 1ğ´ (ğ‘¥) such that 1ğ´ (ğ‘¥) = 1 when
ğ‘¥ âˆˆ ğ´ and otherwise 1ğ´ (ğ‘¥) = 0, and define the indicator function ğœğ´ (ğ‘¥) such that ğœğ´ (ğ‘¥) = 0 when ğ‘¥ âˆˆ ğ´
4
and otherwise ğœğ´ (ğ‘¥) = âˆ. Define the distance between two sets ğ´ and ğµ in the Euclidean space as
Dist(ğ´, ğµ) = supğ‘¥ âˆˆğ´ infğ‘¦âˆˆğµ kğ‘¥ âˆ’ğ‘¦k2.
We first review the definition of Sinkhorn distance.
Definition 1 (Sinkhorn Distance). Let Z be a measurable set. Consider distributions â„™,â„š âˆˆ P(Z),
and let ğœ‡,ğœˆ âˆˆ M(Z) be two reference measures such that â„™  ğœ‡, â„š  ğœˆ. For regularization parameter
ğœ– â‰¥ 0, the Sinkhorn distance between two distributions â„™ and â„š is defined as
Wğœ– (â„™,â„š) = inf
ğ›¾ âˆˆÎ“(â„™,â„š)

ğ”¼(ğ‘‹,ğ‘Œ)âˆ¼ğ›¾ [ğ‘(ğ‘‹,ğ‘Œ)] +ğœ–ğ»(ğ›¾ | ğœ‡ âŠ—ğœˆ)
	
,
where Î“(â„™,â„š) denotes the set of joint distributions whose first and second marginal distributions are
â„™ and â„š respectively, ğ‘(ğ‘¥,ğ‘¦) denotes the cost function, and ğ»(ğ›¾ | ğœ‡ âŠ—ğœˆ) denotes the relative entropy of
ğ›¾ with respect to the product measure ğœ‡ âŠ—ğœˆ:
ğ»(ğ›¾ | ğœ‡ âŠ—ğœˆ) =
âˆ«
log 
dğ›¾ (ğ‘¥,ğ‘¦)
dğœ‡(ğ‘¥) dğœˆ (ğ‘¦)

dğ›¾ (ğ‘¥,ğ‘¦).
â™¦
Remark 1 (Variants of Sinkhorn Distance). Sinkhorn distance in Definition 1 is based on general
reference measures ğœ‡ and ğœˆ. Special forms of the distance has been investigated in the literature, for
instance, when the reference measures ğœ‡ and ğœˆ were chosen to be â„™,â„š, i.e., marginal distributions
of ğ›¾, respectively [49, Section 2]. The relative entropy regularization term can also be considered
as a hard-constrained variant for the optimal transport problem, which has been discussed in [35,
Definition 1] and [8]:
WInfo
ğ‘…
(â„™,â„š) = inf
ğ›¾ âˆˆÎ“(â„™,â„š)

ğ”¼(ğ‘‹,ğ‘Œ)âˆ¼ğ›¾ [ğ‘(ğ‘‹,ğ‘Œ)] : ğ»(ğ›¾ | â„™ âŠ— â„š) â‰¤ ğ‘…
	
,
where ğ‘… â‰¥ 0 quantifies the upper bound for the relative entropy between distributions ğ›¾ and â„™ âŠ— â„š. Another variant of the optimal transport problem is to consider the negative entropy for regularization [35,
Equation (2)]:
WEnt
ğœ–
(â„™,â„š) = inf
ğ›¾ âˆˆÎ“(â„™,â„š)

ğ”¼(ğ‘‹,ğ‘Œ)âˆ¼ğ›¾ [ğ‘(ğ‘‹,ğ‘Œ)] +ğœ–ğ»(ğ›¾)
	
,
where ğ»(ğ›¾) =
âˆ«
log 
dğ›¾ (ğ‘¥,ğ‘¦)
dğ‘¥ dğ‘¦

dğ›¾ (ğ‘¥,ğ‘¦) and dğ‘¥, dğ‘¦ are Lebesgue measures if the corresponding marginal
distributions are continuous, or counting measures if the marginal distributions are discrete. For given
â„™ and â„š, the two regularized optimal transport distances above are equivalent up to a constant. â™£
In this paper, we study the Sinkhorn DRO model. Given a loss function ğ‘“ , a nominal distribution â„™b
and the Sinkhorn radius ğœŒ, the primal form of the worst-case expectation problem of Sinkhorn DRO is
given by
ğ‘‰ := sup
â„™âˆˆğ”¹ğœŒ,ğœ– (â„™b)
ğ”¼ğ‘§âˆ¼â„™[ğ‘“ (ğ‘§)],
where ğ”¹ğœŒ,ğœ– (â„™b) =

â„™ : Wğœ– (â„™b,â„™) â‰¤ ğœŒ
	
,
(Sinkhorn DRO)
where ğ”¹ğœŒ,ğœ– (â„™b) is the Sinkhorn ball of the radius ğœŒ centered at the nominal distribution â„™b. Due to the
convex entropic regularizer [34] in Wğœ– (â„™b,â„™), the Sinkhorn distance Wğœ– (â„™b,â„™) is convex in â„™ and the
Sinkhorn ball is a convex set. Therefore, the problem (Sinkhorn DRO) is an (infinite-dimensional)
convex program.
Remark 2 (Choice of Reference Measures). We discuss below the choices of the two references
measures ğœ‡ and ğœˆ in Definition 1.
5
For the reference measure ğœ‡, observe from the definition of relative entropy and the law of probability,
we can see that the regularization term in Wğœ– (â„™b,â„™) can be written as
ğ»(ğ›¾ | ğœ‡ âŠ—ğœˆ) =
âˆ«
log
dğ›¾ (ğ‘¥,ğ‘¦)
dâ„™b(ğ‘¥) dğœˆ (ğ‘¦)
!
log
â„™b(ğ‘¥)
dğœ‡(ğ‘¥)
!
dğ›¾ (ğ‘¥,ğ‘¦)
=
âˆ«
log
dğ›¾ (ğ‘¥,ğ‘¦)
dâ„™b(ğ‘¥) dğœˆ (ğ‘¦)
!
dğ›¾ (ğ‘¥,ğ‘¦) + âˆ«
log
â„™b(ğ‘¥)
dğœ‡(ğ‘¥)
!
dâ„™b(ğ‘¥).
Therefore, any choice of the reference measure ğœ‡ satisfying â„™b  ğœ‡ is equivalent up to a constant. For
simplicity, in the sequel we will take ğœ‡ = â„™b.
For the reference measure ğœˆ, observe that the worst-case solution â„™ in (Sinkhorn DRO) should satisfy
that â„™  ğœˆ since otherwise the entropic regularization in Definition 1 is undefined. As a consequence,
we can choose ğœˆ such that the underlying true distribution is absolutely continuous with respect to it.
Typical choices include the Lebesgue measure or Gaussian measure for continuous random variables,
and counting measure for discrete measures. See [79, Section 3.6] for the construction of a general
reference measure. â™£
In the following sections, we first derive the tractable formulation of the Sinkhorn DRO model and
then develop an efficient first-order method to solve it. Finally, we examine its performance by several
numerical examples.
3. Strong Duality Reformulation
Problem (Sinkhorn DRO) is an infinite-dimensional optimization problem over probability distributions.
To obtain a more tractable form, in this section, we derive a strong duality result for (Sinkhorn DRO).
Our main goal is to derive the strong dual problem
ğ‘‰D := inf
ğœ†â‰¥0

ğœ†ğœŒ + ğœ†ğœ– âˆ«
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i  dâ„™b(ğ‘¥)

, (Dual)
where the dual decision variable ğœ† corresponds to the Sinkhorn distance constraint in (Sinkhorn DRO),
and by convention we define the dual objective evaluated at ğœ† = 0 as the limit of the objective values
with ğœ† â†“ 0, which equals the essential supremum of the objective function with respect to the measure
ğœˆ; and we define the constant
ğœŒ := ğœŒ +ğœ–
âˆ«
log âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§)

dâ„™b(ğ‘¥), (1)
and the kernel probability distribution
dâ„šğ‘¥,ğœ– (ğ‘§) :=
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ–
âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘¢)/ğœ– dğœˆ (ğ‘¢)
dğœˆ (ğ‘§). (2)
To make the above primal (Sinkhorn DRO) and dual (Dual) problems well-defined, we introduce
the following assumptions on the cost function ğ‘, the reference measure ğœˆ, and the loss function ğ‘“ .
Assumption 1. (I) ğœˆ{ğ‘§ : 0 â‰¤ ğ‘(ğ‘¥, ğ‘§) < âˆ} = 1 for â„™b-almost every ğ‘¥;
(II) âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) < âˆ for â„™b-almost every ğ‘¥;
(III) Z is a measurable space, and the function ğ‘“ : Z â†’ â„ âˆª {âˆ} is measurable.
6
Assumption 1(I) ensures that the Sinkhorn distance is well-defined. If Assumption 1(II) is not satisfied,
then the Sinkhorn ball ğ”¹ğœŒ,ğœ– (â„™b) = P(Z) and the problem (Sinkhorn DRO) has a simple optimal value
ğ‘‰ = supğ‘§âˆˆZ ğ‘“ (ğ‘§). Assumption 1(III) ensures the expected loss ğ”¼ğ‘§âˆ¼â„™[ğ‘“ (ğ‘§)] to be well-defined and lower
bounded for any distribution â„™. In Appendix A, we present sufficient conditions for Assumption 1 that
are easy to verify.
To distinguish the cases ğ‘‰ğ· < âˆ and ğ‘‰ğ· = âˆ, we introduce the following light-tail condition on ğ‘“ .
Condition 1. There exists ğœ† > 0 such that ğ”¼â„šğ‘¥,ğœ–
[ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
] < âˆ for â„™b-almost every ğ‘¥.
Our main result in this section is as follows.
Theorem 1 (Strong Duality). Let â„™b âˆˆ P(Z). Assume Assumption 1 is in force. Then the following holds:
(I) The primal problem (Sinkhorn DRO) is feasible if and only if ğœŒ â‰¥ 0;
(II) Whenever ğœŒ â‰¥ 0, it holds that ğ‘‰ =ğ‘‰ğ·.
(III) If, in addition, Condition 1 holds, then ğ‘‰ =ğ‘‰D < âˆ; otherwise ğ‘‰ =ğ‘‰D = âˆ.
We remark that if ğœŒ < 0, by convention, ğ‘‰ = âˆ’âˆ and ğ‘‰ğ· = âˆ’âˆ as well by Lemma 2 in Section 3.3 below.
Therefore, we have ğ‘‰ =ğ‘‰ğ· as long as Assumption 1 holds.
3.1. Discussions
Before we present the proof of Theorem 1, we would like to make several remarks.
Remark 3 (Connection with Wasserstein DRO). As the regularization parameter ğœ– â†’ 0, the dual
objective of the Sinkhorn DRO converges to the dual formulation of the Wasserstein DRO problem [46,
Theorem 1]
ğœ†ğœŒ +
âˆ«
sup
ğ‘§

ğ‘“ (ğ‘§) âˆ’ğœ†ğ‘(ğ‘¥, ğ‘§)
	
dâ„™b(ğ‘¥).
The proof is given in Appendix EC.3, which essentially follows from the fact that the log-sum-exp
function is a smooth approximation of the supremum. There are several advantages of Sinkhorn DRO.
(I) As we will demonstrate in Section 4, Sinkhorn DRO is tractable for a large class of loss functions.
For the empirical nominal distribution, the worst-case loss can be evaluated efficiently for any
measurable loss function ğ‘“ . In contrast, the main computational difficulty in Wasserstein DRO
is to solve the maximization problem inside the integration above. In fact, 1-Wasserstein DRO is
shown to be tractable only when the loss function can be expressed as a pointwise maximum
of finitely many concave functions [67, Theorem 4.2], and 2-Wasserstein DRO is shown to be
tractable only when the loss function is smooth and the radius of the ambiguity set is sufficiently
small [20, Theorem 3].
(II) The strong duality of Sinkhorn DRO holds in an even more general setting. Essentially, the only
requirements on the space Z and the nominal distribution â„™b are measurability. In contrast, the
strong duality for Wasserstein DRO ([46, Theorem 1], [17, Theorem 1]) requires the nominal
distribution â„™b to be a Borel probability measure and the set Z to be a Polish space.
We remark that Sinkorn DRO and Wasserstein DRO result in different conditions for finite worst-case
values. From Condition 1 we see that the Sinkhorn DRO is finite if and only if under a light-tail condition
on ğ‘“ , while the Wasserstein DRO [46, Theorem 1] is finite iff and only if the loss function satisfies a
growth condition ğ‘“ (ğ‘§) â‰¤ ğ¿ğ‘(ğ‘§, ğ‘§0) + ğ‘€,âˆ€ğ‘§ âˆˆ Z for some constants ğ¿, ğ‘€ > 0 and some ğ‘§0 âˆˆ Z. â™£
Remark 4 (Connection with KL-DRO). Using Jensenâ€™s inequality, we can see that the dual objective
function of the Sinkhorn DRO model can be upper bounded as
ğœ†ğœŒ + ğœ†ğœ– log âˆ«
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i
dâ„™b(ğ‘¥)

,
7
which corresponds to the dual objective function [57] for the following KL-divergence DRO
sup
â„™

ğ”¼ğ‘§âˆ¼â„™[ğ‘“ (ğ‘§)] : ğ·KL (â„™kâ„™
0
) â‰¤ ğœŒ/ğœ–
	
,
where â„™
0
satisfies dâ„™
0
(ğ‘§) =
âˆ«
ğ‘¥
dâ„šğ‘¥,ğœ– (ğ‘§) dâ„™b(ğ‘¥), which can be viewed as a non-parametric kernel density
estimation constructed from â„™b. Particularly, when â„™b =
1
ğ‘›
Pğ‘›
ğ‘–=1
ğ›¿ğ‘¥Ë†ğ‘–
, Z = â„ğ‘‘ and ğ‘(ğ‘¥,ğ‘¦) = kğ‘¥ âˆ’ğ‘¦k
2
2
, â„™
0
is
kernel density estimator with Gaussian kernel and bandwidth ğœ–:
dâ„™
0
(ğ‘§)
dğ‘§
=
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ¾ğœ– (ğ‘§ âˆ’ğ‘¥ğ‘–), ğ‘§ âˆˆ â„
ğ‘‘
,
where ğ¾ğœ– (ğ‘¥) âˆ exp(âˆ’kğ‘¥ k
2
2
/ğœ–) represents the Gaussian kernel. By decomposing ğ›¾ (ğ‘¥, ğ‘§) = â„™b(ğ‘¥) âŠ—ğ›¾ğ‘¥ (ğ‘§),
similar to the proof in Section 3.2 below, (Sinkhorn DRO) can be reformulated as a generalized
KL-divergence DRO problem:
ğ‘‰ = sup
ğ›¾ğ‘¥ âˆˆP (Z),âˆ€ğ‘¥ âˆˆZ
âˆ«
ğ”¼ğ‘§âˆ¼ğ›¾ğ‘¥
[ğ‘“ (ğ‘§)] dâ„™b(ğ‘¥) :
âˆ«
ğ·KL (ğ›¾ğ‘¥ kâ„šğ‘¥ ) dâ„™b(ğ‘¥) â‰¤ ğœŒ/ğœ–

. (3)
Using Divergence inequality [34, Theorem 2.6.3], we can see the Sinkhorn DRO with ğœŒ = 0 is reduced
to the following SAA model based on the distribution â„™
0
:
ğ‘‰ = ğ”¼â„™0 [ğ‘“ (ğ‘§)] =
âˆ«
ğ”¼â„šğ‘¥,ğœ–
[ğ‘“ (ğ‘§)] dâ„™b(ğ‘¥). (4)
In non-parameteric statistics, the optimal bandwidth to minimize the mean-squared-error between
the estimated distribution and the underlying true one is at rate ğœ– =ğ‘‚(ğ‘›
âˆ’1/(ğ‘‘+4)
) [54, Theorem 4.2.1].
However, such an optimal choice for the kernel density estimator may not be the optimal choice for
optimizing the out-of-sample performance of the Sinkhorn DRO. In our numerical experiments in
Section 5, we select ğœ– based on cross-validation. â™£
Let us illustrate our result for a linear loss function ğ‘“ , which turns out to be equivalent to a simple
optimization problem.
Example 1. Suppose that ğ‘“ (ğ‘§) = ğ‘
T
ğ‘§, Z = â„ğ‘‘ and ğœˆ is the corresponding Lebesgue measure, and the
cost function is the Mahalanobis distance, i.e.,ğ‘(ğ‘¥,ğ‘¦) =
1
2
(ğ‘¥ âˆ’ğ‘¦)
TÎ©(ğ‘¥ âˆ’ğ‘¦), where Î© is a positive definite
matrix. In this case, we have the reference measure
â„šğ‘¥,ğœ– âˆ¼ N (ğ‘¥, ğœ–Î©
âˆ’1
).
As a consequence, the dual problem can be written as
ğ‘‰D = inf
ğœ†>0

ğœ†ğœŒ + ğœ†ğœ– âˆ«
Î›ğ‘¥ (ğœ†) dâ„™b(ğ‘¥)

,
where
Î›ğ‘¥ (ğœ†) = log 
ğ”¼(ğ‘¥,ğœ–Î©âˆ’1)
h
ğ‘’
ğ‘
>ğ‘§/(ğœ†ğœ–)
i  =
ğ‘
T
ğ‘¥
ğœ†ğœ– +
ğ‘
TÎ£ğ‘
2ğœ†
2ğœ–
2
.
Therefore
ğ‘‰D = ğ‘
Tğ”¼â„™b[ğ‘¥] + âˆšï¸
2ğœŒ
âˆšï¸
ğ‘
TÎ©âˆ’1ğ‘ := ğ”¼â„™b[ğ‘
T
ğ‘¥] + âˆšï¸
2ğœŒ Â· kğ‘kÎ©âˆ’1 .
This indicates that the Sinkhorn DRO is equivalent to an empirical risk minimization with norm
regularization, and can be solved using efficiently using algorithms for the second-order cone
program. â™£
In the following, we first show that ğ‘‰ =ğ‘‰D when â„™b is an empirical distribution supported on ğ‘› points,
as it is relatively straightforward to prove. Then we show that the same results hold when â„™b is a
general distribution, as it provides more insights on the worst-case distribution.
8
3.2. Proof for an Empirical Nominal distribution
Given data points ğ‘¥Ë†ğ‘– for ğ‘– = 1, . . . , ğ‘›, denote 1
ğ‘›
Pğ‘›
ğ‘–=1
ğ›¿ğ‘¥Ë†ğ‘–
as the corresponding empirical distribution. In
this subsection, we discuss the dual reformulation provided that the nominal distribution â„™b is taken in
this form. Although our strong duality result holds for arbitrary nominal distribution, this is still an
interesting case, as the proof is relatively simple and â„™b is often chosen as the empirical distribution in
practice.
The key to the proof is to write the primal problem in a Lagrangian form and then apply the minimax
inequality to obtain a weak dual. Observe that the primal can be reformulated as a generalized
KL-divergence DRO problem. Hence, by leveraging the strong duality result for the existing DRO
model [57], the minimax inequality does not incur any duality gap.
Proof of Theorem 1 when â„™b =
1
ğ‘›
Pğ‘›
ğ‘–=1
ğ›¿ğ‘¥Ë†ğ‘–
. Based on Definition 1, we reformulate ğ‘‰ as
ğ‘‰ = sup
ğ›¾ âˆˆP (ZÃ—Z):Proj1#ğ›¾=â„™b
(
ğ”¼â„™[ğ‘“ (ğ‘§)] : ğ”¼ğ›¾
"
ğ‘(ğ‘¥, ğ‘§) +ğœ– log
dğ›¾ (ğ‘¥, ğ‘§)
dâ„™b(ğ‘¥) dğœˆ (ğ‘§)
! # â‰¤ ğœŒ
)
.
By the disintegration theorem [23] we represent the joint distribution ğ›¾ =
1
ğ‘›
Pğ‘›
ğ‘–=1
ğ›¿ğ‘¥Ë†ğ‘– âŠ—ğ›¾ğ‘–
, where ğ›¾ğ‘–
is the
conditional distribution of ğ›¾ given the first marginal of ğ›¾ equals ğ‘¥Ë†ğ‘–
. Thereby the constraint is equivalent
to
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼ğ›¾ğ‘–

ğ‘(ğ‘¥Ë†ğ‘–
, ğ‘§) +ğœ– log 
dğ›¾ğ‘–(ğ‘§)
dğœˆ (ğ‘§)
  â‰¤ ğœŒ, ğ›¾ğ‘– âˆˆ P(Z),ğ‘– âˆˆ [ğ‘›].
We remark that any feasible solution ğ›¾ satisfies that ğ›¾  â„™b âŠ— ğœˆ and hence ğ›¾ğ‘–  ğœˆ. Consequently the
term log 
dğ›¾ğ‘– (ğ‘§)
dğœˆ (ğ‘§)

is well-defined. For notational simplicity, we write â„šğ‘– for â„šğ‘¥Ë†ğ‘–
,ğœ– . Based on the changeof-measure identity log 
dğ›¾ğ‘– (ğ‘§)
dğœˆ (ğ‘§)

= log 
dâ„šğ‘– (ğ‘§)
dğœˆ (ğ‘§)

+ log 
dğ›¾ğ‘– (ğ‘§)
dâ„šğ‘– (ğ‘§)

and the expression of â„šğ‘–
, the constraint
can be reformulated as
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼ğ›¾ğ‘–
"
ğ‘(ğ‘¥Ë†ğ‘–
, ğ‘§) +ğœ– log
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ–
âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘¢)/ğœ– dğœˆ (ğ‘¢)
!
+ğœ– log 
dğ›¾ğ‘–(ğ‘§)
dâ„šğ‘–(ğ‘§)

#
â‰¤ ğœŒ, ğ›¾ğ‘– âˆˆ P(Z),ğ‘– âˆˆ [ğ‘›].
Combining the first two terms within the expectation term and substituting the expression of ğœŒ, it is
equivalent to
ğœ–
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼ğ›¾ğ‘–

log 
dğ›¾ğ‘–(ğ‘§)
dâ„šğ‘–(ğ‘§)
  â‰¤ ğœŒ, ğ›¾ğ‘– âˆˆ P(Z),ğ‘– âˆˆ [ğ‘›].
Similarly, the objective function of (Sinkhorn DRO) can be written as 1
ğ‘›
Pğ‘›
ğ‘–=1
ğ”¼ğ›¾ğ‘–
[ğ‘“ (ğ‘§)]. Consequently,
the primal problem (Sinkhorn DRO) can be reformulated as a generalized KL-divergence DRO problem
ğ‘‰ = sup
ğ›¾ğ‘– âˆˆP (Z),ğ‘– âˆˆ [ğ‘›]
(
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼ğ›¾ğ‘–
[ğ‘“ (ğ‘§)] :
ğœ–
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ·KL (ğ›¾ğ‘– kâ„šğ‘–) â‰¤ ğœŒ
)
.
Then Theorem 1(I) holds based on the non-negativity of KL-divergence.
Introducing the Lagrange multiplier ğœ† associated with the constraint, we reformulate (Sinkhorn DRO)
as
ğ‘‰ = sup
ğ›¾ğ‘– âˆˆP (Z),ğ‘– âˆˆ [ğ‘›]
inf
ğœ†â‰¥0
(
ğœ†ğœŒ +
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼ğ›¾ğ‘–

ğ‘“ (ğ‘§) âˆ’ğœ†ğœ– log 
dğ›¾ğ‘–(ğ‘§)
dâ„šğ‘–(ğ‘§)
 )
.
Interchanging the supremum and infimum operators, we have that
ğ‘‰ â‰¤ inf
ğœ†â‰¥0
(
ğœ†ğœŒ + sup
ğ›¾ğ‘– âˆˆP (Z),ğ‘– âˆˆ [ğ‘›]
(
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼ğ›¾ğ‘–

ğ‘“ (ğ‘§) âˆ’ğœ†ğœ– log 
dğ›¾ğ‘–(ğ‘§)
dâ„šğ‘–(ğ‘§)
 )) .
9
Since the optimization over ğ›¾ğ‘–
,ğ‘– âˆˆ [ğ‘›] is separable, by defining for each ğ‘–
ğ‘£ğ‘–(ğœ†) := sup
ğ›¾ğ‘– âˆˆP (Z)

ğ”¼ğ›¾ğ‘–

ğ‘“ (ğ‘§) âˆ’ğœ†ğœ– log 
dğ›¾ğ‘–(ğ‘§)
dâ„šğ‘–(ğ‘§)
  ,
it holds that
ğ‘‰ â‰¤ inf
ğœ†â‰¥0
(
ğœ†ğœŒ +
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ‘£ğ‘–(ğœ†)
)
.
When Condition 1 holds, leveraging a well-known results on entropy regularized linear optimization
(Lemma EC.1), we can see that
ğ‘£ğ‘–(ğœ†) = ğœ†ğœ– log 
ğ”¼â„šğ‘–
h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i  < âˆ,
hence we obtain the weak duality ğ‘‰ â‰¤ ğ‘‰D < âˆ. Otherwise, for any ğœ† > 0, there exists an index ğ‘– such
that
ğ”¼â„šğ‘–
h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i
= âˆ.
We also obtain that ğ‘‰ â‰¤ ğ‘‰D = âˆ, and the weak duality still holds.
Next we prove the strong duality. Recall that the primal problem is a generalized KL-divergence DRO
problem. By leveraging the strong duality result from [57], the minimax inequality above does not
incur any duality gap when ğœŒ > 0. When ğœŒ = 0, since ğ·KL (ğ›¾ğ‘– kâ„šğ‘–) = 0 if and only if ğ›¾ğ‘– = â„šğ‘–
, one can see
that
ğ‘‰ =
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼â„šğ‘–
[ğ‘“ (ğ‘§)].
On the other hand, denote by â„(ğœ†) the objective function for the dual problem. Then we have the
inequality
ğ‘‰D â‰¤ lim
ğœ†â†’âˆ
â„(ğœ†) =
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼â„šğ‘–
[ğ‘“ (ğ‘§)] =ğ‘‰.
This, together with the weak duality result, completes the proof for Theorem 1(II). Theorem 1(III) also
follows based on the discussion of the finiteness of ğ‘‰D.
When the sample space Z is finite, the following result presents a conic programming reformulation.
Corollary 1 (Conic Reformulation for Finite Sample Space). Suppose that the sample space contains ğ¿ elements, i.e., Z = {ğ‘§â„“ }
ğ¿
â„“=1
. If Condition 1 holds and ğœŒ â‰¥ 0, the dual problem (Dual) can be
formulated as the following conic optimization:
ğ‘‰D = min
ğœ†â‰¥0,ğ‘  âˆˆâ„ğ‘›,
ğ‘âˆˆâ„ğ‘›Ã—ğ¿
ğœ†ğœŒ +
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ‘ ğ‘–
s.t. ğœ†ğœ– â‰¥
âˆ‘ï¸
ğ¿
â„“=1
ğ‘ğ‘–,â„“ğ‘ğ‘–,â„“,ğ‘– âˆˆ [ğ‘›],
(ğœ†ğœ–,ğ‘ğ‘–,â„“, ğ‘“ (ğ‘§â„“) âˆ’ğ‘ ğ‘–) âˆˆ Kexp,ğ‘– âˆˆ [ğ‘›], â„“ âˆˆ [ğ¿].
(5)
where ğ‘ğ‘–,â„“ := Prğ‘§âˆ¼â„šğ‘¥Ë†ğ‘–
,ğœ–
{ğ‘§ = ğ‘§â„“ }, with the distribution â„šğ‘¥Ë†ğ‘–
,ğœ– defined in (2), and Kexp denotes the exponential
cone Kexp = {(ğœˆ, ğœ†, ğ›¿) âˆˆ â„+ Ã— â„+ Ã— â„ : exp(ğ›¿/ğœˆ) â‰¤ ğœ†/ğœˆ}.
Problem (5) is a convex program that minimizes a linear function with respect to linear and conic
constraints, which can be solved using interior point algorithms [71, 95]. We will develop a customized
first-order optimization algorithm in Section 4 that is able to solve a more general problem (without a
finite sample space).
10
3.3. Proof for a General Nominal Distribution
In this subsection, we outline the proof of Theorem 1 when â„™b is an arbitrary nominal distribution and
discuss the worst-case distribution.
The feasibility result in Theorem 1(I) can be easily shown using the reformulation (3). To show
ğ‘‰ =ğ‘‰D, it is easy to show the weak duality result following a similar argument as in Section 3.2, by
replacing the finite-sum with the integration with respect to â„™b.
When Condition 1 holds, we prove the strong duality by constructing the worst-case distribution. We
first show the existence of the dual minimizer (Lemma 2), and then build the corresponding first-order
optimality condition (Lemma 3 and Lemma 4). Those results help us to construct a primal optimal
solution for (Sinkhorn DRO) that shares the same optimal value as ğ‘‰D, which completes the first part
of Theorem 1(III). When Condition 1 does not hold, we construct a sequence of DRO problems with
finite optimal values converging into ğ‘‰ and consequently ğ‘‰ =ğ‘‰D = âˆ, which completes the second part
of Theorem 1(III). Putting these two parts together imply Theorem 1(II).
Lemma 1 (Weak Duality). Assume Assumption 1 holds. Then ğ‘‰ â‰¤ ğ‘‰D.
Below we provide the proof of the first part of Theorem 1(III) for the case ğœŒ > 0 under Condition 1,
defer proofs of other degenerate cases to Appendix EC.4. To prove the strong duality, we will construct
a feasible solution of (Sinkhorn DRO) whose loss coincides with ğ‘‰D. To this end, we first show that the
dual minimizer exists.
Lemma 2 (Existence of Dual Minimizer). Suppose ğœŒ > 0 and Condition 1 is satisfied, then the dual
minimizer ğœ†
âˆ—
exists, which either equals to 0 or satisfies Condition 1.
We separate two cases: ğœ†
âˆ— > 0 and ğœ†
âˆ— = 0, corresponding to whether the Sinkhorn distance constraint
in (Sinkhorn DRO) is binding or not.
Lemma 3 below presents a necessary and sufficient condition for the dual minimizer ğœ†
âˆ— = 0,
corresponding to the case where the Sinkhorn distance constraint in (Sinkhorn DRO) is not binding.
Lemma 3 (Necessary and Sufficient Condition for ğœ†
âˆ— = 0). Suppose ğœŒ > 0 and Condition 1 is satisfied,
then the dual minimizer ğœ†
âˆ— = 0 if and only if all the following conditions hold:
(I) ess sup
ğœˆ
ğ‘“ , inf{ğ‘¡ : ğœˆ{ğ‘“ (ğ‘§) > ğ‘¡ } = 0} < âˆ.
(II) ğœŒ
0 = ğœŒ +ğœ–
âˆ«
log
ğ”¼â„šğ‘¥,ğœ–
[1ğ´]

dâ„™b(ğ‘¥) â‰¥ 0, where ğ´ := {ğ‘§ : ğ‘“ (ğ‘§) = ess sup
ğœˆ
ğ‘“ }.
Recall that we have the convention that the dual objective evaluated at ğœ† = 0 equals ess sup
ğœˆ
ğ‘“ . Thus
Condition (I) ensures that the dual objective function evaluated at the minimizer is finite. When the
minimizer ğœ†
âˆ— = 0, the Sinkhorn ball should be large enough to contain at least one distribution with
objective value ess sup
ğœˆ
ğ‘“ , and the condition (II) characterizes the lower bound of ğœŒ.
Lemma 4 below considers the optimality condition when the dual minimizer ğœ†
âˆ— > 0, obtained by
simply setting the derivative of the dual objective function to be zero.
Lemma 4 (First-order Optimality Condition when ğœ†
âˆ— > 0). Suppose ğœŒ > 0 and Condition 1 is satisfied,
and assume further that the dual minimizer ğœ†
âˆ— > 0, then ğœ†
âˆ—
satisfies
ğœ†
âˆ—

ğœŒ +ğœ–
âˆ«
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†
âˆ—
ğœ–)
i  dâ„™b(ğ‘¥)

=
âˆ«
ğ”¼â„šğ‘¥,ğœ–
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†
âˆ—
ğœ–)
ğ‘“ (ğ‘§)

ğ”¼â„šğ‘¥,ğœ–
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†
âˆ—ğœ–)
 dâ„™b(ğ‘¥). (6)
Now we are ready to prove Theorem 1.
Proof of Theorem 1(III) under Condition 1 with ğœŒ > 0. The proof is separated for two cases: ğœ†
âˆ— > 0
or ğœ†
âˆ— = 0. For each case we prove by constructing a primal (approximate) optimal solution.
When ğœ†
âˆ— > 0, we take a probability measure ğ›¾âˆ— such that
dğ›¾âˆ— (ğ‘¥, ğ‘§) =
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘§)
ğœ†
âˆ—ğœ–

âˆ«
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘¢)
ğœ†
âˆ—ğœ–

dğœˆ (ğ‘¢)
dğœˆ (ğ‘§) dâ„™b(ğ‘¥), where ğœ™ (ğœ†;ğ‘¥, ğ‘§) = ğ‘“ (ğ‘§) âˆ’ğœ†ğ‘(ğ‘¥, ğ‘§)
11
Also define the primal (approximate) optimal distribution
â„™âˆ— := Proj2#ğ›¾âˆ—.
Recall the expression of the Sinkhorn distance in Definition 1, one can verify that
Wğœ– (â„™b,â„™âˆ—)
= inf
ğ›¾ âˆˆÎ“(â„™b,â„™âˆ—)
(
ğ”¼ğ›¾
"
ğ‘(ğ‘¥, ğ‘§) +ğœ– log
dğ›¾ (ğ‘¥, ğ‘§)
dâ„™b(ğ‘¥) dğœˆ (ğ‘§)
! #)
â‰¤ ğ”¼ğ›¾âˆ—
"
ğ‘(ğ‘¥, ğ‘§) +ğœ– log
dğ›¾âˆ— (ğ‘¥, ğ‘§)
dâ„™b(ğ‘¥) dğœˆ (ğ‘§)
! #
= ğ”¼ğ›¾âˆ—
ï£®
ï£¯
ï£¯
ï£¯
ï£¯
ï£¯
ï£°
ğ‘(ğ‘¥, ğ‘§) +ğœ– log
Â©
Â­
Â­
Â«
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘§)
ğœ†
âˆ—ğœ–

âˆ«
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘¢)
ğœ†
âˆ—ğœ–

dğœˆ (ğ‘¢)
Âª
Â®
Â®
Â¬
ï£¹
ï£º
ï£º
ï£º
ï£º
ï£º
ï£»
=
1
ğœ†
âˆ—
ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³
âˆ¬ ğ‘“ (ğ‘§) exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘§)
ğœ†
âˆ—ğœ–

âˆ«
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘§)
ğœ†
âˆ—ğœ–

dğœˆ (ğ‘§)
dğœˆ (ğ‘§) dâ„™b(ğ‘¥) âˆ’ğœ†
âˆ—
ğœ–
âˆ«
log âˆ«
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘¢)
ğœ†
âˆ—ğœ–

dğœˆ (ğ‘¢)

dâ„™b(ğ‘¥)
ï£¼ï£´ï£´ï£½
ï£´ï£´
ï£¾
,
where the second relation is because ğ›¾âˆ— is a feasible solution in Î“(â„™b,â„™âˆ—), the third and the fourth
relation is by substituting the expression of ğ›¾âˆ—. Since ğœŒ > 0 and the dual minimizer ğœ†
âˆ— > 0, the optimality
condition in (6) holds, which implies that Wğœ– (â„™b,â„™âˆ—) â‰¤ ğœŒ, i.e., the distribution â„™âˆ— is primal feasible for
the problem (Sinkhorn DRO). Moreover, we can see that the primal optimal value is lower bounded by
the dual optimal value:
ğ‘‰ â‰¥ ğ”¼â„™âˆ—
[ğ‘“ (ğ‘§)] =
âˆ«
ğ‘“ (ğ‘§) dğ›¾âˆ— (ğ‘¥, ğ‘§)
=
âˆ¬
ğ‘“ (ğ‘§)

dğ›¾âˆ— (ğ‘¥, ğ‘§)
dâ„™b(ğ‘¥) dğœˆ (ğ‘§)
!
dğœˆ (ğ‘§) dâ„™b(ğ‘¥)
=
âˆ¬
ğ‘“ (ğ‘§)
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘§)
ğœ†
âˆ—ğœ–

âˆ«
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥,ğ‘¢)
ğœ†
âˆ—ğœ–

dğœˆ (ğ‘¢)
dğœˆ (ğ‘§) dâ„™b(ğ‘¥)
=ğœ†
âˆ—

ğœŒ +ğœ–
âˆ«
log âˆ«
exp 
ğœ™ (ğœ†
âˆ—
;ğ‘¥, ğ‘§)
ğœ†
âˆ—ğœ–

dğœˆ (ğ‘§)

dâ„™b(ğ‘¥)

=ğ‘‰D,
where the third equality is based on the optimality condition in Lemma 4. This, together with the
weak duality result, completes the proof for ğœ†
âˆ— > 0.
When ğœ†
âˆ— = 0, the optimality condition in Lemma 3 holds. We construct the primal (approximate)
solution â„™âˆ— = Proj2#ğ›¾âˆ—, where ğ›¾âˆ— satisfies
dğ›¾âˆ— (ğ‘¥, ğ‘§) = dğ›¾
ğ‘¥
âˆ—
(ğ‘§) dâ„™b(ğ‘¥), where dğ›¾
ğ‘¥
âˆ—
(ğ‘¦) =
(
0, if ğ‘§ âˆ‰ğ´,
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§)
âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘¢)/ğœ–1ğ´ dğœˆ (ğ‘¢)
, if ğ‘§ âˆˆ ğ´.
We can verify easily that the primal solution is feasible based on the optimality condition ğœŒ
0 â‰¥ 0 in
Lemma 3. Moreover, we can check that the primal optimal value is lower bounded by the dual optimal
value:
ğ‘‰ â‰¥
âˆ«
ğ‘“ (ğ‘§) dğ›¾âˆ— (ğ‘¥, ğ‘§) =
âˆ¬
ğ‘“ (ğ‘§) dğ›¾
ğ‘¥
âˆ—
(ğ‘§) dâ„™b(ğ‘¥) =
âˆ¬
ess sup
ğœˆ
ğ‘“ dğ›¾
ğ‘¥
âˆ—
(ğ‘§) dâ„™b(ğ‘¥) = ess sup
ğœˆ
ğ‘“ =ğ‘‰D,
12
where the second equality is because that ğ‘§ âˆˆ ğ´ so that ğ‘“ (ğ‘§) = ess sup
ğœˆ
ğ‘“ . This, together with the weak
duality result, completes the proof for ğœ†
âˆ— = 0.
Remark 5 (Worst-case Distribution). From the proof presented above we observe that when
ğœ†
âˆ— > 0, the worse-case distribution for (Sinkhorn DRO) can be expressed as
dâ„™âˆ— (ğ‘§) =
âˆ«
ğ‘¥

ğ‘’
ğ‘“ (ğ‘§)/(ğœ†
âˆ—
ğœ–) dâ„šğ‘¥,ğœ– (ğ‘§)
ğ”¼â„šğ‘¥,ğœ–
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†
âˆ—ğœ–)

!
dâ„™b(ğ‘¥),
from which we can see that the worst-case distribution shares the same support as the measure ğœˆ.
Particularly, when â„™b is the empirical distribution 1
ğ‘›
Pğ‘›
ğ‘–=1
ğ›¿ğ‘¥Ë†ğ‘–
and ğœˆ is any continuous distribution on â„ğ‘‘
,
the worst-case distribution â„™âˆ— is supported on the entire â„ğ‘‘
. In contrast, the worst-case distribution
for Wasserstein DRO is supported on at most ğ‘› + 1 points [46]. This is another difference, or advantage
possibly, of Sinkhorn DRO compared with Wasserstein DRO. Indeed, for many practical problems,
the underlying distribution can be modeled as a continuous distribution. The worst-case distribution
for Wasserstein DRO is often finitely supported, raising the concern of whether it hedges against the
wrong family of distributions and thus results in suboptimal solutions. The numerical results in Section
5 demonstrate some empirical advantages of Sinkhorn DRO. â™£
4. Efficient First-order Algorithm for Data-driven Sinkhorn Robust Learning
In this section, we consider the data-driven Sinkhorn robust learning problem, where we seek an
optimal decision to minimize the worst-case risk
inf
ğœƒ âˆˆÎ˜
sup
â„™âˆˆğ”¹ğœŒ,ğœ– (â„™b)
ğ”¼ğ‘§âˆ¼â„™[ğ‘“ğœƒ (ğ‘§)],
(7)
where the feasible set Î˜ contains all possible candidates of decision vector ğœƒ, and we take â„™b as the
empirical distribution corresponding to sample points ğ‘¥Ë†ğ‘–
,ğ‘– = 1, . . . , ğ‘›. Based on our strong dual (Dual),
we reformulate (7) as
inf
ğœƒ âˆˆÎ˜,ğœ†â‰¥0
(
ğ¹ (ğœ†,ğœƒ) := ğœ†ğœŒ +
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğœ†ğœ– log 
ğ”¼â„šğ‘¥Ë†ğ‘–
,ğœ– h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i )
, (8)
where the constant ğœŒ and the distribution â„šğ‘¥Ë†ğ‘–
,ğœ– are defined in (1) and (2), respectively.
In Example 1 we have seen an instance of (8) where we can get a closed-form expression for the
above integration. In general, when a closed-form expression is not available, in the following we
present a first-order algorithm to solve this problem, and discuss some alternatives in Section 4.1.
Observe that the objective function of (8) involves a nonlinear transformation of the expectation, thus
an unbiased gradient estimate could be challenging when â„šğ‘¥Ë†ğ‘–
,ğœ– is a general probability distribution.
We propose to solve the following approximation
inf
ğœƒ âˆˆÎ˜,ğœ†â‰¥0
(
ğ¹Ë†(ğ‘š)
(ğœ†,ğœƒ) := ğœ†ğœŒ +
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğœ†ğœ– log 
ğ”¼â„šË†ğ‘š
ğ‘–
h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i )
, (9)
where â„šË†ğ‘š
ğ‘–
=
1
ğ‘š
Pğ‘š
ğ‘—=1
ğ›¿ğ‘§Ë†ğ‘–, ğ‘— denotes the empirical distribution constructed from {ğ‘§Ë†ğ‘–,ğ‘— }
ğ‘š
ğ‘—=1
, independent
and identically distributed samples from â„šğ‘¥Ë†ğ‘–
,ğœ– . In many cases, generating samples from â„šğ‘¥Ë†ğ‘–
,ğœ– is easy.
For instance, choosing the cost function ğ‘(Â·, Â·) =
1
2
k Â· âˆ’ Â· k2
2
and Z = â„ğ‘‘
, then the distribution â„šğ‘¥Ë†ğ‘–
,ğœ–
becomes a Gaussian distribution N (ğ‘¥Ë†ğ‘–
, ğœ–ğ¼ğ‘‘ ). Otherwise we can generate samples by, for example, the
acceptance-rejection method [5]. As a brief summary of our proposed method, we first simulate a batch
of samples to approximate the original Sinkhorn DRO dual objective function, and then use projected
13
Algorithm 1 A batch gradient descent with bisection search for solving (9)
Require: An interval [ğœ†ğ‘™
, ğœ†ğ‘¢] so that 0 < ğœ†ğ‘™ â‰¤ ğœ†
âˆ— â‰¤ ğœ†ğ‘¢, where ğœ†
âˆ—
is an optimal dual variable for (9).
Terminating tolerance Î” > 0.
1: for ğ‘¡ = 0, 1, . . . ,ğ‘‡ âˆ’ 1 do
2: ğœ†0 â† (ğœ†ğ‘™ + ğœ†ğ‘¢)/2.
3: Solve the subproblem (10) at ğœ†0 to get ğœƒ0.
4: Compute ğ‘ âˆˆ
ğœ•
ğœ•ğœ† ğ¹Ë†(ğ‘š)
(ğœ†0,ğœƒ0).
5: Terminate the iteration if ğ‘ = 0 or ğœ†ğ‘¢ âˆ’ğœ†ğ‘™ < Î”.
6: Let ğ‘¡ğ‘¢ â†ğ‘¡0 when ğ‘ > 0. Let ğ‘¡ğ‘™ â†ğ‘¡0 when ğ‘ < 0.
7: end for
Return ğœ†0 and ğœƒ0.
gradient descent with bisection search to solve the approximated problem. Hence our method is named
the batch gradient descent with bisection search.
When the function ğ‘“ğœƒ (ğ‘§) is convex in ğœƒ, problem (9) is a finite convex programming because the
second term of the objective function ğ¹Ë†(ğ‘š)
(ğœ†,ğœƒ) in (9) is a perspective transformation [22, Section 2.3.3]
of the log-sum-exp function in composition of a convex function. We develop a customized batch
gradient descent with bisection search method to solve problem (9) efficiently. The gradient of the
objective function of (9) can be calculated as
âˆ‡ğœƒ ğ¹Ë†(ğ‘š)
(ğœ†,ğœƒ) =
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–

ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)âˆ‡ğœƒ ğ‘“ğœƒ (ğ‘§)

ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–

ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
 ,
ğœ•
ğœ•ğœ† ğ¹Ë†(ğ‘š)
(ğœ†,ğœƒ) = ğœŒ +
ğœ–
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
log 
ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–
h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i

âˆ’
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–

ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
ğ‘“ğœƒ (ğ‘§)

ğœ†ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–

ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
 .
For fixed ğœ† > 0, denote ğ¹Ë†
(ğ‘š)
ğœ†
as the optimal value of the following problem
ğ¹Ë†
(ğ‘š)
ğœ†
= ğœ†ğœŒ + inf
ğœƒ âˆˆÎ˜
(
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğœ†ğœ– log 
ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–
h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i

)
. (10)
By the convexity of ğ¹Ë†(ğ‘š)
(ğœ†,ğœƒ), the function ğ¹Ë†
(ğ‘š)
ğœ†
is convex in ğœ†. This, together with the fact that ğ¹Ë†
(ğ‘š)
ğœ†
is
sub-differentiable with respect to ğœ†, motivates us to use the bisection search method in Algorithm 1 to
solve problem (9). In particular, in each iteration we first find the optimal solution to problem (10) for
a fixed ğœ†, and then use the bisection method to search for the optimal ğœ†. When the gradient âˆ‡ğœƒ ğ‘“ğœƒ (ğ‘§) is
bounded for any ğœƒ and ğ‘§, the sub-problem (10) can be solved using the projected gradient method
with convergence rate ğ‘‚(1/
âˆš
ğ‘€), where ğ‘€ denotes the number of inner iterations [59, Theorem 2.5].
We also argue that the iteration points of Algorithm 1 converge to the optimal solution of infğœ†â‰¥0 ğ¹Ë†
(ğ‘š)
ğœ†
with a linear rate.
Proposition 1. Suppose the function ğ‘“ğœƒ (ğ‘§) is convex in ğœƒ. Then the iteration points {ğœ†
ğ‘¡
}ğ‘¡ of Algorithm 1
converge into ğœ†âˆ— linearly, i.e., |ğœ†
ğ‘¡ âˆ’ğœ†
âˆ—
| =ğ‘‚(2
âˆ’ğ‘¡
), where ğœ†
âˆ—
is the optimal solution of infğœ†â‰¥0 ğ¹Ë†
(ğ‘š)
ğœ†
.
Our last result in this section establishes the consistency for the Monte Carlo approximation (9).
Proposition 2. Let S
âˆ— and ğ‘‰
âˆ— be the set of optimal solutions and the corresponding optimal value of
problem (8), respectively. And let S
(ğ‘š) and ğ‘‰
(ğ‘š) be the set of optimal solutions and the optimal value to
problem (9), respectively. Assume that
(I) The function ğ‘“ğœƒ (ğ‘§) is random lower semi-continuous, and convex in ğœƒ. The set Î˜ is closed, convex,
and contains a non-empty interior.
14
(II) The value function ğ¹ (ğœ†,ğœƒ) defined in (8) is lower semi-continuous, and there exists a point (ğœ†, Â¯ ğœƒÂ¯) âˆˆ Î
such that ğ¹ (ğœ†,ğœƒ) < âˆ for all (ğœ†,ğœƒ) in a neighborhood of (ğœ†, Â¯ ğœƒÂ¯).
(III) The set S
âˆ—
is non-empty and bounded.
Then as ğ‘š â†’ âˆ, ğ‘‰
(ğ‘š) â†’ğ‘‰
âˆ— almost surely and Dist(S
(ğ‘š)
,S
âˆ—
) â†’ 0 almost surely.
This indicates that we can obtain a near-optimal solution of (Sinkhorn DRO) with an arbitrarily
small sub-optimality gap as long as we increase the number of simulation times for Monte Carlo
approximation. The proof leverages results from [86], while the key difference is that the objective
function studied in this paper involves the nonlinear transform of the expectation such that the existing
result in [86] cannot be applied directly. A detailed proof can be found in Appendix EC.5.
4.1. Alternative Algorithmic Choices
In this subsection, we discuss some other possibilities for designing an algorithm to solve (8).
As the objective in (8) involves the composition of two expectations, a natural idea to solve this
problem is to design algorithms leveraging techniques from stochastic compositional optimization
problem [101, 51, 108], but they cannot be applied directly here because they assume that the inner
expected-value is independent of the randomness in the outer expectation, while the inner expectation
of our objective in (8) depends on samples ğ‘¥Ë†ğ‘–
,ğ‘– = 1, . . . , ğ‘›. The recent conditional stochastic compositional
(CSCO) optimization [55, 56], which aims to minimize a composition of two expected-value functions
with the inner expectation taken with respect to a conditional distribution, also opens the door for
designing efficient algorithms for solving (8). Although the objective in (8) cannot be written as
a CSCO problem, it naturally fits the structure when the dual variable ğœ† > 0 is fixed. However, we
find that it takes relatively long time to obtain an optimal variable ğœƒ when ğœ† is fixed, as the lack of
strong-convexity and smoothness structure of the objective makes the state-of-the-art CSCO algorithm
(BSGD in [55]) difficult to converge empirically. Since we need to optimize variables (ğœ†,ğœƒ) jointly, the
global convergence of CSCO for the problem (8) is even more challenging. In extensive simulations
that we omit, we find that our proposed method solves the Sinkhorn DRO problem more efficiently
than the state-of-the-art CSCO algorithm and standard projected gradient descent without bisection
search.
In our algorithm, we optimize ğœƒ for a fixed ğœ†. An alternative would be to optimize (ğœ†,ğœƒ) jointly.
However, as pointed out in [68], for ğœ† of a small value, the variance of the gradient estimate of the
objective function with respect to ğœ† is unstable. Hence, we develop a bisection method to update ğœ† in
outer iterations in Algorithm 1.
Moreover, we observe that in each inner iteration for solving the sub-problem (10), the most
computationally expansive step is to obtain the gradient of ğ¹Ë†
(ğ‘š)
ğœ†
, the complexity of which is of ğ‘‚(ğ‘›ğ‘š).
For large-scale statistical learning problems, it is therefore promising to use the projected stochastic
gradient method instead of projected gradient descent to solve the sub-problem (10), but the condition
that guarantees convergence is more restrictive, which can be a topic for future study. For small-scale
problems, one can also write the problem in standard conic optimization form and use the interior
point method [70, 53] to solve it.
It is worth mentioning that the strategy in [21] can be applied to obtain an unbiased gradient
estimate for the expectation term in (8), but the presence of the logarithm makes it not easy to use
standard stochastic gradient descent with unbiased gradient estimate for optimization. Instead, we
use the Monte Carlo samples problem (9) to approximate (8). It is promising to use other numerical
integration techniques such as Quasi-Monte Carlo method [74] and Wavelet method [6] to approximate
the objective (8) efficiently, which is of research interest for future study.
5. Applications
In this section, we apply our methodology on three applications: the newsvendor model, meanrisk portfolio optimization, and semi-supervised learning. We examine the performance of the
(Sinkhorn DRO) model by comparing it with three benchmarks: (i) the classical sample average
15
approximation (SAA) model; (ii) the Wasserstein DRO model; and (iii) the KL-divergence DRO model.
Unless otherwise specified, the cost function is chosen to be ğ‘(Â·, Â·) =
1
2
k Â· âˆ’ Â· k2
, and the reference
measure ğœˆ for the Sinkhorn distance is chosen to be the Lebesgue measure.
For each of the three applications, with ğ‘› training samples, we select the pair of hyper-parameters
(ğœ–, ğœŒ) using the ğ¾-fold cross-validation method with ğ¾ = 10. Since the grid search for an optimal pair
of hyper-parameters is more costly than the search for a single hyper-parameter, we first tune the
hyper-parameter ğœ– while fixing ğœŒ = 0, which corresponds to the SAA problem in (4). Then for the
chosen ğœ–, we tune the Sinkhorn radius ğœŒ. We run the repeated experiments for 200 times.
In Section 5.1 and Section 5.2, we measure the out-of-sample performance of a solution ğœƒ by its
relative performance gap ğ½ (ğœƒ)âˆ’ğ½
âˆ—
1+


ğ½
âˆ—


, where ğ½
âˆ— denotes the true optimal value when the true distribution
is known exactly, and ğ½ (ğœƒ) the expected loss of the solution ğœƒ under the true distribution, estimated
through an SAA objective value with 105
testing samples. Thus, the smaller the relative performance
gap is, the better out-of-sample performance the solution has.
Further details are included in Appendix EC.1.
5.1. Newsvendor Model
We consider the following distributionally robust newsvendor model:
min
ğœƒ
max
â„™âˆˆğ”¹ğœŒ,ğœ– (â„™b)
ğ”¼â„™

ğ‘˜ğœƒ âˆ’ğ‘¢ min(ğœƒ, ğ‘§)

,
where the random variable ğ‘§ stands for the random demand; its empirical distribution â„™b consists of
ğ‘› = 20 independent samples from an exponential distribution â„™âˆ— with the density ğ‘“ (ğ‘¥;ğ‘ ) =
1
ğ‘ 
exp
âˆ’
ğ‘¥
ğ‘ 

,
where ğ‘  âˆˆ {0.25, 0.5, 0.75, 1, 2, 4}; the decision variable ğœƒ represents the inventory level; and ğ‘˜ = 5,ğ‘¢ = 7
are constants corresponding to overage and underage costs, respectively.
Values of hyper-parameters are recorded in Table 1, from which we can see that the optimal entropic
regularization parameter ğœ– increases when the distribution scale parameter ğ‘  increases. This is because
a distribution â„™âˆ— with larger value of ğ‘  has larger variance, and to achieve better out-of-sample
performance, a larger entropic regularization parameter ğœ– is needed to encourage larger spread of
probability mass.
Table 1 Values of selected hyper-parameters by cross-validation for the newsvendor problem.
Parameter ğ‘  Regularization ğœ– Sinkhorn Radius ğœŒ Wasserstein Radius ğœŒ KL-DRO Radius ğœ‚
0.25 2e-2 1e-2 1e-3 2e-3
0.5 5e-2 6e-3 2e-3 7e-3
0.75 8e-2 1e-3 1e-2 2e-2
1 2e-1 6e-3 3e-1 1e-2
2 4e-1 1e-2 3e-1 4e-2
4 1e-0 6e-2 4e-1 5e-3
We report the violin plots, i.e., box plots with shapes formed by kernel density estimation, for the
relative performance gap across different approaches in Fig. 1. We find that Sinkhorn DRO has the
best out-of-sample mean/median performance in all figures, and has the most stable performance as
indicated by the most concentrated violin plot. Wasserstein DRO, one the other hand, has a comparable
performance as SAA when ğ‘  is small (and small radius ğœŒ, as indicated in Table 1), but is even worse
than SAA for large ğ‘  (and large ğœŒ, as indicated in Table 1). This is because for small ğœŒ, the Wasserstein
robust solution coincides with the SAA solution and thus does not regularizer the problem, similar to
the observation made in [67, Remark 6.7] when the support of â„™âˆ— is â„; whereas for large ğœŒ, it hedges
distributions that are too extreme (which puts positive probability mass on zero demand), leading t
16
SAA Sinkhorn Wasserstein KL-divergence
Method
0.00
0.02
0.04
0.06
0.08
0.10
Relative Performance Gap
n = 20 and s = 0.25
SAA Sinkhorn Wasserstein KL-divergence
Method
0.00
0.05
0.10
0.15
0.20
Relative Performance Gap
n = 20 and s = 0.5
SAA Sinkhorn Wasserstein KL-divergence
Method
0.00
0.05
0.10
0.15
0.20
0.25
Relative Performance Gap
n = 20 and s = 0.75
SAA Sinkhorn Wasserstein KL-divergence
Method
0.05
0.00
0.05
0.10
0.15
0.20
0.25
0.30
Relative Performance Gap
n = 20 and s = 1
SAA Sinkhorn Wasserstein KL-divergence
Method
0.0
0.1
0.2
0.3
0.4
0.5
Relative Performance Gap
n = 20 and s = 2
SAA Sinkhorn Wasserstein KL-divergence
Method
0.0
0.2
0.4
0.6
Relative Performance Gap
n = 20 and s = 4
Figure 1 Out-of-sample performances for the newsvendor model with parameters ğ‘  âˆˆ {0.25, 0.5, 0.75, 1, 2, 4} and the fixed
sample size ğ‘› = 20.
an overly conservative solution. Moreover, the KL-divergence DRO does not have much improvement
compared with the SAA model, likely because the induced worst-case distribution shares the same
support as the empirical distribution.
5.2. Mean-risk Portfolio Optimization
We consider the following distributionally robust mean-risk portfolio optimization problem
min
ğœƒ
max
â„™âˆˆğ”¹ğœŒ,ğœ– (â„™b)
ğ”¼â„™âˆ—
[âˆ’ğœƒ
T
ğ‘§] + ğœš Â· â„™-CVaRğ›¼ (âˆ’ğœƒ
T
ğ‘§)
s.t. ğœƒ âˆˆ Î˜ = {ğœƒ âˆˆ â„
ğ‘‘
+
: ğœƒ
T
1 = 1},
where the random vector ğ‘§ âˆˆ â„ğ‘‘
stands for the returns of assets; the decision variable ğœƒ âˆˆ Î˜ represents
the portfolio strategy that invests a certain percentage ğœƒğ‘– of the available capital in the ğ‘–-th asset; and
the term â„™-CVaRğ›¼ (âˆ’ğœƒ
T
ğ‘§) quantifies conditional value-at-risk [82], i.e., the average of the ğ›¼ Ã— 100%
worst portfolio losses under the distribution â„™. We follow a similar setup as in [67]. Specifically, we set
ğ›¼ = 0.2, ğœš = 10. The random asset ğ‘§ âˆ¼ â„™âˆ— can be decomposed into a systematic risk factor ğœ“ âˆˆ â„ and
idiosyncratic risk factors ğœ– âˆˆ â„ğ‘‘
:
ğ‘§ğ‘– =ğœ“ +ğœ–ğ‘–
, ğ‘– = 1, 2, . . . , ğ·,
where ğœ“ âˆ¼ N (0, 0.02) and ğœ–ğ‘– âˆ¼ N (ğ‘– Ã—0.03,ğ‘– Ã—0.025). We fixed the training sample size ğ‘› = 20 and vary
the number of assets ğ· âˆˆ {10, 20, 50}. We solve this problem using Algorithm 1, in which the projected
gradient descent step to update ğœƒ follows the implementation in [27] to project onto the probability
simplex Î˜.
The violin plots for the relative performance gap across different approaches are reported in Fig. 2.
Similar as the finding in Section 5.1, both the Wasserstein DRO and KL-divergence DRO models do not
outperform the SAA method too much, while Sinkhorn DRO has the best out-of-sample performance
for all plots as indicated by the smallest mean/median as well as the most concentrated violin plots,
and the contrast is more apparent when the dimension ğ· is large.
17
SAA Sinkhorn Wasserstein KL-divergence
Method
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
Relative Performance Gap
n = 20 and D = 10
SAA Sinkhorn Wasserstein KL-divergence
Method
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
Relative Performance Gap
n = 20 and D = 20
SAA Sinkhorn Wasserstein KL-divergence
Method
0.00
0.05
0.10
0.15
0.20
0.25
Relative Performance Gap
n = 20 and D = 50
Figure 2 Out-of-sample performances for the portfolio optimization problem with the dimension ğ· âˆˆ {10, 20, 50} and a
fixed sample size ğ‘› = 20.
5.3. Semi-supervised Learning
Our last example is a semi-supervised learning task following a similar setup as in [15]. Suppose we
have a training data set Dğ‘› = {(ğ‘‹ğ‘–
,ğ‘Œğ‘–)}ğ‘›
ğ‘–=1
, where ğ‘Œğ‘– âˆˆ {âˆ’1, 1} denotes the label of the ğ‘–-th observation.
Additionally, we have a set of unlabeled observations {ğ‘‹ğ‘– }
ğ‘
ğ‘–=ğ‘›+1
. We build the set Eğ‘ âˆ’ğ‘› = {(ğ‘‹ğ‘–
, 1)}ğ‘
ğ‘–=ğ‘›+1
âˆª
{(ğ‘‹ğ‘–
,âˆ’1)}ğ‘
ğ‘–=ğ‘›+1
, which means we replicate each unlabeled data point twice, recognizing that the
missing label can be any of the two available alternatives. Then we formulate an empirical distribution
consisting of samples from the set Xğ‘ = Dğ‘› âˆª Eğ‘ âˆ’ğ‘›, which is denoted as â„™b. Considering the following
distributionally robust formulation:
min
ğœƒ
max
â„™âˆˆğ”¹ğœŒ,ğœ– (â„™b)
ğ”¼â„™

â„“(ğœƒ; (ğ‘‹,ğ‘Œ))
where â„“(ğœƒ; (ğ‘‹,ğ‘Œ)) = log(1 + exp(âˆ’ğ‘Œ Â· ğœƒ
Tğ‘‹)).
We also solve this task using the other three benchmark models. The cost function over this subsection
is set to be
ğ‘( (ğ‘¥,ğ‘¦), (ğ‘¥
0
,ğ‘¦0
)) =
1
2
kğ‘¥ âˆ’ğ‘¥
0
k
2
2
1{ğ‘¦ =ğ‘¦
0
} +ğœ…1{ğ‘¦ â‰ ğ‘¦
0
},
where the parameter ğœ… = âˆ means that there is no labeling error. In this case, in the duality result for
the Sinkhorn DRO, we only need to robustify the feature vectors ğ‘‹.
We consider three performance measures for the obtained classifiers: (i) the training error of samples
with known labels; (ii) the training error of samples with unknown labels; and (iii) the testing error
for new observations. The experiment is conducted using 4 binary classification real data sets from UCI
machine learning data base [40]. In each of the repeated experiments for each data set, we randomly
partition the collected samples into training and testing data sets.
Classification results for these different approaches are reported in Table 2, where the first number
of each entry represents the average classification error, and the second number of entry represents
the half-length of the 95% confidence interval. Detailed parameters for the settings of this task and
the choices of hyper-parameters are reported in Appendix EC.1. We observe that though the Sinkhorn
DRO does not have the best in-sample performance (as indicated by the training error of samples with
known labels), it has the best out-of-sample performance for all data sets (as indicated by the smallest
training error of samples with unknown labels and the smallest testing error).
6. Concluding Remarks
In this paper, we investigated a new distributionally robust optimization framework based on the
Sinkhorn distance. By developing a strong dual reformulation and a customized batch gradient
descent with bisection search algorithm, we have shown that the resulting DRO problem is tractable
18
Table 2 Classification results on real datasets for the semi-supervised learning task. Each experiment is repeated for 200
independent trials, and 95% confidence intervals of classification errors are reported for different approaches.
SAA Sinkhorn Wasserstein KL-divergence
Breast Cancer
Train (Labeled) .058 Â± .061 .051 Â± .065 .051 Â± .063 .057 Â± .060
Train (Unlabeled) .20 Â± .068 .12 Â± .068 .17 Â± .073 .19 Â± .038
Test Error .19 Â± .073 .11 Â± .067 .17 Â± .075 .19 Â± .073
Magic
Train (Labeled) .17 Â± .12 .18 Â± .11 .17 Â± .11 .15 Â± .12
Train (Unlabeled) .28 Â± .082 .25 Â± .091 .27 Â± .077 .26 Â± .078
Test Error .28 Â± .064 .25 Â± .074 .27 Â± .058 .27 Â± .066
QSAR Bio
Train (Labeled) .12 Â± .067 .15 Â± .076 .16 Â± .073 .11 Â± .066
Train (Unlabeled) .25 Â± .057 .22 Â± .063 .23 Â± .073 .25 Â± .037
Test Error .25 Â± .062 .22 Â± .065 .23 Â± .079 .25 Â± .042
Spambase
Train (Labeled) .10 Â± .046 .10 Â± .048 .096 Â± .045 .10 Â± .043
Train (Unlabeled) .19 Â± .038 .14 Â± .046 .16 Â± .036 .18 Â± .034
Test Error .19 Â± .032 .14 Â± .036 .16 Â± .028 .18 Â± .042
under mild assumptions, greatly spans the tractability of Wasserstein DRO. Analysis on the worst-case
distribution indicates that Sinkhorn DRO hedges a more reasonable set of adverse scenarios and
thus less conservative compared with Wasserstein DRO, which is then demonstrated via extensive
numerical experiments. Based on theoretical and numerical findings, we conclude that the Sinkhorn
distance is a promising candidate for modeling distributional ambiguities in decision-making under
uncertainty from the perspective of computational tractability, modeling rationality and out-of-sample
performance.
In the meantime, several topics worth in-depth investigating are left for future works. It is interesting
to design efficient first-order algorithms for Sinkhorn DRO when the nominal distribution is arbitrary
or when the loss function is non-convex in the decision variable. Moreover, a meaningful research
question is the choice of the optimal hyper-parameters in Sinkhorn DRO, such as the radius of the
ambiguity set ğœŒ, the entropic regularization parameters ğœ–, and reference measures ğœˆ. This paper
focuses on regularizing Wasserstein distance with the entropic regularization â€“ the Sinkhorn distance,
but extensions to other types of regularization are possible. Exploring and discovering the benefits of
Sinkhorn DRO in other types of applications may lead to future research directions.
Appendix A: Sufficient condition for Assumption 1
Proposition 3. Assumption 1 holds if there exists ğ‘ â‰¥ 1 so that the following conditions are satisfied:
(I) For any ğ‘¥,ğ‘¦, ğ‘§ âˆˆ Z, ğ‘(ğ‘¥,ğ‘¦) â‰¥ 0, and
(ğ‘(ğ‘¥,ğ‘¦))1/ğ‘ â‰¤ (ğ‘(ğ‘¥, ğ‘§))1/ğ‘ + (ğ‘(ğ‘§,ğ‘¦))1/ğ‘
.
(II) The nominal distribution â„™b has a finite mean, denoted as ğ‘¥. Moreover, ğœˆ{ğ‘§ : 0 â‰¤ ğ‘(ğ‘¥, ğ‘§) < âˆ} = 1
and
Pr
ğ‘¥âˆ¼â„™b{ğ‘(ğ‘¥,ğ‘¥) < âˆ} = 1.
19
(III) There exists ğœ† > 0 such that
âˆ«
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
ğ‘’
âˆ’2
1âˆ’ğ‘
ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) < âˆ.
We make some remarks for the sufficient conditions listed above. The first condition can be satisfied
by taking the cost function as the ğ‘-th power of the metric defined on Z for any ğ‘ â‰¥ 1. The second
condition requires the nominal distribution â„™b is finite almost surely, e.g., it can be a subguassian
distribution with respect to the cost function ğ‘. Combining three conditions together and levering
concentration arguments completes the proof of Proposition 3.
References
[1] Abdullah MA, Ren H, Ammar HB, Milenkovic V, Luo R, Zhang M, Wang J (2019) Wasserstein robust
reinforcement learning. arXiv preprint arXiv:1907.13196 .
[2] Agrawal S, Ding Y, Saberi A, Ye Y (2012) Price of correlations in stochastic optimization. Operations Research
60(1):150â€“162.
[3] Altschuler J, Weed J, Rigollet P (2017) Near-linear time approximation algorithms for optimal transport via
sinkhorn iteration. Advances in Neural Information Processing Systems, 1961â€“1971.
[4] ApS M (2021) Mosek modeling cookbook 3.2.3. https://docs.mosek.com/modeling-cookbook/index.
html#.
[5] Asmussen S, Glynn PW (2007) Stochastic simulation: algorithms and analysis, volume 57 (Springer Science
& Business Media).
[6] Aziz I, Haq F, et al. (2010) A comparative study of numerical integration based on haar wavelets and hybrid
functions. Computers & Mathematics with Applications 59(6):2026â€“2036.
[7] Bacharach M (1965) Estimating nonnegative matrices from marginal data. International Economic Review
6(3):294â€“310.
[8] Bai Y, Wu X, Ozgur A (2020) Information constrained optimal transport: From talagrand, to marton, to
cover. 2020 IEEE International Symposium on Information Theory (ISIT), 2210â€“2215.
[9] Bayraksan G, Love DK (2015) Data-driven stochastic programming using phi-divergences. The Operations
Research Revolution, 1â€“19 (INFORMS).
[10] Ben-Tal A, den Hertog D, De Waegenaere A, Melenberg B, Rennen G (2013) Robust solutions of optimization
problems affected by uncertain probabilities. Management Science 59(2):341â€“357.
[11] Bertsimas D, Natarajan K, Teo CP (2006) Persistence in discrete optimization under data uncertainty.
Mathematical programming 108(2):251â€“274.
[12] Bertsimas D, Sim M, Zhang M (2019) Adaptive distributionally robust optimization. Management Science
65(2):604â€“618.
[13] Blanchet J, Chen L, Zhou XY (2018) Distributionally robust mean-variance portfolio selection with
wasserstein distances. arXiv preprint arXiv:1802.04885 .
[14] Blanchet J, Glynn PW, Yan J, Zhou Z (2019) Multivariate distributionally robust convex regression under
absolute error loss. Advances in Neural Information Processing Systems, volume 32, 11817â€“11826.
[15] Blanchet J, Kang Y (2020) Semi-supervised learning based on distributionally robust optimization. Data
Analysis and Applications 3 1â€“33.
[16] Blanchet J, Kang Y, Murthy K (2019) Robust wasserstein profile inference and applications to machine
learning. Journal of Applied Probability 56(3):830â€“857.
[17] Blanchet J, Murthy K (2019) Quantifying distributional model risk via optimal transport. Mathematics of
Operations Research 44(2):565â€“600.
[18] Blanchet J, Murthy K, Nguyen VA (2021) Statistical analysis of wasserstein distributionally robust estimators.
arXiv preprint arXiv:2108.02120 .
20
[19] Blanchet J, Murthy K, Si N (2021) Confidence regions in wasserstein distributionally robust estimation.
arXiv preprint arXiv:1906.01614 .
[20] Blanchet J, Murthy K, Zhang F (2021) Optimal transport based distributionally robust optimization:
Structural properties and iterative schemes. arXiv preprint arXiv:1810.02403 .
[21] Blanchet JH, Glynn PW (2015) Unbiased monte carlo for optimization and functions of expectations via
multi-level randomization. 2015 Winter Simulation Conference (WSC), 3656â€“3667.
[22] Boyd S, Vandenberghe L (2004) Convex optimization (Cambridge university press).
[23] Chang JT, Pollard D (2001) Conditioning as disintegration. Statistica Neerlandica 51(3):287â€“317.
[24] Chen R, Paschalidis IC (2018) A robust learning approach for regression models based on distributionally
robust optimization. Journal of Machine Learning Research 19(13):1â€“48.
[25] Chen R, Paschalidis IC (2019) Selecting optimal decisions via distributionally robust nearest-neighbor
regression. Advances in Neural Information Processing Systems.
[26] Chen Y, Li W (2021) Natural gradient in wasserstein statistical manifold. arXiv preprint arXiv:1805.08380 .
[27] Chen Y, Ye X (2011) Projection onto a simplex. arXiv preprint arXiv:1101.6081 .
[28] Chen Z, Kuhn D, Wiesemann W (2018) Data-driven chance constrained programs over wasserstein balls.
arXiv preprint arXiv:1809.00210 .
[29] Chen Z, Sim M, Xu H (2019) Distributionally robust optimization with infinitely constrained ambiguity
sets. Operations Research 67(5):1328â€“1344.
[30] Cherukuri A, CortÃ©s J (2019) Cooperative data-driven distributionally robust optimization. IEEE Transactions
on Automatic Control 65(10):4400â€“4407.
[31] Courty N, Flamary R, Habrard A, Rakotomamonjy A (2017) Joint distribution optimal transportation for
domain adaptation. Advances in Neural Information Processing Systems.
[32] Courty N, Flamary R, Tuia D (2014) Domain adaptation with regularized optimal transport. Joint European
Conference on Machine Learning and Knowledge Discovery in Databases, 274â€“289.
[33] Courty N, Flamary R, Tuia D, Rakotomamonjy A (2016) Optimal transport for domain adaptation. IEEE
Transactions on Pattern Analysis and Machine Intelligence 39(9):1853â€“1865.
[34] Cover TM, Thomas JA (2006) Elements of Information Theory (Wiley-Interscience).
[35] Cuturi M (2013) Sinkhorn distances: Lightspeed computation of optimal transport. Advances in neural
information processing systems, volume 26, 2292â€“2300.
[36] Delage E, Ye Y (2010) Distributionally robust optimization under moment uncertainty with application to
data-driven problems. Operations Research 58(3):595â€“612.
[37] Deming WE, Stephan FF (1940) On a least squares adjustment of a sampled frequency table when the
expected marginal totals are known. The Annals of Mathematical Statistics 11(4):427â€“444.
[38] Derman E, Mannor S (2020) Distributional robustness and regularization in reinforcement learning. arXiv
preprint arXiv:2003.02894 .
[39] Doan XV, Natarajan K (2012) On the complexity of nonoverlapping multivariate marginal bounds for
probabilistic combinatorial optimization problems. Operations research 60(1):138â€“149.
[40] Dua D, Graff C (2017) UCI machine learning repository. [Online]. Available: http://archive.ics.uci.
edu/ml .
[41] Duchi JC, Glynn PW, Namkoong H (2021) Statistics of robust optimization: A generalized empirical
likelihood approach. Mathematics of Operations Research 0(0).
[42] Eckstein S, Kupper M, Pohl M (2020) Robust risk aggregation with neural networks. Mathematical Finance
30(4):1229â€“1272.
[43] FrÃ©chet M (1960) Sur les tableaux dont les marges et des bornes sont donnÃ©es. Revue de lâ€™Institut
international de statistique 10â€“32.
[44] Gao R (2020) Finite-sample guarantees for wasserstein distributionally robust optimization: Breaking the
curse of dimensionality. arXiv preprint arXiv:2009.04382 .
21
[45] Gao R, Chen X, Kleywegt AJ (2020) Wasserstein distributionally robust optimization and variation
regularization. arXiv preprint arXiv:1712.06050 .
[46] Gao R, Kleywegt AJ (2016) Distributionally robust stochastic optimization with Wasserstein distance. arXiv
preprint arXiv:1604.02199 .
[47] Gao R, Kleywegt AJ (2017) Data-driven robust optimization with known marginal distributions. Working
paper. Available at https://faculty.mccombs.utexas.edu/rui.gao/copula.pdf .
[48] Gao R, Kleywegt AJ (2017) Distributionally robust stochastic optimization with dependence structure. arXiv
preprint arXiv:1701.04200 .
[49] Genevay A, Cuturi M, PeyrÃ© G, Bach F (2016) Stochastic optimization for large-scale optimal transport.
Advances in Neural Information Processing Systems, volume 29.
[50] Genevay A, Peyre G, Cuturi M (2018) Learning generative models with sinkhorn divergences. Proceedings
of the Twenty-First International Conference on Artificial Intelligence and Statistics, volume 84 of Proceedings
of Machine Learning Research, 1608â€“1617 (PMLR).
[51] Ghadimi S, Ruszczynski A, Wang M (2020) A single timescale stochastic approximation method for nested
stochastic optimization. SIAM Journal on Optimization 30(1):960â€“979.
[52] Goh J, Sim M (2010) Distributionally robust optimization and its tractable approximations. Operations
Research 58(4-part-1):902â€“917.
[53] Grant M, Boyd S (2014) CVX: Matlab software for disciplined convex programming, version 2.1. http:
//cvxr.com/cvx.
[54] HÃ¤rdle W (1990) Applied nonparametric regression (Cambridge university press).
[55] Hu Y, Chen X, He N (2020) Sample complexity of sample average approximation for conditional stochastic
optimization. SIAM Journal on Optimization 30(3):2103â€“2133.
[56] Hu Y, Zhang S, Chen X, He N (2020) Biased stochastic first-order methods for conditional stochastic
optimization and applications in meta learning. Advances in Neural Information Processing Systems,
volume 33, 2759â€“2770.
[57] Hu Z, Hong LJ (2012) Kullback-leibler divergence constrained distributionally robust optimization. Optimization Online preprint Optimization Online:2012/11/3677 .
[58] Huang M, Ma S, Lai L (2021) A riemannian block coordinate descent method for computing the projection
robust wasserstein distance. Proceedings of the 38th International Conference on Machine Learning, 4446â€“
4455.
[59] Jain P, Kar P (2017) Non-convex optimization for machine learning. Foundations and Trends in Machine
Learning 10(3-4):142â€“363.
[60] Kruithof J (1937) Telefoonverkeersrekening. De Ingenieur 52:15â€“25.
[61] Kuhn D, Esfahani PM, Nguyen VA, Shafieezadeh-Abadeh S (2019) Wasserstein distributionally robust
optimization: Theory and applications in machine learning. Operations Research & Management Science in
the Age of Analytics, 130â€“166 (INFORMS).
[62] Li J, Huang S, So AMC (2019) A first-order algorithmic framework for wasserstein distributionally robust
logistic regression. Proceedings of the 33rd International Conference on Neural Information Processing Systems,
3937â€“3947.
[63] Li W, Montufar G (2021) Natural gradient via optimal transport. arXiv preprint arXiv:1803.07033 .
[64] Lin T, Fan C, Ho N, Cuturi M, Jordan M (2020) Projection robust wasserstein distance and riemannian
optimization. Advances in Neural Information Processing Systems, volume 33, 9383â€“9397.
[65] Luise G, Rudi A, Pontil M, Ciliberto C (2018) Differential properties of sinkhorn approximation for learning
with wasserstein distance. Advances in Neural Information Processing Systems.
[66] Luo F, Mehrotra S (2019) Decomposition algorithm for distributionally robust optimization using wasserstein
metric with an application to a class of regression models. European Journal of Operational Research
278(1):20â€“35.
22
[67] Mohajerin Esfahani P, Kuhn D (2017) Data-driven distributionally robust optimization using the wasserstein
metric: performance guarantees and tractable reformulations. Mathematical Programming 171(1):115â€“166.
[68] Namkoong H, Duchi JC (2016) Stochastic gradient methods for distributionally robust optimization with
f-divergences. Advances in Neural Information Processing Systems, volume 29, 2208â€“2216.
[69] Natarajan K, Song M, Teo CP (2009) Persistency model and its applications in choice modeling. Management
Science 55(3):453â€“469.
[70] Nemirovski A (2002) Lectures on modern convex optimization. Society for Industrial and Applied Mathematics
(SIAM.
[71] Nesterov Y, Nemirovskii A (1994) Interior-point polynomial algorithms in convex programming (SIAM).
[72] Nguyen VA, Si N, Blanchet J (2020) Robust bayesian classification using an optimistic score ratio.
International Conference on Machine Learning, 7327â€“7337.
[73] Nguyen VA, Zhang F, Blanchet J, Delage E, Ye Y (2021) Robustifying conditional portfolio decisions via
optimal transport. arXiv preprint arXiv:2103.16451 .
[74] Niederreiter H (1992) Random number generation and quasi-Monte Carlo methods (SIAM).
[75] Patrini G, van den Berg R, Forre P, Carioni M, Bhargav S, Welling M, Genewein T, Nielsen F (2020) Sinkhorn
autoencoders. Uncertainty in Artificial Intelligence, 733â€“743.
[76] Petzka H, Fischer A, Lukovnikov D (2018) On the regularization of wasserstein GANs. International
Conference on Learning Representations.
[77] Peyre G, Cuturi M (2019) Computational optimal transport: With applications to data science. Foundations
and Trends in Machine Learning 11(5-6):355â€“607.
[78] Pflug G, Wozabal D (2007) Ambiguity in portfolio selection. Quantitative Finance 7(4):435â€“442.
[79] Pichler A, Shapiro A (2021) Mathematical foundations of distributionally robust multistage optimization.
arXiv preprint arXiv:2101.02498 .
[80] Popescu I (2005) A semidefinite programming approach to optimal-moment bounds for convex classes of
distributions. Mathematics of Operations Research 30(3):632â€“657.
[81] Rahimian H, Mehrotra S (2019) Distributionally robust optimization: A review. arXiv preprint
arXiv:1908.05659 .
[82] Rockafellar RT, Uryasev S, et al. (1999) Optimization of conditional value-at-risk. Journal of risk 2:21â€“42.
[83] Scarf H (1957) A min-max solution of an inventory problem. Studies in the mathematical theory of inventory
and production .
[84] Shafieezadeh-Abadeh S, Kuhn D, Esfahani PM (2019) Regularization via mass transportation. Journal of
Machine Learning Research 20(103):1â€“68.
[85] Shafieezadeh Abadeh S, Mohajerin Esfahani PM, Kuhn D (2015) Distributionally robust logistic regression.
Advances in Neural Information Processing Systems, volume 28.
[86] Shapiro A, Dentcheva D, RuszczyÅ„ski A (2014) Lectures on stochastic programming: modeling and theory
(SIAM).
[87] Singh D, Zhang S (2020) Tight bounds for a class of data-driven distributionally robust risk measures. arXiv
preprint arXiv:2010.05398 .
[88] Singh D, Zhang S (2021) Distributionally robust profit opportunities. Operations Research Letters 49(1):121â€“
128.
[89] Sinha A, Namkoong H, Duchi J (2018) Certifiable distributional robustness with principled adversarial
training. International Conference on Learning Representations.
[90] Sinkhorn R (1964) A relationship between arbitrary positive matrices and doubly stochastic matrices. The
annals of mathematical statistics 35(2):876â€“879.
[91] Smirnova E, Dohmatob E, Mary J (2019) Distributionally robust reinforcement learning. arXiv preprint
arXiv:1902.08708 .
23
[92] Staib M, Jegelka S (2019) Distributionally robust optimization and generalization in kernel methods.
Advances in Neural Information Processing Systems 32:9134â€“9144.
[93] Taskesen B, Nguyen VA, Kuhn D, Blanchet J (2020) A distributionally robust approach to fair classification.
arXiv preprint arXiv:2007.09530 .
[94] Van Parys BP, Goulart PJ, Kuhn D (2015) Generalized gauss inequalities via semidefinite programming.
Mathematical Programming 156(1-2):271â€“302.
[95] Vandenberghe L, Boyd S (1995) Semidefinite programming. SIAM review 38(1):49â€“95.
[96] Wang C, Gao R, Qiu F, Wang J, Xin L (2018) Risk-based distributionally robust optimal power flow with
dynamic line rating. IEEE Transactions on Power Systems 33(6):6074â€“6086.
[97] Wang J, Gao R, Xie Y (2021) Two-sample test using projected wasserstein distance. 2021 IEEE International
Symposium on Information Theory (ISIT).
[98] Wang J, Gao R, Xie Y (2021) Two-sample test with kernel projected wasserstein distance. arXiv preprint
arXiv:2102.06449 .
[99] Wang J, Gao R, Zha H (2021) Reliable off-policy evaluation for reinforcement learning. arXiv preprint
arXiv:2011.04102 .
[100] Wang J, Jia Z, Yin H, Yang S (2021) Small-sample inferred adaptive recoding for batched network coding.
2021 IEEE International Symposium on Information Theory (ISIT).
[101] Wang M, Fang EX, Liu H (2016) Stochastic compositional gradient descent: algorithms for minimizing
compositions of expected-value functions. Mathematical Programming 161(1-2):419â€“449.
[102] Wang Z, Glynn PW, Ye Y (2015) Likelihood robust optimization for data-driven problems. Computational
Management Science 13(2):241â€“261.
[103] Wiesemann W, Kuhn D, Sim M (2014) Distributionally robust convex optimization. Operations Research
62(6):1358â€“1376.
[104] Wozabal D (2012) A framework for optimization under ambiguity. Annals of Operations Research 193(1):21â€“
47.
[105] Xie W (2019) On distributionally robust chance constrained programs with wasserstein distance. Mathematical Programming 186(1):115â€“155.
[106] Yang I (2017) A convex optimization approach to distributionally robust markov decision processes with
wasserstein distance. IEEE control systems letters 1(1):164â€“169.
[107] Yang I (2020) Wasserstein distributionally robust stochastic control: A data-driven approach. IEEE
Transactions on Automatic Control 66(8):3863â€“3870.
[108] Yang S, Wang M, Fang EX (2019) Multilevel stochastic gradient methods for nested composition optimization.
SIAM Journal on Optimization 29(1):616â€“659.
[109] Yule GU (1912) On the methods of measuring association between two attributes. Journal of the Royal
Statistical Society 75(6):579â€“652.
[110] Zhao C, Guan Y (2018) Data-driven risk-averse stochastic optimization with wasserstein metric. Operations
Research Letters 46(2):262â€“267.
[111] Zhu J, Jitkrittum W, Diehl M, SchÃ¶lkopf B (2021) Kernel distributionally robust optimization: Generalized
duality theorem and stochastic approximation. Proceedings of The 24th International Conference on Artificial
Intelligence and Statistics, 280â€“288.
[112] Zymler S, Kuhn D, Rustem B (2013) Distributionally robust joint chance constraints with second-order
moment information. Mathematical Programming 137(1):167â€“198.
ec1
Supplementary for â€œSinkhorn Distributionally Robust Optimizationâ€
Appendix EC.1: Detailed Experiment Setup
All the experiments are preformed on a MacBook Pro laptop with 32GB of memory running python 3.7.
Candidates of hyper-parameters for DRO models are listed as follows. In each experiment we pick
the regularization term ğœ– spaced from 1e-3 to 9e-1 in exponentially increasing steps. The Sinkhorn
radius ğœŒ is chosen spaced from 1e-5 to 1e-1 in exponentially increasing steps. The Wasserstein
radius ğœŒ and KL-DRO radius ğœ‚ are chosen spaced from 1e-3 to 9e-1 in exponentially increasing steps.
Hyper-parameters for the second and third experiments are reported in Table EC.1 and Table EC.2,
respectively. To obtain the Monte Carlo approximated objective function for the Sinkhorn DRO model,
we take the nominal distribution â„™b as the empirical distribution based on collected samples, and the
inner batch size ğ‘š = 20. We use the projected gradient descent method to solve the subproblem in
(10). For portfolio optimization problems we try the step size ğœ‚â„“ =
1
âˆš
â„“+1
for the â„“-th inner iteration.
Otherwise we try the step size ğœ‚â„“ =
1
â„“+1
during the â„“-th inner iteration. Denote by objâ„“
the objective
function obtained at the â„“-th iteration. The inner iteration is terminated when kobjâ„“+1âˆ’objâ„“
k
1+ kobjâ„“
k
â‰¤ 1e-3.
The SAA, Wasserstein DRO, and KL-divergence DRO models are solved exactly based on the interior
point method-based solver Mosek [4]. In particular, based on [67, Corollary 5.1], the Wasserstein DRO
formulation for the newsvendor problem in Section 5.1 becomes
min
ğœƒ,ğœ†,ğ‘ ,ğ›¾
ğœ†ğœŒ +
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ‘ ğ‘–
s.t. (ğ‘˜ âˆ’ğ‘¢)ğœƒ +ğ›¾ğ‘–,1ğ‘§Ë†ğ‘– â‰¤ ğ‘ ğ‘–
,ğ‘– âˆˆ [ğ‘›],
ğ‘˜ğœƒ âˆ’ğ‘¢ğ‘§Ë†ğ‘– +ğ›¾ğ‘–,1ğ‘§Ë†ğ‘– â‰¤ ğ‘ ğ‘–
,ğ‘– âˆˆ [ğ‘›],
ğ›¾ğ‘–,1 â‰¤ ğœ†,ğ‘– âˆˆ [ğ‘›],
| âˆ’ğ›¾ğ‘–,2 +ğ‘¢| â‰¤ ğœ†,ğ‘– âˆˆ [ğ‘›],
ğ›¾ â‰¥ 0,
where {ğ‘§Ë†1, . . . , ğ‘§Ë†ğ‘›} denotes collected samples from â„™bâˆ—. From [67, Eq. (27)] we can see that the
Wasserstein DRO formulation for the portfolio optimization problem becomes
min
ğœƒ,ğœ,ğœ†,ğ‘ 
ğœ†ğœŒ +
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ‘ ğ‘–
s.t. ğœƒ âˆˆ Î˜,
ğ‘ğ‘—ğœ +ğ‘ğ‘—hğœƒ, ğ‘§Ë†ğ‘–i â‰¤ ğ‘ ğ‘–
,ğ‘– âˆˆ [ğ‘›], ğ‘— âˆˆ [ğ»],
kğ‘ğ‘—ğœƒ k2 â‰¤ ğœ†, ğ‘— âˆˆ [ğ»].
Recall that the KL-divergence DRO problem with radius ğœ‚ â‰¥ 0 has the following tractable formulation:
min
ğœƒ âˆˆÎ˜,ğœ†â‰¥0
n
ğœ†ğœ‚ + ğœ† log 
ğ”¼â„™b
h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/ğœ†
i o .
ec2
Table EC.1 Values of selected hyper-parameters by cross-validation for the portfolio optimization problem.
Dimension ğ· Regularization ğœ– Sinkhorn Radius ğœŒ Wasserstein Radius ğœŒ KL-DRO Radius ğœ‚
10 5e-2 2e-4 6e-3 1e-3
20 7e-1 3e-4 5e-2 2e-3
50 4e-1 2e-4 1e-3 2e-3
Table EC.2 Values of classification parameters and hyper-parameters for DRO models.
Breast Cancer Magic QSAR Bio Spambase
Number of Predictors 30 10 30 56
Train Size (Labeled) 40 30 80 150
Train Size (Unlabeled) 200 300 500 600
Test Size 329 18690 475 3850
Sinkhorn Para. (ğœŒ, ğœ–) (2e-1,2e-5) (5e-1,6e-2) (8e-1,2e-3) (9e-3,2e-5)
Wasserstein Para. ğœŒ 1e-3 3e-3 3e-1 1e-2
KL-DRO Para. ğœ‚ 2e-3 5e-3 3e-2 4e-2
ec3
Appendix EC.2: Proofs of Technical Results in Section 3.2
In order to show the strong duality result in Theorem 1 when â„™b is an empirical distribution, we present
the following technical lemma.
Lemma EC.1. For fixed ğœ and a reference probability distribution â„š âˆˆ P(Z), consider the optimization
problem
ğ‘£(ğœ) = sup
â„™âˆˆP (Z)

ğ”¼â„™

ğ‘“ (ğ‘§) âˆ’ğœ log 
dâ„™
dâ„š
(ğ‘§)
  . (EC.1)
(I) When ğœ = 0,
ğ‘£(0) = ess sup
â„š
(ğ‘“ ) , inf{ğ‘¡ âˆˆ â„ : Pr ğ‘§âˆ¼â„š{ğ‘“ (ğ‘§) > ğ‘¡ } = 0}.
(II) When ğœ > 0 and
ğ”¼â„š
h
ğ‘’
ğ‘“ (ğ‘§)/ğœ
i
< âˆ,
it holds that
ğ‘£(ğœ) = ğœ log 
ğ”¼â„š
h
ğ‘’
ğ‘“ (ğ‘§)/ğœ
i  ,
and limğœ â†“0 ğ‘£(ğœ) = ğ‘£(0). The optimal solution in (EC.1) has the expression
dâ„™(ğ‘§) =
ğ‘’
ğ‘“ (ğ‘§)/ğœ
âˆ«
ğ‘’
ğ‘“ (ğ‘¢)/ğœ dâ„š(ğ‘¢)
dâ„š(ğ‘§).
(III) When ğœ > 0 and
ğ”¼â„š
h
ğ‘’
ğ‘“ (ğ‘§)/ğœ
i
= âˆ,
we have that ğ‘£(ğœ) = âˆ.
Proof of Lemma EC.1 We reformulate ğ‘£(ğœ) based on the importance sampling trick:
ğ‘£(ğœ) = sup
ğ¿: ğ¿â‰¥0
âˆ«

ğ‘“ (ğ‘§)ğ¿(ğ‘§) âˆ’ğœğ¿(ğ‘§) logğ¿(ğ‘§)

dâ„š(ğ‘§) :
âˆ«
ğ¿(ğ‘§) dâ„š(ğ‘§) = 1

.
Then the remaining part follows the discussion in [57, Section 2.1].
Proof of Corollary 1 We now introduce the epi-graphical variables ğ‘ ğ‘–
,ğ‘– = 1, . . . , ğ‘› to reformulate ğ‘‰D as
ğ‘‰D =
ï£±ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´
ï£³
inf
ğœ†â‰¥0,ğ‘ ğ‘–
ğœ†ğœŒ +
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğ‘ ğ‘–
s.t. ğœ†ğœ– log 
ğ”¼â„šğ‘–,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i  â‰¤ ğ‘ ğ‘–
,âˆ€ğ‘–
For fixed ğ‘–, the ğ‘–-th constraint can be reformulated as
n
exp 
ğ‘ ğ‘–
ğœ†ğœ–

â‰¥ ğ”¼â„šğ‘–,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i o
=

1 â‰¥ ğ”¼â„šğ‘–,ğœ– 
ğ‘’

ğ‘“ (ğ‘§)âˆ’ğ‘ ğ‘–

/(ğœ†ğœ–)

=

ğœ†ğœ– â‰¥ ğ”¼â„šğ‘–,ğœ– 
ğœ†ğœ–ğ‘’

ğ‘“ (ğ‘§)âˆ’ğ‘ ğ‘–

/(ğœ†ğœ–)

=
(
ğœ†ğœ– â‰¥
âˆ‘ï¸
ğ¿
â„“=1
â„šğ‘–,ğœ– (ğ‘§â„“)ğ‘ğ‘–,â„“)\
ğ‘ğ‘–,â„“ â‰¥ ğœ†ğœ– exp 
ğ‘“ (ğ‘§â„“) âˆ’ğ‘ ğ‘–
ğœ†ğœ– 
,âˆ€â„“

,
where the second constraint set can be formulated as
(ğœ†ğœ–,ğ‘ğ‘–,â„“, ğ‘“ (ğ‘§â„“) âˆ’ğ‘ ğ‘–) âˆˆ Kexp.
Substituting this expression into ğ‘‰D completes the proof. 
ec4
Appendix EC.3: Proof of the Technical Result in Section 3.1
Proof of Remark 3 We can reformulate the dual objective function as
ğ‘£(ğœ†;ğœ–) = ğœ†ğœŒ + ğœ†ğœ– âˆ«
log âˆ«
exp 
ğ‘“ (ğ‘§) âˆ’ğœ†ğ‘(ğ‘¥, ğ‘§)
ğœ†ğœ– 
dğœˆ (ğ‘§)

dâ„™b(ğ‘¥).
We take limit for the second term in ğ‘£(ğœ†;ğœ–) to obtain:
lim
ğœ–â†’0
ğœ†ğœ– âˆ«
log âˆ«
exp 
ğ‘“ (ğ‘§) âˆ’ğœ†ğ‘(ğ‘¥, ğ‘§)
ğœ†ğœ– 
dğœˆ (ğ‘§)

dâ„™b(ğ‘¥)
=
âˆ«
lim
ğ›½â†’âˆ
ğœ†
ğ›½
log âˆ«
exp
ğ‘“ (ğ‘§) âˆ’ğœ†ğ‘(ğ‘¥, ğ‘§)

ğ›½
ğœ†
!
dğœˆ (ğ‘§)
!
dâ„™b(ğ‘¥)
=
âˆ«
lim
ğ›½â†’âˆ
ğœ†âˆ‡log âˆ«
exp
ğ‘“ (ğ‘§) âˆ’ğœ†ğ‘(ğ‘¥, ğ‘§)

ğ›½
ğœ†
!
dğœˆ (ğ‘§)
!
dâ„™b(ğ‘¥)
=
âˆ«
ï£®
ï£¯
ï£¯
ï£¯
ï£¯
ï£¯
ï£¯
ï£¯
ï£°
lim
ğ›½â†’âˆ
âˆ«
exp 
ğ‘“ (ğ‘§)âˆ’ğœ†ğ‘ (ğ‘¥,ğ‘§)

ğ›½
ğœ†


ğ‘“ (ğ‘§) âˆ’ğœ†ğ‘(ğ‘¥, ğ‘§)

dğœˆ (ğ‘¦)
âˆ«
exp 
ğ‘“ (ğ‘§)âˆ’ğœ†ğ‘ (ğ‘¥,ğ‘§)

ğ›½
ğœ†

dğœˆ (ğ‘¦)
ï£¹
ï£º
ï£º
ï£º
ï£º
ï£º
ï£º
ï£º
ï£»
dâ„™b(ğ‘¥)
=
âˆ«
sup
ğ‘§

ğ‘“ (ğ‘§) âˆ’ğœ†ğ‘(ğ‘¥, ğ‘§)

dâ„™b(ğ‘¥).
Hence, we conclude that the dual objective function of the Sinkhorn DRO problem converges into that
of the Wasserstein DRO problem. 
ec5
Appendix EC.4: Proofs of Technical Results in Section 3.3
Proof of Lemma 1 Recall from Remark 4 that the primal problem ğ‘‰ can be reformulated as
ğ‘‰ = sup
ğ›¾ğ‘¥ âˆˆP (Z),âˆ€ğ‘¥ âˆˆZ
âˆ«
ğ”¼ğ›¾ğ‘¥
[ğ‘“ (ğ‘§)] dâ„™b(ğ‘¥) : ğœ–
âˆ«
ğ”¼ğ›¾ğ‘¥

log 
dğ›¾ğ‘¥ (ğ‘§)
dâ„šğ‘–(ğ‘§)
  dâ„™b(ğ‘¥) â‰¤ ğœŒ

.
Introducing the Lagrange multiplier ğœ† associated to the constraint, we reformulate ğ‘‰ as
ğ‘‰ = sup
ğ›¾ğ‘¥ âˆˆP (Z),âˆ€ğ‘¥ âˆˆZ

inf
ğœ†â‰¥0

ğœ†ğœŒ +
âˆ«
ğ”¼ğ›¾ğ‘¥

ğ‘“ (ğ‘§) âˆ’ğœ†ğœ– log 
dğ›¾ğ‘¥ (ğ‘§)
dâ„šğ‘¥,ğœ– (ğ‘§)
  dâ„™b(ğ‘¥)
 .
Interchanging the order of the supremum and infimum operators, we have that
ğ‘‰ â‰¤ inf
ğœ†â‰¥0
(
ğœ†ğœŒ + sup
ğ›¾ğ‘¥ âˆˆP (Z),âˆ€ğ‘¥ âˆˆZ
âˆ«
ğ”¼ğ›¾ğ‘¥

ğ‘“ (ğ‘§) âˆ’ğœ†ğœ– log 
dğ›¾ğ‘¥ (ğ‘§)
dâ„šğ‘¥,ğœ– (ğ‘§)
  dâ„™b(ğ‘¥)

)
.
Since the optimization over ğ›¾ğ‘¥,âˆ€ğ‘¥ is separable for each ğ‘¥, by defining
ğ‘£ğ‘¥ (ğœ†) = sup
ğ›¾ğ‘¥ âˆˆP (Z)

ğ”¼ğ›¾ğ‘¥

ğ‘“ (ğ‘§) âˆ’ğœ†ğœ– log 
dğ›¾ğ‘¥ (ğ‘§)
dâ„šğ‘¥,ğœ– (ğ‘§)
  , âˆ€ğ‘¥,
and swap the supremum and the integration, we obtain
ğ‘‰ â‰¤ inf
ğœ†â‰¥0

ğœ†ğœŒ +
âˆ«
ğ‘£ğ‘¥ (ğœ†) dâ„™b(ğ‘¥)

. (EC.2)
When there exists ğœ† > 0 such that Condition 1 holds, by leveraging a well-known reformulation on
entropy regularized linear optimization in Lemma EC.1, we can see that almost surely,
ğ‘£ğ‘¥ (ğœ†) = ğœ†ğœ– log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i  < âˆ.
Substituting this expression into (EC.2) implies that ğ‘‰ â‰¤ ğ‘‰D < âˆ. Suppose on the contrary that for any
ğœ† > 0,
Pr ğ‘¥âˆ¼â„™
n
ğ‘¥ : ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i
= âˆ
o
> 0,
then intermediately we obtain ğ‘‰ â‰¤ ğ‘‰D = âˆ, and the weak duality still holds.

Proof of Lemma 2 We first show that ğœ†
âˆ— < âˆ. Denote by ğ‘£(ğœ†) the objective function for the dual
problem, then
ğ‘£(ğœ†) = ğœ†ğœŒ + ğœ†ğœ– âˆ«
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i  dâ„™b(ğ‘¥).
The integrability condition for the dominated convergence theorem is satisfied, which implies
lim
ğœ†â†’âˆ
ğœ†ğœ– âˆ«
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i  dâ„™b(ğ‘¥)
=
âˆ«
lim
ğ›½â†’0
ğœ–
ğ›½
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ›½ ğ‘“ (ğ‘§)/ğœ–
i  dâ„™b(ğ‘¥)
=
âˆ«
lim
ğ›½â†’0
ğœ–âˆ‡ğ›½ log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ›½ ğ‘“ (ğ‘§)/ğœ–
i  dâ„™b(ğ‘¥)
=
âˆ«
lim
ğ›½â†’0
ğœ–
1
ğ”¼â„šğ‘¥,ğœ–
ğ‘’
ğ›½ ğ‘“ (ğ‘§)/ğœ–


ğ”¼â„šğ‘¥,ğœ– 
ğ‘“ (ğ‘§)
ğœ–
ğ‘’
(ğ›½ ğ‘“ (ğ‘§))/ğœ–
  dâ„™b(ğ‘¥)
=
âˆ«
ğ”¼â„šğ‘¥,ğœ–
[ğ‘“ (ğ‘§)] dâ„™b(ğ‘¥),
ec6
where the first equality follows from the change-of-variable technique with ğ›½ = 1/ğœ†, the second equality
follows from the Lâ€™Hospital rule the third and the last equality follows from the dominated convergence
theorem. As a consequence, as long as ğœŒ > 0, we have
lim
ğœ†â†’âˆ
ğ‘£(ğœ†) = âˆ.
We can take ğœ† satisfying Condition 1 and then ğ‘£(ğœ†) < âˆ, which guarantees the existence of the dual
minimizer. Hence ğœ†
âˆ— < âˆ, which implies that either ğœ†
âˆ— = 0 or ğœ†
âˆ—
satisfies Condition 1.
Proof of Lemma 3 Suppose the dual minimizer ğœ†
âˆ— = 0, then taking the limit of the dual objective
function gives
lim
ğœ†â†’0
ğ‘£(ğœ†) =
âˆ«
ğ»
ğ‘¢
(ğ‘¥) dâ„™b(ğ‘¥) < âˆ,
where
ğ»
ğ‘¢
(ğ‘¥) := inf{ğ‘¡ : â„šğ‘¥,ğœ– {ğ‘“ (ğ‘§) > ğ‘¡ } = 0} , ess sup
â„šğ‘¥,ğœ–
ğ‘“ .
For notational simplicity we take ğ»
ğ‘¢ = ess sup
ğœˆ
ğ‘“ . One can check that ğ»
ğ‘¢
(ğ‘¥) â‰¡ ğ»
ğ‘¢
for any ğ‘¥ âˆˆ supp(â„™b):
for any ğ‘¡ so that â„šğ‘¥,ğœ– {ğ‘“ (ğ‘§) > ğ‘¡ } = 0, we have that
âˆ«
1{ğ‘“ (ğ‘§) > ğ‘¡ }ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) = 0,
which, together with the fact that ğœˆ{ğ‘(ğ‘¥, ğ‘§) < âˆ} = 1 for fixed ğ‘¥, implies
âˆ«
1{ğ‘“ (ğ‘§) > ğ‘¡ } dğœˆ (ğ‘§) = 0.
On the contrary, for any ğ‘¡ so that ğœˆ{ğ‘“ (ğ‘§) > ğ‘¡ } = 0, we have that
0 â‰¤
âˆ«
1{ğ‘“ (ğ‘§) > ğ‘¡ }ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) â‰¤ âˆ«
1{ğ‘“ (ğ‘§) > ğ‘¡ } dğœˆ (ğ‘§) = 0,
where the second inequality is because that ğœˆ{ğ‘(ğ‘¥, ğ‘§) â‰¥ 0} = 1. As a consequence, â„šğ‘¥,ğœ– {ğ‘“ (ğ‘§) > ğ‘¡ } = 0.
Hence we can assert that ğ»
ğ‘¢
(ğ‘¥) = ğ»
ğ‘¢
for all ğ‘¥ âˆˆ supp(â„™b), which implies
lim
ğœ†â†’0
ğ‘£(ğœ†) = ğ»
ğ‘¢ < âˆ.
Then we show that almost surely for all ğ‘¥,
ğ”¼â„šğ‘¥,ğœ–
[1ğ´] > 0, where ğ´ = {ğ‘§ : ğ‘“ (ğ‘§) = ğ»
ğ‘¢
}.
Denote by ğ· the collection of samples ğ‘¥ so that ğ”¼â„šğ‘¥,ğœ–
[1ğ´] = 0. Assume the condition above does not
hold, which means that â„™b{ğ·} > 0. For any ğœ > 0 and ğ‘¥ âˆˆ ğ·, there exists ğ»
ğ‘™
(ğ‘¥) < ğ»
ğ‘¢
such that
0 < ğ”¥ğ‘¥ := ğ”¼â„šğ‘¥,ğœ–
[1ğµ(ğ‘¥)] â‰¤ ğœ, where ğµ(ğ‘¥) = {ğ‘§ : ğ»
ğ‘™
(ğ‘¥) â‰¤ ğ‘“ (ğ‘§) â‰¤ ğ»
ğ‘¢
}.
Define ğ»
gap(ğ‘¥) = ğ»
ğ‘¢ âˆ’ğ»
ğ‘™
(ğ‘¥), ğ”¥
ğ‘
ğ‘¥ = 1 âˆ’ ğ”¥ğ‘¥ . Then we find that for ğ‘¥ âˆˆ ğ·,
ğ‘£ğ‘¥ (ğœ†) = ğœ†ğœ– log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
1ğµ(ğ‘¥)
i
+ ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
1ğµ(ğ‘¥)
ğ‘
i 
â‰¤ ğ»
ğ‘¢ + ğœ†ğœ– log 
ğ”¥ğ‘¥ +ğ‘’
âˆ’ğ»
gap (ğ‘¥)/(ğœ†ğœ–)
ğ”¥
ğ‘
ğ‘¥

.
ec7
Since â„™b{ğ·} > 0, the dual objective function for ğœ† > 0 is upper bounded as
ğ‘£(ğœ†) = ğœ†ğœŒ +
âˆ«
ğ‘£ğ‘¥ (ğœ†) dâ„™b(ğ‘¥)
â‰¤ ğ»
ğ‘¢ + ğœ†ğœŒ + ğœ†ğœ– âˆ«
ğ·
log 
ğ”¥ğ‘¥ +ğ‘’
âˆ’ğ»
gap (ğ‘¥)/(ğœ†ğœ–)
ğ”¥
ğ‘
ğ‘¥

dâ„™b(ğ‘¥).
We can see that
lim
ğœ†â†’0
ğœ†ğœŒ + ğœ†ğœ– âˆ«
ğ·
log 
ğ”¥ğ‘¥ +ğ‘’
âˆ’ğ»
gap (ğ‘¥)/(ğœ†ğœ–)
ğ”¥
ğ‘
ğ‘¥

dâ„™b(ğ‘¥) = 0,
and
lim
ğœ†â†’0
âˆ‡

ğœ†ğœŒ + ğœ†ğœ– âˆ«
ğ·
log 
ğ”¥ğ‘¥ +ğ‘’
âˆ’ğ»
gap (ğ‘¥)/(ğœ†ğœ–)
ğ”¥
ğ‘
ğ‘¥

dâ„™b(ğ‘¥)

=ğœŒ +ğœ–
âˆ«
ğ·
log (ğ”¥ğ‘¥ ) dâ„™b(ğ‘¥)
â‰¤ğœŒ +ğœ– log(ğœ)â„™b{ğ·} â‰¤ âˆ’ğœŒ < 0,
where the second inequality is by taking the constant ğœ = exp 
âˆ’
2ğœŒ
ğœ–â„™b{ğ· }

. Hence, there exists ğœ† > 0 such
that
ğ‘£(ğœ†) â‰¤ ğ»
ğ‘¢ + ğœ†ğœŒ + ğœ†ğœ– âˆ«
ğ·
log 
ğ”¥ğ‘¥ +ğ‘’
âˆ’ğ»
gap (ğ‘¥)/(ğœ†ğœ–)
ğ”¥
ğ‘
ğ‘¥

dâ„™b(ğ‘¥) < ğ‘£(0),
which contradicts to the optimality of ğœ†
âˆ— = 0. As a result, almost surely for all ğ‘¥, we have that
ğ”¼â„šğ‘¥,ğœ–
[1ğ´] > 0.
To show the second condition, we re-write the dual objective function for ğœ† > 0 as
ğ‘£(ğœ†) = ğœ†ğœŒ + ğœ†ğœ– âˆ« h
log 
ğ”¼â„šğ‘¥,ğœ–
[1ğ´] + ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
[ğ‘“ (ğ‘§)âˆ’ğ»
ğ‘¢ ]/(ğœ†ğœ–)
1ğ´ğ‘
i  i dâ„™b(ğ‘¥) +ğ»
ğ‘¢
.
The gradient of ğ‘£(ğœ†) becomes
âˆ‡ğ‘£(ğœ†) = ğœŒ +ğœ–
âˆ« h
log 
ğ”¼â„šğ‘¥,ğœ–
[1ğ´] + ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
[ğ‘“ (ğ‘§)âˆ’ğ»
ğ‘¢ ]/(ğœ†ğœ–)
1ğ´ğ‘
i  i dâ„™b(ğ‘¥)
+
âˆ«
ğ”¼â„šğ‘¥,ğœ–
ğ‘’
[ğ‘“ (ğ‘§)âˆ’ğ»
ğ‘¢ ]/(ğœ†ğœ–)1ğ´ğ‘ (ğ»
ğ‘¢ âˆ’ ğ‘“ (ğ‘§))/(ğœ†)

ğ”¼â„šğ‘¥,ğœ–
[1ğ´] + ğ”¼â„šğ‘¥,ğœ–
ğ‘’
[ğ‘“ (ğ‘§)âˆ’ğ»ğ‘¢ ]/(ğœ†ğœ–)1ğ´ğ‘
 dâ„™b(ğ‘¥).
We can see that limğœ†â†’âˆ âˆ‡ğ‘£(ğœ†) = ğœŒ. Take
ğ‘£1,ğ‘¥ (ğœ†) = ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
[ğ‘“ (ğ‘§)âˆ’ğ»
ğ‘¢ ]/(ğœ†ğœ–)
1ğ´ğ‘
i
.
Then limğœ†â†’0 ğ‘£1,ğ‘¥ (ğœ†) = 0 and ğ‘£1,ğ‘¥ (ğœ†) â‰¥ 0. Take
ğ‘£2,ğ‘¥ (ğœ†) =
ğ”¼â„šğ‘¥,ğœ–
ğ‘’
[ğ‘“ (ğ‘§)âˆ’ğ»
ğ‘¢ ]/(ğœ†ğœ–)1ğ´ğ‘ (ğ»
ğ‘¢ âˆ’ ğ‘“ (ğ‘§))/(ğœ†)

ğ”¼â„šğ‘¥,ğœ–
[1ğ´] + ğ”¼â„šğ‘¥,ğœ–
ğ‘’
[ğ‘“ (ğ‘§)âˆ’ğ»ğ‘¢ ]/(ğœ†ğœ–)1ğ´ğ‘
 .
Then limğœ†â†’0 ğ‘£2,ğ‘¥ (ğœ†) = 0 and ğ‘£2,ğ‘¥ (ğœ†) â‰¥ 0. It follows that
lim
ğœ†â†’0
âˆ‡ğ‘£(ğœ†) = ğœŒ +ğœ–
âˆ«
log
ğ”¼â„šğ‘¥,ğœ–
[1ğ´]

dâ„™b(ğ‘¥) = ğœŒ
0

ec8
Hence, if the last condition is violated, based on the mean value theorem, we can find ğœ† > 0 so that
âˆ‡ğ‘£(ğœ†) = 0, which contradicts to the optimality of ğœ†
âˆ— = 0.
Now we show the converse direction. For any ğœ† > 0, we find that
âˆ‡ğ‘£(ğœ†) = ğœŒ +ğœ–
âˆ«

log
ğ”¼â„šğ‘¥,ğœ–
[1ğ´] + ğ‘£1,ğ‘¥ (ğœ†)

dâ„™b(ğ‘¥) + âˆ«
ğ‘£2,ğ‘¥ (ğœ†) dâ„™b(ğ‘¥).
For fixed ğ‘¥, when ğ”¼â„šğ‘¥,ğœ–
[1ğ´] = 1, we can see that ğ‘£1,ğ‘¥ (ğœ†) = ğ‘£2,ğ‘¥ (ğœ†) = 0, then
ğœŒ +ğœ–

log
ğ”¼â„šğ‘¥,ğœ–
[1ğ´] + ğ‘£1,ğ‘¥ (ğœ†)

+ ğ‘£2,ğ‘¥ (ğœ†) = ğœŒ > 0.
When ğ”¼â„šğ‘¥,ğœ–
[1ğ´] âˆˆ (0, 1), we can see that ğ‘£1,ğ‘¥ (ğœ†) > 0, ğ‘£2,ğ‘¥ (ğœ†) > 0. Then
ğœŒ +ğœ–

log
ğ”¼â„šğ‘¥,ğœ–
[1ğ´] + ğ‘£1,ğ‘¥ (ğœ†)

+ ğ‘£2,ğ‘¥ (ğœ†) > ğœŒ +ğœ– log(ğ”¼â„šğ‘¥,ğœ–
[1ğ´]) = ğœŒ
0 â‰¥ 0.
Therefore, âˆ‡ğ‘£(ğœ†) > 0 for any ğœ† > 0. By the convexity of ğ‘£(ğœ†), we conclude that the dual minimizer
ğœ†
âˆ— = 0.

Proof of Lemma 4. Since ğœ†
âˆ— > 0, based on the optimality condition of the dual problem, we have
that
0 = âˆ‡ğœ†

ğœ†ğœŒ + ğœ†ğœ– âˆ«
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i  dâ„™b(ğ‘¥)
 



ğœ†=ğœ†âˆ—
.
Or equivalently, we have that
ğœŒ+ğœ–
âˆ«
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†
âˆ—
ğœ–)
i  dâ„™b(ğ‘¥) âˆ’ âˆ«
ğ”¼â„šğ‘¥,ğœ–
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†
âˆ—
ğœ–)
ğ‘“ (ğ‘§)

ğœ†
âˆ—ğ”¼â„šğ‘¥,ğœ–
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†
âˆ—ğœ–)
 dâ„™b(ğ‘¥) = 0.
Re-arranging the term completes the proof.

Proof of Theorem 1. The feasibility result in Theorem 1(I) can be easily shown by considering the
reformulation of ğ‘‰ in (3) and the non-negativity of KL-divergence. When ğœŒ = 0, one can see that
ğ‘‰D â‰¤ lim
ğœ†â†’âˆ
ğœ†ğœ– âˆ«
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i  dâ„™b(ğ‘¥) = ğ”¼ğ‘§âˆ¼â„™0 [ğ‘“ (ğ‘§)] =ğ‘‰.
Therefore, the strong duality result holds in this case. The proof for ğœŒ > 0 can be found in the main
context. It remains to show the second part of Theorem 1(III). We consider a sequence of real numbers
{ğ‘…ğ‘— }ğ‘— such that ğ‘…ğ‘— â†’ âˆ and take the objective function ğ‘“ğ‘— (ğ‘§) = ğ‘“ (ğ‘§)1{ğ‘§ â‰¤ ğ‘…ğ‘— }. Hence, there exists ğœ† > 0
satisfying Pr
ğ‘¥âˆ¼â„™b

ğ‘¥ : ğ”¼â„šğ‘¥,ğœ–
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)

= âˆ
	
= 0. According to the necessary condition in Lemma 3, the
corresponding dual minimizer ğœ†
âˆ—
ğ‘— > 0 for sufficiently large index ğ‘—. Then we can apply the duality result
in the first part of Theorem 1(III) to show that for sufficiently large ğ‘—, it holds that
sup
â„™âˆˆğ”¹ğœŒ,ğœ– (â„™b)

ğ”¼ğ‘§âˆ¼â„™[ğ‘“ğ‘— (ğ‘§)]	
â‰¥ ğœ†
âˆ—
ğ‘—
ğœŒ + ğœ†
âˆ—
ğ‘—
ğœ–
âˆ«
log 
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ğ‘— (ğ‘§)/(ğœ†ğœ–)
i  dâ„™b(ğ‘¥).
Taking ğ‘— â†’ âˆ both sides implies that ğ‘‰ = âˆ, which completes the proof
ec9
Appendix EC.5: Proofs of Technical Results in Section 4
Proof of Proposition 1 For any fixed ğœ†0 > 0, denote by ğœƒ0 the optimal solution to problem (10). We
can argue that for any ğ‘ âˆˆ
ğœ•
ğœ•ğœ† ğ¹Ë†(ğ‘š)
(ğœ†0,ğœƒ0), ğ‘ is a subgradient of ğ¹Ë†
(ğ‘š)
ğœ†
at ğœ† = ğœ†0. For any ğœ† > 0, let ğœƒ (ğœ†) be
the optimal solution for ğ¹Ë†
(ğ‘š)
ğœ†
. Then we can see
ğ¹Ë†
(ğ‘š)
ğœ†
= ğ¹Ë†(ğ‘š)
(ğœ†,ğœƒ (ğœ†)) â‰¥ ğ¹Ë†(ğ‘š)
(ğœ†0,ğœƒ0) +ğ‘(ğœ† âˆ’ğœ†0) + hâˆ‡ğ¹Ë†(ğ‘š)
(ğœ†0,ğœƒ0),ğœƒ (ğœ†) âˆ’ğœƒ0i
â‰¥ ğ¹Ë†(ğ‘š)
(ğœ†0,ğœƒ0) +ğ‘(ğœ† âˆ’ğœ†0),
where âˆ‡ğ¹Ë†(ğ‘š)
(ğœ†0,ğœƒ0) denotes the subdifferential of ğ¹Ë†(ğ‘š) with respect to ğœƒ = ğœƒ0, the first inequality is
by the convexity of ğ¹Ë†(ğ‘š)
(ğœ†,ğœƒ) with respect to (ğœ†,ğœƒ), and the second inequality is by the optimality
condition for ğœƒ0.
When ğ‘ = 0, we immediately obtain that 0 âˆˆ ğœ•ğ¹Ë†
(ğ‘š)
ğœ†0
, which means that ğœ†0 is the minimizer of ğ¹Ë†
(ğ‘š)
ğœ†
.
Otherwise, the algorithm will update the interval so that ğ‘(ğœ† âˆ’ğœ†0) â‰¤ 0 for any ğœ† within it. We claim
that this interval will contain ğœ†âˆ—. Suppose on the contrary that ğ‘(ğœ†âˆ— âˆ’ğœ†0) > 0. By the convexity of ğ¹Ë†(ğ‘š)
Â·
,
ğ¹Ë†
(ğ‘š)
ğœ†âˆ—
â‰¥ ğ¹Ë†
(ğ‘š)
ğœ†0
+ğ‘(ğœ†âˆ— âˆ’ğœ†0) > ğ¹Ë†
(ğ‘š)
ğœ†0
,
which contradicts to the optimality of ğœ†âˆ—. As a result, the interval length ğ‘™ğ‘¡ = ğœ†ğ‘¢ âˆ’ğœ†ğ‘™ at the ğ‘¡-th iteration
in Algorithm 1 vanishes at the rate ğ‘™ğ‘¡ = (1/2)
ğ‘¡
ğ‘™0, which indicates that the algorithm will converge into
the optimal solution of infğœ†â‰¥0 ğ¹Ë†
(ğ‘š)
ğœ†
linearly.
Proof of Proposition 2. For notational simplicity, we write ğ‘  = (ğœ†,ğœƒ) and Î = â„+ Ã— Î˜. We first show
the second part of this theorem. To begin with, we introduce the following functions:
ğ¹Ëœğ‘š (ğ‘ ) = ğ¹Ë†(ğ‘š)
(ğ‘ ) +ğœÎ(ğ‘ ), ğ¹Â¯(ğ‘ ) = ğ¹ (ğ‘ ) +ğœÎ(ğ‘ ).
We build the pointwise law of large numbers (LLN) for ğ¹Ëœğ‘š. By the strong law of large numbers (LLN),
for each ğ‘– and every (ğœ†,ğœƒ) âˆˆ Î,
ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–
h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i
a.s.
âˆ’âˆ’â†’ ğ”¼â„šğ‘–,ğœ– h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i
.
Then by the continuous mapping theorem, for each ğ‘– and every (ğœ†,ğœƒ) âˆˆ Î,
ğœ†ğœ– log 
ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–
h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i

a.s.
âˆ’âˆ’â†’ ğœ†ğœ– log 
ğ”¼â„šğ‘–,ğœ– h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i  .
Therefore, using the addition and scalar multiplication rule of almost sure convergence, for every
(ğœ†,ğœƒ) âˆˆ Î, it holds that
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğœ†ğœ– log 
ğ”¼â„šË†ğ‘š
ğ‘¥Ë†ğ‘–
h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i

a.s.
âˆ’âˆ’â†’
1
ğ‘›
âˆ‘ï¸ğ‘›
ğ‘–=1
ğœ†ğœ– log 
ğ”¼â„šğ‘–,ğœ– h
ğ‘’
ğ‘“ğœƒ (ğ‘§)/(ğœ†ğœ–)
i  ,
which reveals that ğ¹Ë†(ğ‘š)
(ğ‘ )
a.s.
âˆ’âˆ’â†’ ğ¹ (ğ‘ ) for each ğ‘  âˆˆ Î. This further implies the corresponding LLN for
ğ¹Ëœğ‘š (ğ‘ ).
Now take a compact subset ğ¶ so that S
âˆ—
is contained in the interior of ğ¶. Such a set exists because
S
âˆ—
is bounded. Denote by SËœğ‘š the set of minimizers of ğ¹Ëœğ‘š over ğ¶. By the lower semi-continuity, together
with the pointwise LLN of ğ¹Ëœğ‘š, we find ğ¹Ëœğ‘š is finite-valued on S
âˆ—
for large ğ‘š, which implies that the set
SËœğ‘š is non-empty for large ğ‘š. We show that Dist(SËœğ‘š,S
âˆ—
) â†’ 0 almost surely. Let ğœ” = {ğ‘§ğ‘–,ğ‘— }ğ‘–,ğ‘— be such that
ğ¹Ëœğ‘š (Â·,ğœ”)
ğ‘’
âˆ’â†’ ğ¹Â¯(Â·). This event holds almost surely for all ğœ”. Suppose on the contrary that for any ğ‘š, there
exists a minimizer ğ‘ Ëœğ‘š (ğœ”) of ğ¹Ëœğ‘š over ğ¶ such that Dist(ğ‘ Ëœğ‘š,S
âˆ—
) â‰¥ ğœ€. Due to the compactness of ğ¶, there
ec10
exists a sub-sequence {ğ‘ Ëœğ‘šğ‘—
}ğ‘— that converges into a point ğ‘ 
âˆ— âˆˆ ğ¶, but ğ‘ 
âˆ— âˆ‰ S
âˆ—
. On the other hand, we can
argue that ğ‘ 
âˆ— âˆˆ arg minğ‘  âˆˆğ¶
ğ¹Â¯(ğ‘ ) = S
âˆ— by applying [86, Proposition 7.26]. Then we obtain a contradiction.
Then we show that SËœğ‘š = S
(ğ‘š)
for large ğ‘š. Because of the convexity assumption, any minimizer
of ğ¹Ëœğ‘š over ğ¶ which lies inside of the interior of ğ¶, is also an optimal solution to the problem 9.
Hence, for large ğ‘š we have that SËœğ‘š = S
(ğ‘š)
. This, together with the fact that Dist(SËœğ‘š,S
âˆ—
) â†’ 0 implies
Dist(S
(ğ‘š)
,S
âˆ—
) â†’ 0. Moreover, it suffices to restrict the feasible set into the compact set ğ¶ âˆ© Î. By the
convexity of ğ¹ (ğ‘ ) in ğ‘ , ğ¹Ë†(ğ‘š)
ğ‘.ğ‘ .
âˆ’âˆ’â†’ ğ¹ holds uniformly on ğ¶ âˆ© Î. As a consequence, the first part of this
proposition can be proved by applying [86, Proposition 5.2]. 
ec11
Appendix EC.6: Proof of the Technical Result in Appendix A
We first present an useful technical lemma before showing Proposition 3.
Lemma EC.2. Under the first condition of Proposition 3, for any ğ‘¥ âˆˆ Z, it holds that
âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) â‰¥ ğ‘’
âˆ’2
ğ‘âˆ’1
ğ‘ (ğ‘¥,ğ‘¥)/ğœ–
âˆ«
ğ‘’
âˆ’2
ğ‘âˆ’1
ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§).
Proof of Lemma EC.2 Based on the inequality (ğ‘ +ğ‘)
ğ‘ â‰¤ 2
ğ‘âˆ’1
(ğ‘
ğ‘ +ğ‘
ğ‘
), we can see that
ğ‘(ğ‘¥, ğ‘§) â‰¤ (ğ‘(ğ‘¦, ğ‘§)
1/ğ‘ +ğ‘(ğ‘§,ğ‘¦)
1/ğ‘
)
ğ‘ â‰¤ 2
ğ‘âˆ’1
(ğ‘(ğ‘¦, ğ‘§) +ğ‘(ğ‘§,ğ‘¦)), âˆ€ğ‘¥,ğ‘¦, ğ‘§ âˆˆ Z.
Since ğ‘(ğ‘¥, ğ‘§) â‰¤ 2
ğ‘âˆ’1
(ğ‘(ğ‘¥, ğ‘§) +ğ‘(ğ‘¥,ğ‘¥)), we can see that
âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) â‰¥ exp 
âˆ’2
ğ‘âˆ’1
ğ‘(ğ‘¥,ğ‘¥)/ğœ–
 âˆ«
ğ‘’
âˆ’2
ğ‘âˆ’1
ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§).
The proof is completed.

Proof of Proposition 3 One can see that for any ğ‘¥ âˆˆ supp(â„™b), it holds that
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i
=
âˆ«
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ–
âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘¢)/ğœ– dğœˆ (ğ‘¢)
dğœˆ (ğ‘§)
â‰¤
âˆ«
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ–
âˆ«
ğ‘’
âˆ’2
ğ‘âˆ’1ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§).
dğœˆ (ğ‘§)
â‰¤
âˆ«
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
ğ‘’
âˆ’2
1âˆ’ğ‘
ğ‘ (ğ‘¥,ğ‘§)/ğœ–
ğ‘’
ğ‘ (ğ‘¥,ğ‘¥)/ğœ–
âˆ«
ğ‘’
âˆ’2
ğ‘âˆ’1ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§)
dğœˆ (ğ‘§)
=
ğ‘’
ğ‘ (ğ‘¥,ğ‘¥) (1+2
ğ‘âˆ’1
)/ğœ–
âˆ«
ğ‘’
âˆ’2
ğ‘âˆ’1ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§)
âˆ«
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
ğ‘’
âˆ’2
1âˆ’ğ‘
ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§),
where the first inequality is based on the lower bound in Lemma EC.2, the second inequality is based
on the triangular inequality ğ‘(ğ‘¥, ğ‘§) â‰¥ 2
1âˆ’ğ‘
ğ‘(ğ‘¥, ğ‘§) âˆ’ğ‘(ğ‘¥,ğ‘¥). Note that almost surely for all ğ‘¥ âˆˆ supp(â„™b),
ğ‘(ğ‘¥,ğ‘¥) < âˆ. Moreover,
0 <
âˆ«
ğ‘’
âˆ’2
ğ‘âˆ’1
ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) â‰¤ âˆ«
ğ‘’
âˆ’ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) < âˆ,
where the lower bound is because ğ‘(ğ‘¥, ğ‘§) < âˆ almost surely for all ğ‘§, the upper bound is because
ğ‘(ğ‘¥, ğ‘§) â‰¥ 0 almost surely for all ğ‘§. Based on these observations, we have that
ğ”¼â„šğ‘¥,ğœ– h
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
i
â‰¤
ğ‘’
ğ‘ (ğ‘¥,ğ‘¥) (1+2
ğ‘âˆ’1
)/ğœ–
âˆ«
ğ‘’
âˆ’2
ğ‘âˆ’1ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§)
âˆ«
ğ‘’
ğ‘“ (ğ‘§)/(ğœ†ğœ–)
ğ‘’
âˆ’2
1âˆ’ğ‘
ğ‘ (ğ‘¥,ğ‘§)/ğœ– dğœˆ (ğ‘§) < âˆ
almost surely for all ğ‘¥ âˆ¼ â„™b.

