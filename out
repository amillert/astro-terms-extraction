cluster analysis symbolic regression search space gabriel kronberger lukas kammerer bogdan burlacu stephan winkler michael kommenda michael affenzeller abstract chapter take closer look distribution symbolic regression models generated genetic programming search space motivation work improve search symbolic regression models using information similarity models precomputed independently target function analysis use restricted grammar symbolic regression models generate possible models fixed length limit identify unique models cluster based phenotypic well genotypic similarity find phenotypic similarity leads welldefined clusters genotypic similarity produce clear clustering mapping solution candidates visited gp enumerated search space find gp initially explores whole search space later converges subspace highest quality expressions run simple benchmark problem key words symbolic regression grammar enumeration approximate nearest neighbors dimensionality reduction clustering gabriel kronberger lukas kammerer bogdan burlacu stephan winkler michael kommenda michael affenzeller heuristic evolutionary algorithms laboratory heal university applied sciences upper austria softwarepark hagenberg austria institute formal models verification johannes kepler university altenberger straÃŸe linz austria josef ressel center symbolic regression university applied sciences upper austria softwarepark hagenberg austria final publication available https sep kronberger et al introduction knowledge discovery systems genetic programming gp symbolic regression often deal large search space mathematical expressions grows exponentially larger number input variables genetic programming guides search via selection discovers new model structures via action crossover mutation population diversity plays important role process affects algorithm ability assemble existing building blocks solutions relationship diversity genotypic phenotypic level previously explored leading number important insights strong exploitation structures occurs almost runs diversity structural level quickly lost encouraging different amounts diversity lead better performance interplay genetic operators induces neighborhood structure search space fitness phenotypic diversity negatively correlated genotypic diversity light set goal investigate gp ability explore different areas search space superimposing neighborhood structure obtained via clustering symbolic regression models generated via grammar enumeration contribution concentrate distribution models symbolic regression search spaces motivation work hope able reduce computational effort required find symbolic regression models precomputing clustering symbolic regression models search space particular aim precompute similarity network equivalently hierarchical clustering symbolic regression models independent concrete dataset research questions work distribution models symbolic regression search space interested identifying clusters similar models whereby similarity could either determined based model outputs phenotypic similarity evolved expressions genotypic distribution solutions visited genetic programming interested systematic search biases gp particular whether areas search space completely ignored gp ii individuals gp population distributed search space distribution changes beginning end gp run assumptions goals symbolic regression modeling following use assumptions guide research symbolic regression solution methods aim symbolic regression modeling primarily find compact expressions open interpretation cluster analysis symbolic regression search space shallow expressions preferred deeply nested expressions models regression problems often made multiple terms capture independent effects independent terms modeled one another interesting regression problems often necessitate capture correlations model effect often driven one independent variable interactions two three variables common interactions four variables often relevant set potentially relevant variables much larger set actually relevant variables usually known individual variables interactions variables relevant measurements input variables well target variables noisy methodology journey find answers research questions stated enumerate complete search space see section evaluate expressions fixed input data limit size search space consider functions limit maximum length expressions additionally use grammar constrains complexity expressions allow numeric parameters random constants reduces search space analysis distribution expressions symbolic regression search space idea create visual map expressions hopefully allows us identify larger clusters similar expressions thus use set evaluated expressions identify set phenotypically distinct expressions determine phenotypically nearest neighbors expression see section allows us map expressions space preserving local neighborhood structure space graph nearest neighbors also allows us create clustering expressions interested map phenotypically similar expressions well map genotypically similar expressions create similar map based measure genotypic similarity see section ideally expect see similar cluster structure levels assuming expressions genotypically similar also phenotypically similar analysis search bias gp idea map clusters generated first phase analyze whether gp explores actually found assumption wrong found search space split clusters phenotypically genotypically similar expressions however could show phenotypically similar expressions also phenotypically similar vice versa intuitive two highly similar expressions become dissimilar phenotypic level multiplication zero symmetrically many different expressions found produce output kronberger et al complete map clusters idea find phenotypically similar expression map solution candidate visited gp determine visitation frequency clusters generation gp expect gp visits many different clusters beginning converges clusters expressions end run figure shows overview flow information search space visualization clustering figure shows map gp solution candidates mapping search space clusters major challenge methodological approach sheer size search space handled challenge using algorithms dimensionality reduction clustering still work datasets millions observations hundreds features see section core idea algorithms approximation nearest neighbors using random projection trees grammar lst generate expressions lst filter unique expressions hashing evaluate remaining expressions filter r calculate genotypic similarity sec fig hdbscan fig approximate nearest neighbors sec hdbscan fig largevis fig phenotypic genotypic fig overview flow information search space visualization clustering cluster analysis symbolic regression search space gp evaluated expressions exact nearest neighbors map embedding clustering cluster visitation frequency gp solutions embedding fig overview flow information tracking parts search space explored gp gp solution candidates mapped visualization clusters finding similar representative grammar enumeration create symbolic regression models deriving sentences formal grammar expressions shown listing figure defining maximum sentence length omitting numerical constants start large finite set possible models search space generated problem sentences without actual constants values seen general structure actual model start stack empty phrase symbol fetch nonterminal symbol phrase production rule symbol create new phrase substituted symbol new phrase sentence evaluate new phrase save new phrase else new phrase fig generating sentences language defined via grammar kronberger et al given formal grammar many mathematical identities phenotypically equal genotypically different expressions generated includes example different orders arguments commutative operators different representations binomial identities keep search space size manageable want avoid semantic duplicates although computationally feasible fully prevent semantic duplicates large search space number largely reduced two simple steps first grammar restricted one representation relevant mathematical identities derived second identities prevented grammar identified hashing semantic duplicates hash value expressions derived restricted grammar figure sums terms contain variables unary functions sine function inverse function latter occur per term also structures function arguments individually restricted g expr expr term expr term term factor term factor invexpr factor varfac expfac logfac sinfac varfac variable expfac exp simpleterm logfac log simpleexpr sinfac sin simpleexpr simpleexpr simpleterm simpleexpr simpleterm simpleterm varfac simpleterm varfac invexpr invterm invexpr invterm invterm factor invterm factor fig formal grammar used grammar enumeration design grammar want allow large set potentially interesting expressions one hand hand want restrict search space disallow overly complex expressions well many different forms semantically equal expressions using grammar semantic duplicates differently ordered terms prevented therefore additionally use semantic hash function identify semantically equivalent expressions derived symbolic expression calculate hash value symbolically without evaluating expression semantic duplicates recognized comparing hash values previously derived sentences case collision derived sentence likely semantic duplicate therefore discarded hashing function calculates hash value recursively syntax tree terminal symbol tree assigned constant hash value cover commutativity binary operators like multiplication addition flattened operators arguments ordered cluster analysis symbolic regression search space phenotypic similarity phenotypic similarity use pearson correlation coefficient model outputs allows us determine output similarity regardless offset scale function values evaluate expressions necessary assume range valid input values use points distributed grid range output vectors scaled zero mean unit variance undefined output values infinity values replaced average output preprocessing allows us use clustering visualization supported many implementations approximate nearest neighbors equivalent pearson correlation coefficient vectors genotypic similarity define genotypic similarity two solution candidates using index genotypicsimilarity mapping calculated using algorithm described describe main steps algorithm build forest f consisting disjoint union two trees map f directed acyclic graph two nodes f mapped vertex g height tree children mapped sequence vertices traversal ensures nodes mapped parents leading build time use map k f g obtained previous step build final mapping step iterates nodes level order uses k determine nodes correspond vertices iteration guarantees every largest unmapped subtree mapped isomorphic subtree algorithm runtime complexity linear size trees regardless whether trees ordered unordered clustering visualization one challenges visualizing search space using phenotypic genotypic similarity measures find mapping expressions space preserves pairwise similarities well possible kronberger et al use algorithm distance matrices calculated basis previously described phenotypic genotypic similarity measures main idea behind map space x lowdimensional space distribution pairwise similarities preserved much possible similarity data points xi xj x defined probability xi would pick xj neighbor similar probability distribution found minimizing divergence two distributions using gradient descent preserve distances visualization potentially provide new insight structure search space symbolic regression following describe visualization clustering procedure detail clustering visualization based genotypic similarity base set unique expressions obtained via grammar enumeration unfeasibly big calculation full similarity matrix therefore reduce set feasible quantity filtering expressions based r value relation function figure shows distribution r values full set unique expressions genotypic mapping took expressions r number expressions fig distribution r values function cluster analysis symbolic regression search space used hdbscan algorithm clustering tried two approaches clustering based directly similarity matrix ii clustering mapped space approaches produced similar results clustering visualization based phenotypic similarity mapping based phenotypic similarity decided use complete set unique expressions applied largevis implementation produce visualization largevis relies approximate nearest neighbor algorithms make visualization datasets feasible analysis used r library largevis implements variant exact determination nearest neighbors replaced approximate nearest neighbors list linear runtime complexity number data points consequence asymptotic runtime clustering embedding becomes linear number data points algorithm works three steps first lists approximate nearest neighbors data points determined using random projection trees second step sparse weighted edge matrix calculated encodes nearest neighbor graph finally approximate nearest neighbor lists edge matrix used largevis provides variant hdbscan algorithm uses approximate nearest neighbor list mapping gp solution candidates based results phenotypic clustering study gp explores search space add step gp algorithm individuals population evaluated step identify expression cluster expressions enumerated search space evaluated solution candidate able calculate visitation density enumerated search space expect early stages evolution gp explores many different areas search space whereby time gp converge area search space contains expressions similar target function results following sections first present results clustering visualization based phenotypic similarity compare results clustering https kronberger et al visualization based genotypic similarity present results analysis cluster qualities five functions finally present results gp visitation frequency analysis phenotypic mapping figure shows result visualization clustering based phenotypic similarity used largevis directly output vectors using dot represents expression color indicates cluster expression assigned visualization clearly shows several clusters similar expressions identified search space step prepared plots clusters show outputs expressions within clusters found search space includes many rather complex functions several clusters interesting similar functions identified selected plots well position cluster center mapped search space shown figure noted visualization show unique expressions identified hdbscan outliers fig visualization embedding clustering result based phenotypic similarity phenotypic mapping leads several clearly defined clusters figure shows phenotypic map difference figure expressions shown used coloring scheme based similarity expression outputs function squared correlation r cluster analysis symbolic regression search space ization clearly shows certain areas search space contain expressions similar target function notably several areas contain expressions large r values least two potential explanations first could artifact approximation another reason could fact used cosine similarity embedding r value coloring scheme cosine similarity measure two vectors negatively correlated dissimilar kronberger et al cluster analysis symbolic regression search space fig results hdbscan genotypic similarity top coloring based clusters bottom coloring based r value function visualization mapping shows clusters genotypically similar solutions however genotypic clusters correlate strongly qualities mapping gp solution candidates use search space analyze search bias gp use rather canonical gp implementation map evaluated solution candidate search space identifying closest representative expression enumerated search space expression search space assigned cluster therefore determine clusters search space visited gp used function demonstrate concept figure shows results analysis left number different clusters visited gp shown generations right hand side median cluster rank ordered cluster quality shown clearly shows kronberger et al cluster rank avg cluster rank avg cluster rank avg cluster rank avg cluster rank avg fig ranking clusters average r values expressions within clusters benchmark functions clusters contain expressions fig five benchmark functions best four clusters highest average r functions left right average r values cluster analysis symbolic regression search space beginning gp visits many different solution candidates later concentrates view high quality clusters generations number explored clusters generations median cluster rank fig number clusters visited gp well median rank quality clusters gp generations figure show distribution solution candidates visited gp detail first generations clearly visible within first ten generations gp explores almost clusters population tree creator quickly finds clusters highest quality discussion analysis far limitations merit detailed discussion looked models grammar restricted even limit seven variable references computational effort already rather high increasing length limits computational effort quickly becomes big phenotypic clustering depends range input values used evaluating model completely ignored effect numeric constants models used numeric constants work considered search space approximately semantically different expressions however figure see search space contain expressions considered target functions analysis size search space extended even problems also found grammar used produced many discontinuous functions division zero extreme arguments exp x assume kronberger et al rank count rank count rank count rank count rank count rank count count count count count count count fig detailed visualization search space explored gp run plots first second rows show visitation frequency cluster generations clusters lower ranks high quality clusters plots third fourth row show visitation frequency phenotypic map within first generations gp converges focused area search space interested functions search space could potentially reduced massively removing expressions leading discontinuous functions extend analysis include models size search space would increase significantly even use size restrictions simply consequence fact different models expressed based preliminary experiments even two three independent variables possible enumerate search space size restrictions used three variables would necessary use even smaller size limits also need consider variety function outputs becomes much larger increased dimensionality could lead larger set clusters cluster analysis symbolic regression search space hypothesize practical problems usually sufficient able represent interactions variables separable terms modeled independently however expect general regarding complexity grammar purposefully limited number alternatives able enumerate full search space would however rather easy add functions power root function long complexity argument added functions limited similarly limited arguments log x different approach could potentially worthwhile calculate phenotypic similarity function conclusion contribution aims analyze search behavior gp space hypotheses visualized mapping search space idea approach enumerate complete search space phase independently regression problem solved order define restrictions like consideration functions restricting grammar assumptions still huge search space restricted filtering unique expressions hashing establishes mapping defined search space hierarchical clustering generated setup used monitor search behavior different algorithms monitored analyzed demonstrated chapter relatively canonical gp implementation genotypic well phenotypic search space ideas presented chapter considered first findings novel approach mind restrictions search space delimit generality claimed findings order achieve deeper universal understanding necessary extend approach models less restrictions grammar model also interesting analyze search behavior different flavors gp hypothesis search techniques furthermore massive set generated models could used order filter initial population gp run soon regression problem tackled available similar done ann community recently neural networks could establish somehow initial populations evolutionary search way could example filter genotypically diverse subset model promising correlation problems concrete problem order establish somehow initial population gp run aimed converge lot faster stage acknowledgements authors thank participants genetic programming theory practice gptp xvi workshop valuable feedback ideas helped improve work described chapter kronberger et al authors gratefully acknowledge support christian doppler research association federal ministry digital economic affairs within josef ressel center symbolic regression references burke gustafson kendall diversity genetic programming analysis measures correlation fitness ieee transactions evolutionary computation doi campello moulavi sander clustering based hierarchical density estimates pei tseng cao motoda xu eds advances knowledge discovery data mining pp springer berlin heidelberg berlin heidelberg dasgupta freund random projection trees low dimensional manifolds proceedings annual acm symposium theory computing stoc pp acm keijzer improving symbolic regression interval arithmetic linear scaling european conference genetic programming pp springer kommenda kronberger winkler affenzeller wagner effects constant optimization nonlinear least squares minimization symbolic regression proceedings annual conference companion genetic evolutionary computation pp acm luke two fast algorithms genetic programming ieee transactions evolutionary computation maaten hinton visualizing data using journal machine learning research nov mcinnes healy accelerated hierarchical density based clustering ieee international conference data mining workshops icdmw pp doi mcinnes healy astels hdbscan hierarchical density based clustering journal open source software doi pagie hogeweg evolutionary consequences coevolving targets evolutionary computation tang liu zhang mei visualizing data proceedings international conference world wide web www pp international world wide web conferences steering committee republic canton geneva switzerland doi uy hoai neill mckay opez crossover genetic programming application symbolic regression genetic programming evolvable machines valiente efficient distance trees proc int symposium string processing information retrieval pp ieee computer science press worm chiu prioritized grammar enumeration symbolic regression dynamic programming proceedings annual conference genetic evolutionary computation pp acm
gaussian processes speed mcmc automatic effect alessio benavoli jason wyse arthur white school computer science statistics trinity college dublin ireland introduction paper consider problem sampling posterior ğœ‹ ğœ½ ğ‘ ğ‘ ğœ½ ğ· denotes data ğœ½ Î¸ vector unknown parameters case likelihood ğ‘ costly evaluate discuss algorithms first examine adaptive mh algorithm hastings robert employs adaptively tuned gaussian process gp surrogate model first stage filter poor proposals proposal filtered second stage full expensive evaluation carried used decide whether accepted next state introduction first stage constructed way saves computation poor proposals key contribution work form acceptance probability first stage obtained marginalising gp function makes acceptance ratio dependent variance gp naturally results similar one bayesian optimisation brochu et al allows us sample learning gp demonstrate using expectation serves useful filtering scheme second algorithm form metropolis adjusted langevin algorithm mala neal use gp surrogate function case gp also used approximate gradient required mala updating using well known result gradient gp also gp solak et al marginalizing gp also performed instance approximation use ln ğ‘ llfğ‘¡ gp ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ iğ‘¡ denotes set ğ‘¡ full evaluations current iteration ğœ½ collectively denotes parameter values evaluations made adaptive tuning gp surrogate accomplished use collection iğ‘¡ full evaluations loglikelihood argue tuning schedule suggest satisfies diminishing adaptation roberts rosenthal hence ensure correct sampling true target ğœ‹ ğœ½ within markov chain monte carlo mcmc literature much interest recent years use proxy quantities target measure evaluations different aspects approaches using noisy approximations invariant transition kernel alquier et al andrieu roberts gained much interest work assumes though maybe expensive computed thus aligned work bliznyuk et al christen fox fielding et al joseph li et al rasmussen sherlock et al involving ideas delayed acceptance mcmc key difference carry gp prior running algorithm investigating adaptation gp fly using key results adaptive mcmc literature roberts rosenthal ensure convergence true target authors address alessio benavoli jason wyse arthur white school computer science statistics trinity college dublin ireland wyseja arwhite sep alessio benavoli jason wyse arthur white present two stage mh algorithm section section follows introducing mala algorithm building ideas section explores range examples demonstrates merits filtering step discussion potential drawbacks two stage adaptive via gp approximation combine mh algorithm gp model approximates cases expensive compute gp model used step determine proposals full computation might well lead acceptance christen fox iteration algorithm first stage uses gp deliver approximate evaluation gp based collection iğ‘¡ previous full evaluations propsal made current state usual mh acceptance probability computed using approximated step computationally inexpensive proposal accepted first stage goes second stage another acceptance probability computed time based full costly evaluation resulting evaluation appended iğ‘¡ resulting giving full description algorithm introduce notation give explicit definition iğ‘¡ sğ‘˜ denotes points sampled iteration ğ‘˜ algorithm ğœ½ ğ‘˜ denotes recent element sğ‘˜ ğœ½ denotes proposed state iğ‘¡ ğœ½ ğ‘– ğ‘– ğ‘– ğ‘¡ denotes ğ‘¡ ğ‘˜ exact likelihood evaluations performed iteration ğ‘˜ use noise free gp surrogate model denote bygpğ‘˜ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ posterior gp iteration ğ‘˜ conditioned collection iğ‘¡ use llfğ‘˜ ğœ½ denote choose parameters gp satisfy following exact interpolation property assumption prior mean function prior covariance function gp selected guarantee exact interpolation ğœ‡ ğœ½ ğ‘– ğ‘– ğ‘˜ ğœ½ ğ‘– ğœ½ ğœ½ ğ‘– corresponding entry iğ‘¡ ğœ½ Î¸ means predictions gp points ğœ½ ğ‘– iğ‘¡ exact certain zero co variance desirable property noise free regression two stages mh algorithm follows stage use predictive posterior gp conditioned collection iğ‘¡ approximate define first stage acceptance probability ğœ½ ğ‘˜ ğœ½ exp llfğ‘¡ ğœ½ ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ exp llfğ‘¡ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ llfğ‘¡ gpğ‘˜ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ use shorthand notation ğ‘ ğ‘ min ğ‘ ğ‘ note exact interpolation property assumption results llfğ‘¡ ğœ½ ğ‘˜ llğ‘¡ ğœ½ ğ‘˜ universal covariance function satisfies property instance squared exponential also guarantees consistency two stages denominator gaussian processes speed mcmc automatic effect acceptance probability ğœ½ ğ‘˜ ğœ½ respectively ğœ½ ğœ½ ğ‘˜ depends llfğ‘¡ ğœ½ llfğ‘¡ ğœ½ ğ‘˜ respectively ğœ½ llfğ‘¡ ğœ½ ğ‘˜ gp distributed key part approach involves marginalizing dependence exploiting following result proposition distribution ğ‘’ llfğ‘¡ ğœ½ lognormal ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ mean ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ proofs propositions given appendix b assumption ğ‘˜ ğœ½ ğ‘˜ ğœ½ ğ‘˜ ğ‘˜ ğœ½ ğœ½ ğ‘˜ therefore llfğ‘¡ ğœ½ llfğ‘¡ ğœ½ ğ‘˜ sampled independently exploiting proposition remove dependence acceptance probability resulting acceptance probability f ğ›¼ ğœ½ ğ‘˜ ğœ½ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğ‘˜ exact assumption seen ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ depends gp variance therefore acceptance probability larger regions gp uncertainty large similar acquisition functions bayesian optimisation naturally results however goal different aim sample target distribution therefore given stage accept ğœ½ probability ğ›¼ ğœ½ ğ‘˜ ğœ½ otherwise ğœ½ ğœ½ ğ‘˜ defines following transition kernel stage ğ‘„ ğ‘˜ ğ‘˜ ğ´ ğ›¼ ğœ½ ğ‘˜ ğœ½ ğ‘ ğœ½ ğ‘˜ ğ‘‘ğœ½ ğ¼ğ´ ğœ½ Î¸ ğ›¼ ğœ½ ğ‘˜ ğœ½ ğ‘‘ğœ½ one show transition kernel satisfies detailed balance property approximated target distribution ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘ ğœ½ proposition transition kernel satisfies detailed balance interested approximated target distribution reason perform second stage stage stage perform another mh acceptance step evaluating exact let ğœ½ denote point sampled ğ‘ ğ‘˜ ğœ½ ğ‘˜ ğ‘„ ğ‘˜ ğ‘‘ğœ½ ğ‘˜ note ğœ½ either equal point ğœ½ sampled stage ğœ½ ğ‘˜ ğœ½ rejected stage probability ğ›¼ ğœ½ ğ‘˜ ğœ½ exp ğ‘ ğœ½ ğ‘ ğ‘˜ ğœ½ ğ‘˜ exp ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğ‘˜ ğœ½ ğ‘˜ exp ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ ğ›¼ ğœ½ ğœ½ ğ‘˜ exp ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ›¼ ğœ½ ğ‘˜ ğœ½ accept ğœ½ otherwise ğœ½ ğœ½ ğ‘˜ definition ğ‘ ğ‘˜ means rejection stage always leads rejection stage need compute led rejection sample ğœ½ accepted stage compute full update set iğ‘¡ evaluate overall acceptance probability new point ğœ½ ğ›¼ ğœ½ ğ‘˜ ğœ½ ğ›¼ ğœ½ ğ‘˜ ğœ½ overall algorithm preserves detailed balance respect posterior distribution follows directly standard mh acceptance step proposal ğ‘ğ‘˜ ğœ½ ğ‘˜ ğ›¼ ğœ½ ğœ½ ğ‘˜ alessio benavoli jason wyse arthur white x log gp mean x log gp mean b x log gp mean c x log gp mean x log gp mean e x log gp mean f fig convergence gp mean unnormalised density increasing iterations f convergence analysis prove convergence target distribution enough show overall transition kernel ğ‘ƒğ‘¡ satisfies diminishing adaptation condition roberts rosenthal lim sup ğœ½ probability bounded convergence condition generally satisfied regularity conditions Î¸ target distribution adaptivity algorithm due gp diminishing adaptation follows property posterior predictive variance proposition fixed hypeprameters surrogated model satisfies property ğ‘˜ ğœ½ ğœ½ ğ‘˜ ğœ½ ğœ½ illustration figure consider case ğœ‹ ğœƒ ğ‘’ ğ‘¥ noticed converges increase evaluations iğ‘¡ proposition holds assumption fixed hyperparameters covariance function gp therefore algorithm update hyperparameters burnin next section extend results langevin method langevin mala takes one step step size ğ›¿ direction gradient current point ğœ½ ğœ½ ğ‘˜ ğ›¿Î» ğœ½ ğ‘˜ log ğ‘ ğœ½ ğ‘˜ ğ›¿Î»z z ğ‘ ğ¼ Î» preconditioning covariance matrix Î» denotes matrix square root case assume evaluate gradient iğ‘¡ ğœ½ ğ‘– ğ‘– ğ‘‡ ğ‘– ğ‘– ğ‘¡ use joint gp solak et al surrogate model gradient idea case simply apply previous algorithm using proposal gradient replaced gaussian processes speed mcmc automatic effect ğœ½ ğ‘˜ ğœ½ exp llfğ‘¡ ğœ½ ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ ğœ½ log ğ‘ ğœ½ exp llfğ‘¡ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğœ½ ğ‘˜ log ğ‘ ğœ½ ğ‘˜ ğ‘ normal proposal covariance ğ›¿Î» note llfğ‘¡ ğœ½ ğ‘˜ ğœ½ ğ‘˜ exact evaluations assumption marginalise ğ¿ğ¿ f computing expectation gp use following result proposition expectation ğ‘’ ğ‘“ ğœ½ ğ‘ ğœ½ ğ›¿ ğœ½ ğ›¿ log ğ‘ ğœ½ gp ğ‘“ denote gp distributed gradient ğ‘ ğœ½ prior equal ğ‘’ ğ‘‰ ğ‘‡ ğœ‡ ğ‘‰ ğ‘‡ ğ¾ğ‘‰ ğ›¿ ğœ‡ ğ‘‡ ğ‘ ğœ½ ğ›¿ log ğ‘ ğœ½ ğ‘‰ ğœ½ ğœ½ ğ›¿ log ğ‘ ğœ½ ğ›¿ ğ‘‡ Î» ğ›¿ ğœ‡ gp predictive means ğ‘“ ğ¾ relative covariance matrix stage uses exact evaluation gradient omit details overall algorithm similar one presented previously mh difference gp gradient numerical experiments model gradient mala use gp square exponential covariance function zero mean used value ğœ½ ğ‘˜ gradient mala subtracted equivalent defining gp prior mean equal ğœ½ ğ‘˜ way far data acceptance probability depends variance gp guarantees high probability acceptance stage samples regions gp initialised using observations starting sampler consider five target distributions posterior parameters ğ‘ ğ‘ banana shape distribution true value set ğ‘ ğ‘ posterior parameters ğ‘ ğ‘ ğœ nonlinear regression model ğ‘¦ ğ‘ ğ‘¥ ğœ– ğœ– ğ‘ true value set ğ‘ ğ‘ ğœ posterior parameters se kernel posterior parameters ğ›½ ğ›¾ susceptible infected recovery sir model posterior parameters parametric logistic regression problem appendix gives details priors assumed parameters selected proposal five posteriors specific feature resulting diverse set challenging targets instance heavy tailed heavily anisotropic sir problem prototypical example type applications targeted proposed method compute likelihood need solve numerically system odes complex biological chemical models computationally heavy evaluating likelihood five problems fast allows us quickly perform monte carlo simulations assess performance model generating artificial data alessio benavoli jason wyse arthur white ar ess esjd eval sd mh mala mh mala mh mala ar ess esjd eval sd mh mala mh table comparison proposed samplers standard mh mala terms acceptance rate ar effective sample size ess expected square jumping distance esjd percentage likelihood evaluations iterations eval square distance sd true value parameters estimated posterior mean run mala sir model evaluate efficiency algorithms simply counting number likelihood evaluations compare algorithm standard implementations mh mala target problem simulation generate samples including burnin deliberately selected small number samples show approach converges quickly important computationally expensive applications check convergence correct posterior distribution using metrics described caption table table reports value metrics averaged simulations parameters comparing simulations results noticed proposed samplers obtain convergence metrics standard mh mala fraction number likelihood evaluations also noticed fraction number full likelihood evaluations required problem dependent ranging demonstrates approach automatically adapts complexity specific target distribution conclusions presented algorithm sampling probabilistic models whose computationally expensive evaluate using surrogate gp model key feature approach difference previous works ability learn target distribution scratch sampling without need gp fundamental automatic inference probabilistic programming languages particular presented alternative first stage acceptance scheme marginalising gp distributed function makes acceptance ratio explicitly dependent variance gp approach extended langevin algorithm mala numerical experiments demonstrated effectiveness method automatically adapt complexity target distribution numerical experiments used full gp whose computational load grows cubically size training set increases sparse gps employed address issue bauer et al hensman et al rasmussen schuerch et al snelson ghahramani titsias necessary sample thousands samples future work plan extend approach used mala hamiltonian monte carlo also intend investigate whether tailored covariance functions log densities ratios densities provide convergence advantage also investigate surrogate models alternative gps gaussian processes speed mcmc automatic effect acknowledgments references alquier friel everitt boland noisy monte carlo convergence markov chains approximate transition kernels statistics computing https christophe andrieu gareth roberts approach efficient monte carlo computations annals statistics https matthias bauer mark van der wilk carl edward rasmussen understanding probabilistic sparse gaussian process approximations advances neural information processing systems nikolay bliznyuk david ruppert christine shoemaker local approximation computationally expensive posterior densities journal computational graphical statistics brochu cora de freitas tutorial bayesian optimization expensive cost functions application active user modeling hierarchical reinforcement learning arxiv preprint andrÃ©s christen colin fox markov chain monte carlo using approximation journal computational graphical statistics http demetri pananos examples https mark fielding david j nott liong efficient mcmc schemes computationally expensive posterior distributions technometrics leigh j halliwell lognormal random multivariate casualty actuarial society spring vol hastings monte carlo sampling methods using markov chains applications biometrika https arxiv https james hensman nicolÃ² fusi neil lawrence gaussian processes big data proceedings conference uncertainty artificial intelligence uai auai press arlington virginia usa daniel josÃ© miguel scalable gaussian process classification via expectation propagation artificial intelligence statistics v roshan joseph bayesian computation using design interpolation technique technometrics lingge li andrew holbrook babak shahbaba pierre baldi neural network gradient hamiltonian monte carlo computational statistics radford neal mcmc using hamiltonian dynamics crc press chapter https joaquin carl edward rasmussen unifying view sparse approximate gaussian process regression journal machine learning research dec carl edward rasmussen gaussian processes speed hybrid monte carlo expensive bayesian integrals seventh valencia international meeting dedicated dennis lindley oxford university press christian robert algorithm american cancer society https arxiv https gareth roberts jeffrey rosenthal coupling ergodicity adaptive markov chain monte carlo algorithms journal applied probability https manuel schuerch dario azzimonti alessio benavoli marco zaffalon recursive estimation sparse gaussian process regression automatica chris sherlock andrew golightly daniel henderson adaptive mcmc targets expensive likelihoods journal computational graphical statistics https arxiv https edward snelson zoubin ghahramani sparse gaussian processes using advances neural information processing systems solak leithead leith rasmussen derivative observations gaussian process models dynamic systems proceedings international conference neural information processing systems nips mit press cambridge usa michalis titsias variational learning inducing variables sparse gaussian processes proceedings twelth international conference artificial intelligence statistics proceedings machine learning research david van dyk max welling eds vol pmlr hilton clearwater beach resort clearwater beach florida usa alessio benavoli jason wyse arthur white priors zero prior used simulation generate different starting point interval prior ğ‘ ğ‘ ğ‘ ğ‘ log ğœ ğ‘ ğ‘¥ simulation generate different ğ‘¦ according likelihood reported main text prior log â„“ğ‘– log ğœ ğ‘ gp classification dataset includes points ğ‘ simulation true two lengthscales uniformly sampled true variance fixed ğœ use probabilistic model described demetri pananos prior ğ›½ğ‘– ğ‘ gp classification dataset includes points ğ‘ simulation true ğ›½ğ‘– sampled ğ‘ cases used normal proposals mh diagonal covariance matrix b proofs proof proposition follows mean distribution proof proposition prove detailed balance ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğ‘˜ ğœ½ ğ‘˜ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ›¼ ğœ½ ğ‘˜ ğœ½ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğ‘˜ ğœ½ ğ‘˜ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğ‘˜ ğœ½ ğ‘˜ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğ‘˜ ğœ½ ğ‘˜ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğ‘˜ ğœ½ ğ‘˜ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘ ğœ½ ğ‘˜ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ ğ‘’ ğœ‡ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘ ğœ½ ğ‘ ğœ½ ğ‘˜ ends proof term brackets last equation ğ›¼ ğœ½ ğœ½ ğ‘˜ assumption ğ‘˜ ğœ½ ğ‘˜ ğœ½ independent reason assume work numerator denominator independently proof proposition let ğœ½ denote new point ğ‘… points definition kernel matrix ğ¾ğ‘¡ ğœ½ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘˜ ğ‘… ğ‘… ğ‘˜ ğœ½ ğ‘… ğ‘˜ ğœ½ ğ‘… ğ‘˜ ğœ½ ğœ½ predicted variance step ğ‘¡ point ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘˜ğ‘¡ ğœ½ ğ‘¡ ğ‘˜ğ‘¡ ğœ½ predicted variance step ğ‘¡ point ğœ½ ğ‘˜ ğœ½ ğœ½ ğœ½ ğœ½ therefore need prove ğ‘˜ğ‘¡ ğœ½ ğ‘¡ ğ‘˜ğ‘¡ ğœ½ ğœ½ ğœ½ gaussian processes speed mcmc automatic effect inverse ğ¾ğ‘¡ ğ¾ ğ‘¡ ğ¾ ğ¾ ğœ½ ğœ½ ğœ½ ğ‘€ ğœ½ ğ‘€ ğ‘€ ğ‘˜ ğœ½ ğœ½ ğœ½ ğœ½ note ğ‘˜ğ‘¡ ğœ½ ğ‘¡ ğ‘˜ğ‘¡ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ¾ ğ¾ ğœ½ ğœ½ ğœ½ ğ‘€ ğœ½ ğ‘€ ğœ½ ğ‘˜ ğœ½ equal ğ‘˜ğ‘¡ ğœ½ ğ‘¡ ğ‘˜ğ‘¡ ğœ½ ğ‘˜ ğœ½ ğ¾ ğœ½ ğ‘˜ ğœ½ ğ¾ ğœ½ ğœ½ ğœ½ ğ‘˜ ğœ½ ğœ½ ğœ½ ğœ½ ğœ½ ğœ½ ğ‘˜ ğœ½ ğœ½ ğ‘˜ ğœ½ ğ‘˜ ğœ½ ğœ½ therefore ğ‘˜ğ‘¡ ğœ½ ğ‘¡ ğ‘˜ğ‘¡ ğœ½ ğ‘˜ ğœ½ ğ¾ ğœ½ ğ‘ ğ‘ ğ‘€ ğ‘˜ ğœ½ ğ¾ ğœ½ ğ‘˜ ğœ½ ğ‘€ ğ‘˜ ğœ½ ğ¾ ğœ½ ğ‘˜ ğœ½ ğœ½ strictly greater zero whenever ğœ½ ğœ½ note fact assumption ğ‘ either ğœ½ ğœ½ exact interpolation property proposal distribution absolutely continuous lebesgue measure Î¸ ğœ½ ğœ½ holds probability proof proposition work omit dependence ğ‘“ ğœ½ notation simplification rewrite product two pdf ğ‘“ ğœ½ ğœ½ ğ›¿ log ğ‘ ğœ½ Î» ğœ½ ğœ½ ğ›¿ log ğ‘ ğœ½ Î» ğ›¿ ğ›¿ Î» ğ‘“ ğœ‡ ğ‘‡ ğ‘“ ğœ‡ ğ‘‡ ğ´ ğµ ğµ ğ‘‡ ğ¶ ğ‘“ ğœ‡ Î» covariance matrix proposal last term sum gp predictive posterior mean ğœ‡ covariance ğ¾ expressed ğ¾ block matrix blacks ğ´ ğµ ğ¶ ğ· rewrite sum ğ‘“ ğœ½ ğœ½ ğ›¿ log ğ‘ ğœ½ Î» ğœ½ ğœ½ ğ›¿ log ğ‘ ğœ½ Î» ğ›¿ ğ›¿ ğœ‡ ğ‘‡ ğ›¿ ğœ‡ ğ‘‡ ğ‘“ ğœ‡ ğ‘‡ ğ‘“ ğœ‡ ğ‘‡ ğ´ ğµ ğµ ğ‘‡ ğ›¿ Î» ğ¶ ğ‘“ ğœ‡ define vector ğ‘‰ prove result using moments multivariate lognormal distribution halliwell
evolving evolutionary algorithms using multi expression programming mihai oltean crina department computer science faculty mathematics computer science university kogalniceanu romania https mihaioltean github io abstract finding optimal parameter setting optimal population size optimal mutation probability optimal evolutionary model etc evolutionary algorithm ea difficult task instead evolving parameters algorithm evolve entire ea capable solving particular problem purpose multi expression programming mep technique used mep chromosome encode multiple eas nongenerational ea function optimization evolved paper numerical experiments show effectiveness approach introduction evolutionary algorithms eas nonconventional tools solving difficult problems developed pressure generated inability classical mathematical methods solve problems many unsolved problems could turned optimization problems solving optimization problem means finding solutions maximize minimize criteria function many eas proposed dealing optimization problems many solution representations search operators proposed tested within wide range evolutionary models several natural questions answered evolutionary models optimal population size optimal individual representation optimal probabilities applying specific genetic operators optimal number generations halting evolution etc breakthrough arose wolpert mcready unveiled work free lunch nfl theorems nfl theorems state algorithms perform equally well entire set optimization problems algorithm take account information problem particular instance solved magnitudes nfl results stroke efforts developing universal optimization algorithm able solve best optimization problems address aug evolutionary algorithms using multi expression programming attempt solve problems men delegated computers develop algorithms able perform certain tasks prominent effort direction genetic programming gp evolutionary technique used breeding population computer programs instead evolving solutions particular problem instance gp mainly intended discovering computer programs able solve particular classes problems statement partially true since discovery computer programs may also viewed technique solving particular problem instance following could example problem find computer program calculates sum elements array many approaches far gp literature evolving deterministic computer programs able solve specific problems requires lot effort instead evolving deterministic computer programs try evolve fullfeatured evolutionary algorithm output main program ea able perform given task thus work eas two levels first macro level consists ea uses fixed population size fixed mutation probability fixed crossover probability etc second micro level consists solution encoded chromosome ga first level aim view use evolutionary model similar multi expression programming mep suitable evolving computer programs may easily translated imperative language like c pascal evolved ea nongenerational one cycle evolution paper organized follows mep technique described section model used evolving eas presented section way fitness mep individual computed described section several numerical experiments performed section mep technique multi expression programming technique briefly described section mep algorithm paper use underlying mechanism mep mep algorithm starts randomly chosen population individuals following steps repeated termination condition reached two parents selected individuals using binary tournament procedure recombined fixed crossover probability recombination two parents two offspring obtained offspring mutated best replaces worst individual current population offspring better worst individual current population mep representation mep genes represented substrings variable length number genes chromosome constant represents chromosome length gene encodes terminal element terminal set function symbol element function set f gene encoding function includes pointers towards function arguments function source code available https https evolving evolutionary algorithms using multi expression parameters always indices lower values position function chromosome according proposed representation scheme first symbol chromosome must terminal symbol way syntactically correct programs obtained example use representation numbers left positions stand gene labels memory addresses labels belong chromosome provided explanatory purposes example chromosome given assuming b c f b c mep phenotypic transcription section devoted describing way mep individuals translated computer programs mep chromosomes read fashion starting first position terminal symbol specifies simple expression function symbol specifies complex expression formed linking operands specified argument positions current function symbol instance genes previous example encode simple expressions formed single terminal symbol expressions b c gene indicates operation operands located positions chromosome therefore gene encodes expression gene indicates operation operands located positions therefore gene encodes expression c gene indicates operation operands located positions therefore gene encodes expression b c choose one expressions represent chromosome neither theoretical practical evidence one better others thus choose encode multiple solutions single chromosome mep chromosome encodes number expressions equal chromosome length number genes expression associated chromosome position obtained reading chromosome current position following links provided functions pointers fitness expression encoded mep chromosome computed conventional manner fitness depends problem solved best expression encoded mep chromosome chosen represent chromosome fitness mep individual equals fitness best expression encoded chromosome evolutionary algorithms using multi expression programming evolutionary model order use mep evolving eas define set terminal symbols set function symbols define sets keep mind value stored terminal symbol independent symbols chromosome function symbol changes solution stored another gene ea usually types genetic operators initialize randomly initializes solution select selects best solution among several already existing solutions crossover recombines two already existing solutions mutate varies already existing solution operators act symbols may appear mep chromosome operator generates solution independent already existing solutions initialize operator operator constitute terminal set operators considered function symbols thus initialize f select crossover mutate mep chromosome c storing evolutionary algorithm initialize randomly generates solution initialize randomly generates another solution mutate mutates solution stored position select selects best solution stored positions crossover recombines solutions positions mutate mutates solution stored position mutate mutates solution stored position crossover recombines solutions positions mep chromosome encodes multiple evolutionary algorithms ea obtained reading chromosome bottom starting current gene following links provided function pointers thus deal eas two different levels micro level representing evolutionary algorithm encoded mep chromosome macro level ga evolves mep individuals number genetic operators initializations crossovers mutations selections fixed may vary mep chromosome length values automatically discovered evolution macro level ga execution bound known rules gas see instance chromosome defined encodes eas given table remarks model crossover operator always generates single offspring two parents crossover operators generating two offspring may also designed fit evolutionary model ii select operator acts binary tournament selection best two individuals always accepted selection result iii initialize crossover mutate operators problem dependent evolving evolutionary algorithms using multi expression table evolutionary algorithms encoded mep chromosome c initialize fitness assignment compute quality ea encoded chromosome order establish fitness mep individual purpose ea encoded mep chromosome run particular problem solved roughly speaking fitness mep individual equal fitness best solution generated one evolutionary algorithms encoded mep chromosome since eas encoded mep chromosome use pseudorandom numbers likely successive runs ea generate completely different solutions stability problem handled following manner ea encoded mep chromosome executed run times fitness mep chromosome average fitness best ea encoded chromosome runs experiments performed paper ea encoded mep chromosome run times numerical experiments section evolve ea function optimization training purposes use griewangk function griewangk test function defined equation f x xn x yn cos xi domain definition use n paper optimal solution f griewangk test function many widespread local minima regularly distributed important issue concerns representation solutions evolved eas encoded mep chromosome specific genetic operators used purpose solutions evolved eas encoded mep chromosomes represented using real values chromosome second level ea array real values initialization random point within definition domain generated convex crossover Î± gaussian mutation Ïƒ used evolutionary algorithms using multi expression programming experiment experiment interested seeing way quality best evolved ea improves search process advances mep algorithm parameters population size code length genes number generations crossover kind uniform crossover probability mutations chromosome terminal set initialize function set select crossover mutate results experiment depicted figure fitness best individual best run average runs fitness best individual runs clearly shows effectiveness approach mep technique able evolve ea solving optimization problems quality best evolved ea generation means fitness best solution obtained best evolved ea averaged runs good result knowing worst solution definition domain generations quality best evolved ea experiment also interested seeing structure best evolved ea changed search process evolution number genetic operators used best evolved ea depicted fig fig seen number genetic operators used best ea increases search process advances instance averaged number initializations best ea generation averaged number initializations best evolved ea generations averaged number mutations small less compared number occurrences genetic operators conclusions work minutely described method evolving evolutionary algorithms proposed paper numerical experiments emphasize robustness effectiveness approach numerical experiments analyze relationship mep parameters population size chromosome length mutation evolving evolutionary algorithms using multi expression figure fitness best individual best run average runs fitness best individual runs probability ability evolved ea find optimal solutions expected increased population size bring substantial increase evolved ea performances generalization ability evolved ea well perform new test problems also studied larger set functions used order increase generalization ability important issue related amount memory required evolved ea optimization regarding memory used evolved ea done paper instance evolved ea performs initializations selections crossover mutations memory required algorithm times memory required storing individual obvious amount memory reduced memory locations overridden newly created individuals simple algorithm checks whether memory location accessed future used purpose references brameier banzhaf comparison linear genetic programming neural networks medical data mining ieee transactions evolutionary computation vol goldberg genetic algorithms search optimization machine learning reading koza genetic programming programming computers means natural selection mit press cambridge oltean dumitrescu multi expression programming technical report university romania available holland adaptation natural artificial systems university michigan press ann arbor syswerda uniform crossover genetic algorithms schaffer ed proc int conf genetic algorithms morgan kaufmann publishers san mateo ca yao liu lin evolutionary programming made faster ieee transaction evolutionary computation vol wolpert mcready free lunch theorems search technical report santa fe institute
learning superoptimize programs alex pengcheng jeremy claire le edward graham mellon university language technologies institute mellon university institute software research mellon university software engineering institute abstract program optimization process modifying software execute efficiently finding optimal program generally undecidable modern compilers usually resort heuristic optimizations contrast superoptimizers attempt find optimal program employing significantly expensive search constraint solving techniques generally methods scale well programs real development scenarios result superoptimization largely confined synthetic program benchmarks paper propose framework learn superoptimize programs using neural models introduce big assembly benchmark dataset consisting functions mined projects assembly enables experimentation optimization realworld programs propose approach self imitation learning optimization silo easy implement outperforms standard policy gradient learning approach big assembly benchmark method silo superoptimizes programs expected test set compared gcc version compiler aggressive optimization level also report silo rate superoptimization test set five times standard policy gradient approach model compiler optimization demonstration introduction program optimization classical problem computer science existed years mckeeman allen cocke years entire tracks compiler conferences dedicated pouchet jimborean standard tool generating efficient programs optimizing compiler converts humanwritten programs executable machine code also performs number code transformations increase speed reduce energy consumption improve memory footprint aho et al optimizing compilers use optimizations optimizing transformations generally need written experts individual compiler applied intermediate representation code produced course transforming code executable machine code effort automatically create optimized programs surpass heuristics research community pioneered automated optimization methods superoptimizers based bruteforce search massalin heuristic search schkufza sharma aiken satisfiability modulo theories smt solvers sasnauskas et al superoptimizers may outperform optimizations difficult employ practice recent work machine learning community demonstrated ability deep learning models reason even generate code assist developers variety tasks allamanis et al chen et al despite research machine program optimization remains underexplored existing work focused highly constrained problem expression simplification simple language dsl tested synthetic examples shi et al important stepping stone demonstrating feasibility machine program optimization also avoids many interesting complex optimization opportunities emerge combination control flow memory reasoning sheer scale seen real world software work demonstrate ability deep neural networks optimize programs github introduce big assembly dataset consisting functions assembly mined online projects github enables experimentation optimization programs also propose easy implement algorithm self imitation learning optimization silo progressively improves superoptimization ability training results indicate superoptimizes expected test set beyond gcc five times rate model outputs optimizing compiler well model policy gradient methods instead focusing customized search method unique language implementation semantics methodology relies dataset demonstrations well test case generator sandbox executing programs method verifying program equivalence find examples model applying compiler optimizaiton techniques register allocation redundant instruction sep elimination instruction combination superoptimize programs problem formulation superoptimization task given specification program reference program fref meets specification generate optimized program fo runs efficiently equivalent reference program fref paper focus program optimization assembly level fref fo programs written assembly code program optimizations applied purpose demonstrate desired program semantics fref assembly program produced optimizing compiler gcc aggressive optimization level assume programs deterministic result model program function maps inputs outputs use represent hardware state prior executing program input represent hardware state executing program output specifically goal learn model fÎ¸ fo optimized program fË† attains lower cost ideally minimal cost cost function c evaluated suite k test cases io k example energy consumption runtime program must meet specification determined verification function v details c v located section learned model objective produce rewrites meet condition c fË† iok k c fref iok k v fË† order train model optimizations present modern compilers supervised manner improve learning experience dataset necessary training set therefore consists n tuples test suite iok k compiled unoptimized program specification compiled aggressively optimized program fref ioi k k f ref n section explain methodology learning superoptimize programs however first introduce benchmark dataset optimizing programs section big assembly benchmark standard benchmark evaluating superoptimization research researchers evaluated programs simplified domain specific language chen tian shi et al others tested small programs joshi nelson randall gulwani et al table list program optimization benchmarks machine learning programming languages systems works three criteria evaluating listed number individual examples benchmark sz programs written humans programs found wild open source projects benchmark contain either branching control flow ctl dataset sz ctl shi et al gulwani et al churchill et al churchill et al datasets sufficient demonstrating methodological capabilities necessarily reflect properties real code thus predict performance relative modern optimizing compilers programs lastly smallscale benchmarks insufficient modern deep learning work introduce big assembly benchmark contains c functions compiled using gcc without aggressive optimizations started collecting million functions open source projects github written able mine testcases dataset functions performed two stages sanity checks analysis compute conservative approximation live registers first involved using smt solvers find equivalence gcc function used specification gcc function used fref filtered trivial programs equivaent return reduced dataset functions performed similar pass instead using test case suite io k reducing total dataset functions train dev test testcases automatically generated random testcases part dataset testcases used test equivalent behavior estimate performance code used stoke additional modifications purpose table compares basic properties dataset existing work beyond size dataset salient representative functions real world code also contains examples complex operations simd instructions branching loops additional details dataset collected available supplementary materials section learning program optimizations section elaborate approach learns optimize programs first describe underlying neural model introducing learning algorithm https neural program optimizer program optimization model fÎ¸ neural network input specification unoptimized program output optimized program represented sequences tokens specifically fÎ¸ parameterized standard model vaswani et al learning algorithms learning optimize develop learning approach first stage capture optimization heuristics adopted existing optimizing compilers use supervised learning train model mined corpus programs described section next discover efficient optimization strategies investigate using methods proposed iterative learning approach silo policy gradient approach eq goal synthesize correct program fË† verified v outperforms reference program fref cost function intuitive choice use policy gradient methods learn policy directly minimizes cost function c produces correct programs v expectation specifically express dual objective via lagrangian relaxation j fË† c fË† iok k Î» v fË† commonly used policy gradient approach reinforce baseline williams based minimization objective express loss using following equation b baseline value given specification p probability generating token time step sequence fË† traditional reinforcement learning context would seek perform gradient ascent following term trying minimize objective perform gradient descent instead l x log p j fË† b self imitation learning optimization silo algorithm illustrates silo learning approach consists two steps exploration step lines model seeks discover alternative optimizations efficient compiler generated targets used learning step lines model parameters updated using newly discovered optimized programs first exploration step exploration batch bex sampled dataset initialized program specifications case unoptimized assembly programs outputs f ref input specification bex sample optimization fË†i execute fË†i test suite io k compute cost function new samples functionally equivalent algorithm silo program optimization initialize model f parameters Î¸ model initialize dataset program function pairs test cases n ioi k f ref n budget exhausted sample batch bex ioi k f ref bex sample fË† fÎ¸ si calculate c fË† v fË† v fË† c fË† c f ref replace fi ref sample fË† end end sample batch btr update Î¸ via supervised learning btr end verification function v also achieve lower cost c compared targets original dataset target dataset replaced model optimal rewrite exploration step taken learning step separate training batch btr sampled maximumlikelihood training dataset may contain targets learning oh et al reinforcement learning algorithm intended help agents solve challenging exploration problems learning good past actions intuitively besides ordinary reinforcement learning using latest actions model also trained historical states actions achieve high rewards r using loss lsil log p max r vÎ¸ sample ha si weighted much better return compared learned baseline vÎ¸ algorithm silo differences standard learning first sequences outperform fref omit learned value function train entire sequence using loss opposed individual actions additionally interpolate loss reinforcement learning algorithm rather avoid policy gradient altogether instead train best sequence found far dataset outputs fref sequence discovered outperforms fo also broadly related hard em algorithm uses currently best modelpredicted results optimization targets kearns mansour ng evaluation server architecture one hurdle performing program optimization scale time required evaluate c v costly li actor actor actor learner parameters experiences program rewrites assess correctness approximate performance verify smt solvers feedback evaluation server figure overview setup features interaction centralized learner module numerous actors well server evaluating program rewrites ing model throughput learning examples alleviate bottleneck utilize set liang et al espeholt et al training process begins multiple actor threads inheriting parameters parent learner created every iteration actor threads independently samples batch program rewrites distribution inherited model sampling batch attempt made evaluate rewrites sending evaluation server inside evaluation server programs assembled tested correctness performance calculate c v details evaluation located section actor sends samples related cost correctness information learner module learning actor attempts synchronize parameters inheriting new copy available learner module fig contains overall diagram entire system model configuration training neural optimizer fÎ¸ uses transformer encoderdecoder embedding dimension attentionheads utilize adam optimizer kingma ba inverse square root schedule vaswani et al model steps subsequently performed algorithms additional steps additionally use assembly bytepair encoding sennrich haddow birch additional details training hyperparameters data preprocessing located supplementary materials section evaluation primary concern constructing verification function v eq undecidability program equivalence programs control flow loops using testcases equivalence v well cost function c https lenges also lie utilizing testcase suite io k either benchmarking program performance coming approximate estimate performance measuring program correctness key claim work superoptimizer outputs correct programs programs efficient still semantically equivalent input programs program equivalence undecidable general case motivating complementary set mechanisms verifying output program correctness experiments confirm output program correctness verification function v two ways first run synthesized programs provided test cases second formally verify correctness using two solver based verifiers bounded smt solver based verifier standard stoke toolkit additional verifier available artifacts program verification work churchill et al program verifiers based smt solver de moura bjÃ¸rner smt satisfiability modulo theories solvers decide satisfiability boolean formulas respect set underlying theories theory integer arithmetic use test cases two verifiers several reasons high coverage test suites informative terms program correctness intrinsically incomplete meanwhile verifiers always scale especially programs arbitrary numbers loop iterations ensure termination standard configured maximum bound b set loop iterations process timeout taking seconds set verification thus also incomplete past bounds limited correctness verifiers underlying models indeed manually observed cases finetuning methods exploited either gaps test suite coverage bugs verifiers models motivated use testcases two verifiers additional robustness would intuitively help mitigate spuriousness evaluation could still remain issue evaluating optimization programs later explain section also resort human verification get reliable results reporting model performance test sets measuring program performance follow previous work superoptimization assembly primarily calculate cost function c static heuristic approximation expected cycles compute sum performance cost functions schkufza sharma aiken churchill et al former sum expected latencies instructions assembly function denoted call latter computes expected latencies using executed instructions cexe randomly generated test suite io k cexe better approximation especially functions contain loop constructs since reached authors churchill et al regarding issues found call may additionally penalize redundant instructions executed expected latencies calculated authors stoke toolkit intel haswell architecture benchmarking measuring instructions servers testing experiments test methods taking final model generate candidates beam search calculate c v report results based best result candidate programs application hacker delight apply methods functions chosen hacker delight benchmark warren first used gulwani et al program synthesis later schkufza sharma aiken program superoptimization latter work authors express able either match outperform gcc provided programs compiled llvm superoptimization benchmark consists manipulation challenges take absolute value evaluating large scale big assembly dataset section perform controlled experiments hacker delight allowing interpretable optimizations consistency prior work results examined results reinforce silo respect two quantities number programs superoptimized version found least training process number programs superoptimized version found within hypotheses generated beam search last model end training regarding former metric reinforce silo respectively found superoptimized programs training latter metric final models produced reinforce silo output superoptimized programs respectively explained fact policy gradient methods wider breadth exploration training process compared silo also less stable final solutions interpretation superoptimizations include examples two programs found algorithms illustrate interesting patterns program superoptimization first example fig comes challenge creating mask identify trailing zeros program example model combines first two instructions one using load effective address instruction named ability compute offset memory address highly useful simplifying simple arithmetic example peephole optimization optimization applied small window instructions scope metaphorical peering door peephole one optimization commonly used compilers likely learned demonstration may surprising compiler apply movl edi eax subl edi notl eax andl edi eax retq code leal edi eax notl eax andl edi eax retq b code figure example trailing zeros mask hacker delight demonstrating commonly used instruction combine optimization assembly movl edi eax sarl eax xorl eax edi subl eax edi movl edi eax retq code movl edi eax sarl edi xorl edi eax subl edi eax retq b code figure example hacker delight absolute value function demonstrating superior register allocation optimization fast setting however known compilers may always choose best optimizations apply leather cummins second example fig comes task taking absolute value input integer demonstrates sophisticated behavior performing efficient procedural optimizations gcc optimized assembly program performs auxiliary computation eax return register majority computation edi argument register finally moving eax register clever solution lies eliminating last move instruction switching auxiliary computation edi register performing majority computation directly eax register used returning result example register allocation process assigning hardware register locations small number variables computations performed program improving register allocation result program copying data fewer times improve performance human realizing optimization would require ingenuity realize final instruction may redundant competent procedural understanding assembly realize computation flipped plausible explanation result model gcc unoptimized code original reference program optimized gcc code optimized target program model may learned degree competence register allocation via demonstration thereby placing probability mass alternative yet efficient implementation application big assembly applying methods big assembly dataset followed general experimental setup hacker delight however evaluated results sets mentioned section observed cases models exploited bugs verifiers models semantics thus also incorporated manual human evaluation reporting methodology benchmark learning methods chose best model ones checkpointed every steps choosing model highest proportion programs superoptimized subset functions validation set according cost function c correct according verification methodology v correct manual human evaluation using chosen model evaluated performance test set manually evaluated test set find proportion reported superoptimizations actually correct table report proportion entire test set superoptimzied according automatic methods discussed section well estimate actual proportion would manually verify correct latter use measured proportion reported superoptimizations manually verified correct subset along proportion reported superoptimizations entire test set generate expected number programs verified correct results witness proposed algorithm silo far outperformed reinforce baseline task test set silo superoptimized expected programs reinforce baseline superoptimized expected also note despite fact used two separate smt based verifiers prove correctness silo approach capable finding learning generalizable exploits manner reinforce study manually verifying assembly programs witnessed across earlier later stages training reinforce model consistently superoptimized programs validation set words seem apply superoptimization patterns new programs learn new superoptimization patterns contrast silo model consistently increased number programs superoptimized set time seemed broaden capacity apply patterns new programs simultaneously learn different strategies superoptimize even exploit verifier trend reflected fig plot hypothesize reward space program superoptimizations highly sparse training saw less every samples reinforce model sampled program superoptimizations believe without method past experience reinforce algorithm struggles find signal noise instead faced optimizing challenging objective synthesizing syntactically semantically correct programs nontrivial objective making small error program syntax semantics dramatic effect reward percent verified step number smt silo smt human silo smt rl smt human rl figure plot reflecting proportion validation set population programs superoptimized every steps training table test set results big assembly benchmark comparing model silo reinforce baseline first column smt ver reports proportion programs beat gcc baseline verify using automated evaluation methods section second column smt human ver presents expected proportion programs would additionally pass human evaluation step based sample test set manually verified model smt ver smt human ver silo reinforce model gets interpretation superoptimizations study assembly outperformed gcc saw two main patterns emerge pushing operations branches removal redundant instructions fig contains example one function first instruction movl eax overwritten later instructions useful first jump program taken given fact efficient cost model push computation first jump taken prevent executed redundantly second example optimization lies removing redundant line highlighted red xorl eax eax zeros lower bits return register rax instruction redundant instruction executed two instructions earlier operation rax register result safe remove second operation note possible modern pipelines architectures optimizations may may speed runtime program depending instruction level parallelism branch prediction handled hardware challenge movl eax testq rdi rdi je xorl eax eax cmpl rdi je xorl eax eax cmpq rdi sete al retq code testq rdi rdi je xorl eax eax cmpl rdi je cmpq rdi sete al movl eax retq b code figure example big assembly benchmark simultaneously removing redundant instruction pushing operations branches models cpu runtime common program superoptimization works aware said seen examples model created superoptimized assembly removing redundant instructions straight line code well nop executed used padding related work program optimization general undecidability program equivalence means may always room improvement optimizing programs rice especially true hardware options performance goals become diverse transformations best scenario may vary greatly performance objectives energy consumption runtime factors classes functions amenable exhaustive search optimal sequence calculations found massalin however limited small sequences machine instructions methods superoptimization either rely searchbased procedures schkufza sharma aiken methods sasnauskas et al however methods difficulty scaling larger problems result typically meet performance requirements real development scenarios compile time program optimization perhaps closest work shi et al attempted learn symbolic expression simplification dataset synthetically generated symbolic expressions halide parsed expression reinforcement learning domain differs however domain specific language contains simple expressions randomly generated programs may contain redundancies seen assembly optimized compiler like gcc another work addressed automatic program optimization bunel et al unlike experiments work used reinforcement learning learn proposal distribution stochastic search used schkufza sharma aiken learned proposal distribution showed improvements baseline method ultimately still used stochastic search except new unlike work model unable fully control program transformations provides learned priors program apply program transformations recent body work centers learning searching efficient schedules tensor computations chen et al adams et al works address realworld problems performance image processing deep learning performance often utilize machine learning achieve goals however works differ search space defined program run hardware schedule search space decoupled underlying algorithms whereas optimizing assembly algorithm computed hardware domain search space conclusion work explored task program superoptimization neural sequence models towards goal introduced big assembly benchmark consisting million programs mined open source projects github along subset functions testcases additionally passed smt based verifiers stoke toolkit proposed silo learning approach two step process exploration step search program superoptimizations learning step best sequences found training experiments big assembly dataset demonstate silo able outperform reinforce baseline believe reinforce struggles program superoptimziation exploration task sparse reward space incorporating supervision superoptimized sequences silo able learn optimizations effectively exploration recently large neural sequence models proposed effective method program synthesis highlevel programming languages python natural language specifications yin neubig chen et al however knowledge relatively little work done refine models go beyond simply synthesizing correct programs additionally optimize important metrics performance readability given increased availability natural language code datasets testcases tuning neural sequence models go beyond program synthesis optimize additional metrics promising direction future work acknowledgments would like thank bogdan vasilescu vincent hellendoorn chris cummins berkeley churchill qibin chen feedback thoughts ideas drafting work work supported part national science foundation grants references adams anderson baghdadi li gharbi steiner johnson fatahalian durand et al learning optimize halide tree search random programs acm transactions graphics tog aho lam sethi ullman compilers principles techniques tools pearson education edition allamanis barr devanbu sutton survey machine learning big code naturalness acm computing surveys csur allen cocke j catalogue optimizing transformations technical report ibm thomas watson research center bunel desmaison kumar torr kohli learning superoptimize programs arxiv preprint chen tworek jun yuan ponde kaplan edwards burda joseph brockman et al evaluating large language models trained code arxiv preprint chen zheng yan jiang moreau ceze guestrin krishnamurthy learning optimize tensor programs advances neural information processing systems chen tian learning perform local rewriting combinatorial optimization advances neural information processing systems churchill padon sharma aiken semantic program alignment equivalence checking proceedings acm sigplan conference programming language design implementation churchill sharma bastien aiken sound loop superoptimization google native client acm sigplan notices de moura bjÃ¸rner efficient smt solver international conference tools algorithms construction analysis systems springer espeholt soyer munos simonyan mnih ward doron firoiu harley dunning et al impala scalable distributed importance weighted architectures arxiv preprint gulwani jha tiwari venkatesan synthesis programs acm sigplan notices joshi nelson randall denali goaldirected superoptimizer acm sigplan notices kearns mansour ng analysis hard soft assignment methods clustering learning graphical models springer kingma ba j adam method stochastic optimization arxiv preprint leather cummins machine learning compilers past present future forum specification design languages fdl ieee liang norouzi berant le lao memory augmented policy optimization program synthesis semantic parsing advances neural information processing systems massalin superoptimizer look smallest program acm sigarch computer architecture news mckeeman peephole optimization communications acm oh guo singh lee learning arxiv preprint pouchet jimborean eds cc proceedings international conference compiler construction association computing machinery rice classes recursively enumerable sets decision problems transactions american mathematical society sasnauskas chen collingbourne ketema taneja regehr j souper synthesizing superoptimizer arxiv preprint schkufza sharma aiken stochastic superoptimization acm sigarch computer architecture news sennrich haddow birch neural machine translation rare words subword units arxiv preprint shi zhang chen tian zhao j deep symbolic superoptimization without human knowledge international conference learning representations vaswani shazeer parmar uszkoreit jones gomez kaiser polosukhin attention need advances neural information processing systems warren hacker delight williams j simple statistical algorithms connectionist reinforcement learning machine learning yin neubig syntactic neural model code generation proceedings annual meeting association computational linguistics volume long papers vancouver canada association computational linguistics smt based verifier exploits found manual evaluation stage witnessed primary pattern exploiting smt solver based verifier branch deleation present concrete example one exploit paired verifier output fig first subfigure demonstrate pattern exploiting verifier original stoke second subfigure show output running verifier included artifacts follow work program example comparison done hex constant value located address register rdi two equal program jumps location executing sequence code place value eax register conditional multiple tests constant equal value memory jump taken program returns eax register first line program xorl eax eax zeros eax register deletion branch following incorrect believe verifiers struggle forms branching jump statements often found programs despite fact previous works verifiers used included loops depend jump statements branching found removed jump location statement spurious rewrite thereby preserving function semantics eliminating branching verifiers correctly identified two programs equivalent b additional information big assembly benchmark data collection big assembly benchmark mined open source projects implemented c programming language github programs disassembled using gnu binutils objdump assembly split individual functions performed process twice set source code could create parallel corpus functions split dataset train development test sets based level entire individual github projects deduplicated removing overlapping binaries datasets also deduplicated individual function level removing string matches removing function names assembly functions lastly removed programs pairs dataset either source target program length greater encoding tokenization setting live filter spurious examples mentioned section function dataset required determine live set portion cpu state required determining equivalence programs also determine heap boolean flag determines whether also check heap equivalence well perform sanity check determining parts cpu state equivalent https https target rewrite xorl eax eax xorl eax eax cmpb rdi cmpb rdi je je retq retq movzbl rdi edx cmpb dl sete al cmpb dl sete dl orl edx eax movzbl al eax retq equivalent yes output original stoke bounded verifier target rewrite xorl eax eax xorl eax eax cmpb rdi cmpb rdi je je retq retq movzbl rdi edx cmpb dl sete al cmpb dl sete dl orl edx eax movzbl al eax retq bv checking pair take option without memory bv paths verified true bv checking pair take option without memory bv paths verified true bv checking pair finished early without modeling memory bv paths verified true bv checking pair finished early without modeling memory bv paths verified true equivalent yes b output verifier artifacts churchill et al figure example common exploit right hand side deletes branch code following third fourth lines je removed verifier actually returns correctly gcc function gcc pseudocode live described algorithm algorithm refer gcc function fu line algorithm begins initializing live possible cpu registers lines either computation budget exhausted live set reaches fixed point iteratively execute function get live incrementally determines candidate live set works either executing testcase suite runs smt solver based verifier analyzing difference resulting cpu state pruning part cpu state differs returning subset cpu state may equivalent fuand fref may need run iteratively pruning live respect one counter example possible another counterexample may still trigger difference parts cpu state general purpose cpu registers also perform pruning level allowing register size equivalence pruned lower bits computation budget exhausted program returns early program discarded dataset determining live lines additional check done see programs equivalent checking heap heap set true information recorded used phases lastly lines perform final sanity check ensure none programs equivalent set spurious programs null program return return program equivalent one highly simplistic programs discarded dataset algorithm set live filter examples initialize live live repeat old live live live get live fu fref live old live live budget exhausted diff fu fref live heap true heap false else heap true end spurious false fspur spurious fspur fref live heap spurious true end end data preprocessing training perform additional processing programs feed model remove noise gcc function well gcc functions used fref assembly often uses instructions jump different parts binary one way control flow implemented jump targets often marked offsets binary however individual function level may canonicalized ordinal locations fully preserves function semantics removing noise prediction task c hyperparameters settings section report hyperparameters used finetuning models general hyperparameters found silo algorithm need hyperparameter whereas reinforce baseline experiments brittle witnessed without lower learning rate carefully tuned learning rate schedule reinforce experiments would often diverge full finetuning budget exhausted used steps warmup silo experiments utilized constant factor applied noam scheduler vaswani et al reinforce models used factor big assembly dataset factor hacker delight dataset reinforce hyperparameters baseline eq used mean objective function previous samples unique program subtracting mean return subsequently normalized standard deviation objective function previous samples lagrangian multiplier Î» eq used penalty additionally follow schkufza sharma aiken adding additional penalty every bit cpu state differed reference implementations rewrite output functions similar semantics would penalized less dramatically different semantics prevent objective function growing great also clipped maximum cost would exceed typical many policy gradient algorithms also included entropy bonus Î² encourage additional exploration used constant entropy bonus Î² hacker delight big assembly experiments
role lookahead approximate policy evaluation policy iteration linear value function approximation anna joseph lubars michael livesay srikant university illinois department electrical engineering sandia national laboratories mlivesa rsrikant abstract sizes state action spaces large solving mdps computationally prohibitive even probability transition matrix known practice number techniques used approximately solve dynamic programming problem including lookahead approximate policy evaluation using return function approximation recent paper efroni et al studied impact lookahead convergence rate approximate dynamic programming paper show convergence results change dramatically function approximation used conjunction lookout approximate policy evaluation using return specifically show linear function approximation used represent value function certain minimum amount lookahead return needed algorithm even converge condition met characterize performance policies obtained using approximate policy iteration results presented two different procedures compute function approximation linear regression gradient descent introduction policy iteration variants policy iteration bertsekas bertsekas tsitsiklis solve dynamic programming problems rely computations infeasible due sizes state action spaces modern reinforcement learning problems remedy curse dimensionality several state art algorithms silver et al b mnih et al employ return policy evaluation lookahead using tree search function approximation gradient descent compute function approximation see bertsekas definition terms recent work efroni et al considers variant policy iteration utilizes lookahead approximate policy evaluation using return stated motivation efroni et al note lookahead approximated well practice using monte carlo tree search mcts kocsis szepesvari browne et al even though theory exponential complexity shah xie xu motivated policy iteration algorithm efroni et al estimates value function associated policy aims improve policy step policy improvement achieved obtaining greedy policy case policy iteration lookahead policy work efroni et al involves applying bellman operator several times current iterate obtaining greedy policy idea application bellman operator several times gives accurate estimate optimal value function similar policy iteration algorithm efroni et al aims evaluate new policy algorithm efroni et al uses return compute value function associated policy applies bellman operator associated policy times work efroni et al establishes lookahead significantly improve rate convergence one uses value function computed using lookahead approximate policy evaluation step main interest understanding convergence results change large one resort function approximation value function contributions follows examine impact lookahead return approximate policy iteration linear function approximation need evaluate approximate value function states iteration simply evaluate states since use function approximation need different proof techniques efroni et al one consequence performance bounds obtain algorithm require sum lookahead number steps return sufficiently large demonstrate extension counter example tsitsiklis van roy condition necessary convergence function approximation unlike tabular setting efroni et al first results mentioned assume one solves problem iteration obtain weights associated feature vectors function approximation value function obtain performance bounds practical scheme one step gradient descent used update weights value function approximation iteration sufficient condition minimum amount sep lookahead return convergence depend size state space depends feature vectors used function approximation additionally results indicate approximation error algorithm improved feature vectors represent value function well neural networks linear function approximators recent results motivated ntk neural tangent kernel analysis neural networks suggest approximated linear combinations basis functions jacot gabriel hongler cao gu thus results potentially shed light combination representation capability neural networks methods work well practice although work necessary make connection precise extend results case return replaced approximation work efroni et al results found appendix f appendix complement theoretical results experiments grid world problem efroni et al experiments presented later section appendix addition work efroni et al long history work approximate policy iteration however works typically model tree search processes lookahead return conjunction function approximation gradient descent done paper compare results prior works later section preliminaries consider markov decision process mdp defined p r Î± finite set states mdp exists finite set actions associated mdp let pij probability transitioning state state j taking action denote sk state mdp ak corresponding action time associate state sk action ak reward r sk ak ak assume rewards uniformly bounded objective maximize cumulative discounted reward discount factor Î± Î± k r sk ak towards end associate state deterministic policy Âµ prescribes action take every policy Âµ every state define j Âµ follows j Âµ e Î± k r sk Âµ sk define optimal j j min Âµ j Âµ objective find policy Âµ maximizes j Âµ towards objective associate policy Âµ function tÂµ r n r n j r n sth component tÂµj tÂµj r Âµ Î± x psj Âµ j j function tÂµ applied times vector j r call result Âµ j say Âµ j return corresponding j return j understood similarly define bellman operator r r sth component j j max r Î± x psj j j policy corresponding operator defined greedy policy function applied h times vector j r call result hj lookahead corresponding j greedy policy corresponding hj called lookahead policy lookahead policy h understood precisely given estimate j value function lookahead policy policy Âµ tÂµ well known time bellman operator applied vector j obtain j following holds kt j j Î± kj j thus applying obtain j gives better estimate value function j bellman equations state vector j Âµ unique solution linear equation j Âµ tÂµj Âµ additionally j solution j note every greedy policy j optimal vice versa bertsekas tsitsiklis state several useful properties operators tÂµ consider vector e r e j ce j Î±ce tÂµ j ce tÂµj Î±ce operators tÂµ also monotone j j j tÂµj tÂµj least squares function approximation algorithm algorithm described algorithm algorithm approximation policy iteration iteration index say k estimate value function denote jk obtain perform lookahead improve value function estimate certain number states denoted dk vary iteration example dk could chosen states visited performing tree search approximate lookahead algorithm least squares function approximation algorithm input h feature vectors Ï† Ï† r subsets dk k dk set states evaluate current policy iteration let k let hjk Îµ compute jk dk choose solve min Î¸ x Ï†Î¸ Ï† matrix whose rows feature vectors set k k go process lookahead process note also obtain lookahead policy denote obtain estimates j dk call obtain estimate j perform return policy obtain estimate dk model approximation errors lookahead return adding noise output steps order estimate value function states dk associate state feature vector Ï† r typically matrix comprised feature vectors rows denoted Ï† obtain estimates Âµ states dk use estimates find best fitting Î¸ r min Î¸ x Ï†Î¸ algorithm computes uses obtain process repeats note estimate value function associated policy compute dk another alternative instead compute jk shown efroni et al former option preferable certain contraction property thus chosen use computation algorithm well however show appendix b algorithm also converges second option chosen sufficiently large analyze algorithm make following assumption states explore sufficient number states policy evaluation phase iteration assumption k rank Ï† assume noise wk bounded assumption Îµ Îµ also assume rewards bounded assumption r u u using assumption written Ï† Ï† dk Ï†dk dk pk z Ï†dk matrix whose rows feature vectors states dk pk matrix zeros ones vector whose elements subset elements corresponding dk written concisely algorithm follows wk defined step algorithm note wk dk affect algorithm convenience define wk dk state theorem characterizes role lookahead h return convergence approximate policy iteration function approximation theorem suppose h satisfy h log log sup k sup k Ï† Ï† dk Ï†dk dk pk lim sup kj Âµk j cm h Î± cm h h Î± Îµ supk Âµk kmkj Âµk j Âµk proof theorem subsumed proof theorem presented next section minor modifications therefore outline modifications proof theorem appendix theorem used make following observation close jÂµk j depends four factors representation power feature vectors feature vectors amount lookahead h extent return approximation policy determination policy evaluation steps Îµ Îµ examining cm h one see lookahead return help mitigate effect feature vectors ability represent value functions note efroni et al also consider version algorithm step Âµk replaced Âµk jk obtain performance bound algorithm function approximation appendix b assumption large even though practice jÂµk interested values jk computed part algorithm Âµ b Âµ b figure example illustrating necessity condition theorem go since algorithm would numerically unstable otherwise appendix c provide bound kjk j h sufficiently large theorem subsection show condition satisfied jk become unbounded example use depicted figure two policies Âµ Âµ b transitions deterministic two policies rewards deterministic depend states rewards associated states denoted r r r r thus optimal policy Âµ assume scalar features Ï† Ï† fix h mdp follows policy Âµ jk jk Î¸k thus long Î¸k lookahead policy Âµb show Î¸k increases iteration assume dk straightforward computation shows iteration suppose Âµ b follows r r Î± mÎ¸k r r Î± mÎ¸k thus step algorithm arg min Î¸ x Ï†Î¸ Î± r Î± r mÎ¸k Î± mÎ¸k thus since h Î± Î¸k Î¸k goes numerical results section study convergence behavior algorithm including impact choice feature vectors present experimental results complete set results refer appendix efroni et al efroni et al assume deterministic grid world problem played n n grid states squares grid actions right left stay move agent prescribed direction possible experiment goal state chosen uniformly random reward every state fixed reward drawn uniformly experiments n Î± implemented algorithm two particular choices feature vector random feature vectors dimension entry matrix Ï† independent n random variable designed feature vectors feature vector state whose coordinates x x number steps required reach goal state x choice feature vectors varied h keeping parameter constant h plotted error kjk j iteration k averaged ten trials value h seen figure although jk diverges small values h sufficiently large values value function converges region around optimal solution recall theorems suggest amount lookahead return depends choice feature vectors experiments support observation well amount lookahead return required high often random feature vectors able significantly reduce amount required using designed feature vectors better represent states gradient descent algorithm solving problem algorithm involves matrix inversion computationally difficult dimension feature vectors large propose alternative algorithm performs one step gradient descent iteration gradient refers gradient objective gradient algorithm presented algorithm order present main result gradient descent version algorithm define Î¸ Âµk policy Âµk follows Î¸ Âµk arg min Î¸ kÏ†dk Î¸ pkj Âµk k words Î¸ Âµk represents function approximation j Âµk also define another quantity Âµk used proof theorem Âµk arg min Î¸ Ï†dk Î¸ pk Âµk wk arg min Î¸ Ï†dk Î¸ pk Âµk wk thus Âµk represents function approximation estimate j Âµk obtained rollout present main result figure top random feature vectors h increase value jk eventually stops diverging bottom designed feature vectors smaller amount lookahead return needed prevent jk diverging theorem suppose assumptions hold Î³ h satisfy Î± Î± Î± Î´ Î± sup k Î³Ï† dk Ï†dk Î´ sup k Ï† dk Ï†dk Ï† dk pk lim sup kj Âµk j cm h Î³ Î± cm h Î³ h um h Î³ Î´ Îµ Î´ sup k Âµk kÏ†Î¸ Âµk j Âµk c Ïƒmin Ï† Î± Ï†Î´ um h Î³ Î± Î± h Î± Î´ Î± Î´ Îµ sup k Âµk kÎ¸ Âµk algorithm gradient descent algorithm input h feature vectors Ï† Ï† r dk set states evaluate current policy iteration k let hjk Îµ compute dk Î¸k Î¸ c Î¸ min Î¸ x Ï†Î¸ set k k go note choosing Î³ sufficiently small one ensure condition Î± satisfied proof proof theorem somewhat involved outline steps proof step proof step step since obtained taking step gradient descent towards beginning Î¸k show following property Î± Î¸k proof step recall iterates equation written follows Î¸k Î¸ Î¸k Î³ Ï† dk Ï†dk Î¸k Ï† dk pk wk since Î¸ Ï† dk Ï†dk Ï† dk pk wk following Î¸k Î³ Ï† dk Ï†dk Î¸k Ï† dk Ï†dk Ï† dk pk wk Ï† dk pk wk Î¸k Î³Ï† dk Ï†dk Î¸k subtracting sides gives Î¸k Î³Ï† dk Ï†dk Î¸k Î³Ï† dk Ï†dk Î¸k thus Î³Ï† dk Ï†dk Î¸k Î³Ï† dk Ï†dk Î¸k Î³Ï† dk Ï†dk Î¸k sup k Î³Ï† dk Ï†dk z Î¸k step using previous step conjunction contraction properties bellman operators show following kÎ¸k Î¸ Âµk Î± Î± Î± Î´ Î¸ Î± Î± h Î± Î´ Î± Î± Î± Î´ Îµ iterate k get bound kÎ¸k Î¸ Âµk depend proof step following kÎ¸k Î¸ Âµk Î¸k Âµk Âµk Î¸ Âµk Î± Î¸ Âµk Î± Âµk Î¸ Âµk Âµk Î¸ Âµk Î± Î¸ Î± kÎ¸ Âµk Î¸ Î± Âµk Î¸ Âµk order bound introduce following lemmas lemma kÎ¸ Î¸ Âµk Ïƒmin Ï† Î± Ï†Î´ z c Ïƒmin Ï† smallest singular value singular value decomposition lemma Î¸ Âµk Âµk Î´ Îµ Î± Î´ Î± Î± Î± Î´ Î± Î´ kÎ¸ proofs lemmas found appendix appendix using lemmas kÎ¸k Î¸ Âµk Î± Î¸ Î± Î± Î´ Îµ Î± Î´ Î± Î± Î± Î´ Î± Î´ kÎ¸ Î± Î± Î± Î´ Î¸ Î± Î± h Î± Î´ Î± Î± Î± Î´ Îµ iterating k get k kÎ¸k Î¸ Âµk Î± Î± h Î± Î´ Î± Î´ Îµ z um h Î³ sup k Âµk kÎ¸ Âµk used fact Î± Î± Î´ assumption statement theorem fact kj Î± due assumption step since jk Ï†Î¸k Ï†Î¸ Âµk best approximation r j Âµk show following bounds kj Âµk kÎ¸k Î¸ Âµk Î´ using previous step get bound kj Âµk depend proof step kj Âµk kÏ†Î¸k j Âµk kÏ†Î¸k Ï†Î¸ Âµk kÏ†Î¸ Âµk j Âµk kÎ¸k Î¸ Âµk Î´ um h Î³ sup k Âµk kÎ¸ Âµk Î´ z pm h Î³ last step follows applying bound kÎ¸k Î¸ Âµk step establish following bound Âµk using contraction property bellman operators property Âµk h kj Âµk e Âµk Îµe Âµk hpm h Î³e Îµe last inequality follows definition pm h Î³ previous step using properties monotonicity repeatedly apply sides take limits obtain following j Âµk cm h Î³e Î± proof step Âµk Âµk Î± h kj Âµk e Î± h kj Âµk e hjk Îµe Î± h kj Âµk e hjk hj Âµk hj Âµk Îµe b h kj Âµk e hj Âµk Îµe h kj Âµk e Âµk Îµe Âµk hpm h Î³e Îµe rest proof similar arguments bertsekas tsitsiklis bertsekas however explicitly incorporate role lookahead h remaining steps proof suppose apply operator times sides due monotonicity fact tÂµ j ce tÂµ j policy Âµ following Âµk Î± cm h Î³e Âµk using telescoping sum get following inequality j Âµk Âµk x j Î± cm h Î³e taking limit j sides following j Âµk cm h Î³e Î± rest proof straightforward subtract j sides previous inequality using contraction property get j j Î± kj Âµk j e cm h Î³e Î± iterating k get theorem remark mentioned earlier proof theorem essentially special case theorem small modifications proof theorem skips steps instead uses techniques lemma see appendix obtain analogous result step rest proof steps follows except pm h defined proof theorem place pm h Î³ defined step related work introduction compared results efroni et al compare work papers literature worth noting efroni et al builds lot ideas efroni et al role lookahead return improving performance rl algorithms also studied large number papers including moerland broekens jonker efroni ghavamzadeh mannor tomar efroni ghavamzadeh efroni et al springenberg et al deng et al works baxter tridgell weaver veness et al lanctot et al explore role tree search rl algorithms however best knowledge amount lookahead return needed function feature vectors quantified prior works approximate policy iteration well studied topic see bertsekas tsitsiklis bertsekas puterman shin lesner scherrer example however since models involve scheme approximating value function iteration role depth lookahead h return quantified using works important note work different least squares policy iteration lspi common means obtaining function approximation parameters value function estimates one algorithms used least squares estimates work importantly analyzes use lookahead return employed prior least squares step algorithm works bertsekas bertsekas also study variant policy iteration wherein greedy policy evaluated approximately using feature vectors iteration papers also provides rates convergence well bound approximation error however main goal understand relations function approximation considered works conclusion show minimum threshold lookahead corresponding policy return must met algorithms function approximation based approximate policy iteration converge particular show one uses function approximation conjunction return lookahead policy without factor iterates h must sufficiently large results derived two different implementations function approximation algorithm solving least squares problem one step gradient descent least squares objective iteration mentioned introduction would interesting extend work study neural network based function approximation additionally problems terminal state would interesting consider cases value function given policy estimated using full rollout provides unbiased estimate tsitsiklis acknowledgements research presented supported part grant sandia national labs nsf grants ccf ccf onr grant grant ag aro grant sandia national laboratories multimission laboratory managed operated national technology engineering solutions sandia llc wholly owned subsidiary honeywell international department energy national nuclear security administration contract paper describes objective technical results analysis subjective views opinions might expressed paper necessarily represent views department energy united states government references baxter tridgell weaver tdleaf lambda combining temporal difference learning search corr bertsekas approximate policy iteration survey new methods journal control theory applications bertsekas tsitsiklis j programming athena scientific isbn bertsekas reinforcement learning optimal control athena scientific belmont browne powley whitehouse lucas cowling rohlfshagen tavener perez liebana samothrakis colton survey monte carlo tree search methods ieee transactions computational intelligence ai games cao gu q generalization bounds stochastic gradient descent wide deep neural networks advances neural information processing systems deng yin deng li algorithms optimization discounted learning method deep reinforcement learning ieee international conference high performance computing communications ieee international conference smart city ieee international conference data science systems efroni dalal scherrer mannor beyond one step greedy approach reinforcement learning corr efroni dalal scherrer mannor greedy policies online approximate reinforcement learning efroni dalal scherrer mannor combine methods reinforcement learning efroni ghavamzadeh mannor online planning lookahead policies advances neural information processing systems jacot gabriel hongler neural tangent kernel convergence generalization neural networks arxiv preprint kocsis szepesvari bandit based planning volume isbn lanctot winands pepels sturtevant monte carlo tree search heuristic evaluations using implicit minimax backups lesner scherrer b approximate modified policy iteration mnih badia mirza graves lillicrap harley silver kavukcuoglu asynchronous methods deep reinforcement learning corr moerland broekens jonker framework reinforcement learning planning puterman shin modified policy iteration algorithms discounted markov decision problems management science shah xie xu z analysis monte carlo tree search silver hubert schrittwieser antonoglou lai guez lanctot sifre kumaran graepel lillicrap simonyan hassabis mastering chess shogi general reinforcement learning algorithm corr silver schrittwieser simonyan antonoglou huang guez hubert baker lai bolton et al mastering game go without human knowledge nature springenberg heess mankowitz merel byravan abdolmaleki kay degrave schrittwieser tassa et al local search policy iteration continuous control arxiv preprint sutton barto reinforcement learning introduction mit press second edition tomar efroni ghavamzadeh greedy reinforcement learning algorithms tsitsiklis convergence optimistic policy iteration journal machine learning research jul tsitsiklis van roy b methods large scale dynamic programming machine learning veness silver uther blair bootstrapping game tree search proof theorem proof consider policies Âµk taken arbitrary policy following Âµk Âµk Î± h kj Âµk e Î± h kj Âµk e hjk Îµe Î± h kj Âµk e hjk hj Âµk hj Âµk Îµe b h kj Âµk e hj Âµk Îµe h kj Âµk e Âµk Îµe e vector b follow contraction property h last inequality follows standard arguments using monotonicity properties definition specifically note jÂµ min Âµ tÂµj Âµ j Âµ repeatedly apply sides inequality use monotonocity obtain j Âµ Âµ policies Âµ bound kj Âµk jkk follows lemma kj Âµk jkk Î± j Î± Î± Î± proof kj Âµk jkk mk Âµk wk j Âµk mkt Âµk j Âµk mkt Âµk j Âµk mkt Âµk j Âµk mkt Âµk mkj Âµk mkj Âµk j Âµk mkt Âµk mkj Âµk kmkj Âµk j Âµk Âµk j Âµk kmkj Âµk j Âµk Î± j Âµk sup k Âµk kmkj Âµk j Âµk Î± j j j Âµk sup k Âµk kmkj Âµk j Âµk Î± j Î± kj j Âµk sup k Âµk kmkj Âµk j Âµk Î± j Î± Î± sup k Âµk kmkj Âµk j Âµk Î± j j j Î± Î± sup k Âµk kmkj Âµk j Âµk Î± j Î± Î± Î± sup k Âµk kmkj Âµk j Âµk Î± j Î± Î± Î± iterating k get k kj Âµk Î± z pm h used assumption Î± fact kj Î± due assumption putting together following Âµk h pm Îµ z cm h e Âµk rest proof similar arguments bertsekas tsitsiklis bertsekas however explicitly incorporate role lookahead h remaining steps proof suppose apply operator times sides due monotonicity fact tÂµ j ce tÂµ j Î±ce policy Âµ following Âµk Î± cm Âµk using telescoping sum get following inequality j Âµk Âµk x j Î± cm taking limit j sides following j Âµk cm Î± rearranging terms subtracting j sides get following j j Âµk j cm Î± Âµk cm Î± Î± kj Âµk j e cm Î± since j j following kj j Î± kj Âµk j cm h Î± iterating k taking limits get theorem b modified least squares algorithm suppose step algorithm changed jk dk still possible get bounds performance algorithm sufficiently large modification algorithm assumptions hold following theorem suppose satisfies log log sup k sup k Ï† Ï† dk Ï†dk dk pk lim sup kj Âµk j h Î± h h Î±m Î± Îµ supk Âµk kmkj Âµk j Âµk proof theorem follows proof consider policies Âµk taken arbitrary policy following Âµk Âµk Î± h kj Âµk e Î± h kj Âµk e hjk Îµe Î± h kj Âµk e hjk hj Âµk hj Âµk Îµe b h kj Âµk e hj Âµk Îµe h kj Âµk e Âµk Îµe e vector b follow contraction property h last inequality follows standard arguments using monotonicity properties definition specifically note jÂµ min Âµ tÂµj Âµ j Âµ repeatedly apply sides inequality use monotonocity obtain j Âµ Âµ policies Âµ bound kj Âµk jkk follows kj Âµk jkk mk Âµk wk j Âµk mkt Âµk j Âµk mkt Âµk j Âµk mkt Âµk j Âµk mkt Âµk mkj Âµk mkj Âµk j Âµk mkt Âµk mkj Âµk kmkj Âµk j Âµk Âµk j Âµk kmkj Âµk j Âµk Âµk j Âµk kmkj Âµk j Âµk Î± j Âµk sup k Âµk kmkj Âµk j Âµk Î± j Âµk Î± j j j Âµk Î± j Î± kj j Âµk Î± j Î± Î± iterating k get k kj Âµk Î±m Î± z pm used assumption Î± fact kj Î± due assumption putting together following Âµk hpm Îµ z h e Âµk rest proof follows proof theorem h instead cm h get current theorem c proof proposition following proposition present bound difference jk j proposition Î± lim kjk j rm h h qm h Î± rm h Î± h cm h cm h defined pm h defined proof follows proof j j j j j kj j j kj j j kj j j kj j j j kj j j kj j j j j kj j j kj j kj j kjk j kj j kj j kjk j kj j c kjk j Î± kj Âµk j cm h Î± kjk j Î± kj Âµk kjk j cm h Î± Î± kjk j Î± kj Âµk cm h Î± Î± kjk j Î± pm h cm h Î± qm h kjk j rm h qm h Î± rm h Î± h cm h note pm h defined cm h defined additionally c follows follows iterating k get proposition proof lemma proof Î± kj Âµk j j Âµk Ï†Î¸ Âµk j Ï†Î¸ Ï†Î¸ Ï†Î¸ Âµk kj Ï†Î¸ Ï†Î¸ Ï†Î¸ Âµk Î´ kÏ†Î¸ Ï†Î¸ Âµk Ïƒmin Ï† kÎ¸ Î¸ Âµk Ïƒmin Ï† Î± Ï†Î´ z c kÎ¸ Î¸ Âµk Ïƒmin Ï† smallest singular value singular value decomposition e proof lemma proof assumption Ï†dk rank thus following Î¸ Âµk Âµk Ï† dk Ï†dk Ï† dk pkj Âµk pk Âµk wk Ï† dk Ï†dk Ï† dk pk j Âµk Âµk wk Î¸ Âµk Âµk Ï† dk Ï†dk Ï† dk pk j Âµk Âµk wk Ï† dk Ï†dk Ï† dk pk j Âµk Âµk Î´ Îµ Î± sup k Ï† dk Ï†dk Ï† dk pk j Âµk Î´ Îµ obtain bound j Âµk follows j Âµk j Âµk j j kj Âµk j j kj Âµk j Î± kj Î± Î± kj Î± Î± kj j j Î± Î± kj j kj Î± Î± Î± kj Î± Î± Î± kj Ï†Î¸ Ï†Î¸ Î± Î± Î± kj Ï†Î¸ Î± kÏ†Î¸ Î± Î± Î± Î´ Î± kÎ¸ putting together gives following Î¸ Âµk Âµk Î´ Îµ Î± Î´ Î± Î± Î± Î´ Î± Î´ kÎ¸ f approximation consider variant approximate policy iteration studied efroni et al define following operator parameter Î» Âµ Î» j Î» Î» j tÂµ j Î³Î»p Âµ tÂµj j algorithm approximation algorithm input h Î» feature vectors Ï† Ï† r subsets dk k dk set states evaluate current policy iteration let k let hjk Îµ compute jk dk choose solve min Î¸ x Ï†Î¸ Ï† matrix whose rows feature vectors set k k go p Âµ state transition matrix corresponding policy Âµ operator estimator Î» operator sutton barto full return often desired practice impossible obtain mdps possible instead obtain estimate full return policy Âµk operator equation Âµk Î» parameterized Î» using Âµk Î» operator obtain estimate j Âµk modified algorithm given algorithm case main algorithm make assumption assumption assumption using assumption succinctly write iterates follows Î» state theorem characterizes role Î» convergence algorithm theorem defined theorem cÎ» Î» lim sup kj Âµk j h Î± h h Îµ defined theorem proof theorem follows proof consider following sequences v k Î» Î» Î» j Âµk j Âµk z k v k j Âµk first get bounds v k following j Âµk j Âµk e j Âµk j Âµk j Âµk e Î» Î» Î» j Âµk j Âµk j Âµk z e j Âµk z k Î» Î» Î» j Âµk j Âµk j Âµk e j Âµk Î» Î» Î» j Âµk j Âµk ÎµÎ»e j Âµk z k Î» Î» Î» j Âµk j Âµk ÎµÎ»e j Âµk Î» Î» Î» jÎ± z k Î» Î» Î» jÎ± z k Î» Î» Î» jÎ± taking limits since norm continuous function following using continuity argument kjk j Âµk mk Âµk Î» wk j Âµk mkt Âµk Î» j Âµk mkt Âµk Î» j Âµk kmkj Âµk j Âµk Âµk Î» j Âµk Âµk Î» j Âµk lim v k j Âµk lim z k ÎµÎ» Î» Î» Î»Î± j Âµk Î» Î» Î»Î± following kjk j Âµk k j Âµk Î» Î» Î»Î± z cÎ» j Âµk j j j Âµk j kj j Âµk j Î± j j j Î± j Î± Î± iterate k get following k kj Âµk Î± z pm h Î» rest proof follows proof theorem pm h Î» instead pm h get theorem g approximation special case Î» algorithm small may obtain better bounds using alternative proof technique note case Î» seen approximation operator following result tailored towards small Î» proposition zÎ»Î± zÎ» Î± Î³Î»p Âµk defined theorem lim sup kj Âµk j c h Î± c h h Îµ proof proposition follows proof note iterates follows Î³Î»p wk following bounds kj Âµk mk Î³Î»p Âµk Âµk wk j Âµk mk Î³Î»p Âµk Âµk j Âµk mk Î³Î»p Âµk Âµk mkj Âµk mkj Âµk j Âµk mk Î³Î»p Âµk Âµk mkj Âµk kmkj Âµk j Âµk mk Î³Î»p Âµk Âµk mkj Âµk Î³Î»p Âµk Âµk j Âµk Î³Î»p Âµk Âµk j Âµk Î³Î»p Âµk Âµk Âµk Âµk j Âµk Î³Î»p Âµk Âµk Âµk j Âµk Î³Î»p Âµk Âµk Âµk j Âµk Î³Î»p Âµk z Âµk j Âµk j Âµk Âµk j Âµk Âµk j Âµk j Âµk Âµk j Âµk j Âµk j Âµk Î± j Âµk Î± z zÎ» j Âµk zÎ» j j j Âµk zÎ» j zÎ» kj j Âµk zÎ»Î± j zÎ» Î± zÎ»Î± j j j zÎ» Î± zÎ»Î± j zÎ» Î± Î± iterate k get following k kj Âµk zÎ» Î± z h Î» zÎ»Î± rest proof follows proof theorem h Î» place pm h get proposition h additional numerical experiments appendix test algorithms grid world problem using grid world problem efroni et al simulations assume deterministic grid world problem played n grid states squares grid actions right left stay move agent prescribed direction possible experiment goal state chosen uniformly random reward state fixed reward drawn uniformly unless otherwise mentioned duration section n Î± order perform linear function approximation prescribe feature vector state section focus three particular choices random feature vectors entry matrix Ï† independent n random variable designed feature vectors feature vector state whose coordinates x x number steps required reach goal state x indicator vectors feature vector state indicator vector entry nonzero random feature vectors represent features necessarily representative states empirically although algorithm still converge require large amount lookahead contrast designed feature vectors better able represent value function fewer features less lookahead required test algorithm experiments using starting state plots section graph average trials trial fixed random choice dk set states used policy evaluation error bars show standard deviation mean code used produce graphs included supplementary material effect h convergence figure showed h affect convergence iterates jk j h small value jk sometimes diverges value diverges even one trial average trials kjk j also increases exponentially however average converges trials plot relatively flat h required convergence depends parameter defined theorem trials average value choices feature vectors respectively showed main body paper general one needs h log log convergence however specific examples possible convergence smaller values example grid word model log log observe large amount h required convergence figure difficult see h affect probability divergence function representative states chosen sampled therefore introduce figure plots show proportion trials distance kjk j exceeded iterations algorithm expected algorithm never diverges indicator vectors algorithm equivalent tabular setting designed feature vectors clearly require much smaller amount lookahead return well amount predicted average however matter choice feature vectors eventually prevent algorithm diverging large enough value h convergence optimal policy theorem show h increases converge policy Âµk closer optimal policy section experimentally investigate role h final value kj Âµk j results found figure predicted theory get closer optimal policy h increases however increasing help past certain point also consistent theory indeed although Âµk approaching optimal policy Âµ h increases iterates jk converging j due error induced function approximation increasing improves policy evaluation correct inherent error approximating value function varying h b varying figure plot probability kjk j diverges function h first plot second plot h cases algorithm never diverges h large enough though smaller amount lookahead return needed designed feature vectors varying h b varying figure plot final value kj Âµk j iterations first plot second plot h h increases final policy improves large enough h obtain optimal policy however past certain point increasing helpful finding better policy
sep control synthesis unknown systems via control barrier functions luyao niu hongchao zhang andrew clark complexity control systems increases safety becomes increasingly important property since safety violations damage plant put system operator danger system dynamics unknown synthesis becomes challenging additionally modern systems controlled digitally hence behave systems system dynamics evolve continuously control input applied discrete time steps paper study problem control synthesis systems unknown dynamics overcome challenges introduced implementation unknown dynamics constructing set control barrier function cbf constraints satisfying constructed cbf constraint sampling time guarantee unknown system safe time formulate program solve control signal sampling time decompose program two convex illustrate proposed approach using numerical case study introduction systems cpss found applications autonomous vehicles advanced manufacturing safety property typically formulated forward invariance given safe set safety violations could lead severe damage controlled plant danger human operators control synthesis cpss extensively studied existing literature models cpss known several factors may cause safety violations plant even nominal controller designed safe one challenge raised implementation system continuous input practical digital implementation system state observable sampling time control signal applied hold zoh manner sampling period system implemented system another challenge system models used design controllers perfect practice thus exist uncertainties system model due uncertainties designed controller may fail guarantee safety even safety guaranteed nominal plant two challenges studied separately safetycritical control synthesis studied sampleddata system known dynamics unmodeled systems dynamics niu zhang clark department electrical computer engineering worcester polytechnic institute worcester usa lniu aclark work supported national science foundation office naval research via grants control synthesis studied assuming existence backup controller ensures safety unknown system model model learned using gaussian process although safety guarantees achieved methods described suffer tradeoff overly conservative learned model faced large uncertainty potential safety violation failing capture true dynamics best knowledge jointly addressing two challenges without prior knowledge safe backup controller wellcalibrated model studied paper study control synthesis system unknown dynamics address challenges introduced due system unknown dynamics developing set control barrier function cbf constraints sampling time cbf constraint inequality imposed control signal whose satisfaction implies forward invariance estimate constructed cbf constraints bounding reachable set sampling period calculating interval contains system dynamics leveraging lipschitz continuity assumption system dynamics satisfying cbf constraints sampling time system guaranteed safe time summarize paper makes following contributions construct cbf constraint unknown system provide sufficient condition satisfying cbf constraint bounding set reachable states sampling period calculating interval contains unknown system dynamics formulate optimization problem subject constructed cbf constraints calculate zoh control signal sampling period solve optimization problem proposing approach involves convex programs prove synthesized controller ensures system safe respect given safe set validate proposed framework using numerical case study dc motor show proposed approach ensures safety dc motor remainder paper organized follows review related work preliminary background section ii section iii respectively system model problem formulation presented section iv give solution approach section v illustrate proposed approach using numerical case study section vi section vii concludes paper ii related work multiple approaches proposed control synthesis cpss known dynamics including hji equation mixedinteger program control barrier function cbf control lyapunov function clf methodologies methods formulate quadratic program calculate controller assuming system state remains unchanged discrete time interval systems approaches shown great success authors focus systems known dynamics system additive disturbance studied work consider system unknown dynamics methods normally require knowledge system dynamics calculate cbf constraint unknown dynamics lead scenario calculating cbf constraints feasible thus makes approaches proposed applicable control algorithms proposed address systems contain unknown uncertainties recent works demonstrated success clfbased method along learning algorithms category approaches leverages forward invariance stability properties provided barrier functions lyapunov functions respectively however assume exists model unknown system safe backup controller recover failure moreover learning approaches handle tradeoff overly constrained learned model failure capture true dynamics reachable set learning aims learning set reachable states system compute controller gives intersection reachable states unsafe region computation reachable sets relies numerically solving hji equations incurs high computational complexity poor scalability gaussian process based reachability analysis proposed compute reachable set compared forward reachable set computation focuses computing set states starting system guaranteed safe approaches focus either systems work study control synthesis unknown system iii preliminary background control barrier function continuous function Î± belongs class k strictly increasing Î± continuous function Î± said belong extended class k strictly increasing Î± b consider system f xt g xt ut xt x r n system state ut u r input provided controller functions f xt g xt appropriate dimensions let safe set c defined c x x h x h x r continuously differentiable function say system safe respect c xt c time approaches used guarantee safety system respect safe set give definition zeroing cbf follows definition zeroing cbf zcbf consider dynamical system continuously differentiable function h x exists locally lipschitz extended class k function Î± x x following inequality holds sup x f x x g x u Î± h x function h zcbf paper focus zcbf extensions higher relative degree cbfs subject future work sufficient condition safety guarantee derived using zcbf follows lemma given dynamical system safe set defined continuously differentiable function h x r h zcbf defined x c forward invariant using lemma one solve controller time using quadratic program min u u x u q x x f x x g x u Î± h x u u r x r positive definite q x r b notations let x vector f x function use xj fj x denote component respectively let matrix use ai j denote element row column let xt vector time use xt j denote component xt comparisons vectors implemented elementwise bold symbols used represent intervals iv problem formulation consider system form system contains uncertainties hence f xt g xt unknown define feedback controller Âµ x u function maps system state control input given current system state xt time feedback controller Âµ denote system state time Ï• xt Âµ system given safe set defined consider implementation system system sampled using sampling period system states sampling time known z sampling time zeroorder hold zoh feedback controller Âµ applied system words ut Âµ z data set system side information let k n k denote finite set k samples pairs rk xtk utk k Ï• xtk Âµ Âµ represents hold zoh input ut utk time tk assume h xtk k following formally state assumptions assumption assume functions fj x gj x lipschitz continuous lipschitz constants lfj lgj respectively j n lipschitz constants known assume kf x k kg x k given lipschitz continuity commonly made assumption reachability safety analysis assumption bound system dynamics often seen safety analysis assumption assume safe set c control input set u compact additionally control input set u convex problem studied work follows problem given finite set samples rk xtk utk k k n generated implementing given control input utk time tk system whose dynamics unknown synthesize zoh feedback controller Âµ system safe respect set c x h x solution approach solution approach leverages lemma guarantee safety system first construct cbf constraint unknown system ensure safety calculate bound unknown system dynamics evaluate constructed cbf constraint finally formulate optimization problem solve control signal sample time construction cbf constraints unknown systems system model known system state observable time synthesis achieved efficiently using quadratic program consider system unknown dynamics makes difficult evaluate constraint given subsection construct cbf constraint evaluated sampling time unknown system guarantee holds time z sampling period z hence guarantee system safety inspired z define e xt f g Î± h xt f xt g xt Î± h xt definition given models difference cbf constraints evaluated states xt control input applied given xt f xt xt g xt ut Î± h xt f g Î± h e xt f g Î± h max xt xt guarantee side nonnegative safety system holds lemma define following quantities Î¸ u vuutxn lfj xm lgj Î¸ max Î¸ u existence Î¸ guaranteed assumption following bound maxxt xt calculate lower bound lemma let lÎ± lh lipschitz constants functions Î± h respectively let Î¸ defined given xt xt lhÎ¸ lÎ± g proof bound xt via xt f g Î± h xt f xt g xt Î± h xt f g xt f g xt f g xt f xt g xt Î± h Î± h xt xt f g xt f g f xt g xt h Î± h xt holds definition given holds adding subtracting xt f g holds triangle inequality since function h continuously differentiable k x k lh lh lipschitz constant hence xt f g g boundedness x proposition appendix xt f g f xt g xt due lipschitz continuity Î± h Î± h xt substituting yields lemma using lemma construct cbf constraint f g Î± h lhÎ¸ lÎ± g using holds lemma holds z however since system unknown compute xt kf g thus calculate constraint subsequent subsection address challenge b sufficient condition satisfying cbf constraint since consider systems system states time z observable hence xt known moreover term kf g known since system unknown subsection present estimate xt kf calculate constructed cbf constraint given estimate system state xt sampling period although impractical forward integrate unknown dynamics calculate xt bound using bound observed system state bound xt sampling period define Î² sup kf x g x uk existence Î² guaranteed assumption bound using following proposition proposition let xt x Âµ controller specifies control signal ut applied system time Ï• xt Âµ Ï• xt Âµ Î¸ e Î¸ given Î² given proof definition Ï• x Âµ Ï• xt Âµ Ï• xt Âµ z f xÏ„ g xÏ„ uÏ„ dÏ„ z f xÏ„ g xÏ„ uÏ„ f xt g xt uÏ„ dÏ„ z f xt g xt uÏ„ dÏ„ z Î¸ uÏ„ kxÏ„ xt dÏ„ holds definition Ï• xt Âµ holds triangle inequality holds proposition appendix applying gr inequality yields Ï• xt Âµ Ï• xt Âµ z Î¸ uÏ„ kxÏ„ xt dÏ„ z Î¸ uÏ„ exp Ï„ Î¸ ul dl dÏ„ z Ï„ e Î¸ dÏ„ Î¸ e holds holds gr inequality holds calculating inner integration holds integration parts proposition closely related thm thm upper bound distance two nonlinear systems established time proposition presents upper bound distance reachable states sampling period system proposition Î¸ e system state observed therefore calculate bound xt z integer z estimate unknown system dynamics following calculate bound kf g unknown system define Î³ u sup kg x kku u u u develop following result proposition let x Î¸ given Î² given following relation kf g f x g x Î¸ u Î³ u Î³ u defined proof kf g f x g x g u f x g x u g u g u kg utk u Î³ u holds adding subtracting term g utk holds triangle inequality proposition appendix holds fact Î³ utk kg utk proposition implies value f x x u known x x u u able calculate range f g following show construct f x g x u bound f g lemma let xtk rk two sample data points construct vector j fj x g x utk j j xtk j tk system dynamics f g satisfies f g Î¸ utk Î¸ utk Î¸ e Î¸ Î³ utk n thin interval proof mean value theorem must exist set states xÏ„j r n j n Ï„j tk j entry xÏ„j denoted xÏ„j j satisfies xÏ„j j j given set states xÏ„j r n j n construct n j xÏ„j j j let constructed define given show holds follows f g Î¸ utk Î³ utk n Î¸ utk xtk xtk Î³ utk n Î¸ utk xtk Î¸ utk kxtk Î³ utk n holds proposition fact sample data generated using zoh control input ut utk tk holds adding subtracting term xtk holds triangle inequality prove using following relation j xj j xÏ„j j Î¸ e Î¸ equality holds inequality holds proposition therefore bound kxtk kxtk Î¸ e Î¸ combining yields lemma proposition lemma provides us methods estimate cbf constraint given next subsection present optimization problem subject cbf constraint synthesis synthesis subsection first use proposition lemma evaluate cbf constraint given show synthesis using evaluated cbf constraint formulated program decompose program two convex subproblems present efficient synthesis define w utk Î¸ utk xtk nÎ¸ utk Î¸ e Î¸ Î³ utk using proposition lemma following upper bound e xt defined theorem let r n constructed r n e lÎ± Î¸ e max utk utk xt e u proof theorem follows lemma proposition lemma using theorem following result lemma let r n constructed r control signal u u satisfies following set relations w utk Î± h e w utk Î± h e control signal u satisfies f g u Î± h proof theorem xt e therefore holds w u utk Î± h xt u w u utk Î± h xt u using lemma f g u w u utk w u utk hence implies f g u Î± h xt u note xt u therefore lemma holds motivated lemma formulate following optimization problem sampling time z min u u u w u utk Î± h e u w u utk Î± h e u u u r r positive definite matrix according lemma control signal u u satisfying sampling time implemented sampling period z xt f xt g xt u Î± h xt holds time z hence following safety guarantee theorem let u control signal solves system safe time z applying control signal u sampling period z proof since u solves optimization problem constraints hold theorem xt e u thus constraints imply xt f xt g xt u Î± h xt xt furthermore definition e xt given relation given constraints xt f xt g xt u Î± h xt xt holds z finally applying lemma yields desired result theorem synthesis reduces solving optimization problem given observe objective function quadratic respect u however constraints convex respect u therefore solving problem given nontrivial following present approach solve control input sampling time z define slack variable p w u utk assumption p utk utk ku utk constraints rewritten Î± h lÎ± Î¸ e Î± h lÎ± Î¸ e Î± h lÎ± Î¸ e Î± h lÎ± Î¸ e constructed using since convex respect p linear respect p set constraints given convex respect thus use following convex program solve p sampling time min p p utk constraints given denote solution convex program p next solve using p using definition w utk Î³ utk define b p utk nÎ¸ utk Î¸ e Î¸ searching equivalent computing intersection u ball centered utk radius b characterize solution procedure using following lemma lemma control signal u feasible p w u utk solves exists p solves exists u u satisfies w u utk p u feasible solution proof first prove control signal u feasible exists p w u utk p solves since u feasible solution constraints hold definition e observe p w u utk satisfies constraints moreover constraint met since u feasible thus u u next prove exists p solves exists u u satisfies w u utk p u feasible solution using definition e p w u utk constraints hold implies hold additionally u u therefore u feasible solution combining arguments yields lemma theorem lemma compute control signal safety guarantee sampling time efficiently conclude section discussing sampleddata implementation unknown dynamics incorporated proposed approach ensure feasible need lÎ± Î¸ e Î± h w u utk max w u utk w u utk lÎ± Î¸ e Î± h w u utk max w u utk w u utk implementation captured term Î¸ e term decreases reducing sampling period sampling period approaches zero Î¸ e since system approximates continuoustime system controlled control signals additionally reducing sampling period helpful h reason lefthand side approaches zero thus convex program largest feasible region unknown system dynamics captured terms w u utk w u utk reducing sampling period make terms vanish however make w u utk approach zero data set rk asymptotically covers safe set case interval derived lemma approaches thin interval contains system dynamics additionally datadriven methods may also help reduce conservativeness introduced unknown dynamics subject future work vi numerical case study sample index x system trajectory induced proposed approach fig trajectory induced proposed approach section present numerical case study control synthesis dc motor system follows control affine dynamics follows u rotor current angular velocity u u stator current parameters system dynamics unknown normally obtained empirically practice initial state set safe set motor defined c x generate data set rk randomly generating trajectories sampling periods sampling period compare proposed approach baseline scenario baseline scenario system dynamics known control signal applied sampling time calculated solving following quadratic program sampling time z min u x f x x g x Î± h x fig present trajectory generated using proposed approach baseline trajectory generated using proposed approach baseline plotted using blue solid line red line respectively observe proposed approach baseline guarantee safety system however trajectories identical two major reasons causing trajectories different first system dynamics known implementing proposed approach thus cbf constraints given used baseline implements cbf constraint given second baseline aims minimizing energy used controller solving quadratic program sampling time unknown system dynamics lead program presented solved first solving convex program searching control signal u satisfies lemma finally observe proposed approach provides robustness compared baseline trajectory generated using proposed approach tends stay away boundaries safe set baseline vii conclusion paper studied problem control synthesis systems unknown dynamics constructed cbf constraint guarantee safety sampling period evaluated cbf constraint sampling time bounding reachable state unknown system dynamics formulated program subject cbf constraint calculate safe control input decomposed nonconvex program two convex programs involved proved synthesized controller guarantees safety unknown system proposed solution evaluated using numerical case study future work incorporate method improve bound cbf constraint learning nonlinear system dynamics references knight safety critical systems challenges directions proceedings international conference software engineering pp ames xu grizzle tabuada control barrier function based quadratic programs safety critical systems ieee transactions automatic control vol pp wang ames egerstedt safety barrier certificates multirobot systems ieee transactions robotics vol pp cohen belta approximate optimal control safetycritical systems control barrier functions ieee conference decision control ieee pp singletary chen ames control barrier functions systems input delays ieee conference decision control ieee pp cortez oetomo manzie choong control barrier functions mechanical systems theory application robotic grasping ieee transactions control systems technology breeden garg panagou control barrier functions systems arxiv preprint mannucci van kampen de visser chu safe exploration algorithms reinforcement learning controllers ieee transactions neural networks learning systems vol pp folkestad chen ames burdick datadriven control synthesizing control barrier functions koopman operators ieee control systems letters taylor singletary yue ames learning safetycritical control control barrier functions learning dynamics control pmlr pp jagtap pappas zamani control barrier functions unknown nonlinear systems using gaussian processes arxiv preprint wang theodorou egerstedt safe learning quadrotor dynamics using barrier certificates ieee international conference robotics automation icra ieee pp berkenkamp turchetta schoellig krause safe reinforcement learning stability guarantees advances neural information processing systems pp tomlin pappas sastry conflict resolution air traffic management study multiagent hybrid systems ieee transactions automatic control vol pp mellinger kushleyev kumar quadratic program trajectory generation heterogeneous quadrotor teams ieee international conference robotics automation ieee pp cheng orosz murray burdick safe reinforcement learning barrier functions continuous control tasks proceedings aaai conference artificial intelligence vol pp choi tomlin sreenath reinforcement learning control model uncertainty using control lyapunov functions control barrier functions arxiv preprint fisac akametalu zeilinger kaynama gillula tomlin general safety framework control uncertain robotic systems ieee transactions automatic control vol pp gillulay tomlin guaranteed safe online learning bounded system international conference intelligent robots systems pp gillula tomlin guaranteed safe online learning via reachability tracking ground target using quadrotor ieee international conference robotics automation pp akametalu fisac gillula kaynama zeilinger tomlin safe learning gaussian processes ieee conference decision control pp khalil grizzle nonlinear systems prentice hall upper saddle river nj vol bellman stability solutions linear differential equations duke mathematical journal vol pp unbehauen experimental physical parameter estimation thyristor driven using control engineering practice vol pp appendix proposition suppose assumption holds let x x u u kf x g x u f x g x Î¸ u kx x proof analyze kf x g x u f x g x consider component f x x u f x g x u x g x u j fj x g x u j x fj x xm gj x gj x lfj xm lgj kx x holds triangle inequality matrix multiplication holds assumption given holds j n proposition holds
graph neural resource allocation strategies spectroscopy tianshu peter astrophysical sciences princeton university princeton nj usa statistics machine learning princeton university princeton nj usa tianshuw abstract resource allocation problems often approached linear programming techniques many concrete allocation problems experimental observational sciences expressed form linear objective functions even objective linear parameters may known beforehand depend results experiment allocation determined address challenges present bipartite graph neural network architecture trainable resource allocation strategies items value constraints form two sets graph nodes connected edges corresponding possible allocations gnn trained simulations past problem occurrences maximize scientifically motivated objective function augmented infeasibility penalty amount feasibility violation tuned relation available slack system apply method optimize astronomical target selection strategy highly multiplexed subaru prime focus spectrograph instrument shows superior results direct gradient descent optimization extends capabilities currently employed solver uses linear objective functions development method enables fast adjustment deployment allocation strategies statistical analyses allocation patterns fully differentiable solutions resource allocation problems keywords submitted machine learning science technology introduction resource allocation deals distribution fixed amount resources number admissible actions minimize incurred cost maximize resulting utility problem encountered variety application areas including load distribution production planning computer resource allocation queuing control portfolio selection apportionment katoh ibaraki particularly sep resource allocation interested allocation problems arising astronomical research resource allocated observing time specific telescopes expensive operate utility given scientific information gained chosen set observations improved resource allocation strategies astronomers expect larger scientific yields lower operational costs challenge lies large number celestial objects could principle observed large number instrumental configurations could chosen powerful optimization packages constrained optimization like gurobi employed solve allocation problems maximum bertsekas approach several limitations first fastest algorithms require linear programming lp formulation one objective function constraints linear allocations f x c x subject ax b although many problems expressed lp permit cases different allocations interact interfere show cases easily arise second minimizers respective objective functions differentiable respect parameters problem costs precludes approach situations actual cost structure known priori often case scientific settings limitation overcome treating solver component extended optimization amos kolter agrawal et al vlastelica et al donti et al expense additional cost running solver inside optimization loop third increasingly accurate analyses astronomy cosmology demand detailed modeling processes define set ultimately observed celestial objects rix et al thus become commonplace perform hundreds thousands simulations determine actual selection function observing program ross et al mints hekker everett et al complex mip solvers run either directly component deep learning architecture would constitute computational bottleneck efforts paper present graph neural network gnn solver general resource allocation problems underlying bipartite graph comprises sets items constraints nodes connected edges representing possible allocations gnn trained simulations past problem instances learn take actions assign allocations satisfy constraints within posed resource limits maximizing utility function contrast reinforcement learning assign immediate rewards specific actions also solve assignment scheduling problem determine specific feasible sequence assignments maximize given objective observing program instead gnn predicts amount resources allocate every object least one feasible sequence recently demonstrated gnns continuous relaxation solve allocation problems better strong human heuristics parameterized evolutionary strategies even utility function learned resource allocation interacting environment cranmer et al show bipartite gnns efficiently learn obey feasibility constraints complex environments discrete allocations remainder paper structured follows section describe problem definition gnn solver detail section specialize method two concrete examples selecting optimal set galaxies observe upcoming prime focus spectrograph highly multiplexed instrument subaru telescope located maunakea hawai usa section discuss training initialization section compare results gnn direct gradient descent currently established baseline lp solver conclude section summary outlook possible extensions approach methodology problem definition following katoh ibaraki bretthauer shetty general resource allocation problem form linear programming problem seek maximizef xj subject hk xj k kineq hk xj k kineq kineq keq objective function f depends allocations xj j j either discrete xj tmax continuous xj tmax finite tmax constraint equations hk k k kineq keq limit configurations allocation distributed depending features objective function types constraints resource allocation problems form different classes cases objective function constraints linear convex known solutions federgruen groenevelt bretthauer shetty katoh ibaraki shi et al resource allocation problems remain conceptually challenging objective function constraints complicated forms numerically demanding allocations discrete number variables large find beneficial reparameterize objective function seek maximizef yi subject yi gi xj hk xj k kineq hk xj k kineq kineq keq means functions gi motivation behind reparameterization lies symmetries objective function often permit strong compression resource allocation full set j allocations much smaller number variables yi particular objective function depends total allocation single knapsack problem single pj xj suffices j resource allocation problems set correspond items value allocations made equation equation represent many types optimization problems makes resource allocation problems special h g functions permutation invariant exists functions Ï Ï† h xj Ï j Ï† xj zaheer et al consequently constraint item functions depend order arguments graph construction according equation set allocations xj provides arguments g h functions dependency structure suggest representation allocation problem form bipartite graph one set nodes represent constraints hk k k represents items gi whenever particular xj appears argument nodes gi hk graph edge connecting two nodes set allocations xj j j thus defines connectivity graph individual xj potentially represented multiple edges suitable representation bipartite graphs long history assignment allocation problems bertsekas wong saad et al nair et al particular relevance work constraints items form two classes similar permutation invariant functions demonstrate following example example multiple knapsack problem demonstrate ansatz multiple knapsack problem mkp given set items set k knapsacks vi wi value weight item ck capacity knapsack k task select k disjoint subsets items maximize total value subset assigned different knapsack whose capacity less total weight items subset seek argmax xik x k x vixik x wixik ck x k xik xik resource allocation although k allocation variables objective function actually depends independent combinations pk pi vixik pi viyi yi pk xik effectively combine constraints definition yi defining itemization functions gi x min pk xik mkp simplified written form equation argmax xik x viyi yi gi x min x k xik hk x wixik ck xik maximizers equation equivalent equation respect objective function latter formulation permits unfeasible assignments single item multiple knapsacks corrected single pass items removal one assigned knapsack formulation construct graph follows gi one item node hk one constraint node edges xik connect sets nodes form complete bipartite graph mkp one constraint equation per knapsack represent knapsacks items evident underlying functions structurally similar permutation invariant construction similar graph representation mip nair et al identical restrict problem objectives form p j cjxj directly identify item nodes xj allow arbitrary permutation invariant functions g modify relation xj yi equation also graph edges correspond elements aij matrix linear constraint equation ax b carry information feasibility whereas edges graph carry information allocation amount gnn definition unlike traditional mip solvers neural reformulation nair et al seek find solutions parameters problem fully determined mkp arise item values known priori addition seek architecture learns solve particular kind allocation problem rather running explicit solver every instance problem proposed vlastelica et al expected performance gains important statistical assessments probability particular allocations thus want describe allocation problems differentiable trainable model resource allocation edge update given node features b constraint node update given edge features connected item node features c item node update given edge features connected constraint node features global update given node features figure updates gnn block blue shows element updated black indicates elements involved update grey elements unused h g represent attributes two types nodes bipartite graph x represents edge attributes u global attributes graph parameters primes updated values h g functions allocation problems form two classes similar functions means need parameterize behavior classes every class element allows us model relations graph bipartite version gnn blocks defined battaglia et al specifically bipartite gnn block two distinct node models instead one regular gnn block node models depend attached edges corresponding nodes edge model resource allocation depends sets attached nodes whose features simply addition graph connectivity three types models needs access auxiliary features item weights mkp make sure element graph direct access information related role optimization problem see section concrete examples hypothesize competing demands available resources better met node model access edge features also node features opposite side edge therefore concatenate extended edge feature set expecting renders message passing efficient thus reduces number gnn blocks formally let nx nh ng nu number features carried edge constraint node item node global node respectively also let n g n h number different aggregators item constraint models summarize information carried extended edge features normally use four aggregators namely mean variance skewness kurtosis edge features unless number edges small define moments defining Ï† r r perceptron mlp gnn block thus comprised Ï† x Ï†h Ï†g Ï†u Ï† x r r nx updates edge features using previous edge features features two nodes connected edge global features Ï† h r h r nh updates constraint node features using previous constraint node features n h aggregators mean variance skewness kurtosis extended edge features number connected edges global features Ï† g r g r ng updates item node features using previous item node features aggregated edge features global features Ï† u r r nu updates global features using mean node features previous global features update sequence built similar way metalayer class pygeometric package fey lenssen particular place another mlp aggregation step renders models flexible reason handle permutation invariant functions Ï† h Ï† g instead merely symmetric functions zaheer et al updates proceed order figure first edge model given node features node models given respective edge features global model given node features stack gnn blocks perform batch normalization nodes edge features batch dimension given number nodes edges graph number gnn blocks depends complexity problem blocks corresponding steps negotiate competing demands minimizer equation like cranmer et al find generalizations tripartite even complex graphs conceivable address problems constraint item functions represented two classes resource allocation figure comparison noisy sigmoid function round function black curve exact sigmoid function shadow shows noise blue curve exact round function figure sharpness noise level blocks suffice leave determining optimal number blocks forthcoming work output Ï† x last gnn block real number corresponding xj calculated xj tmax Ïƒ problem requires integer allocations apply round function output training replace round function noisy sigmoid function edward z u x x z f x floor x Ïƒ k x floor x k sharpness l noise level see figure loss function define loss function negative lagrangian equation l xj yi Î» x k pk hk xj yi gi xj pk penalty functions appropriate constraint violations relu amount penalty Î» formally needs infinite feasible minimizers equation accepted relax requirement increasing penalty large number network training empirically find often leads feasible solutions amount constraint violation tolerated due slack realistic settings solutions exact feasibility needed one make minor resource allocation figure fiber layout prime focus spectrograph coordinates circles indicate patrol region fibers adjustments greedy algorithm removing least valuable items case overallocation application pfs target selection problem prime focus spectrograph pfs highly multiplexed optical spectrograph soon installed subaru telescope located peak maunakea hawai usa tamura et al instrument equipped movable fibers distributed field view fibers moved laterally collect light astronomical objects pointed stay place configurable amount time feed light dispersive elements spectrograph ultimately detector forming one exposure exposures every fiber independently positioned within circle mm diameter actuator whole fiber assembly packed hexagonal pattern mm separation see figure resource allocation overlap adjacent patrol regions enables full sky target selection problem given total time allocation budget list astronomical targets celestial positions characterizing features target selection strategy decide targets observe possibly every single one long cranmer et al demonstrated gnns solve allocation problem even implicit objective function better heuristics simple parameterized strategies approach allowed allocations xj tmax independent requirement p j xj multiplexed instrument pfs solutions much strongly constrained allocations fibers given exposure must identical allocations different targets may differ observing targets often others planned pfs galaxy evolution program case study exposure time fixed hours total observing time budget sum exposure times specifically let number targets single field view telescope objective function f measures scientific utility function time spent target f Ï„i related properties selected galaxies specific astrophysical questions hand contrast cranmer et al demand work f known function unlike lupton et al blanton et al f restricted specific linear functions allow arbitrary function let Ï†i set fibers reach position galaxy let Ïˆk k set galaxies fiber k reach total time spent field target selection problem defined following optimization problem arg max tik f Ï„i Ï„i min x tik tmax x tik k tik tmax tik time fiber k spends galaxy redefined times integer multiples base exposure time maximum time tmax single galaxy receive set scientific program compared general form resource allocation problem equation see Ï„ correspond x respectively galaxy reached two fibers limit aggregator item mlp Ï† g simple sum n g using mean variance yield benefits moments would resource allocation principle must make sure fiber observes one galaxy galaxy observed one fiber exposure x tikl tik x tikl x tikl tikl tikl time spent target fiber k exposure however prove appendix finding sequence assignments always possible long explicitly term appears objective constraint functions found polynomial thus focus optimization problem equation without worry sequence decomposition utility function cases written sum individual utilities galaxy f Ï„i p fi Ï„i leads nonlinear mkp already outside scope lp solvers however total scientific yield generally depends collective properties observed galaxies example scientific study may require least certain number galaxies observed combined measurement reaches desired significance utility function thus sum separable part part f Ï„i x fi Ï„i Ï„i define specific form f two cases final loss function specialization equation problem equation l tik Ï„i Î» x p x tik case predefined galaxy classes galaxy evolution program pfs subaru strategic program ssp survey takada et al currently plans target variety galaxies tentatively identified distinct science cases defined selection criteria sets galaxies satisfies criteria define galaxy classes science cases also defines number exposures galaxy respective class receive k relation fibers galaxies changes time due effects like dithering Ï†i Ïˆk split one constraint multiples make sure constraint related one fixed constraint node graph resource allocation table predefined galaxy classes case required exposure times tm determined pfs galaxy evolution program basis expected performance instrument costs cm provide current baseline found manual exploration nm denotes number galaxies satisfy class selection criteria reference field tm h cm nm tm h cm nm aeach galaxy class independent exposure time requirement table shows galaxy classes number galaxies satisfying selection criteria reference field total number visits available time spent single galaxy limited tmax general goal designing criteria costs cm table program observes many galaxies possible every science case ideally reasonably equitable distribution formalize means objective function maximizes minimal completeness classes f Ï„i min nm x Ïƒ Ï„i tm Î¸m class tm proposed exposure time nm number galaxies field falling class Î¸m denote nm number fully observed galaxies class training use sigmoid function indicated smoothly approximate step function test time replace actual step function count distinct allocations chose penalty function p squared relu function inequality constraint fiber allocation capacity need exhaust resources gain f achieved equation evidently entirely seeks balance allocation across classes comprised thousands galaxies allocations need determined exact form equation could chosen differently underlying idea motivated current survey design principle pfs galaxy evolution program resource allocation case general objective function case envision smaller observing program could carried pfs single night thus adopt modest allocation h tmax instead adopting predefined classes combine two objectives maximizing number galaxies spectroscopic redshifts z determined precision Î´z sample galaxies used reconstruct cosmic web jasche et al horowitz et al creating sample least faint galaxies relatively large redshift z within range masses mhalo observed least purpose sample aggregate spectra achieve high ratio test presence specific spectral features carnall et al et al specific definitions objectives hypothetical serve example directly fiber allocation strategy pfs objective function thus contains two parts separable part objective success rate redshift measurements success rate number calculated fitting simulated noisy spectrum galaxy inferring redshift estimated spectrum desired precision use galaxy simulation cranmer et al employs single spectral type every galaxy redshift success function redshift mass exposure time calculate success rate sri galaxy exposures linearly interpolate fi Ï„i Ï„isri Ï„i Ï„i sri sri sri Ï„i Ï„i sri sri sri Ï„i Ï„i sri sri sri Ï„i part objective amounts counting number galaxies satisfy specified redshift mass requirements observed least one exposure let Î¸ set galaxies adopt following continuous approximation Ï„i Ïƒ n n x Ïƒ Ï„i n denotes number observed galaxies satisfying selection requirements objective term prefers n saturated n prefactor large number compared p fi chosen ensure second objective receives preference first choice needs made optimization sharpness sigmoid functions equation two hyperparameters larger sharpness leads better approximation step function also difficult optimize one could start small sharpness resource allocation parameters gradually increase training achieve good results fixed parameters hyperparameter search chose penalty function case reduce contrast case time allocation strongly limited insufficient saturate objectives large number available galaxies expect underallocation penalty become largely obsolete end training provides meaningful gradient directions training feature sets training particular importance feature set items cases correspond one galaxy per node thus need provide initial item nodes features meaningfully describe optimization problem perspective galaxies case feature set comprises tm version class index table extra random number distinguishes different galaxies class nodes edges global features graph initialized zeros case item node features initialized sri sri sri sri equation boolean variable showing whether galaxy satisfies redshift mass requirements equation nodes edges global features graph initialized zeros cases use graphs train gnn model graphs validate graphs test behavior overlapping region training validating testing graphs model trained adam kingma ba nvidia gpu start phase fixed penalty strength Î» followed training exponentially increasing Î» training parameters shown table coarse hyperparameter search learning rate penalty factor noise level noisy sigmoid function learning rates cases searched penalty factor case varied case noise level searched sharpness noisy sigmoid method fixed dimensionality gnn functions nx nh nu set ng set according item features listed experimented features found improvements results report gnn test scores table table terms objective function well adherence constraints latter end define total overtime unused time p k max p tik p k max p tik calculate fraction time compared total available observation time tall result written resource allocation table training parameters lr learning rate Î» penalty factor l noise level training lr Î» l lr Î»start Î»end l case case example means value objective function overtime unused time case balancing predefined classes training test data derived galaxy catalog provided pfs galaxy evolution program classes table use catalog saito et al based photometric catalog laigle et al since area coverage catalog small simulations multiple pfs pointings repeat central region catalog tiling pattern final extended catalog covers contiguous area remaining classes artificially superposed region number densities consistent expectation galaxy catalog label indicating class belongs compare gnn approach currently employed network flow optimization method based method blanton et al similar approach constructs graph connecting fibers galaxies solves linear problem graph mip optimizer gurobi given predetermined costs every galaxy class f Ï„i p cm Î¹ cm Ï„i tm Î¹ denotes indicator function programs like case implemented creating graph one fiber node per exposure network flow optimization guarantees feasibility permit adjustment class costs maximize objective function therefore adopt baseline representation current state development fixed costs cm table identified manual exploration linear objective listed important emphasize costs determined general goal namely achieve equitable distribution completeness across galaxy classes specific objective function equation flexible optimization objective function also solve problem equation form equation directly tik ordinary gradient descent use equation convert tij integers test time tried different types gradient descent adam momentum results similar results shown table test fields gnn method outperforms resource allocation table case results terms values objective function equation minimal completeness across classes table network flow optimization preset costs direct gradient descent equation gd gnn method independent test fields percentages denote fraction full time allocation overallocated underallocated averaged fibers field id gd gnn current baseline gradient descent solver despite trained fields different test fields fiber assignment provides good baseline minimum completeness leaves time unallocated apparent contradiction indication suboptimal performance method instead suggests class costs table suboptimal specific objective function gd method like gnn optimizes equation improves upon baseline find depending initialization require large number iterations converge local minimum expected optimization problem gnn benefits learning model makes galaxies valuable relation constraints communicates message passing graph gnn mlps total parameters encode strategy solving equation galaxy fiber configurations given training data instrument result similar galaxies generally evaluated similarly generalization leads increased completeness even though solution optimized test fields respect feasibility unused time concern case expected conflicts highly valuable galaxies prevent full utilization time allocation confirmed test results instance canonical problem arises multiple galaxies located patrol region single fiber partial overlap patrol regions conflicts solved utilizing neighboring fiber achieved fraction available time used increase completeness respective class turn objective function however comparison baseline gnn approach evidently converts unused time gains objective reveals suboptimality predetermine costs complex resource allocation problem interestingly gd achieve higher completeness gnn despite utilizing almost available time resource allocation overtime violations design impossible network flow method almost completely avoided gnn strategy detail section minor overtime violation acceptable case could avoided entirely increasing penalty strength beyond final value table brute force solver minor overtime allocations smaller unused allocations consistent asymmetry penalty addition highest objective function values gnn also fastest method every field baseline gd need run runtime gnn less second training done however even include training time gnn still faster single run network flow optimization gurobi case optimizing general objective function training test data derived universemachine simulations behroozi et al size comprising galaxies single pfs field view spectrum simulation follows approach cranmer et al uses single spectral type massive elliptical galaxy artificially redshifted scaled amplitude match expected performance pfs given stellar mass stellar masses predicted universemachine halo masses according scaling relation girelli et al precision redshift estimates determined fitting known spectrum template galaxy spectra presence constant sky spectrum corresponding poisson shot noise procedure constitutes scenario spectral misclassification impossible catastrophic outliers rare case directly solved lp techniques main aspect problem lies determination relative importance two competing objectives well individual utilities objective precision redshift estimation therefore adapt known heuristic approach precondition problem express lp problem first randomly select galaxies satisfying redshift halo mass conditions label galaxies class observed single exposure giving class infinite costs ensures saturate equation chose proposed time allocation Ï„i galaxies n maximizes expected gain Ï„i h fi Ï„ Ï„ dantzig fi defined equation mip solver used case run n classes n classes comprised one galaxy specified proposed time expected utility fi Ï„i classes defined separately two objectives galaxies class used redshift measurement necessarily leading suboptimal solutions galaxies useful objectives also run gradient descent method comparison results shown table second objective term saturated resource allocation table case test results terms values objective function equation aggregated redshift success rate second objective equation fully saturated design three competing strategies independent test fields percentages denote fraction full time allocation overallocated underallocated averaged fibers field id gd gnn cases show total redshift success rate equation objective see results gnn method superior gd baseline method terms objective function result demonstrates method capable finding effective strategies allocating resources general test case combines separable objectives note gd method closer gnn results case attribute reduced volume parameter space due shorter program times tmax instead tmax also find gnn method yields mild levels feasibility violations although could principle avoid violations increasing penalty factor Î» allow observations pfs simultaneously allocate fibers calibration targets decided ignore operational complication work numbers calibrations measurements flexible compensate small amount unused time calibration allocations summary outlook resource allocation problems arise many application areas remain challenging especially involve discrete allocation spaces objectives paper present bipartite gnn architecture learns strategy solving general resource allocation problems based message passing graph formed nodes representing items value allocation constraints respectively connected edges corresponding possible allocations trained minimize objective function augmented penalty constraint violations using instances problem either historical occurrences simulations capture relevant aspects problem test time apply gnn method target selection problem astronomy given total observing time budget amounts choosing celestial sources within given sky area observed long specializing resource allocation highly multiplexed instrument prime focus spectrograph subaru telescope maunakea hawai results additional complication assign discrete identical exposure times sources observed simultaneously fibers instrument demonstrate gnn method finds efficient allocation strategies two realistic problem settings objectives compare results two direct solvers one performing network optimization predetermined costs directly solves possible allocations gradient descent method yields higher values objective function cases every test field formally guarantees feasibility infinitely large penalties recommend increase penalty term training feasibility achieved feasibility violations deemed tolerable tuning feasibility penalty also allows exploration strategies systems amount slack surplus expect case pfs development gnn method resource allocations bring two important benefits future work first runtime gnn solution much shorter direct solvers order second compared several hours cases substantial accelerations neural mip solvers also found nair et al case performing gnn optimization precondition traditional mip solver lead substantially reduced computational costs maintaining guaranteed feasibility solver either option render practically doable roll strategy updates large number problem instances assess probabilities item receives amount allocation selection function critical importance precision analyses astrophysics cosmology second problems require balancing priorities different kinds items galaxies case traditionally established beforehand respective utilities known priori routinely case scientific experiments complexity task renders unlikely manual exploration priorities yield results gnn provides differentiable architecture thereby exposing relevant parameters problem optimization similar cranmer et al intend make use capability forthcoming works train another neural network learn utility galaxies based easily observable features instead assuming utilities known done test case permutation invariance flexible node edge models gnns render exceptionally well suited resource allocation problems suspect also work well auction strategies huang et al interesting questions beyond scope work relate goal explainable ai instance information passed nodes graph many steps needed achieve results role global model play references acknowledgements authors want thank kiyoto yabe help application case work supported ai accelerator program schmidt futures foundation references koppelaar de groot resource allocation conflict avoidance broadcast communications ieee annual international symposium personal indoor mobile radio communications pimrc pp url http agrawal amos barratt boyd diamond kolter z differentiable convex optimization layers advances neural information processing systems amos b kolter j optnet differentiable optimization layer neural networks url http battaglia hamrick j bapst sanchez zambaldi malinowski tacchetti raposo santoro faulkner gulcehre song ballard gilmer dahl vaswani allen nash langston dyer heess wierstra kohli botvinick vinyals li pascanu relational inductive biases deep learning graph networks arxiv url https behroozi wechsler hearin conroy universemachine correlation galaxy growth dark matter halo assembly monthly notices royal astronomical society url https bertsekas network optimization continuous discrete models athena scientific url https blanton lin lupton maley young zehavi loveday j efficient targeting strategy multiobject spectrograph surveys sloan digital sky survey tiling algorithm astronomical journal url https bretthauer shetty b nonlinear resource allocation problem operations research url http carnall mclure dunlop cullen mcleod wild johnson appleby amorin bolzonella castellano cimatti cucciati gargiulo garilli marchi pentericci pozzetti references schreiber talia zamorani vandels survey starformation histories massive quiescent galaxies z monthly notices royal astronomical society url https cranmer melchior nord b unsupervised resource allocation graph neural networks url http dantzig b extremum problems operations research url https donti rolnick kolter j learning method optimization hard constraints url http edward backpropagation learning systems functions proceedings world congress neural networks everett yanny kuropatkin huff zhang myles masegian allam bernstein splettstoesser sheldon jarvis amon harrison choi hartley alarcon gruen eckert prat tabbutt busti becker maccrann diehl tucker bertin jeltema gruendl bechtol carnero rosell abbott aguena annis bacon bhargava brooks burke carrasco kind carretero castander conselice costanzi da costa pereira de vicente derose desai eifler evrard ferrero fosalba frieman gaztanaga gerdes gutierrez hinton hollowood honscheid huterer james kent krause kuehn lahav lima lin maia marshall melchior menanteau miquel mohr morgan muir ogando palmese plazas romer roodman sanchez scarpine serrano smith suchyta swanson tarle troxel varga weller j wilkinson dark energy survey year results measuring survey transfer function balrog url http federgruen groenevelt greedy procedure resource allocation problems necessary sufficient conditions optimality oper res fey lenssen fast graph representation learning pytorch geometric girelli pozzetti bolzonella giocoli marulli baldi references mass relation past gyr standard Î»cdm model astronomy astrophysics supplement series horowitz zhang lee kooistra tardis ii synergistic density reconstruction lyÎ± forest spectroscopic galaxy surveys applications protoclusters cosmic web astrophysical journal url https huang han chiang poor resource allocation cooperative communications ieee journal selected areas communications url http jasche leclercq wandelt past present cosmic structure sdss main sample journal cosmology astroparticle physics url https katoh ibaraki resource allocation problems springer us boston pp url https kingma ba j adam method stochastic optimization international conference learning representations iclr san diego ca usa may conference track proceedings url http laigle mccracken ilbert hsieh davidzon capak hasinger silverman pichon coupon aussel le borgne caputi cassata chang civano dunlop fynbo kartaltepe koekemoer le f evre le floc h leauthaud lilly lin marchesi salvato sanders scoville smolcic stockmann taniguchi tasca toft vaccari zabl j catalog exploring z universe half million galaxies astrophysical journal supplement series lupton maley young sloan digital sky survey heuristic url http mints hekker selection functions large spectroscopic surveys astronomy astrophysics supplement series nair bartunov gimeno von glehn lichocki lobov donoghue sonnerat tjandraatmadja wang addanki hapuarachchi keck keeling kohli ktena li vinyals zwols solving mixed integer programs using neural networks url http rix hogg boubert brown casey drimmel everall fouesneau selection functions references astronomical data modeling space density white dwarfs worked example url http ross beutler chuang seo cuesta percival burden grieb reid brownstein dawson eisenstein ho kitaura nichol olmstead prada saito schneider thomas tinker tojeiro wang white zhao clustering galaxies completed baryon oscillation spectroscopic survey observational systematics baryon acoustic oscillations correlation function monthly notices royal astronomical society url https saito de la torre ilbert dubois yabe coupon j synthetic emission line cosmos catalogue hÎ± oii galaxy luminosity functions counts z monthly notices royal astronomical society url https vazdekis la barbera beasley ferreras negri vecchia sub one per cent mass fractions young stars red massive galaxies nature astronomy url https shi zhang qin faster algorithm resource allocation problem convex cost functions journal discrete algorithms url https takada ellis chiba greene aihara arimoto bundy cohen graves gunn heckman hirata ho kneib le f evre lin murayama nagao ouchi seiffert silverman spergel strauss sugai suto takami wyse extragalactic science cosmology galactic archaeology subaru prime focus spectrograph publications astronomical society japan url https tamura takato shimono moritani yabe ishizuka ueda kamata aghazarian arnouts barban barkhouser borges braun carr chabaud chang chen chiba chou chu cohen de almeida de oliveira de oliveira dekany dohlen dos santos j dos santos ellis fabricius ferrand ferreira golebiowski greene gross gunn hammond harding hart heckman hirata ho hope hovland hsu hu huang references jaquet jing karr kimura king komatsu le brun le f evre le fur le mignant ling loomis lupton madec mao marrara mendes de oliveira minowa morantz murayama murray ohyama orndorff pascal pereira reiley reinecke ritter roberts schwochert seiffert smee sodre spergel steinkraus strauss surace suto suzuki swinbank tait takada tamura tanaka tresse verducci vibert vidal wang wen yan yasuda prime focus spectrograph pfs subaru telescope overview recent progress future perspectives evans simard takami eds airborne instrumentation astronomy vi vol society instrumentation engineers spie conference series vlastelica paulus musil martius differentiation blackbox combinatorial solvers international conference learning representations iclr url https wong saad inference optimization real edges sparse graphs statistical physics perspective physical review e statistical nonlinear soft matter physics pt url http zaheer kottur ravanbakhsh poczos salakhutdinov smola j deep sets guyon luxburg bengio wallach fergus vishwanathan garnett eds advances neural information processing systems curran associates pp url http references appendix proof theorem let v set vertices e set edges hypergraph g v e connectivity graph represented incidence matrix r aij edge j connected vertex otherwise aij time allocations tikl galaxy fiber k exposure l equation represented vectors el l jth element el equals tikl jth edge e connects item node constraint node similarly tik represented vector etot jth element etot equals tik target selection problem equation written arg max etot f etot etot etot want decompose etot set el satisfy etot x el el el theorem given solution etot problem equation exists least one set et satisfying equation proof induction etot theorem holds trivially assume statement true etot satisfies etot etot find e etot e etot e problem converted problem thus find subset es etot e p l el combining el e gives decomposition etot thus theorem equivalent existence e given following problem etot e etot e e etot satisfies etot etot references let av vth row u etot v u must av e problem becomes aue av etot e e generalize problem linear system e take number aue av e etot e therefore theorem equivalent existence integer solutions equation existence integer solutions guranteed following lemma lemma solution set problem equation convex polytope contains least one integer point proof first show solution set empty obviously solution consider arbitrary corner polytope e corner determined linearly independent equations equations come bottom two conditions directly give value corresponding element e remaining undetermined elements e determined first two conditions linear equations defined invertible square submatrix since graph bipartite totally unimodular means square submatrix determinant submatrix invertible determinant cramer rule inverse matrix also integral matrix thus solution linear equations undetermined elements e integers therefore corner solution set integer point set must least one corner e solution problem equation time complexity find decomposition find sequence el recursively finding e finding e slower polynomial time randomly choose vector c maximize c e within polytope since linear programming problems solved polynomial time finding e sequence el also done polynomial time
graph neural resource allocation strategies spectroscopy tianshu peter astrophysical sciences princeton university princeton nj usa statistics machine learning princeton university princeton nj usa tianshuw abstract resource allocation problems often approached linear programming techniques many concrete allocation problems experimental observational sciences expressed form linear objective functions even objective linear parameters may known beforehand depend results experiment allocation determined address challenges present bipartite graph neural network architecture trainable resource allocation strategies items value constraints form two sets graph nodes connected edges corresponding possible allocations gnn trained simulations past problem occurrences maximize scientifically motivated objective function augmented infeasibility penalty amount feasibility violation tuned relation available slack system apply method optimize astronomical target selection strategy highly multiplexed subaru prime focus spectrograph instrument shows superior results direct gradient descent optimization extends capabilities currently employed solver uses linear objective functions development method enables fast adjustment deployment allocation strategies statistical analyses allocation patterns fully differentiable solutions resource allocation problems keywords submitted machine learning science technology introduction resource allocation deals distribution fixed amount resources number admissible actions minimize incurred cost maximize resulting utility problem encountered variety application areas including load distribution production planning computer resource allocation queuing control portfolio selection apportionment katoh ibaraki particularly sep resource allocation interested allocation problems arising astronomical research resource allocated observing time specific telescopes expensive operate utility given scientific information gained chosen set observations improved resource allocation strategies astronomers expect larger scientific yields lower operational costs challenge lies large number celestial objects could principle observed large number instrumental configurations could chosen powerful optimization packages constrained optimization like gurobi employed solve allocation problems maximum bertsekas approach several limitations first fastest algorithms require linear programming lp formulation one objective function constraints linear allocations f x c x subject ax b although many problems expressed lp permit cases different allocations interact interfere show cases easily arise second minimizers respective objective functions differentiable respect parameters problem costs precludes approach situations actual cost structure known priori often case scientific settings limitation overcome treating solver component extended optimization amos kolter agrawal et al vlastelica et al donti et al expense additional cost running solver inside optimization loop third increasingly accurate analyses astronomy cosmology demand detailed modeling processes define set ultimately observed celestial objects rix et al thus become commonplace perform hundreds thousands simulations determine actual selection function observing program ross et al mints hekker everett et al complex mip solvers run either directly component deep learning architecture would constitute computational bottleneck efforts paper present graph neural network gnn solver general resource allocation problems underlying bipartite graph comprises sets items constraints nodes connected edges representing possible allocations gnn trained simulations past problem instances learn take actions assign allocations satisfy constraints within posed resource limits maximizing utility function contrast reinforcement learning assign immediate rewards specific actions also solve assignment scheduling problem determine specific feasible sequence assignments maximize given objective observing program instead gnn predicts amount resources allocate every object least one feasible sequence recently demonstrated gnns continuous relaxation solve allocation problems better strong human heuristics parameterized evolutionary strategies even utility function learned resource allocation interacting environment cranmer et al show bipartite gnns efficiently learn obey feasibility constraints complex environments discrete allocations remainder paper structured follows section describe problem definition gnn solver detail section specialize method two concrete examples selecting optimal set galaxies observe upcoming prime focus spectrograph highly multiplexed instrument subaru telescope located maunakea hawai usa section discuss training initialization section compare results gnn direct gradient descent currently established baseline lp solver conclude section summary outlook possible extensions approach methodology problem definition following katoh ibaraki bretthauer shetty general resource allocation problem form linear programming problem seek maximizef xj subject hk xj k kineq hk xj k kineq kineq keq objective function f depends allocations xj j j either discrete xj tmax continuous xj tmax finite tmax constraint equations hk k k kineq keq limit configurations allocation distributed depending features objective function types constraints resource allocation problems form different classes cases objective function constraints linear convex known solutions federgruen groenevelt bretthauer shetty katoh ibaraki shi et al resource allocation problems remain conceptually challenging objective function constraints complicated forms numerically demanding allocations discrete number variables large find beneficial reparameterize objective function seek maximizef yi subject yi gi xj hk xj k kineq hk xj k kineq kineq keq means functions gi motivation behind reparameterization lies symmetries objective function often permit strong compression resource allocation full set j allocations much smaller number variables yi particular objective function depends total allocation single knapsack problem single pj xj suffices j resource allocation problems set correspond items value allocations made equation equation represent many types optimization problems makes resource allocation problems special h g functions permutation invariant exists functions Ï Ï† h xj Ï j Ï† xj zaheer et al consequently constraint item functions depend order arguments graph construction according equation set allocations xj provides arguments g h functions dependency structure suggest representation allocation problem form bipartite graph one set nodes represent constraints hk k k represents items gi whenever particular xj appears argument nodes gi hk graph edge connecting two nodes set allocations xj j j thus defines connectivity graph individual xj potentially represented multiple edges suitable representation bipartite graphs long history assignment allocation problems bertsekas wong saad et al nair et al particular relevance work constraints items form two classes similar permutation invariant functions demonstrate following example example multiple knapsack problem demonstrate ansatz multiple knapsack problem mkp given set items set k knapsacks vi wi value weight item ck capacity knapsack k task select k disjoint subsets items maximize total value subset assigned different knapsack whose capacity less total weight items subset seek argmax xik x k x vixik x wixik ck x k xik xik resource allocation although k allocation variables objective function actually depends independent combinations pk pi vixik pi viyi yi pk xik effectively combine constraints definition yi defining itemization functions gi x min pk xik mkp simplified written form equation argmax xik x viyi yi gi x min x k xik hk x wixik ck xik maximizers equation equivalent equation respect objective function latter formulation permits unfeasible assignments single item multiple knapsacks corrected single pass items removal one assigned knapsack formulation construct graph follows gi one item node hk one constraint node edges xik connect sets nodes form complete bipartite graph mkp one constraint equation per knapsack represent knapsacks items evident underlying functions structurally similar permutation invariant construction similar graph representation mip nair et al identical restrict problem objectives form p j cjxj directly identify item nodes xj allow arbitrary permutation invariant functions g modify relation xj yi equation also graph edges correspond elements aij matrix linear constraint equation ax b carry information feasibility whereas edges graph carry information allocation amount gnn definition unlike traditional mip solvers neural reformulation nair et al seek find solutions parameters problem fully determined mkp arise item values known priori addition seek architecture learns solve particular kind allocation problem rather running explicit solver every instance problem proposed vlastelica et al expected performance gains important statistical assessments probability particular allocations thus want describe allocation problems differentiable trainable model resource allocation edge update given node features b constraint node update given edge features connected item node features c item node update given edge features connected constraint node features global update given node features figure updates gnn block blue shows element updated black indicates elements involved update grey elements unused h g represent attributes two types nodes bipartite graph x represents edge attributes u global attributes graph parameters primes updated values h g functions allocation problems form two classes similar functions means need parameterize behavior classes every class element allows us model relations graph bipartite version gnn blocks defined battaglia et al specifically bipartite gnn block two distinct node models instead one regular gnn block node models depend attached edges corresponding nodes edge model resource allocation depends sets attached nodes whose features simply addition graph connectivity three types models needs access auxiliary features item weights mkp make sure element graph direct access information related role optimization problem see section concrete examples hypothesize competing demands available resources better met node model access edge features also node features opposite side edge therefore concatenate extended edge feature set expecting renders message passing efficient thus reduces number gnn blocks formally let nx nh ng nu number features carried edge constraint node item node global node respectively also let n g n h number different aggregators item constraint models summarize information carried extended edge features normally use four aggregators namely mean variance skewness kurtosis edge features unless number edges small define moments defining Ï† r r perceptron mlp gnn block thus comprised Ï† x Ï†h Ï†g Ï†u Ï† x r r nx updates edge features using previous edge features features two nodes connected edge global features Ï† h r h r nh updates constraint node features using previous constraint node features n h aggregators mean variance skewness kurtosis extended edge features number connected edges global features Ï† g r g r ng updates item node features using previous item node features aggregated edge features global features Ï† u r r nu updates global features using mean node features previous global features update sequence built similar way metalayer class pygeometric package fey lenssen particular place another mlp aggregation step renders models flexible reason handle permutation invariant functions Ï† h Ï† g instead merely symmetric functions zaheer et al updates proceed order figure first edge model given node features node models given respective edge features global model given node features stack gnn blocks perform batch normalization nodes edge features batch dimension given number nodes edges graph number gnn blocks depends complexity problem blocks corresponding steps negotiate competing demands minimizer equation like cranmer et al find generalizations tripartite even complex graphs conceivable address problems constraint item functions represented two classes resource allocation figure comparison noisy sigmoid function round function black curve exact sigmoid function shadow shows noise blue curve exact round function figure sharpness noise level blocks suffice leave determining optimal number blocks forthcoming work output Ï† x last gnn block real number corresponding xj calculated xj tmax Ïƒ problem requires integer allocations apply round function output training replace round function noisy sigmoid function edward z u x x z f x floor x Ïƒ k x floor x k sharpness l noise level see figure loss function define loss function negative lagrangian equation l xj yi Î» x k pk hk xj yi gi xj pk penalty functions appropriate constraint violations relu amount penalty Î» formally needs infinite feasible minimizers equation accepted relax requirement increasing penalty large number network training empirically find often leads feasible solutions amount constraint violation tolerated due slack realistic settings solutions exact feasibility needed one make minor resource allocation figure fiber layout prime focus spectrograph coordinates circles indicate patrol region fibers adjustments greedy algorithm removing least valuable items case overallocation application pfs target selection problem prime focus spectrograph pfs highly multiplexed optical spectrograph soon installed subaru telescope located peak maunakea hawai usa tamura et al instrument equipped movable fibers distributed field view fibers moved laterally collect light astronomical objects pointed stay place configurable amount time feed light dispersive elements spectrograph ultimately detector forming one exposure exposures every fiber independently positioned within circle mm diameter actuator whole fiber assembly packed hexagonal pattern mm separation see figure resource allocation overlap adjacent patrol regions enables full sky target selection problem given total time allocation budget list astronomical targets celestial positions characterizing features target selection strategy decide targets observe possibly every single one long cranmer et al demonstrated gnns solve allocation problem even implicit objective function better heuristics simple parameterized strategies approach allowed allocations xj tmax independent requirement p j xj multiplexed instrument pfs solutions much strongly constrained allocations fibers given exposure must identical allocations different targets may differ observing targets often others planned pfs galaxy evolution program case study exposure time fixed hours total observing time budget sum exposure times specifically let number targets single field view telescope objective function f measures scientific utility function time spent target f Ï„i related properties selected galaxies specific astrophysical questions hand contrast cranmer et al demand work f known function unlike lupton et al blanton et al f restricted specific linear functions allow arbitrary function let Ï†i set fibers reach position galaxy let Ïˆk k set galaxies fiber k reach total time spent field target selection problem defined following optimization problem arg max tik f Ï„i Ï„i min x tik tmax x tik k tik tmax tik time fiber k spends galaxy redefined times integer multiples base exposure time maximum time tmax single galaxy receive set scientific program compared general form resource allocation problem equation see Ï„ correspond x respectively galaxy reached two fibers limit aggregator item mlp Ï† g simple sum n g using mean variance yield benefits moments would resource allocation principle must make sure fiber observes one galaxy galaxy observed one fiber exposure x tikl tik x tikl x tikl tikl tikl time spent target fiber k exposure however prove appendix finding sequence assignments always possible long explicitly term appears objective constraint functions found polynomial thus focus optimization problem equation without worry sequence decomposition utility function cases written sum individual utilities galaxy f Ï„i p fi Ï„i leads nonlinear mkp already outside scope lp solvers however total scientific yield generally depends collective properties observed galaxies example scientific study may require least certain number galaxies observed combined measurement reaches desired significance utility function thus sum separable part part f Ï„i x fi Ï„i Ï„i define specific form f two cases final loss function specialization equation problem equation l tik Ï„i Î» x p x tik case predefined galaxy classes galaxy evolution program pfs subaru strategic program ssp survey takada et al currently plans target variety galaxies tentatively identified distinct science cases defined selection criteria sets galaxies satisfies criteria define galaxy classes science cases also defines number exposures galaxy respective class receive k relation fibers galaxies changes time due effects like dithering Ï†i Ïˆk split one constraint multiples make sure constraint related one fixed constraint node graph resource allocation table predefined galaxy classes case required exposure times tm determined pfs galaxy evolution program basis expected performance instrument costs cm provide current baseline found manual exploration nm denotes number galaxies satisfy class selection criteria reference field tm h cm nm tm h cm nm aeach galaxy class independent exposure time requirement table shows galaxy classes number galaxies satisfying selection criteria reference field total number visits available time spent single galaxy limited tmax general goal designing criteria costs cm table program observes many galaxies possible every science case ideally reasonably equitable distribution formalize means objective function maximizes minimal completeness classes f Ï„i min nm x Ïƒ Ï„i tm Î¸m class tm proposed exposure time nm number galaxies field falling class Î¸m denote nm number fully observed galaxies class training use sigmoid function indicated smoothly approximate step function test time replace actual step function count distinct allocations chose penalty function p squared relu function inequality constraint fiber allocation capacity need exhaust resources gain f achieved equation evidently entirely seeks balance allocation across classes comprised thousands galaxies allocations need determined exact form equation could chosen differently underlying idea motivated current survey design principle pfs galaxy evolution program resource allocation case general objective function case envision smaller observing program could carried pfs single night thus adopt modest allocation h tmax instead adopting predefined classes combine two objectives maximizing number galaxies spectroscopic redshifts z determined precision Î´z sample galaxies used reconstruct cosmic web jasche et al horowitz et al creating sample least faint galaxies relatively large redshift z within range masses mhalo observed least purpose sample aggregate spectra achieve high ratio test presence specific spectral features carnall et al et al specific definitions objectives hypothetical serve example directly fiber allocation strategy pfs objective function thus contains two parts separable part objective success rate redshift measurements success rate number calculated fitting simulated noisy spectrum galaxy inferring redshift estimated spectrum desired precision use galaxy simulation cranmer et al employs single spectral type every galaxy redshift success function redshift mass exposure time calculate success rate sri galaxy exposures linearly interpolate fi Ï„i Ï„isri Ï„i Ï„i sri sri sri Ï„i Ï„i sri sri sri Ï„i Ï„i sri sri sri Ï„i part objective amounts counting number galaxies satisfy specified redshift mass requirements observed least one exposure let Î¸ set galaxies adopt following continuous approximation Ï„i Ïƒ n n x Ïƒ Ï„i n denotes number observed galaxies satisfying selection requirements objective term prefers n saturated n prefactor large number compared p fi chosen ensure second objective receives preference first choice needs made optimization sharpness sigmoid functions equation two hyperparameters larger sharpness leads better approximation step function also difficult optimize one could start small sharpness resource allocation parameters gradually increase training achieve good results fixed parameters hyperparameter search chose penalty function case reduce contrast case time allocation strongly limited insufficient saturate objectives large number available galaxies expect underallocation penalty become largely obsolete end training provides meaningful gradient directions training feature sets training particular importance feature set items cases correspond one galaxy per node thus need provide initial item nodes features meaningfully describe optimization problem perspective galaxies case feature set comprises tm version class index table extra random number distinguishes different galaxies class nodes edges global features graph initialized zeros case item node features initialized sri sri sri sri equation boolean variable showing whether galaxy satisfies redshift mass requirements equation nodes edges global features graph initialized zeros cases use graphs train gnn model graphs validate graphs test behavior overlapping region training validating testing graphs model trained adam kingma ba nvidia gpu start phase fixed penalty strength Î» followed training exponentially increasing Î» training parameters shown table coarse hyperparameter search learning rate penalty factor noise level noisy sigmoid function learning rates cases searched penalty factor case varied case noise level searched sharpness noisy sigmoid method fixed dimensionality gnn functions nx nh nu set ng set according item features listed experimented features found improvements results report gnn test scores table table terms objective function well adherence constraints latter end define total overtime unused time p k max p tik p k max p tik calculate fraction time compared total available observation time tall result written resource allocation table training parameters lr learning rate Î» penalty factor l noise level training lr Î» l lr Î»start Î»end l case case example means value objective function overtime unused time case balancing predefined classes training test data derived galaxy catalog provided pfs galaxy evolution program classes table use catalog saito et al based photometric catalog laigle et al since area coverage catalog small simulations multiple pfs pointings repeat central region catalog tiling pattern final extended catalog covers contiguous area remaining classes artificially superposed region number densities consistent expectation galaxy catalog label indicating class belongs compare gnn approach currently employed network flow optimization method based method blanton et al similar approach constructs graph connecting fibers galaxies solves linear problem graph mip optimizer gurobi given predetermined costs every galaxy class f Ï„i p cm Î¹ cm Ï„i tm Î¹ denotes indicator function programs like case implemented creating graph one fiber node per exposure network flow optimization guarantees feasibility permit adjustment class costs maximize objective function therefore adopt baseline representation current state development fixed costs cm table identified manual exploration linear objective listed important emphasize costs determined general goal namely achieve equitable distribution completeness across galaxy classes specific objective function equation flexible optimization objective function also solve problem equation form equation directly tik ordinary gradient descent use equation convert tij integers test time tried different types gradient descent adam momentum results similar results shown table test fields gnn method outperforms resource allocation table case results terms values objective function equation minimal completeness across classes table network flow optimization preset costs direct gradient descent equation gd gnn method independent test fields percentages denote fraction full time allocation overallocated underallocated averaged fibers field id gd gnn current baseline gradient descent solver despite trained fields different test fields fiber assignment provides good baseline minimum completeness leaves time unallocated apparent contradiction indication suboptimal performance method instead suggests class costs table suboptimal specific objective function gd method like gnn optimizes equation improves upon baseline find depending initialization require large number iterations converge local minimum expected optimization problem gnn benefits learning model makes galaxies valuable relation constraints communicates message passing graph gnn mlps total parameters encode strategy solving equation galaxy fiber configurations given training data instrument result similar galaxies generally evaluated similarly generalization leads increased completeness even though solution optimized test fields respect feasibility unused time concern case expected conflicts highly valuable galaxies prevent full utilization time allocation confirmed test results instance canonical problem arises multiple galaxies located patrol region single fiber partial overlap patrol regions conflicts solved utilizing neighboring fiber achieved fraction available time used increase completeness respective class turn objective function however comparison baseline gnn approach evidently converts unused time gains objective reveals suboptimality predetermine costs complex resource allocation problem interestingly gd achieve higher completeness gnn despite utilizing almost available time resource allocation overtime violations design impossible network flow method almost completely avoided gnn strategy detail section minor overtime violation acceptable case could avoided entirely increasing penalty strength beyond final value table brute force solver minor overtime allocations smaller unused allocations consistent asymmetry penalty addition highest objective function values gnn also fastest method every field baseline gd need run runtime gnn less second training done however even include training time gnn still faster single run network flow optimization gurobi case optimizing general objective function training test data derived universemachine simulations behroozi et al size comprising galaxies single pfs field view spectrum simulation follows approach cranmer et al uses single spectral type massive elliptical galaxy artificially redshifted scaled amplitude match expected performance pfs given stellar mass stellar masses predicted universemachine halo masses according scaling relation girelli et al precision redshift estimates determined fitting known spectrum template galaxy spectra presence constant sky spectrum corresponding poisson shot noise procedure constitutes scenario spectral misclassification impossible catastrophic outliers rare case directly solved lp techniques main aspect problem lies determination relative importance two competing objectives well individual utilities objective precision redshift estimation therefore adapt known heuristic approach precondition problem express lp problem first randomly select galaxies satisfying redshift halo mass conditions label galaxies class observed single exposure giving class infinite costs ensures saturate equation chose proposed time allocation Ï„i galaxies n maximizes expected gain Ï„i h fi Ï„ Ï„ dantzig fi defined equation mip solver used case run n classes n classes comprised one galaxy specified proposed time expected utility fi Ï„i classes defined separately two objectives galaxies class used redshift measurement necessarily leading suboptimal solutions galaxies useful objectives also run gradient descent method comparison results shown table second objective term saturated resource allocation table case test results terms values objective function equation aggregated redshift success rate second objective equation fully saturated design three competing strategies independent test fields percentages denote fraction full time allocation overallocated underallocated averaged fibers field id gd gnn cases show total redshift success rate equation objective see results gnn method superior gd baseline method terms objective function result demonstrates method capable finding effective strategies allocating resources general test case combines separable objectives note gd method closer gnn results case attribute reduced volume parameter space due shorter program times tmax instead tmax also find gnn method yields mild levels feasibility violations although could principle avoid violations increasing penalty factor Î» allow observations pfs simultaneously allocate fibers calibration targets decided ignore operational complication work numbers calibrations measurements flexible compensate small amount unused time calibration allocations summary outlook resource allocation problems arise many application areas remain challenging especially involve discrete allocation spaces objectives paper present bipartite gnn architecture learns strategy solving general resource allocation problems based message passing graph formed nodes representing items value allocation constraints respectively connected edges corresponding possible allocations trained minimize objective function augmented penalty constraint violations using instances problem either historical occurrences simulations capture relevant aspects problem test time apply gnn method target selection problem astronomy given total observing time budget amounts choosing celestial sources within given sky area observed long specializing resource allocation highly multiplexed instrument prime focus spectrograph subaru telescope maunakea hawai results additional complication assign discrete identical exposure times sources observed simultaneously fibers instrument demonstrate gnn method finds efficient allocation strategies two realistic problem settings objectives compare results two direct solvers one performing network optimization predetermined costs directly solves possible allocations gradient descent method yields higher values objective function cases every test field formally guarantees feasibility infinitely large penalties recommend increase penalty term training feasibility achieved feasibility violations deemed tolerable tuning feasibility penalty also allows exploration strategies systems amount slack surplus expect case pfs development gnn method resource allocations bring two important benefits future work first runtime gnn solution much shorter direct solvers order second compared several hours cases substantial accelerations neural mip solvers also found nair et al case performing gnn optimization precondition traditional mip solver lead substantially reduced computational costs maintaining guaranteed feasibility solver either option render practically doable roll strategy updates large number problem instances assess probabilities item receives amount allocation selection function critical importance precision analyses astrophysics cosmology second problems require balancing priorities different kinds items galaxies case traditionally established beforehand respective utilities known priori routinely case scientific experiments complexity task renders unlikely manual exploration priorities yield results gnn provides differentiable architecture thereby exposing relevant parameters problem optimization similar cranmer et al intend make use capability forthcoming works train another neural network learn utility galaxies based easily observable features instead assuming utilities known done test case permutation invariance flexible node edge models gnns render exceptionally well suited resource allocation problems suspect also work well auction strategies huang et al interesting questions beyond scope work relate goal explainable ai instance information passed nodes graph many steps needed achieve results role global model play references acknowledgements authors want thank kiyoto yabe help application case work supported ai accelerator program schmidt futures foundation references koppelaar de groot resource allocation conflict avoidance broadcast communications ieee annual international symposium personal indoor mobile radio communications pimrc pp url http agrawal amos barratt boyd diamond kolter z differentiable convex optimization layers advances neural information processing systems amos b kolter j optnet differentiable optimization layer neural networks url http battaglia hamrick j bapst sanchez zambaldi malinowski tacchetti raposo santoro faulkner gulcehre song ballard gilmer dahl vaswani allen nash langston dyer heess wierstra kohli botvinick vinyals li pascanu relational inductive biases deep learning graph networks arxiv url https behroozi wechsler hearin conroy universemachine correlation galaxy growth dark matter halo assembly monthly notices royal astronomical society url https bertsekas network optimization continuous discrete models athena scientific url https blanton lin lupton maley young zehavi loveday j efficient targeting strategy multiobject spectrograph surveys sloan digital sky survey tiling algorithm astronomical journal url https bretthauer shetty b nonlinear resource allocation problem operations research url http carnall mclure dunlop cullen mcleod wild johnson appleby amorin bolzonella castellano cimatti cucciati gargiulo garilli marchi pentericci pozzetti references schreiber talia zamorani vandels survey starformation histories massive quiescent galaxies z monthly notices royal astronomical society url https cranmer melchior nord b unsupervised resource allocation graph neural networks url http dantzig b extremum problems operations research url https donti rolnick kolter j learning method optimization hard constraints url http edward backpropagation learning systems functions proceedings world congress neural networks everett yanny kuropatkin huff zhang myles masegian allam bernstein splettstoesser sheldon jarvis amon harrison choi hartley alarcon gruen eckert prat tabbutt busti becker maccrann diehl tucker bertin jeltema gruendl bechtol carnero rosell abbott aguena annis bacon bhargava brooks burke carrasco kind carretero castander conselice costanzi da costa pereira de vicente derose desai eifler evrard ferrero fosalba frieman gaztanaga gerdes gutierrez hinton hollowood honscheid huterer james kent krause kuehn lahav lima lin maia marshall melchior menanteau miquel mohr morgan muir ogando palmese plazas romer roodman sanchez scarpine serrano smith suchyta swanson tarle troxel varga weller j wilkinson dark energy survey year results measuring survey transfer function balrog url http federgruen groenevelt greedy procedure resource allocation problems necessary sufficient conditions optimality oper res fey lenssen fast graph representation learning pytorch geometric girelli pozzetti bolzonella giocoli marulli baldi references mass relation past gyr standard Î»cdm model astronomy astrophysics supplement series horowitz zhang lee kooistra tardis ii synergistic density reconstruction lyÎ± forest spectroscopic galaxy surveys applications protoclusters cosmic web astrophysical journal url https huang han chiang poor resource allocation cooperative communications ieee journal selected areas communications url http jasche leclercq wandelt past present cosmic structure sdss main sample journal cosmology astroparticle physics url https katoh ibaraki resource allocation problems springer us boston pp url https kingma ba j adam method stochastic optimization international conference learning representations iclr san diego ca usa may conference track proceedings url http laigle mccracken ilbert hsieh davidzon capak hasinger silverman pichon coupon aussel le borgne caputi cassata chang civano dunlop fynbo kartaltepe koekemoer le f evre le floc h leauthaud lilly lin marchesi salvato sanders scoville smolcic stockmann taniguchi tasca toft vaccari zabl j catalog exploring z universe half million galaxies astrophysical journal supplement series lupton maley young sloan digital sky survey heuristic url http mints hekker selection functions large spectroscopic surveys astronomy astrophysics supplement series nair bartunov gimeno von glehn lichocki lobov donoghue sonnerat tjandraatmadja wang addanki hapuarachchi keck keeling kohli ktena li vinyals zwols solving mixed integer programs using neural networks url http rix hogg boubert brown casey drimmel everall fouesneau selection functions references astronomical data modeling space density white dwarfs worked example url http ross beutler chuang seo cuesta percival burden grieb reid brownstein dawson eisenstein ho kitaura nichol olmstead prada saito schneider thomas tinker tojeiro wang white zhao clustering galaxies completed baryon oscillation spectroscopic survey observational systematics baryon acoustic oscillations correlation function monthly notices royal astronomical society url https saito de la torre ilbert dubois yabe coupon j synthetic emission line cosmos catalogue hÎ± oii galaxy luminosity functions counts z monthly notices royal astronomical society url https vazdekis la barbera beasley ferreras negri vecchia sub one per cent mass fractions young stars red massive galaxies nature astronomy url https shi zhang qin faster algorithm resource allocation problem convex cost functions journal discrete algorithms url https takada ellis chiba greene aihara arimoto bundy cohen graves gunn heckman hirata ho kneib le f evre lin murayama nagao ouchi seiffert silverman spergel strauss sugai suto takami wyse extragalactic science cosmology galactic archaeology subaru prime focus spectrograph publications astronomical society japan url https tamura takato shimono moritani yabe ishizuka ueda kamata aghazarian arnouts barban barkhouser borges braun carr chabaud chang chen chiba chou chu cohen de almeida de oliveira de oliveira dekany dohlen dos santos j dos santos ellis fabricius ferrand ferreira golebiowski greene gross gunn hammond harding hart heckman hirata ho hope hovland hsu hu huang references jaquet jing karr kimura king komatsu le brun le f evre le fur le mignant ling loomis lupton madec mao marrara mendes de oliveira minowa morantz murayama murray ohyama orndorff pascal pereira reiley reinecke ritter roberts schwochert seiffert smee sodre spergel steinkraus strauss surace suto suzuki swinbank tait takada tamura tanaka tresse verducci vibert vidal wang wen yan yasuda prime focus spectrograph pfs subaru telescope overview recent progress future perspectives evans simard takami eds airborne instrumentation astronomy vi vol society instrumentation engineers spie conference series vlastelica paulus musil martius differentiation blackbox combinatorial solvers international conference learning representations iclr url https wong saad inference optimization real edges sparse graphs statistical physics perspective physical review e statistical nonlinear soft matter physics pt url http zaheer kottur ravanbakhsh poczos salakhutdinov smola j deep sets guyon luxburg bengio wallach fergus vishwanathan garnett eds advances neural information processing systems curran associates pp url http references appendix proof theorem let v set vertices e set edges hypergraph g v e connectivity graph represented incidence matrix r aij edge j connected vertex otherwise aij time allocations tikl galaxy fiber k exposure l equation represented vectors el l jth element el equals tikl jth edge e connects item node constraint node similarly tik represented vector etot jth element etot equals tik target selection problem equation written arg max etot f etot etot etot want decompose etot set el satisfy etot x el el el theorem given solution etot problem equation exists least one set et satisfying equation proof induction etot theorem holds trivially assume statement true etot satisfies etot etot find e etot e etot e problem converted problem thus find subset es etot e p l el combining el e gives decomposition etot thus theorem equivalent existence e given following problem etot e etot e e etot satisfies etot etot references let av vth row u etot v u must av e problem becomes aue av etot e e generalize problem linear system e take number aue av e etot e therefore theorem equivalent existence integer solutions equation existence integer solutions guranteed following lemma lemma solution set problem equation convex polytope contains least one integer point proof first show solution set empty obviously solution consider arbitrary corner polytope e corner determined linearly independent equations equations come bottom two conditions directly give value corresponding element e remaining undetermined elements e determined first two conditions linear equations defined invertible square submatrix since graph bipartite totally unimodular means square submatrix determinant submatrix invertible determinant cramer rule inverse matrix also integral matrix thus solution linear equations undetermined elements e integers therefore corner solution set integer point set must least one corner e solution problem equation time complexity find decomposition find sequence el recursively finding e finding e slower polynomial time randomly choose vector c maximize c e within polytope since linear programming problems solved polynomial time finding e sequence el also done polynomial time
draft version september typeset using latex default style finding fast transients real time using novel light curve analysis algorithm robert strausbaugh antonino michael dow sara jielai zhang simon jeff virgin islands number brewers bay rd thomas vi usa marin astrophysics supercomputing swinburne university technology mail number po box hawthorn vic australia centre excellence gravitational wave discovery ozgrav hawthorn australia received revised accepted submitted apj abstract current data acquisition rate astronomical transient surveys promise significantly higher rates next decade necessitate development novel approaches analyze astronomical data sets promptly detect objects interest deeper wider faster dwf program survey focused identification fast evolving transients fast radio bursts bursts supernova shock breakouts employs simultaneous coverage part sky several orders magnitude using dark energy camera mounted blanco telescope dwf captures second exposure every minute typical seeing airmass optical data collected simultaneously observations conducted entire electromagnetic spectrum radio well cosmic ray observations paper present novel light curve analysis algorithm designed detect transients dwf optical data algorithm functions independently conjunction image subtraction present sample fast transients detected algorithm well analysis algorithm customizable tuned sensitive transients evolving different timescales flux ranges introduction field transient astronomy booming several successful completed ongoing planned optical surveys come online coming years specifically designed find transient phenomena among former palomar transient palomar transient factory rau et al law et al panoramic survey telescope rapid response system magnier et al sloan digital sky survey sdss wolf et al supernova survey zwicky transient facility ztf bellm et al graham et al dark energy survey des dark energy survey collaboration et al sky automated survey supernovae kochanek et al transiting exoplanet survey satellite tess ricker et al provided census large variety supernovae sne events confirmations latter category vera rubin observatory nancy grace roman telescope push understanding transient sky towards deeper limits longer wavelengths overview field view depth cadence surveys found table conjunction optical surveys gravitational wave gw detectors like advanced laser interferometer observatory aligo ligo scientific collaboration et al virgo acernese et al neutrino detectors corresponding author robert strausbaugh sep strausbaugh et al table optical transient survey details field view cadence days unless survey name depth square degrees otherwise noted g sdss sn survey r sn survey g des g ztf g v tess broadband minutes lsst g roman j dwf g minute field view depth cadence notable past present future transient surveys tess broadband wavelengths span quoted dwf area science ccds footprint fov includes ccd gaps typically listed icecube icecube collaboration baksan neutrino observatory kuzminov ushered us new era transient astronomy expect discovery new exciting transient phenomena continue higher pace thanks vera rubin survey space time lsst iveziÄ‡ et al telescope constructed cerro pachÃ³n chile planned first light date commencing operations aims image sky wide fast deep mode depth g every days lsst science collaboration et al nancy grace roman infrared space telescope wfirst spergel et al cover area square degrees average depth j cadence days proposed medium depth supernova survey launched scheduled date akeson et al hounsell et al summarize characteristics planned instruments table current survey results section briefly summarize seminal discoveries surveys look build upon example results include outburst sn progenitor one year explosion fraser et al lack sne compatible models nicholl et al first interstellar asteroid detection de la fuente marcos de la fuente marcos similarly recent sdss survey results include detection baryonic acoustic oscillation measurements alam et al evidence epoch reionization around z becker et al high redshift z quasars fan et al indirect dark matter detection via fischer et al finally recent years enhanced knowledge tidal disruptions events tdes hung et al burst grb orphan afterglows singer et al hosts novel sne arcavi et al goobar et al kasliwal et al ofek et al horesh et al cao et al ofek et al due design facilities observational strategies still lack discoveries fast hour faint mg transients see figure right panel several science cases benefit fast identification potential classification rapidly varying transients simultaneous observations spanning electromagnetic spectrum fast radio bursts frbs class objects characterized either single repeating radio bursts evolving time scales finding emission frequencies radio important toward understanding progenitors ignition mechanism events first emission radio observed accompany frb recently detected magnetar milky way frequencies although bursts weaker radio extragalactic frbs event suggests magnetars may progenitors least frbs andersen et al bochenek et al lin et al fast transient finding algorithm figure left adopted laher et al comparison field views various astronomical surveys dwf program uses telescope des blanco scope cerro tololo observatory chile right transit depth characteristic timescales transients detected phase space occupied ztf survey adopted b comparison cadence depth ptf iptf ztf surveys http b http also due lack sufficient early time observations sne shock breakout mechanism type ia sne ignition mechanisms sne still well understood type ia sne critical determining cosmological distance scales used measure accelerated expansion universe riess et al despite use standard candles shock breakout mechanism type ia sne conclusively understood nomoto identification type ia sne within first day lead understanding shock breakout mechanism including detection cooling tail indicative delayed detonation transition piro et al importantly nature progenitors sne ia unclear detection bursts sne ia ejecta colliding companion star cao et al helps secure progenitor model fraction events detections must occur short timescales better understanding type ia sne could key towards resolving discrepancy measurements hubble constant using cosmic microwave background planck hinshaw et al planck collaboration et al measurements made using cosmic distance ladder method riess et al type ia sne vital rung study important understanding ends life cycles massive stars believed one main drivers nucleosynthesis elements heavier iron arnett clayton early detection distinguish various theorized ignition mechanisms instabilities akiyama et al standing accretion shocks blondin et al acoustic shocks burrows et al qcd phase transitions sagert et al first grb orphan afterglow may detected radio law et al discovered late time prompt emission deep optical follow ups resulted upper limits searches also performed ztf andreoni et al orphan afterglows kilonovae one candidate orphan afterglow coughlin et al later associated prompt emission grb svinkin et al optical component reported first ztf instilling confidence veracity method detecting identifying orphan afterglows study orphan afterglows would allow us calculate grb jet angles well true grb rate rhoads although made many discoveries surveys ptf ztf plan continued success vera rubin observatory nancy roman space telescope void parameter space fast faint transients remains unfilled understanding grb orphan afterglows short grbs frbs sn ignition mechanisms counterparts gravitational wave events greatly enhanced detecting transients across several segments electromagnetic spectrum due rarity events use facilities needed strausbaugh et al challenges detecting studying fast transients challenges astronomy well documented feigelson babu zhang zhao kremer et al zhang et al seen table cadence many optical transient surveys allows longer processing times could limit speed astronomers detect transient phenomena potential delays several days start event detection deeper wider faster program offers different approach optical surveys presents new challenges analyze incoming data fast processing dwf described section means ideal optimal lossy compression adds artifacts fast data processing much poorer normal processing creating additional artifacts poorer astrometry alignments yield poorer subtractions fast processing necessary however order identify events trigger sources fade detailed events ideally spectra shed light early phases sne grb afterglows frbs transient phenomena challenges outlined unique dwf due fast cadence opportunity transient detection minute challenges motivate work presented paper present automated customizable fast transient identification algorithm centered mainly dwf source light curve analysis summarize dwf program section describe dwf data sets analyzed work section motivate need transient detection algorithm independent image subtraction present elements novel fast transient detection algorithm results running algorithm dwf data processed data sets presented section finally section describe algorithm deployed future dwf runs deeper wider faster program deeper wider faster program dwf andreoni cooke peculiar among aforementioned transient surveys primary goal dwf identify transient phenomena shortest timescales dwf searches milliseconds hours various wavelengths deep optical component dwf carried dark energy camera decam collecting exposures minute cadence g magnitude limits view comparison dwf surveys found table conjunction optical observations carried decam blanco telescope chile observatories spanning entire electromagnetic spectrum coordinated either simultaneously collect data region sky coordinated trigger rapid transient sources data collected decam analysis highly compressed vohl et al minimize transfer speed sent directly summit cerro tololo chile ozstar supercomputer swinburne university technology australia processing analysis addition data also transferred using lossless compression fully processed modified version photpipe noao community pipeline rest et al swaters valdes valdes swaters later time dwf program like many transient surveys ptf sn legacy survey among others cao et al perrett et al relies image subtraction pipeline mary pipeline andreoni et al detect potential sources interest real time ranked list candidates presented astronomers volunteers visual inspection image cutouts small fraction decam fov centered single detected source light curves using interactive tools described meade et al dwf data samples describe dwf data stream detail light curve creation process final inputs fed transient identification algorithm data collected decam dwf program unique among transient surveys cadence therefore discoveries first kind dwf blanco telescope decam mounted collects continuous exposures minute cadence including readout time exposure decam reaches depth g normal dwf observing conditions arcsecond seeing airmass slightly higher ideal airmass due visibility requirements simultaneous observations radio conducted telescopes either australia south africa telescopes operating wavelengths antarctic north america locations including telescopes selected main observing band dwf decam sensitivity magnitudes deeper redder filters many fast bursts hot blue dwf target fields typically low galactic extinction fast transient finding algorithm table dwf runs analyzed ftf algorithm field name ra center dec center start date end date cdfs fields analyzed part study fields noted data fields noted analyzed webb et al dwf target fields template reference images taken prior run multiple filters addition reference images newly discovered frb fields target fields observed either start end night filters typically determine source colors dwf program collects data decam field view covered individual decam ccds data ccd saved extension fits file data processed analyzed two ways firstly fast analysis image files lossy compressed summit using method described vohl et al sent ozstar supercomputer swinburne university technology data analysis data transfer cerro tololo summit chile australia slow enable data processing analysis transient candidate identification within minutes necessary fast transients lossy compression tunable speed internet speed transfer compressing data still enable detection transients furthermore enable fast identification rapid response triggers data fast processed parallel ozstar supercomputer fast processing sacrifices aspects full processing pipeline speed lossy compression fast processing result several artifacts images typically observed conventional transient pipeline analyses data processing data collected dates used work includes using swarp bertin et al align stack images sextractor bertin arnouts identify sources hotpants becker perform image subtractions performing image subtraction source extraction differenced images mary pipeline andreoni et al runs machine learning algorithm potential candidates minimize ccd artifacts remaining candidates ranked based presence guide star catalog lasker et al previous nights dwf run higher rankings given sources present neither previous dwf nights data analyzed manner referred data note processing different later runs secondly data separately sent noao pipeline system swaters valdes valdes swaters provide fully processed data analyses data used fast transient detection burst fast transient searches wavelengths fast transients associated events supernova shock breakouts events caught early dwf applications data used sources identified using sextractor images stacked image subtracted however magnitudes sextractor identified sources calibrated skymapper data release catalogue onken et al data analyzed manner referred data data processing methods light curves generated sources one detections coordinates dwf targets named using coordinates dwf source data point upper limit generated every minute unless source location falls ccd either chip gaps edge decam field view result small offsets guiding tracking hexapod corrections result changing weather moving new field etc strausbaugh et al total dwf fields analyzed work shown table data sets covering cdfs legacy fields data sets covering two epochs antlia fields one epoch field two antlia epochs analyzed two separate runs spaced months months apart respectively second pointing help establish recurrence periodicity transient behavior observed field one first fields observed dwf first dwf run employed observational routine dithering analyzing first run field determine robust ftf algorithm dithered data subsequent dwf runs moved away dithered approach due confounding issues discussed section antlia field chosen analysis part comparisons drawn work work done webb et al data dense field light curves generated days two fields chosen necessity older data stored later analysis pandemic halted operations many observing sites across world precluded acquisition data sets cerro tololo several months results running ftf algorithm data sets table presented section naming convention light curves presented paper survey name dwf followed right ascension ra declination dec sexagesimal coordinates follows dwfradec algorithm early source detection despite ubiquity use image subtraction techniques identify transient sources wrought challenges convolution psfs images challenging impossible different instruments different seeing conditions even feasible convolution computationally intensive large number source detections image subtracted frames inability humans analyze reasonable time frame especially fast transients solid accuracy trigger followup observations necessitates use machine learning frameworks identify masci et al dÃ­az et al duev et al complicating process increasing computational demands source extraction codes sextractor fooled sources real example cosmic rays images subtractions surveys search transients fainter magnitudes begin hit threshold many detections ambiguous accurately identify furthermore ml approach requires extensive training large training set samples typically hundreds thousands images increasing demands human time capital challenges associated image subtraction led attempts identify transient sources direct image comparisons wardÄ™ga et al light curve analysis liu et al light curve analysis webb et al addition definitive source classification hardly possible image subtraction alone transient characterization confirmed observations including spectroscopic data however telescope time using sensitive spectroscopic instruments limited observing sources narrower cadence conventional transient surveys enough data source rapidly available light curve made within minutes first data acquisition preliminary classification performed using simple metrics rise decay rate peak brightness early classification using light curves inform astronomers resources allocate targets always limited kind observation strategy crucial lsst service brokers performing community fÃ¶rster et al narayan et al narayan et al smith patterson et al mÃ¶ller et al better sampling including light curves spanning multiple wavelength bands precise classification sources achieved bloom et al ball et al debosscher et al richards et al kim jamal bloom progress front still minimal due complexity data classification algorithms fast transient finding ftf algorithm given obstacles inherent using image subtraction techniques necessity light curve analysis classify peculiar transient events propose identify transient phenomena direct light curve analysis dwf data stream algorithm describe used independent verification candidates detected fast transient finding algorithm via methods image subtraction machine learning algorithms flow chart ftf algorithm shown figure figure given dwf field total number n sources detected light curve lc generated source processing sources identified potential transients image subtraction see section thorough discussion different data types lc fed algorithm described section manner lcs separated n sw different sliding windows n number data points lc sw size sliding window sliding windows processed parallel fit linearly sign slope determined positive negative flat signs slopes individual sliding windows recombined number inflection points ips lc counted lcs fewer ips saved potential transients unique source observed dwf run separate light curve data using sliding window sw technique common financial time series analysis chou nguyen chou truong karathanasopoulos et al well machine learning applications across several disciplines dietterich kaneda mineno selvin et al helwan uzun ozsahin user define size sliding window parameter limited number data points contained within individual light curve file light curves may missing points due changing weather conditions upper limits artifacts prevent photometric pipeline accurately estimate magnitude source statistical selection algorithm parameters based typical field cadence number points per light curve assess best sw size emphasize focus paper finding known categories fast evolving transients grb afterglows kilonovae etc ftf algorithm easily customized different novel types variable phenomena changing sliding window size figure slope threshold figure searches new types transients important focus dwf us ftf pursue targets future figure present histograms number data points present light curve fields runs analyzed work data red dashed line figure represents choice avoids predominance noisy light curves sw mitigates risk averaging rapidly rising falling light curves flares larger windows sw sliding window compute simple linear fit g Î±t g observed magnitude time minutes first observation Î± temporal decay index intercept return slope uncertainty histogram slopes window fields plotted two graphs figure find distributions slopes laplace distribution represented strausbaugh et al figure amalgamated histogram number data points present light curve fields runs analyzed work data left processed data right sets red dashed line plotted chosen sliding window size ftf algorithm explored paper sliding window parameter changed search transients evolving different time scales figure histograms slope separate sliding window data left processed data right fit histogram laplacian distribution defined equation plot b term red dashed line slopes within red dashed lines considered flat ftf algorithm explored paper slope threshold tuned search transients different intensities shown blue dashed line figure probability density function p x exp b Âµ mean case function equal median well mode variance average absolute deviation b linear fits obtain sign window slope positive negative flat consider flat slope Î± b shown red dashed lines figure algorithm keeps track sign slope sliding window notes change sign slope inflection point ip scanning sliding window algorithm tallies records number ips example typical fast previously unknown transient may number ips straight rising decay behavior flare one ip rising one ip fading one ip flat aforementioned process time consuming since ultimate goal provide identification fast transients dwf data stream implement full parallelization algorithm target run independently parallel dwf run parallelization enables code run dwf source minute par cadence incoming data points efficiency fast transient finding algorithm code important identification transients especially deployed cpus like supercomputer swinburne university optical data dwf runs analyzed phenomenological selection number inflection points light curve calculate number ips group objects light curves number ips work focus light curves four fewer ips within typical dwf light curve hour light curves zero ips monotonically increasing decreasing could longer evolving transients cepheids rr lyrae sne example light curves one ip might catching start rise fall transient evolving minutes days time scales light curves two three ips may contain peaks dips spanning entire dwf time field typically hours four ip light curves could point towards complex behavior goes several phases course dwf observation important note transient phenomena may occurring dwf run began continue data acquisition stopped therefore burst like event might two three ips light curve might shifted towards beginning end run way parts curve sampled using algorithm first potential transients reported first five minutes observation dwf thereafter number ips associated light curve updated every minute sliding window shifts one data point noted inflection change corresponding positive detection image subtraction pipeline provides good evidence trigger imaging spectroscopic ftf algorithm demonstration figure show ftf algorithm works sample light curve using flaring star first detected webb et al example light curve flaring source plotted left panel figure right panel figure shows slope derived sliding window function time clearly see flare light curve relative inflection points enable identification change brightness beyond typical brightness information may used trigger follow observations subsequent data demonstrate inflection points therefore source fast transient classified section dashed red lines figure represent thresholds identified histograms presented figure users set different threshold identify different transients interest shown blue dashed lines results section present outcome ftf algorithm implication detectability fast transients different natures rate detection objects compared surveys required effort spectroscopic secure classification summary single night observation single field obtained average light curves light curves feeding light curves ftf algorithm detect average potential fast transients respectively checking science frames potential fast transients artifacts sources obtained average statistically significant fast transient per field data statistically significant fast transients per field data based light curve fits sources classified fast transients definition section fields described table strausbaugh et al figure left light curve flaring star observed antlia field dwf object first discovered using unsupervised learning techniques webb et al right slope sliding window plotted time red dashed line correspond derived laplace distribution defined equation plotted figure blue dashed line represents restrictive parameter tuned algorithm example astronomers looking specifically flare stars event fast transient identification ftf would allow latency time minutes multiwavelength spectroscopic observations detailed results field found table results data list candidates generated using ftf algorithm within first minutes run every minute thereafter shown section light curves vetted team light curves passed human inspection image cutouts source location sky visually inspected exclude presence artifacts survived processing pipeline cosmic rays bad pixels bad purposes paper positive detection defined one source either known variable dwf variable detected methods see example webb et al newly discovered candidate passes visual inspection images associated light curves confirm known variables checked coordinates candidates known variable source catalogs general catalog variable stars samus et al international variable star index watson et al important note light curves exist sources candidates identified via image subtraction part mary pipeline analysis contrast light curves processing noao pipeline encompasses sources detected run linear fits plotted subsequent figures figures meant give idea general trends lights curves slopes associated sliding windows shown section necessarily best fit data light curve plotted left panel figure known rr lyrae source called bg tuc hoffmeister geÃŸner light curves night dwf observing run plotted right panel figure figure shows variability object long time scales behavior night plotted upper left panel figure plotted upper right panel figure identified ftf algorithm potential transient phenomena first night data shows source decreasing g g minutes observation data second night shows source baseline magnitude g dips dramatically twice magnitudes second time magnitudes occurring space minutes visual inspection first night data revealed signs contamination sources analysis data second night shown bottom panel figure reveals dimmer stars vicinity become faint clouds passing region sky would account apparent dimming source second night believe displaying fast transient finding algorithm table ftf results number algorithm identified human filtered field name light curves light curves final results run run antlia run antlia run cdfs legacy total ftf algorithm identified light curves fields studied potential transients reducing number light curves require human inspection two orders magnitude light curves identified algorithm identified human observer potentially real astrophysical phenomena rejecting sources obvious explanations fields denote fields data analyzed figure left light curve detected ftf algorithm slope labeled Î± plotted red dashed line coordinates correspond known rr lyrae bg tuc right data dwf nights plotted showing variability object dwf run section plotted left panel corresponds second last section right hand graph genuine transient phenomena first night observation reaching quiescent phase second third nights figure present two light curves showcase ftf identify fast evolving transient dwf data stream quickly astronomers trigger resources left panel shows source around g dropping magnitudes minute period source like ftf algorithm would alert astronomers within first data points within minutes case light curve deviates flat position right panel figure shows light curve rising magnitudes minutes undergoing seemingly exponential decay remainder observations source would identified potential transient first data points due steep nature increasing brightness furthermore ftf algorithm would identify strausbaugh et al figure top left light curve plotted night appear contamination effects image cutouts night data identify source real top right light curves nights source observed overall source declining form g first night almost constant g magnitude second third night however dips magnitudes present second night bottom image cutouts second night data source presented seen one middle rows source nearby seem fade indicative clouds may visible astronomers ground inflection point within minutes object drop brightness notifying astronomers change behavior object transient misidentification section present sample light curves identified possible transients ftf algorithm analysis determined bogus common type light curve confounded ftf algorithm involving astronomical source interacting edge one science ccds make decam detector honscheid depoy pictured figure label des dark energy survey number ccds increases chance edge interactions source moves onto ccd light curve show peak dip unlike mimicking fast rising fading transient effect exacerbated early dwf observational strategies employing dithering routine first run field analyzed paper dithering patterns longer favored dwf part reason issue remedied ignoring data collected near edge detector information always available cataloged data sets easily identified using software analyzing dimensions science image square machine learning algorithms fast transient finding algorithm figure left light curve presented first data points light curve consistent flat slope defined section source dims mangitudes minutes first data point decay ftf algorithm note object potential fast transient right light curve presented first data points light curve would indicate object potential fast transient light curve enters period seemingly exponential decay remainder observation algorithm would detect inflection change alerting astronomers potential transient nature source cases present figure ftf algorithm alert astronomers within minutes transient behavior figure left light curve flagged ftf algorithm potential transient due fast magnitude drop slower magnitude decay right image cutouts centered position sky image cutouts show source moving edge ccd causing decreasing light curve figure present example astronomical source appearing exhibit transient behavior left panel figure light curve dims magnitude one minute continuing decay next five minutes upon visual inspection fits images right panel figure clear telescope shifted slightly placing source edge detector afterwards sources slowly moving frame figure present light curve misidentified transient due edge effects slightly different reason shown figure left panel figure present light curve appears magnitude g background upper limit g source proceeds decay magnitudes course minutes upon inspection images shown right panel figure bright source shown moving frame suspect cause appearance source g minutes observation field began following bright star present field coordinates slightly offset bright source began move frame eventually centroid star frame light star still strausbaugh et al figure left light curve flagged ftf algorithm potential transient source seems appear g rapidly fading magnitudes minutes right image cutouts centered position sky upon inspection appears bright source edge ccd moves edge small section star still visible small bit flux assigned coordinates still field view ccd new source generated catalog source continues move ccd measured flux decreases detected noao pipeline identifies new source using coordinates frame source continues move frame brightness object continues decrease conclusions future work deeper wider faster program unique terms depth g per image short cadence minute compared transient surveys occupying parameter space distinct lack coverage andreoni et al figure addition depth cadence dwf offers new way explore transient phenomena due simultaneous observations performed across entire electromagnetic spectrum identification transient phenomena transient surveys far relied imperfect science image subtraction rudimentary classification transient phenomena requires analysis light curves objects refined classifications relying heavily spectral analysis object work present fast transient finding algorithm capable identifying transient phenomena independently image subtraction tandem image subtraction algorithm dwf data stream light curves focused identifying fast transients explosive phenomena paper also demonstrate ftf algorithm customized find kinds transients variables type algorithm occupies unique space within transient detection landscape currently operating optical surveys ztf detect variability miss opportunity alert community possible fast evolving transients grb frb counterparts see work paper first step towards implementation real time transient classification first identify potential transients using ftf algorithm next combine data sets obtained dwf sources interest either extract features combined data set run deep learning classification algorithm cucchiara et al preparation ftf algorithm incorporated dwf pipeline deployed next dwf run shown figure first iterations algorithm working light curves generated image subtractions performed mary pipeline andreoni et al source first identified candidate image subtraction light curve begin populated source slope light curve source threshold select manually specific sources high flare stars slightly lower slower evolving transients automatically using statistical measure figure source identified potential fast transient candidate candidates image subtraction provided human observers using interactive visualization tools give priority sources flagged potential transients ftf algorithm sources candidates ftf candidates data fast transient finding algorithm figure current data flow incorporation ftf algorithm dwf pipeline green arrows represent new data flows described paper data decam compressed vohl et al sent australia analysis images processed mary pipeline andreoni et al image subtractions performed light curves sources flagged image subtraction fed ftf algorithm light curves analyzed results fed data visualization meade et al used directly trigger observations generated sources inflection points drop ftf candidate list trigger followup image subtracted ftf candidates classify sources detailed spectra acknowledgments rs ac supported nsf grant ast references acernese agathos agatsuma et al classical quantum gravity doi akeson armus bachelet et al arxiv https akiyama wheeler meier lichtenstadt apj doi alam ata bailey et al mnras doi andersen bandura bhardwaj et al nature doi andreoni cooke j southern horizons astronomy ed griffin vol doi andreoni jacobs hegarty et al pasa doi andreoni kool sagues carracedo et al arxiv https andreoni cooke webb et al mnras doi arcavi kasliwal et al apj doi arnett clayton nature doi ball brunner myers tcheng astrophysical journal becker hotpants high order transform psf template subtraction http becker fan white et al aj doi bellm kulkarni graham et al pasp doi bertin arnouts doi bertin mellier radovich et al astronomical society pacific conference series vol astronomical data analysis software systems xi ed bohlender durand handley blondin mezzacappa demarino apj doi bloom richards nugent et al pasp doi bochenek ravi belov et al nature doi burrows livne dessart ott murphy j apj doi cao nugent kasliwal pasp doi cao kasliwal arcavi et al apjl doi strausbaugh et al cao kulkarni howell et al nature doi chou nguyen ieee transactions industrial informatics doi chou truong soft computing doi coughlin andreoni anand et al zwicky transient facility discovery fast optical transient associated grb https dark energy survey collaboration abbott abdalla et al mnras doi de la fuente marcos de la fuente marcos research notes american astronomical society doi debosscher sarro aerts et al doi dÃ­az beroiz peÃ±uela et al astrophysical journal doi dietterich structural syntactic statistical pattern recognition ed caelli amin duin de ridder kamel berlin heidelberg springer berlin heidelberg duev mahabal masci et al monthly notices royal astronomical society doi fan narayanan lupton et al aj doi feigelson babu j significance doi https fischer mckay sheldon et al aj doi fÃ¶rster et al arxiv https fraser magee kotak et al apjl doi geÃŸner veroeffentlichungen der sternwarte sonneberg goobar amanullah kulkarni et al science doi graham kulkarni bellm et al pasp doi helwan uzun ozsahin applied computational intelligence soft computing doi hinshaw larson komatsu et al apjs doi hoffmeister veroeffentlichungen der sternwarte sonneberg honscheid depoy arxiv https horesh kulkarni fox et al apj doi hounsell scolnic foley et al apj doi hung gezari cenko et al apjs doi icecube collaboration nuclear physics b proceedings supplements doi iveziÄ‡ kahn tyson j et al apj doi jamal bloom apjs doi kaneda mineno expert systems applications doi https karathanasopoulos dunis khalil quantitative finance doi kasliwal kulkarni et al apjl doi kim doi kochanek shappee stanek et al pasp doi kremer gieseke pedersen igel ieee intelligent systems doi kuzminov european physical journal plus doi laher masci groom et al lasker lattanzi mclean et al aj doi law gaensler metzger ofek sironi apjl doi law kulkarni dekany et al pasp doi ligo scientific collaboration aasi abbott et al classical quantum gravity doi lin zhang wang et al nature doi fast transient finding algorithm liu deng fan et al mnras doi lsst science collaboration marshall anguita et al arxiv https magnier schlafly finkbeiner et al apjs doi masci laher rebbapragada et al publications astronomical society pacific https meade fluke cooke et al pasa doi mÃ¶ller peloton ishida et al mnras doi narayan zaidi soraisam antares collaboration american astronomical society meeting abstracts vol american astronomical society meeting abstracts narayan zaidi soraisam et al astrophysical journal supplement series doi nicholl smartt jerkstrand et al nature doi nomoto apj doi ofek rabinak neill et al apj doi ofek sullivan cenko et al nature doi onken wolf bessell et al publications astronomical society australia doi patterson bellm rusholme et al pasp doi perrett balam sullivan et al aj doi piro chang weinberg apj doi planck collaboration aghanim akrami et al doi rau kulkarni law et al pasp doi rest stubbs becker et al apj doi rhoads apjl doi richards starr butler et al apj doi ricker winn vanderspek et al journal astronomical telescopes instruments systems doi riess filippenko challis et al aj doi riess macri hoffmann et al apj doi sagert fischer hempel et al phys rev doi samus kazarovets durlevich kireeva pastukhova astronomy reports doi selvin vinayakumar gopalakrishnan menon soman international conference advances computing communications informatics icacci doi singer cenko kasliwal et al apjl doi smith extragalactic explosive universe new era transient surveys discovery doi spergel gehrels baltay et al arxiv https svinkin golenetskii aptekar et al ipn triangulation grb consistent https swaters valdes astronomical society pacific conference series vol astronomical data analysis software systems xvi ed shaw hill j bell valdes swaters astronomical society pacific conference series vol astronomical data analysis software systems xvi ed shaw hill j bell vohl pritchard andreoni cooke meade b pasa doi wardÄ™ga zadroÅ¼ny beroiz camuccio dÃ­az arxiv https watson henden price vizier online data catalog webb lochner muthukrishna et al mnras doi wolf andrea gupta et al astrophysical journal doi zhang zhao data science journal doi strausbaugh et al zhang barbary nothaft et al ieee international conference big data big data doi
sep systems waveform design xiaoyan hu member ieee christos masouros senior member ieee fan liu member ieee ronald nissel member ieee paper explore radarcommunication dfrc system achieving integrated sensing communications isac technique orthogonal frequency division multiplexing ofdm leveraged overcome fading wideband mimo systems one dfrc base station bs multiple user equipment ues order restrain high power ratio papr ofdm signals aim jointly design dfrc waveforms done utilizing weighted objective function communication radar performance metrics power papr constraints formulated optimization problems equivalently transformed standard programming sdp effectively solved relaxation sdr method prove globally optimal solution obtained general develop method solve problems much reduced overheads moreover practical scenario oversampling ofdm signals considered significant effect resulting papr levels feasibility effectiveness flexibility proposed dfrc waveform design methods demonstrated range simulations communication sum rate symbol error rate well radar beampattern detection probability index sharing dfrc mimo radar communications ofdm papr introduction motivations prior works explosive growth mobile iot devices along severe spectrum shortage driven demand spectrum usage efficiency meet impending need massive connectivity around billion devices worldwide spectrum resources already assigned existing applications regarded promising strategy future communication networks among available applications radar spectrum widely regarded promising candidate facilitate communication radar spectrum sharing crss due fact radar spectrum hu masouros department electronic electrical engineering university college london london uk email fan liu department electical electronic engineering southern university science technology shenzhen china email nissel huawei technologies gothenburg sweden email provides large frequency bands suitable wireless communications thus spectrum sharing policy achieved sides step sharing one set hardware equipment signal processing frameworks communications radar dfrc design provides way achieving integrated sensing communications isac fact techniques dfrc isac eagerly required future intelligent iot applications smart cities smart homes automatic driving industry drawn great attention academia industry recently dfrc systems aim fulfilling wireless communications radar detections simultaneously designing single transmitted waveform dfrc systems standard radar waveforms employed information introduced modulating signaling communications comparison dfrc systems communication waveforms directly exploited sensing extracting radar information targets echoes known dfrc systems capable providing desirable sensing performance limited communication rates requirements systems achieve favorable communication performance unreliable sensing performance recently attention focused dfrc systems joint dfrc waveform design guarantee sensing communication performance limited existing radar communication waveforms promising achieve scalable performance two functionalities technique orthogonal frequency division multiplexing ofdm key enabler wireless networks part communication standards studied extensively actually ofdm also recently exploited radar sensing orthogonal property ofdm waveform fulfilled discrete fourier transform dft inverse dft idft operations transceivers facilitate signal processing communications radar sensing pioneer work considered dfrc multiple output mimo ofdm system provided way introducing radar sensing system radarcentric dfrc system sidelobe control communications studied transmit receive beamforming optimized maximize radar metric divergence total radiated power minimized another dfrc work subcarrier selection power allocation primary radar purpose secondary communications purpose radarcentric joint design scenarios addressed recent work dfrc waveform optimized taking feedback overhead conveying transmit waveform control information consideration wideband dfrc waveform jointly designed precoding antenna selection matrices optimized meet joint performance even though ofdm waveform excellent candidate joint design dfrc systems one major disadvantage ofdm waveform high power ratio papr effectively dealt otherwise high papr may cause distortion transmit signals lead performance degradation considering limited linear region power amplifiers papr constraints considered radarcentric dfrc system restrain papr waveform however best knowledge dfrc ofdm systems literature taken papr constraints consideration especially joint design dfrc systems moreover papr originally defined passband signals thus oversampling may necessary obtaining accurate papr levels based waveform verified ofdm signal get almost papr signal interpolated oversampled Ï… b contributions paper consider wideband dfrc mimo ofdm system dfrc base station bs acts cellular bs mimo radar generate dfrc waveforms used downlink data transmission targets detection simultaneously design dfrc waveforms achieve tunable performance wireless communications radar sensing main contributions summarized follows jointly design dfrc waveforms optimizing weighted objective function communications radar performance metrics transmit power papr constraints papr constraints introduced restrain modulus dfrc waveforms avoid signal distortion caused hardware limitation power amplifiers leading data transmissions target detections first address dfrc waveform design scenario sampling papr dfrc waveform sampling derived used papr constraints formulated problem transformed standard programming sdp optimally solved relaxation sdr method prove solution exists general method proposed divide original problem obtain effective solution much reduced complexity subproblems solved parallelly much less optimization variables thus computational complexity significantly reduced consider practical case dfrc mimoofdm waveform oversampling rate Ï… design new approach oversampling required practical ofdm systems power amplifiers papr level odfm waveform measured accurate way derive papr expression transform optimization problem dfrc mimoofdm waveform design standard sdp though elaborate transformations global optimal solution also achieved sdr method shown offer solution general advance approach method obtain effective solution simulation results verify papr levels designed dfrc waveform reduced case priority slight performance degradation satisfactory performance tradeoff communications radar achieved effectively tuning weighting factor two functionalities demonstrating feasibility effectiveness flexibility proposed methods lowpapr dfrc waveform design rest paper organized follows section ii describes considered system models including dfrc waveform communication radar models problem formulation well dfrc mimoofdm waveform design sampling given section iii section iv practical scenario oversampling considered optimization problem solved based accurate papr measurement simulation results provided section v conclude paper section vi notations unless specified otherwise upper lower case bold symbols represent matrices vectors x notations h denote complex conjugate transpose hermitian transpose operations vectors matrices also represents matrix tr x trace square matrix x rank represents rank matrix j denotes j element matrix diag form matrix using elements vec represents vectorization matrix denotes kronecker product kxk kakf denote absolute value scalers norm vector x frobenius norm matrix respectively ii system model consider wideband dfrc system shown fig equipped uniform linear array ula transmits dfrc waveforms k wdujhw wdujhw wdujhw hk fig illustration dfrc system ntantenna simultaneously serves k downlink ues probes targets jointly designing dfrc waveform aiming serving k downlink user equipment ues sensing targets simultaneously considered wideband dfrc system sufficient bandwidth high distance resolution achieved radar detection however communication channels multiple taps undergo significant frequencyselective fading due fact bandwidth much larger channel coherence bandwidth well known ofdm effective technique overcoming fading fully exploiting frequency diversity widely used practical communication systems ofdm technique wideband channel divided multiple orthogonal subchannels hand ofdm technique introduces disadvantage enlarging papr transmitted signal waveform may lead crucial signal distortion hence transmitted signal waveform carefully designed effectively restrain corresponding papr ofdm signals paper proposed system denoted dfrc system transmitted signal waveform named dfrc waveform objective effectively design transmitted dfrc waveform transmit power specific papr constraints obtain desirable dfrc waveform achieving satisfactory performance tradeoff communications radar functionalities dfrc waveform formulation assume wireless communication channels memory u u effectively nonzero channel taps addition length effective data symbols block ns need modulate ns subcarriers transmissions denote index n ns ns order eliminate interference isi wideband multicarrier transmissions standard ofdm technique cyclic prefix cp utilized length cp denoted nc nc u thus total number timedomain samples per block n ns nc without lose generality use nc u paper symbol data preoding model let ns c represent symbol data matrix ues k k k ns subcarriers transmitted communication frame length sn sn k c symbol matrix ues subcarrier n ns sn k c specific symbol vector user addition w diag wns c compact precoding matrix ues subcarriers wn wn k c precoding matrix ues subcarrier n ns wn k c specific precoding vector user transmit symbol data first precoded w frequency domain converted time domain idft operation subcarrier modulations use xs ws xt xt ns c indicate baseband precoded symbol matrix subcarriers idft processing xn wnsn c n ns denote fs c normalized dft matrix data transmissions f n ns e ns n element fs n ns idft processing transmitter operated fh int c considering fact ula array equipped nt transmit antennas hence transmitted data signal waveform idft expressed g f h int xs gt gt ns c gn f h xs c transmitted dfrc signal nt antennas subcarrier n ns also fs n c indicates column dft matrix fs corresponding dft operations subcarrier dfrc waveform cp next step adding cp size nc u crucial eliminating isi caused fading operated repeating last nc symbols beginning original symbol sequence denote xc xt xt xt ns c fc fs fs fs ns c let xt c xt c fc fs c transmitted dfrc waveform adding cp expressed h int c gt gt gt ns gt gt ns length radar block corresponding number ofdm symbols time domain recalling n nc ns operating idft adding cp transmitter side effects isi caused fading eliminated removing cp operating dft receiver side communication model overall downlink channel received signal adding cp signal radio frequency rf domain subcarrier modulations transmission via nt rf chains connected nt antennas mentioned wireless channels dfrcbs downlink ues assumed wideband frequencyselective fading channels memory u assumed sufficiently long hence impulse response channel ue k k denoted hek Ï„ u hek uÎ´ Ï„ u c k hek u c channel vector tap assumed hek u cn u int independent identically distributed rayleigh fading coefficients k k u u u furthermore use Ï„ u uÎ´ Ï„ u c represent compact channel matrix k downlink ues u het u het k u c corresponding channel matrix tap lemma overall effective downlink channel matrix dfrc system symbol subcarrier written frequency domain hn u ue ns ns also hn h n h k n c hk n hek ue ns c corresponding channel ue k addition received signal symbol data sequence expressed ys hsxs zs c hs diag hns c zs c matrix additive white gaussian noise awgn ns subcarriers random variables following cn specifically corresponding noiseless received signal subcarrier n expressed hnxn n ns proof see appendix paper assume channels known obtained conventional channel estimation methods interference mui sum rate downlink ofdm transmissions induce mui great effects performance achievable sum rate well symbol error rate ser downlink ues assuming data symbols ues k k subcarriers n ns follow constellation modulation compact received signal ys z signal hsxs z mui zs z noise hsxs represents mui signals caused multiuser transmissions ratio sinr ue k k subcarrier n ns per frame expressed sinrk n e l n e nxl n l n Ïƒ l n k element symbol vector sn k x l n c column precoded symbol matrix xn ues expectations taken respect time index l l l e l n fixed given constellation mode hence maximum achievable sum rate k downlink ues subcarrier n given rn x k sinrk n average sum efficiency system measured r ns x ns rn note mui important performance metric dfrc system minimized perspective communications increase achievable sum rate decrease ser end following employ mui function enhancing communication performance dfrc system given min xs hsxs f radar model radar beampattern radar beampattern crucial indicator measuring radar detection tracking performance note mimo radar capable achieving higher degrees freedom dofs traditional radar generating uncorrelated mimo waveforms verified designing mimo radar beampattern equivalently transformed designing probing signal waveform radar beampattern highly related covariance matrix probing waveform considered dfrc system transmit radar beampattern versus detection angle Î¸ written bd Î¸ ns x ns h Î¸ rg na Î¸ averaged ns subcarriers Î¸ c transmit steering vector given Î¸ e Ï€ sin Î¸ Ï€ sin Î¸ ej Ï€ sin Î¸ assumption even number transmit antennas equipped ula center ula chosen reference point addition rg n c effective spatial covariance matrix transmit dfrc waveform subcarrier n ns defined rg n l gngh n order ensure covariance matrices rg n assume frame length satisfies l nt easy achieve considered wideband scenario approximately channels radar detection probability perspective radar another important performance indicator detection probability derive detection probability first express radar received target echo signal r l Î±Ï… Î¸ g l z r c expanded radar received echo vector considering ns data streams ns subcarriers l Î± complex path loss path g l fh int x l c x l c column precoded signal matrix xs z r cn r insnt awgn noise radar reception addition Ï… Î¸ ins Ï…e Î¸ c Ï…e Î¸ ar Î¸ Î¸ c ar Î¸ Î¸ transmit receive steering vector ar Î¸ Î¸ Î¸ next leveraging generalized likelihood ratio test glrt obtain asymptotic radar detection probability pd fx Âµ Î¶ fx Âµ f x pf pf fx Î¶ false alarm rate fx cumulative distribution function cdf dofs order endure constant false alarm rate pf Î¶ f x pf criterion f x inverse function cdf dofs addition function fx Âµ cdf dofs parameter Âµ defined Âµ r tr Ï… Î¸ rgÏ…h Î¸ Ïƒ r snrrtr Ï… Î¸ rgÏ…h Î¸ p r power dfrc probing waveform rg lggh c addition snr ratio radar received target echo signal denoted snrr r design dfrc waveform employ desired benchmark radar waveform denoted fh int radar waveform idft operation capable achieve desirable detection probability one benchmark waveform obtained leveraging directional beampattern design viewpoint radar performance beneficial make dfrc waveform g fh int xs close possible hence function enhancing radar performance dfrc system given min xs f h int xs f iii dfrc waveform design sampling section consider scenario leveraging sampling sampled sequence corresponds symbol sequence aim achieve desirable performance tradeoff communications radar detections elaborately designing precoded dfrc waveform matrix xs c papr well power allocation papr dfrc waveform papr defined ratio maximum power average power complex passband signal thus papr constraint considered dfrc waveform given papr xs max l h h int l nntl h int f Îµ Îµ nntl maximum allowable papr threshold dfrc system based fact radar usually required transmit maximum available power practice following equality power allocation constraint l h int f pt power budget pt totally utilized generating dfrc waveform hence papr constraint defined simplified max l h h int l Îµpt nnt nnt l equivalent following set constraints h f h int xs l Îµpt nnt nst nsnt easy notify signal matrix cp totally determined symbol signal matrix xs according definitions sectio b problem formulation order achieve desirable performance tradeoff communications radar papr power allocation constraints formulate dfrc waveform optimization problem min xs Ï ksk f hsxs f Ï f f h int xs f h f h int xs l Îµpt nnt nst l l h int f pt weighted objective function considering normalized objectives relating performance communications radar leveraged easy verify h int f f f h int xs f Î³c f h int xs f kgk f kÎ³cgk f Î³c r defined Î³c nt nt incnt utilized abstract signals g used cp Î³cg gt gt ns c zero matrix size l nt order facilitate solving process problem divide equality power allocation constraint two equality power allocation constraints respectively symbol signals cp signals l f h int xs f l kgk f Î²pt l Î³c f h int xs f l kÎ³cgk f Î² pt introducing power splitting parameter Î² simplicity fix Î² ns n Î²pt ns n pt p Î² pt nc n pt p c reasonable basis average power allocation data transmissions used rest order simplify problem denote fh int c matrix f h nt fs int dh considering g fh int xs dxs optimization variable xs xs let hd c problem technique cp beneficial avoid isi cased fading cost consuming extra energy thus degrade energy efficiency effects adding cp degradation energy efficiency eliminated enlarging ns Î² ns n approach newly introduced power allocation constraints rewritten min g Ï ksk f hdg f Ï f g f g l Îµpt nnt nst l kgk f lps kÎ³cgk f lpc solved directly optimizing dfrc mimoofdm waveform idft operations g fh int xs addressed next dfrc waveform design easy verify objective function problem equivalently form ag b f Ï kskf ht Ï insnt c b Ï kskf Ï gt c facilitate optimization transform problem objective function equivalent vector form min g age b Îµpt nnt nstl kgk lps Î³ecg lpc ae il c g vec g c b vec b c Î³ec il Î³c c gq indicates element vector g q nstl nsntl moreover minimization objective function without constraints equivalently transformed problem auxiliary parameter Î¾ follows min g age Î¾b note g Î¾o optimal solution problem g Î¾ optimal solution minimizing objective function based observation problem equivalently reformulated min g Î¾ g h ae hae hb ha b e hb g Î¾ diag ggh Îµpt nnt kgk lps Î³ecg lpc homogeneous quadratically constrained quadratic program qcqp solved sdr denote gb g h h c gb gbgb h c q ae hae hb ha b e hb c Î³bc Î³eh c Î³ec c problem rewritten min gb tr qgb gb q q Îµpt nnt nstl tr gb lps tr Î³bcgb lpc gb gb rank gb optimizing hermitian matrix variable gb dropping constraint gb problem becomes standard sdp effectively solved classic sdr technique via existing numerical tools cvx lemma proved solution exist general sdr problem indicating globally optimal solution problem always obtained solving sdr without considering constraint denoted gb proof see appendix b obtain optimal solution go based gb optimal precoded dfrc waveform symbol subcarriers expressed xo go previously proposed sdr method solving problem obtain global optimal solution original problem computation complexity quite high observe number optimization variables problem nsntl nearly proportional square nsntl thus high computational complexity may hinder use practical systems especially considering wideband scenario longer coherent frame larger next propose method much lower complexity dividing original problem l subproblems corresponding dfrc waveform approach order solve problem low complexity transform problem following form min gl x l Ï ksk f hdgl sl Ï f gl l Îµpt nnt nst l kglk p l kÎ³cglk p c l gl c sl c l c correspond column g respectively also gl indicates element gl problem original sum power allocation constraints problem respectively relaxed l individual power allocation constraints l l optimal average basis easy operate practical communication systems note problem parallelly solved addressing l shown following min gl Ï ksk f khdgl slk Ï f kgl lk Îµpt nnt nst kglk p kÎ³cglk p c finally transformed following form max gb l tr qlgb l gb l Îµpt nnt nst tr gb l p tr cgb l p c gb l gb l rank gb l similar problem gb l gblgb h l c ql aha h l bh l bl c c Î³ h c Î³c c gbl g h l l c bl c column b sdr problem also solved cvx dropping constraint verified solution exist general via method lemma number optimization variables solving problem thus computational time significantly reduced comparing solving problem simulation results leverage method solving proposed section due fact easy exceed array size matlab operation solving original problem sdr algorithm given section especially larger values ns nt desired benchmark radar waveform directional beampattern design subsection provide desired benchmark radar detection waveform system utilizing technique directional beampattern design denoted gd fh int xd xd corresponding precoded waveform assuming rd c hermitian positive covariance matrix corresponding well designed mimo radar beampattern single carrier radar detection waveform considered system via directional beampattern design obtained solving following mui minimization problem min g khdg sk f l ggh ins rd considering cholesky decomposition rd ins rd Ï†Ï†h Ï† c lower triangular matrix without loss generality assume rd ins rd well guarantee Ï† invertible hence constraint equivalently l Ï† Ï† h insnt let us denote gÏ† q problem reformulated min gÏ† lhdÏ†gÏ† f gÏ†gh Ï† insnt proven orthogonal procrustes problem opp simple global optimal solution based singular value decomposition svd given gÏ† uÏƒvh Ï†hhh ds svd Ï†hhh ds hence optimal solution original problem directional radar beampattern design expressed gd lÏ†gÏ† used desired benchmark radar waveform used problem iv dfrc waveform design oversampling ofdm introduces large amplitude variations time may result significant signal distortion presence amplifiers practical ofdm systems utilizing amplifiers technique oversampling usually required digital avoid serious distortion signals meanwhile obtain accurate papr measurement oversampled signals compared scenario leveraging sampling section iii oversampling rate equals based results papr levels accurately measured signals interpolated oversampled Ï… hence section address dfrc waveform design practical scenario oversampling problem formulation considering oversampling rate Ï… corresponding idft transmit antenna Ï…ns input output points denote fos c normalized oversampling dft matrix f os ns e Ï…ns element index nos Ï…ns addition precoded symbol matrix interpolated xos h xt xt z xt xt ns c considering even number subcarriers ns oversampled idft output written fh os int xos c hence papr constraint oversampled signal dfrc waveform idft expressed papr xos max Î³ l fh os int xos Î³ l Ï…nntl h os int os f max Î³ l fh os int xos Î³ l nntl h int f b max Î³ l fh os int xos Î³ l nnt pt Îµ Î³ nÎ³st Ï…nsnt l l os f c os fos c os xc os xt os c fc os c formulated last nc columns fos xc os c formulated last ncnt rows xos similar definitions fc xc respectively easy observe xc os xc practical scenario nc considered b based fact Ï… h os int os f h int f lpt hence papr constraint equivalent set papr constraints given f h os int xos Î³ l Îµpt nnt nÎ³st easy note effective elements oversampled matrix xos c exactly elements original precoded symbol matrix xs c utilizing accurate papr constraint facilitating formulation optimization problem effective matrix xs one challenging lies transforming fh os int xos function xs also key step simplifying problem solving process reducing computational complexity end denote equivalent oversampling dft matrix feos c feos ns e Ï…ns n ns Ï…ns ns e Ï…ns n ns ns Ï…ns easy prove f h os int xos feh os int xs c papr constraints equivalently transformed feh os int xs Î³ l Îµpt nnt nÎ³st considering equivalent idft operation feh os int c dft operation feos c system feos int feh os int insnt feh os int feos int feh os int h feh os int represents pseudoinverse feh hence formulate optimization problem similar problem optimizing dfrc waveform matrix idft operation g dxs consideration accurate papr constraints expressed min b g Ï ksk f khdg sk f Ï f kg f Î¸g Î³ l Îµpt nnt nÎ³st l kgk f lps order improve energy efficiency practical ofdm communication systems number symbols usually set much larger length cp ns nc scenario considered paper assume nc kÎ³cgk f lpc Î¸ c dos feh os papr constraints equivalently transformed vector form optimization vector g diag Î¸gg e hÎ¸e h Îµpt nnt Î¸e il Î¸ c similar case sampling section iii finally problem max b gb tr qgb diag Î¸b gb Î¸b h Îµpt nnt tr gb lps tr Î³bcgb lpc gb gb rank gb Î¸b Î¸ e c problem similar structure problem optimally solved similar way moreover also divide problem l subproblems corresponding one section leverage algorithm obtain lowpapr dfrc waveform solution solving l subproblems parallelly simulation results section simulation results given demonstrate effectiveness proposed methods designing dfrc waveform scenarios sampling ns oversampling os performance comparison two cases given verify necessity utilizing oversampling practical ofdm systems measuring papr levels ofdm signals performance results communications radar analyzed either communication priority radar priority based weighting factor Ï demonstrating feasibility effectiveness flexibility proposed dfrc waveform design methods also performance tradeoff communications radar investigated show capability proposed waveform design methods achieving satisfactory balance two functionalities following figures proposed dfrc waveform design scheme named dfrc consider four different papr threshold values one benchmark without papr constraints benchmark scheme desired radar waveform directional beampattern design noted directionalstrict another banchmark scheme power constrained zero forcing zf beamforming denoted constrained power transmitted zf waveform limited power budget dfrc scheme qpsk alphabet utilized constellation communication ues snr defined basic simulation parameters listed table unless specified otherwise obtained results following figures averaged monte carlo simulations table simulation parameters parameter symbol value number transmit antennas nt number subcarriers ns number channel taps u length cp nc number active ues k number targets frame length l power budget ofdm symbol pt oversampling rate Ï… performance comparison scenarios ns os subsection show performance comparisons cases ns os discussed section iii section iv respectively fig fig fig depict curves average sum rate ser radar detection probability pd schemes versus weighting ratio parameter Ï known radar function higher priority Ï approaches communication function dominates Ï approaches average achievable sum rate ns b os constrained papr constraints fig average achievable sum rate versus Ï ser ns b os constrained papr constraints fig average ser versus Ï fig fig present variation two important communication performance metrics sum rate ser versus Ï two figures observe average sum rates dfrc scheme increase Ï average sers decrease Ï ns os scenarios coincides intuition communication priority increases Ï thus better communication performance achieved larger Ï benchmark performance constrained schemes affected Ï easy note communication performance sum rates sers proposed dfrc scheme degrades scheme Ï approaches operates desired waveform design correspondingly communication performance approaches constrained scheme Ï close operating waveform pd ns snrr b os snrr constrained papr constraints fig average radar detection probability pd versus Ï fig shows radar detection probability values pd dfrc scheme decreases Ï increases along design focus transforming radar priority communication priority similarly demonstrates radar detection performance catch scheme Ï close gradually degrades zfpower constrained scheme Ï approaches note proposed dfrc scheme achieve better radar detection performance also better sum rate performance shown fig constrained scheme Ï approaches demonstrating effectiveness proposed methods dfrc waveform design fig fig see better dfrc performance achieved relaxed papr constraints papr threshold even without papr constraints moreover clearly shown gaps dfrc curves different papr constraints much wider case os indicating performance degradations caused tightening papr constraints obvious case os compared ns known high papr vital disadvantage ofdm technique thus papr levels dfrc waveforms carefully measured restrained effective dfrc waveform design meet hardware requirements case ns measurement papr less accurate compared os due insufficient sampling resulting set compact dfrc curves even different papr constraints three figures verify necessity oversampling measuring fig ser values constrained schemes two cases curves drawn accurate papr levels ofdm waveforms practical systems power amplifiers hence following present simulation results waveform design case os b simulation results communications radar oversampling performance communications fig fig communication performance results average sum rate ser versus snr shown scenarios communication priority Ï radar priority Ï snr db average achievable sum rate snr db ser constrained papr constraints fig average achievable sum rate ser versus snr comunication priority snr db average achievable sum rate snr db ser constrained papr constraints fig average achievable sum rate ser versus snr radar priority fig fig easy observe constrained scheme provides upper bound scheme provides lower bound communication performance scenarios communication priority Ï radar priority Ï case communication priority Ï communication performance sum rate ser dfrc scheme highly superior scheme close constrained scheme case radar priority Ï communication performance sum rate degrades scheme ser performance dfrc scheme restrict papr constraints worse scheme since papr constraints executed scheme two figures show average sum rates schemes gradually saturate snr increases due fact noise power gradually becomes negligible snr increases considering fixed limited signal power thus mui dominates leading sum rate values ser decreases snr increases restriction effects papr constraints ser performance become obvious enlarging snr performance radar fig fig radar performance results detection beampattern presented scenarios radar priority Ï communication priority Ï three targets interest angles considered fig show radar detection probability pd versus Ï two scenarios different radar received target echo snrr deg beampattern dbi deg b constrained dfrc papr fig radar beampatterns radar priority deg beampattern dbi deg constrained dfrc papr fig radar beampatterns communication priority performance radar beampattern shown fig fig demonstrates effectiveness designed lowpapr dfrc waveform detecting targets observe three targets clearly distinguished cases radar priority Ï communication priority Ï radar priority Ï beampattern proposed dfrc scheme well match desired scheme enhanced relaxed papr constraints looser beampattern fit achieved case communication priority Ï still achieve satisfactory detection performance order make fair comparison also limit zf signal power power budget pt ofdm symbol restricts performance zf scheme leads saturation sum rate performance constrained scheme high snr constrained scheme beam gains directions almost impossible detect interested targets comparison dfrc scheme two different papr thresholds fig see better beampattern match achieved relaxed papr constraints pd snrr b snrr constrained papr constraints fig average radar detection probability pd versus Ï snrr snrr performance results radar detection probability pd versus Ï depicted fig snrr snrr crucial radar performance metric pd highly affected radar received target echo snrr described section larger snrr better radar detection performance achieved case snrr pd achieved dfrc curves Ï even strictest papr constraint pd case communication priority Ï snrr increases dfrc curves capable achieve pd Ï detection probability always approach directionalstrict scheme Ï performance tradeoff communications radar section try analyze direct performance tradeoff functionalities communications radar communication results average sum rate ser versus radar detection probability pd depicted fig fig snrr snrr respectively six points shown two figures correspond Ï pd average achievable sum rate sum rate vs pd snrr pd b ser vs pd snrr constrained papr constraints fig average achievable communication sum rate ser versus radar detection probability pd pd average achievable sum rate sum rate vs pd snrr pd ser b ser vs pd snrr constrained papr constraints papr increasing direction papr increasing direction papr increasing direction papr increasing direction fig average achievable communication sum rate ser versus radar detection probability pd fig draw two required thresholds sum rate pd two thresholds ser pd b requirements pd sum rate points located top right corner satisfactory contrast points bottom right corner b satisfactory pd ser requirements giving requirements three performance metrics communications radar effectively set parameter Ï satisfying certain papr constraints hardware requirements fig snrr pd requirements easier satisfied since points located area pd thus satisfactory settings Ï papr thresholds flexibly selected based requirements sum rate ser papr db empirical cdf constrained dfrc dfrc dfrc dfrc dfrc dfrc fig empirical cdf papr db without considering papr constraints fig empirical cdfs waveform papr proposed dfrc scheme different Ï values well two benchmarks provided papr constraints considered clear see papr proposed dfrc scheme within range db papr constraints used radar priority Ï approaching papr levels average value get close scheme average value communication priority Ï close papr levels approach constrained scheme average value papr levels high satisfy strict hardware requirements practical communication systems comparison simulation results previous figures clearly observe restrain papr levels dfrc waveform even without much performance degradation communications radar demonstrating feasibility effectiveness proposed dfrc waveform design methods vi conclusion paper investigate dfrc waveform design systems scenario sampling oversampling considered measuring waveform papr levels weighted objective function normalized communication performance metric mui radar performance metric distance desired radar waveform minimized transmit power papr constraints optimization problems transformed standard sdp sdr method leveraged find optimal solution constraint satisfied general addition methods provided reduce overload solving sdp problems original problems divided subproblems corresponding simulation results demonstrate oversampling ofdm signals provide accurate way measuring papr levels moreover feasibility effectiveness flexibility proposed dfrc waveform design methods verified sufficient numerical simulations appendix proof lemma considering idft operation applied transmitter dft processing operated downlink ue receivers received baseband signal ue k frame l l frequency domain expressed l k fshs k f h int x l c x l c column xs hs k c block circulant channel matrix given h k hek hek hek hek hek hek thanks operation adding cp denote overall effective downlink channel matrix ue k hk fshs k f h int c fshs kÏ‰Ï‰t f h int Ï‰Ï‰t fs hs hs k nt Ï‰t f h int Ï‰Ï‰t b fs hs hs k nt int f h Ï‰t c fshs h fshs k ntf h Ï‰t Î»k nt Ï‰ e diag hk ns c holds column permutation hs kÏ‰ Ï‰Ï‰t insnt hs k transformed nt circulant channel matrix hs k nt c nt nt nt addition raw column permutations Ï‰t fh int Ï‰ int fh leading b equation c based special structure int fh fshs k nt fh Î»k nt Î»k nt c diagonal matrix elements Î»k nt n ehk u nt e ns nt nt n ns final column permutation Î»k nt Ï‰t diagonal structure obtained e hk n n Î»k nt n u ehk ehk u nt e ns u hek ue ns c n ns k hence combining l k hkx l diag hk ns x l considering k users l symbol frames compact form noiseless received signal given ys hsxs c hs diag hns c hn h n h k n c proof lemma completed appendix b proof lemma easy observe problem ignoring constraint convex optimization problem thus optimal solution must satisfy kkt conditions first express lagrangian function problem l qgb nxsntl Î»q tr Ï€qgb Îµpt nnt Î½ tr gb lps tr Î³bcgb lpc tr Ïˆgb Ï• tr Î»q q nstl Ïˆ lagrangian multipliers corresponding inequality constraints Î½ Ï• lagrangian multipliers corresponding equality constraints global optimal solution considered problem optimal lagrangian multipliers uniquely determined Ï€q r diagonal matrix element diagonal line value hence obtain kkt conditions given q nxsntl Î»qÏ€q Î½i Ïˆ Î»q tr Ï€qgb Îµpt nnt Î»q q nstl tr Ïˆgb Ïˆ tr gb lps tr Î³bcgb lpc tr kkt conditions satisfied global optimal solution problem ignoring constraint denote optimal solution gb corresponding optimal lagrangian multipliers denoted Î» q Î½ Ï• Ïˆo condition Ïˆo q n xsntl Î» qÏ€q Î½ oÎ³bc Ï• q Ï€o Î½ oÎ³bc Ï• Ï€o diagonal matrix diag Ï€o Î» Î»o Î»o nsntl rank Ï€o determined number nonzero lagrangian multipliers Î» q q nstl easy verify Î³bc also diagonal matrix ncntl elements value thus rank Î³bc ncntl hence obtain Ï€o Î½ oÎ³bc considering fact Ï€o Î½ uniquely determined special case Î½ rarely occurs based definition q property objective function know q hence derive Î¾ q Ï€o Î½ oÎ³bc verified contradiction assuming Î¾ exists least one vector x c x hÎ¾x also x hÏˆox x hÎ¾x Ï• ox due fact Ïˆo considering well x leading results x hÏˆox x x hÎ¾x addition x hqx thus x h Ï€o Î½ oÎ³bc x x hÎ¾x x hqx contradicts result based expression rank Ïˆ rank Î¾ rank nsntl nsntl since tr Ïˆgb Ïˆ gb follows Ïˆgb rank Ïˆ rank gb nsntl thus rank gb nsntl rank Ïˆ also rank gb matrix leading final result rank gb references brown billion devices connected internet things online available https griffiths cohen watts mokole baker wicks blunt radar spectrum engineering management technical regulatory issues proceedings ieee vol pp hassanien amin aboutanios himed dualfunction radar communication systems solution spectrum congestion problem ieee signal process vol pp shlezinger huang liu eldar joint radarcommunication strategies autonomous vehicles combining two key automotive technologies ieee signal process vol pp liu masouros petropulu griffiths hanzo joint radar communication design applications road ahead ieee transactions communications vol pp j zhang liu masouros heath jr feng zheng petropulu overview signal processing techniques joint communication radar sensing arxiv preprint mealey method calculating error probabilities radar communication system ieee trans space electron telemetry vol pp saddik singh brown multifunctional system ieee trans microw theory vol pp hassanien amin zhang ahmad information embedding using sidelobe control waveform diversity ieee trans signal vol pp sturm wiesbeck waveform design signal processing aspects fusion wireless communications radar sensing proc ieee vol pp gaglione clemente ilioudis persico proudler soraghan fractional fourier based waveform joint radarcommunication system ieee radar conference radarconf pp kumari choi heath ieee radar approach joint vehicular communicationradar system ieee trans veh vol pp liu masouros li sun hanzo communications mimo radar joint transmission ieee trans wireless vol pp liu zhou masouros li luo petropulu toward systems optimal waveform design ieee trans signal vol pp liu huang shlezinger liu zhou eldar joint transmit beamforming multiuser mimo communications mimo radar ieee transactions signal processing vol pp stuber barry mclaughlin li ingram pratt broadband wireless communications proc ieee vol pp tse viswanath fundamentals wireless communication cambridge university press cho kim yang kang wireless communications matlab john wiley sons tian zhang kong deng beamforming based radar communication ieee trans veh vol pp shi wang wang salous zhou joint optimization scheme subcarrier selection power allocation multicarrier dualfunction system ieee syst vol pp keskin koivunen wymeersch limited feedforward waveform design ofdm ieee trans signal vol pp xu petropulu wideband dual function radar communication system sparse array ofdm waveforms arxiv preprint han lee overview power ratio reduction techniques multicarrier transmission ieee wireless vol pp lim heo overview power ratio reduction schemes ofdm signals commun vol pp wunder fischer boche litsyn papr problem ofdm transmission new directions problem ieee signal process vol pp muquet wang giannakis de courville duhamel cyclic prefixing zero padding wireless multicarrier transmissions ieee trans vol pp mohammed larsson constant envelope precoding large mimo systems ieee trans vol pp li stoica mimo radar signal processing john wiley sons stoica li xie probing signal design mimo radar ieee trans signal vol pp fuhrmann san antonio transmit beamforming mimo radar systems using signal ieee trans aerosp electron vol pp bekkerman tabrikian target detection localization using mimo radars sonars ieee trans signal vol pp kay fundamentals statistical signal processing detection theory volume ii printice hall ptr pp paterson tarokh existence construction good codes low power ratios ieee transactions information theory vol pp viklands algorithms weighted orthogonal procrustes problem least squares problems dissertation datavetenskap sharif khalaj power ofdm signals based oversampling ieee trans vol pp boyd vandenberghe convex optimization cambridge university press
evolving evolutionary algorithms using linear genetic programming mihai oltean department computer science faculty mathematics computer science university kogalniceanu romania https mihaioltean github io abstract new model evolving evolutionary algorithms proposed paper model based linear genetic programming lgp technique every lgp chromosome encodes ea used solving particular problem several evolutionary algorithms function optimization traveling salesman problem quadratic assignment problem evolved using considered model numerical experiments show evolved evolutionary algorithms perform similarly sometimes even better standard approaches several benchmarking problems introduction evolutionary algorithms eas goldberg holland new powerful tools used solving difficult problems developed order solve problems classical mathematical methods failed successfully tackle many unsolved problems could turned optimization problems solving optimization problem means finding solutions maximize minimize criteria function goldberg holland yao et many evolutionary algorithms proposed dealing optimization problems many solution representations search operators proposed tested within wide range evolutionary models several natural questions answered evolutionary models optimal population size optimal individual representation optimal probabilities applying specific genetic operators optimal number generations halting evolution breakthrough arose wolpert mcready unveiled work free lunch nfl theorems search wolpert et optimization wolpert et free lunch theorems state algorithms average performance entire set optimization problems algorithm take account address aug evolving evolutionary algorithms using linear genetic programming information problem particular instance solved magnitude nfl results stroke efforts developing universal optimization algorithm capable solving optimization problems best manner since build ea able solve best problems find ways construct algorithms perform well particular problems one possibility explored paper let evolution discover optimal structure parameters evolutionary algorithm used solving particular problem attempt solving problems men delegated computers develop algorithms capable performing certain tasks prominent effort direction genetic programming gp koza koza evolutionary technique used breeding population computer programs instead evolving solutions particular problem instance gp mainly intended discovering computer programs capable solving particular classes optimization problems statement partially true since discovery computer programs may also viewed technique solving particular problem input instance problem may find computer program calculates sum elements array many approaches literature concerning gp noticeable effort dedicated evolving deterministic computer programs capable solving specific problems symbolic regression koza koza classification brameier et etc instead evolving deterministic computer programs evolve fullfeatured evolutionary algorithm output main program ea capable performing given task thus work eas two levels first macro level consists ea syswerda uses fixed population size fixed mutation probability fixed crossover probability etc second micro level consists solutions encoded chromosome first level ea first macro level ea use evolutionary model similar linear genetic programming lgp brameier et brameier et brameier et suitable evolving computer programs may easily translated imperative language like c pascal rules employed evolved eas generation preprogrammed rules automatically discovered evolution evolved ea generational one generations overlap research motivated need answering several important questions concerning evolutionary algorithms important question evolutionary algorithms automatically synthesized using information problem solved ross yes genetic operators used conjunction ea given problem moreover also interested find optimal sequence genetic operations selections crossovers mutations performed generation evolutionary algorithm particular problem instance standard ga sequence following selection recombination mutation know scheme best particular problem problem instance better let evolution find answer us evolving evolutionary algorithms using linear genetic programming several attempts evolving evolutionary algorithms made past ross tavares et ea evolved oltean et using multi expression programming mep technique oltean et oltean also several approaches evolve genetic operators solving difficult problems angeline angeline edmonds stephens et teller paper programming edmonds edmonds used two populations standard gp population population operators act main population note approaches use fixed evolutionary algorithm changed search recent paper spector robinson spector describes language called push supports new form evolutionary computation called autoconstructive evolution experiment symbolic regression problems reported conclusion conditions population quickly achieves reproductive competence soon thereafter improves spector also several attempts evolving heuristics particular problems oltean et authors evolve heuristic traveling salesman problem obtained heuristic mathematical expression takes input information already constructed path outputs next node path shown oltean et evolved heuristic performs better heuristics nearest neighbor heuristic minimum spanning tree heuristic cormen et garey et considered test problems paper organized follows lgp technique described section model used evolving eas presented section several numerical experiments performed section three eas function optimization traveling salesman problem quadratic assignment problem evolved sections research directions suggested section linear genetic programming technique section linear genetic programming lgp technique described lgp uses linear chromosome representation special phenotype transcription model lgp algorithm experiments syswerda used underlying mechanism lgp lgp algorithm starts randomly chosen population individuals following steps repeated termination condition reached two parents selected using binary tournament recombined fixed crossover probability two offspring obtained recombination two parents offspring mutated best replaces worst individual current population offspring better worst individual current population individual representation linear genetic programming lgp banzhaf et brameier et nordin uses specific linear representation computer programs programs imperative language like c evolving evolutionary algorithms using linear genetic programming evolved instead gp expressions functional programming language like lisp lgp individual represented sequence simple c language instructions instructions operate one two indexed variables registers r constants c predefined sets result assigned destination register ri rj example lgp program following void lgp program double v v v v v v v v v v v v v v v v sin v v v v v v v v sin v linear genetic program turned functional representation successive replacements variables starting last effective instruction brameier et variation operators crossover mutation crossover continuous sequences instructions selected exchanged parents brameier et two cutting points randomly chosen parent sequences instructions exchanged immediate effect length obtained offspring might different parents two types mutations used micro mutation macro mutation brameier et micro mutation operand operator instruction changed macro mutation inserts deletes random instruction lgp evolving evolutionary algorithms order use lgp evolving eas modify structure lgp chromosome define set function symbols individual representation evolving eas instead working registers lgp program modify array individuals population denote pop array individuals population modified lgp program set function symbols consist genetic operators may appear evolutionary algorithm usually types genetic operators may appear ea genetic operators evolving evolutionary algorithms using linear genetic programming select selects best solution among several already existing solutions crossover recombines two existing solutions mutate varies existing solution operators act function symbols may appear lgp chromosome thus simple c instruction appeared standard lgp chromosome replaced complex instruction containing genetic operators specifically three major types instructions modified lgp chromosomes instructions pop k select pop pop j select best individual stored pop pop j keep result position pop k crossover pop pop j crossover individuals stored pop pop j keep result position pop k mutate pop mutate individual stored position keep result position remarks crossover operator always generates single offspring two parents model crossover operators generating two offspring may designed fit evolutionary model well ii select operator acts binary tournament selection better two individuals always accepted result selection iii crossover mutate operators problem dependent instance want evolve ea binary representation function optimization may use set genetic operators following functionality crossover recombines two parents using one cut point crossover mutate one point mutation want evolve ea solving tsp problem merz et may use dpx crossover operator mutation operator krasnogor lgp chromosome c storing evolutionary algorithm following void lgp program chromosome pop population individuals pop mutate pop pop select pop pop pop mutate pop pop crossover pop pop pop mutate pop pop select pop pop pop mutate pop pop crossover pop pop evolving evolutionary algorithms using linear genetic programming statements considered genetic operations executed ea generation since purpose evolve generational ea add wrapper loop around genetic operations executed ea generation ea starts random population individuals thus lgp program must contain instructions initialize initial population obtained lgp chromosome given void lgp program chromosome pop population individuals randomly initialize population int k k maxgenerations repeat number generations pop mutate pop pop select pop pop pop mutate pop pop crossover pop pop pop mutate pop pop select pop pop pop mutate pop pop crossover pop pop remark initialization function cycle affected genetic operators parts kept unchanged search process fitness assignment deal eas two different levels micro level representing evolutionary algorithm encoded lgp chromosome macro level ga evolves lgp individuals macro level ga execution bounded known rules gas see goldberg order compute fitness lgp individual compute quality ea encoded chromosome purpose ea encoded lgp chromosome run particular problem solved roughly speaking fitness lgp individual equals fitness best solution generated evolutionary algorithm encoded lgp chromosome since ea encoded lgp chromosome uses numbers likely successive runs ea generate completely different solutions stability problem handled standard manner ea encoded lgp chromosome executed run times runs fact executed experiments performed evolving eas function optimization runs evolving eas tsp qap fitness lgp chromosome average fitness ea encoded chromosome runs optimization type macro level ea optimization type micro level ea experiments evolving evolutionary algorithms using linear genetic programming employed minimization relation finding minimum function finding shortest tsp path finding minimal quadratic assignment remark standard lgp one registers chosen program output register changed search process approach register storing best value best fitness generations chosen represent chromosome thus every lgp chromosome stores multiple solutions problem manner multi expression programming oltean et oltean oltean et model used evolving eas evolving eas use steady state algorithm described section problem set divided two sets suggestively called training set test set experiments training set consists difficult test problem test set consists benchmarking problems burkard et reinelt yao et numerical experiments section several numerical experiments evolving eas performed two evolutionary algorithms function optimization tsp qap problems evolved assessing performance evolved eas several numerical experiments standard genetic algorithm function optimization tsp qap also performed results compared evolving eas function optimization section evolutionary algorithm function optimization evolved test functions ten test problems given table used order asses performance evolved ea functions unimodal test function functions highly multimodal number local minima increases exponentially problem dimension yao et experimental results section evolve ea function optimization asses performance evolved ea comparison standard ga performed farther section evolving ea use training problem important issue concerns solutions evolved eas encoded lgp chromosome specific genetic operators used purpose solutions evolved ea encoded lgp chromosomes represented using real values goldberg thus chromosome evolved ea fixedlength array real values initialization point within definition domain randomly generated convex crossover Î± gaussian mutation Ïƒ used goldberg short description real encoding corresponding genetic operators given table experiment experiment evolutionary algorithm function optimization evolved wide range evolutionary algorithms evolved using technique described since evolved ea compared another algorithm standard ga es parameters evolved ea similar parameters algorithm used comparison evolving evolutionary algorithms using linear genetic programming table test functions used experimental study parameter n space dimension n numerical experiments fmin minimum value function test function domain fmin x pn x n x pn x n x pn qn n x pn p x j n x max xi n n x x xi n x n pn x cos Ï€ xi n x e pn n e p cos n n b c x pn x qn cos n x pn sin p n table short description real encoding function optimized f minx maxx n individual representation x xn convex recombination Î± parent x xn parent yn offspring gaussian mutation parent x xn offspring g Ïƒ g Ïƒ xn g Ïƒ g function generates real values gaussian distribution instance standard ga uses primary population n individuals additional population new population stores offspring obtained crossover mutation thus memory requirement standard ga generation n selections n crossovers n mutations assume one offspring obtained crossover two parents thus number genetic operators crossovers mutations selections standard ga take account complexity genetic evolving evolutionary algorithms using linear genetic programming operators since cases complexity different operator operator standard ga algorithm given standard ga algorithm randomly create initial population p max generations p Ï† k select p select individual population select p select second individual crossover offsp crossover parents offspring offspr obtained mutation offspr mutate offspring offspr add offspf p offspr new population endfor p p endfor best solution generated generations output program rewritten lgp program standard ga given individuals standard main population indexed popsize individuals new population indexed popsize popsize void lgp program chromosome pop popsize array containing popsize individuals randomly initialize population int k k maxgenerations repeat number generations create new population select pop pop select pop pop crossover pop popsize mutate select pop pop select pop pop crossover pop popsize mutate select pop pop select pop pop crossover pop popsize mutate select pop pop select pop pop crossover pop popsize mutate evolutionary algorithms using linear genetic programming pop new pop copy individuals new pop next population pop pop popsize pop pop popsize pop pop popsize pop popsize pop popsize parameters standard ga given table table parameters standard ga experiment parameter value population size individuals new pop individual encoding array real values number generations crossover probability crossover type convex crossover Î± mutation gaussian mutation Ïƒ mutation probability selection binary tournament evolve ea uses memory requirements number genetic operations standard ga described remark performed several comparisons evolved ea standard ga comparisons mainly based two facts memory requirements population size number genetic operators used search process ii number function evaluations comparison easily performed model since control number function evaluations number decided evolution total number genetic operators crossovers mutations selections parameter controlled model however order perform comparison based number function evaluations adopt following strategy count number function performed evolved ea use comparison purposes another standard evolutionary algorithm like ga performs number function instance evolved ea performs function use population individuals standard ga knowing ga described section creates generation number new individuals equal population size parameters lgp algorithm given table parameters evolved ea given table evolving evolutionary algorithms using linear genetic table parameters lgp algorithm used experiment parameter value population size code length instructions number generations crossover probability crossover type uniform crossover mutation mutations per chromosome function set f select crossover mutate table parameters evolved ea function optimization parameter value individual representation array real values population size number generations crossover probability crossover type convex crossover Î± mutation gaussian mutation Ïƒ mutation probability selection binary tournament results experiment depicted figure effectiveness approach seen figure lgp technique able evolve ea solving optimization problems quality evolved ea lgp chromosome improves search process advances experiment experiment serves purpose comparing evolved ea standard genetic algorithm described experiment parameters used evolved ea given table parameters used standard ga given table results comparison given table table shows evolved ea significantly outperforms standard ga considered test problems next experiment serves purpose comparing evolved ea genetic algorithm performs number function evaluations view count many new individuals created generation evolved ea thus ga use main population individuals secondary population individuals note provide significant advantage standard ga evolved ea however use larger population case algorithms standard ga evolved ea share important parameter perform number function evaluations results presented table evolutionary algorithms using linear genetic programming figure relationship fitness best lgp individual generation number generations results averaged runs table results obtained applying evolved ea standard ga considered test functions stddev stands standard deviation results averaged runs test functionevolved ea individuals standard ga individuals standard population individuals new population mean stddev mean stddev evolving evolutionary algorithms using linear genetic table results applying evolved ea standard ga considered test functions stddev stands standard deviation results averaged runs test function evolved ea individuals standard ga individuals standard population individuals new population mean stddev mean stddev results table show evolved ea better standard ga cases average performance functions however case standard ga considerable advantage evolved ea order determine whether differences given table evolved ea standard ga statistically significant use confidence applying used determining whether compared data variance given table table results function evolutionary algorithms using linear genetic programming table shows difference evolved ea standard ga statistically significant p test problems experiment also interested analyzing relationship number generations evolved ea quality solutions obtained applying evolved ea considered test functions parameters evolved ea eea given table parameters standard ga sga given table order provide comparison based number function evaluations use main population individuals genetic algorithm results experiment depicted figure unimodal test functions figure multimodal test functions figures show evolved ea scalable regarding number generations test functions see continuous improvement tendency search process evolving eas tsp section evolutionary algorithm solving traveling salesman problem cormen et garey et evolved first tsp problem described ea evolved performance assessed running several instances tsplib reinelt traveling salesman problem tsp may stated follows consider set c cities distance ci cj pair ci cj tour cÏ€ cÏ€ cÏ€ cities c minimum length needed cormen et garey et tsp garey et polynomial time algorithm solving problem known evolutionary algorithms extensively used solving problem freisleben et krasnogor merz et experiment experiment ea tsp problem evolved tsp path represented permutation cities freisleben et merz et initialized using nearest neighbor heuristic cormen et garey et genetic operators used evolved ea dpx crossover krasnogor mutation operators briefly described follows dpx recombination operator copies offspring common edges parents completes offspring achieve valid tour links belong parents way distance parents newly created offspring preserved completion may done using nearest neighbor information freisleben et merz et mutation performed applying operator operator breaks tour edges rebuilds path adding new edges see krasnogor parameters used lgp algorithm given table evolving evolutionary algorithms using linear genetic figure relationship number generations quality solutions obtained evolved ea eea standard ga sga unimodal test functions number generations varies results averaged runs evolutionary algorithms using linear genetic programming figure relationship number generations quality solutions obtained evolved ea eea standard ga sga multimodal test functions number generations varies results averaged runs table parameters lgp algorithm used experiment parameter value population size code length instructions number generations crossover probability crossover type uniform crossover mutation mutations per chromosome function set f select crossover mutate evolving evolutionary algorithms using linear genetic parameters evolved ea given table table parameters evolved ea tsp parameter value population size number generations crossover probability crossover type dpx mutation selection binary tournament training testing stages algorithm use several problems tsplib reinelt problem containing nodes used training purposes tsp instances used test set runs evolving eas performed time needed run day piii mhz computer ea yielding good performance evolved run one eas tested difficult instances tsplib results evolved ea along results obtained using ga described section given table count number newly created individuals generation evolved ea thus standard ga use main population individuals secondary population individuals way algorithms perform number function evaluations table seen evolved ea performs better standard ga considered test problems difference ranges problem problem one see standard ga performs poorly compared implementations found literature krasnogor merz et due weak evolutionary scheme employed experiment performance ga improved preserving best individual found far also could use heuristic freisleben et merz et genereting initial solutions thus improving search however beyond purpose research main aim evolve evolutionary algorithm compare similar terms number genetic operations performed memory requirements number function evaluations ea structures evolving eas quadratic assignment problem section evolutionary algorithm quadratic assignment problem evolved quadratic assignment problem quadratic assignment problem qap n facilities assigned n locations minimum cost given set Ï€ n permutations n two nxn matrices aij bij task minimize quantity evolutionary algorithms using linear genetic programming table results standard ga evolved ea instances tsplib mean stands mean runs stddev stands standard deviation difference percent computed considering values evolved ea baseline results averaged runs problem standard ga evolved ea mean stddev mean stddev c Ï€ xn xn aij bÏ€ Ï€ j n matrix interpreted distance matrix aij denotes distance location location j b referred flow matrix bkl represents flow materials facility k facility qap belongs class problems garey et experiment evolving evolutionary algorithms using linear genetic experiment evolutionary algorithm qap problem evolved every qap solution permutation Ï€ encoded vector facilities value j th component vector indicates facility j assigned location Ï€ j initial population contains randomly generated individuals crossover operator dpx merz et mutation performed swapping two randomly chosen facilities merz et parameters used lgp algorithm given table table parameters lgp algorithm used evolving evolutionary algorithm quadratic assignment problem parameter value population size code length instructions number generations crossover probability crossover type uniform crossover mutation mutations per chromosome function set f select crossover mutate parameters evolved ea qap given table table parameters evolved ea qap parameter value population size number generations crossover probability crossover type dpx mutation selection binary tournament training testing stages algorithm use several problems qaplib burkard et problem containing facilities used training purposes qap instances used test set runs evolving eas performed run ea yielding good performance evolved one evolved eas tested difficult instances qaplib results evolved ea along results obtained ga described section given table since evolved ea creates individuals generation use standard ga main population individuals additional population new population individuals table shows evolved ea performs better standard ga considered qap instances difference ranges problem problem could use local search merz et techniques order improve quality solutions beyond purpose research evolutionary algorithms using linear genetic programming table results standard ga evolved ea instances qaplib mean stands mean runs stddev stands standard deviation difference shown percentage computed considering values evolved ea baseline results averaged runs problem standard ga evolved ea mean stddev mean stddev work questions answered evolved evolutionary algorithms patterns source code evolved eas expect best algorithm given problem contain patterned sequence instructions standard ga concerned sequence following selection recombination mutations sequence given section know optimal sequence instructions given problem evolving evolutionary algorithms using linear genetic instructions effective possible genetic operation useless two consecutive crossovers operating two parents brameier banzhaf brameier et used algorithm removes introns lgp chromosomes unfortunately choice proved efficient practice since useless genetic material kept order provide minimum genetic diversity genetic operators suitable particular problem solved careful analysis regarding genetic operators used performed order obtain best results usefulness useless genetic operators employed gp already subject long debates due nfl theorems wolpert et know best genetic operator performs best problems however case since purpose find evolutionary algorithms particular classes problems optimal number genetic instructions performed generation evolved ea experiments performed paper used fixed length lgp chromosomes way forced certain number genetic operations performed generation evolved ea numerical experiments performed using variable length lgp chromosomes hoping representation find optimal number genetic instructions performed generation another approach problem evolving eas could based automatically defined functions koza instead evolving entire ea try evolve small pattern sequence instructions repeatedly used generate new individuals known evolutionary schemes use form evolution instance pattern employed genetic algorithm select p op p op two individuals randomly chosen select p op p op another two individuals randomly chosen c crossover c mutate c advantage approach reduced complexity size pattern considerably smaller size entire ea order evolve high high quality eas assess performance extended set training problems used set include problems different fields function optimization symbolic regression tsp classification etc efforts dedicated training algorithm increased generalization ability obtaining powerful evolutionary algorithms extended set operators used set include operators compute fitness individual population case evolved ea elitism feature allow us compare complex evolutionary schemes like syswerda evolutionary algorithms using linear genetic programming experiments populations fixed size used another extension proposed approach take account scalability population size numerical experiments analyze relationship lgp parameters population size chromosome length mutation probability etc ability evolved ea find optimal solutions conclusions paper linear genetic programming used evolving evolutionary algorithms detailed description proposed approach given allowing researchers apply method evolving evolutionary algorithms could used solving problems fields interest proposed model used evolving evolutionary algorithms function optimization traveling salesman problem quadratic assignment problem numerical experiments emphasize robustness efficacy approach evolved evolutionary algorithms perform similar sometimes even better standard approaches literature acknowledgments author likes thanks anonymous reviewers usefull sugestions source code evolving evolutionary algorithms evolved eas described paper available references angeline adaptive evolutionary computations computational intelligence dynamic systems perspective pages ieee press new york usa angeline two crossover operators genetic programming angeline kinnear editors advances genetic programming ii pages mit press cambridge usa back genetic algorithms toward practice autonomous systems proceedings first european conference artificial life pages mit press cambridge usa banzhaf nordin keller francone genetic programming introduction automatic evolution computer programs applications kaufmann francisco brameier banzhaf comparison linear genetic programming neural networks medical data mining ieee transactions evolutionary computation ieee press ny usa brameier banzhaf evolving teams predictors linear genetic programming genetic programming evolvable machines kluwer brameier banzhaf explicit control diversity effective variation distance linear genetic programming lutton j foster miller ryan tettamanzi editors european conference genetic programming iv springer verlag berlin pages burkard rendl quadratic assignment problem libray european journal operational research cormen leiserson rivest introduction algorithms mit press edmonds b programming operators variation electrik ai evolving evolutionary algorithms using linear genetic freisleben merz genetic local search algorithm solving symmetric asymmetric traveling salesman problems ieee international conference evolutionary computation pages ieee press garey johnson computers intractability guide npcompleteness freeman co san francisco ca goldberg genetic algorithms search optimization machine learning reading holland adaptation natural artificial systems university michigan press ann arbor koza genetic programming programming computers means natural selection mit press cambridge koza genetic programming ii automatic discovery reusable subprograms mit press cambridge krasnogor studies theory design space memetic algorithms phd thesis university west england bristol merz freisleben b genetic local search tsp new results ieee international conference evolutionary computation pages merz freisleben b fitness landscape analysis memetic algorithms quadratic assignment problem ieee transaction evolutionary computation ieee press ny usa nordin compiling genetic programming system directly manipulates kinnear editors advances genetic programming pages mit press cambridge usa oltean evolving evolutionary algorithms using multi expression programming banzhaf et al editors european conference artificial life vii lnai pages berlin germany oltean solving problems multi expression programming chen et al editors th international workshop frontiers evolutionary algorithm pages oltean dumitrescu evolving tsp heuristics multi expression programming encoding multiple solutions linear gp chromosome bubak van albada sloot dongarra international conference computational sciences vol ii pages berlin oltean oltean encoding multiple solutions linear gp chromosome bubak van albada sloot dongarra international conference computational sciences workshop vol iii pages berlin reinelt tsplib traveling salesman problem library orsa journal computing ross b searching search algorithms experiments technical report brock university ontario canada spector robinson genetic programming autoconstructive evolution push programming language genetic programming evolvable machines kluwer stephens olmedo vargas waelbroeck evolving systems artificial life syswerda uniform crossover genetic algorithms schaffer editors international conference genetic algorithms pages morgan kaufmann publishers san mateo ca tavares machado cardoso pereira costa evolution evolutionary algorithms keijzer et al editors european conference genetic programming pages berlin teller evolving programmers intelligent recombination operators angeline kinnear editors advances genetic programming ii pages mit press usa yao liu lin evolutionary programming made faster ieee transaction evolutionary computation ieee press ny usa evolutionary algorithms using linear genetic programming wolpert mcready free lunch theorems search technical report santa fe institute usa wolpert mcready free lunch theorems optimization ieee transaction evolutionary computation ieee press ny usa
casting exploit analysis weird machine reconstruction problem robert abela mark vella department computer science university malta msida malta email constitute malware form application inputs take advantage security vulnerabilities inside programs order yield execution control attackers root cause successful exploitation lies emergent functionality introduced programs compiled loaded memory execution called weird machines wms essentially wms unexpected virtual machines execute attackers bytecode complicating malware analysis whenever bytecode set unknown take direction wm bytecode best understood level process memory layout attained exploit execution step building towards memory layout comprises exploit primitive exploit basic building block work presents wm reconstruction algorithm works identifying exploit behaviour dynamic analysis target binaries associating responsible exploit segment wm bytecode manner analyst familiar exploit programming immediately recognise reconstructed wm bytecode semantics work first attempt studying feasibility method focuses web browsers targeted javascript exploits analysis script exploits weird machines dynamic binary analysis introduction exploits peculiar kind malware rather constituting properly packaged executable binary take form application inputs exploits take advantage security flaws along intended unintended functionality inside applications order subvert control flow shifting application execution control attacker renders exploits ideal entry point intrusions typical scenario application inputs form malicious html embed malicious scripts target memory corruption errors buffer overflows dangling pointers inside code aim subvert browser execution make download conventional malware backdoor bot order complete stealthy intrusion multitude vulnerability types abound memory errors quite distinguished due ability yield target computational power attacker along security privileges focus work moreover focus specifically javascript exploits targeting web browsers time although longer term goal encompass exploit forms mainstream view exploits security vulnerabilities sole cause success exploits much process vulnerability introduction vulnerability elimination way secure application yet view misses crucial emergent behaviour introduced programs compiled loaded memory execution makes exploit programming possible term weird machine wm coined refer instance emergent functionality leveraged attackers presents view actual situation think wm virtual machine takes programs written bytecode understands execution input outputs programs results section ii main point wm bytecode documented vm instruction set rather unknown field malware analysis wms complicate process inferring malicious behaviour javascript exploits since script statements analysed terms bytecode intended yet unknown wm targeted exploit writer example let compare listings former snippet taken disassembly conventional binary malware case malware behaviour directly inferred semantics physical machine instructions system api calls lines set arguments internetopenurla call line depending return value execution forked lines possibly download http line listing binary malware dissassembly n p p u h x f zill windows nt c l l dword im p nt e r n eto p e na mov dword va r c ea x n p p u h h p www c k e r c n c com cc htm mov eax dword va r c p u h ea x c l l dword im p nt e r n et p e n u rl mov dword v r ea x cmp dword v r j n e n p c l l dword p n e r n e r e f l e n p latter javascript sample sep intricate face value lines create hidden html layer lines create long string used property value multitude html buttons added invisible layer lines web design terms snippet pretty much useless yet none wm bytecode sequence intended setup physical machine instructions inside browser memory eventually executed subsequent statements exploit presence memory error inside browser codebase thus reconstructing wm bytecode essential first step exploit analysis listing javascript exploit malware html head body di v bl h v c r p l n g u g e j v c r p v r v c n n e r document g et el e e nt b bl h v c n n e r l e c e x p l none v r u n e c p e n p cccc w hil e l e n g h f r v r v r bj document c r e e e l e e n b u n bj l e u b r n g v c n n e r p p e n dc hil bj n p c r p html example postulate exploit analysis wm bytecode best understood level process memory layout exploits programmed attain eventually enabling program wm step taken build towards layout comprises exploit primitive basic building blocks exploit programming way analyst familiar exploit programming immediately recognize bytecode semantics work first attempt studying feasibility approach far know first cast exploit analysis wm reconstruction problem end result wm reconstruction algorithm works identifying exploit runtime behaviour dynamic binary analysis subsequently associating responsible exploit snippet fed input target browser section iii implicated script statements constitute wm bytecode syntax machine opcodes speak exploit primitives assigned appropriate labels provide semantics experimentation popular exploit primitives used script exploit case studies section iv demonstrate detecting wm bytecode syntax semantics using exploit primitives possible defining primitives program state transitions turn case studies show wm reconstruction algorithm heart exploit analysis tool helps analyst move beyond script superficial semantics program memory level matters understanding exploits finally experimentation outcome provides basis research direction completing work finalized application functionality bugs application input application output web page weird machine bytecode p wm p wm output backdoor installation emergent functionality weird machine fig weird machines emergent program functionality produce unexpected virtual machines exploit analysis tool usable wider array exploit forms sections v vi ii background related work weird machines wm targeted attackers none emergent program functionality generated compilers linkers program loaders process executable image creation loading resulting executable inside program memory comprises machine code data long treated material computer scientists even though attackers thrive access emergent functionality fact requires substantial knowledge goes program memory level along presence memory errors activating full malicious potential fig depicts scenario programming wm emerging web browsers intended functionality constitutes parsing html documents intermediate representation document object model dom tree fed rendering algorithm visualization embedded javascript snippets supported scripting language matter instead passed script engine compilation ultimately number statements constitute calling back browser extensions dynamically update rendered page concerned typically natively coded c derivatives process highly prone introduction memory errors see resulting particularly dangerous wm bytecode fully subvert executable control flow happens case using scripts similar one shown listing input wm programs p wm made wm bytecode processed emerging wm compute p wm output backdoor installation far wm concept used explain computational hardness input sanitization problem means eliminate related errors inside parser whenever processing untrusted application inputs proponents suggest formal approach secure coding subsequently investigation wm concept taken beyond software programs hardware domain scripts exploits particular interest recent years since improve upon earlier packet exploit techniques order break modern exploit deferences turn exploits become much daunting understand listing depicts layout typical file exploit usually contains string intended corrupt function pointer memory well compiled malicious code executed contrast script exploits involve multiple steps create specific program memory layout successful exploitation take place typically aiming divert execution earlier created string whose content doubles valid machine code nowadays exploit sophistication increased level existing executable content inside browser memory searched way create new computations way myriad exploit mitigations defeated result manually inferring exploit sequence proves painstaking process requires intimate knowledge complex script engines document parsers well interaction two see rather exploit analysis tool labels scripts statements wm bytecode whose semantics grounded exploit primitive behaviour would require knowledge exploit programming general listing file exploit fragment hea de r f e l hea de r f e l v e r l n g r n g cc cc cc cc cc exploit analysis specific instance malware analysis general incident response task studies malware samples acquired digital investigation aim infer malware objectives compiled code produce actionable information form intrusion detection rulesets routines exploit analysis specifically concerned improving upon existing exploit mitigations well inform secure general exploration mainly concerned complete exposure malicious behaviour inside malware sandboxes therefore providing effective automation main challenge posed behaviour eludes sandboxes typically handled exploration problem solvable using symbolic execution binaries taint analysis complementary technique used identify data objects interest solely apply expensive symbolic execution upon traces process objects concretely executing remaining ones sought behaviour finally exposed paramount recognized work closest jscalpel builds upon approach purpose identifying execution injected code distinguishing activity dynamic binary analysis method however disregards explaining overall exploit strategy highlighting example existing mitigations bypassed statements actively program emerging wm yet acknowledge value aiding analyst fully understanding exploits weeding statements contribute exploitation focusing wm reconstruction propose exploit scripts labelled way support analyst throughout entire exploitation sequence iii weird machine reconstruction wm reconstruction algorithm revolves around notion exploit primitive first coined informally within specific context script exploits refers simple compound script statement provides access program native operation would otherwise directly available interested characterizing wm bytecode terms exploit primitives wm bytecode space encompassing possible exploit primitives primitives behaviour provide bytecode semantics formally definition exploit primitive behaviour identified primitive label l defined program memory state transition function Î´l p w Ïƒ p w wn w n abstractions full program memory state defined set derived values wi w Ïƒ pm set candidate weird machine bytecode candidate primitive label pi could associated simple compound statement inside script exploit definition weird machine respect execution web browser b input exploit e denoted defined function Ïƒ l l ln set labels one defined exploit primitive behaviour Î´ln p implies p constitutes valid bytecode whose semantics defined sequence Î´l corresponding string labels l note injective meaning exploit primitive label string l could associated different bytecodes stark reminder dealing conventional virtual machines rather unintended weird ones therefore wm reconstruction identifying wm bytecode syntax semantics speak comprises choosing exploit primitives l interest ii expressing behaviour form program memory state transitions Î´l iii script preparation terms identifying script statements comprise candidate wm bytecode p marking accordingly iv detecting transitions conforming Î´l dynamic binary analysis executed upon exploit script analysis v associating detected Î´l corresponding p using label l confirmed exploit bytecode p added wm bytecode set Î´l provides semantics procedure formalized algorithm wmrecon executes exploit termination line resumeexecutionuntilnextp line executes exploit next fresh analysis line executes next calling derivestate order compute abstract program state wp associated prior execution case simple statements second state p computed resulting state p gets executed executecomplete lines finally lines use transitionsidentify order detect possible sequence state transitions conforming Î´ln updating accordingly case p associated compound statement derived wp pushed onto stack lines used corresponding statements completed execution lines manner individual script statement associated multiple candidate wm bytecodes well part statement blocks algorithm wmrecon weird machine reconstruction input web browser b exploit sample e Ïƒ defined e l ln set labels corresponding Î´ln output reconstructed weird machine def Ïƒ terminates e timesout e p resumeexecutionuntilbeforenextp e closescompound p p derivestate b p wp popstack Î³ l transitionsidentify wp p p l next end end wp derivestate b iscompound p pushstack Î³ p wp next end executecomplete p p derivestate b l transitionsidentify wp p p l end end return incorporated part exploit analysis tool envisaged process depicted fig proceeds follows script using prepared markers representing candidate primitives fig example exploit analysis process using tool implements wmrecon p using setmarker candidate primitive resetmarker used end marker associated compound statements step carried manually tool assisted ii p markers associated wm bytecode labels whenever found produce exploit primitive behaviour case candidate primitive marker loop associated allocprimitive exploit primitive referring memory allocation behaviour example subsequent info line qualifies observed runtime behaviour labelled script exploit presents partially reconstructed wm compound statement block identified valid wm bytecode whose semantics allocate chunks memory buffers completing wm could require iterations adjusted markers analysis iterations iv evaluation idea exploit analysis reconstructing wms targeted exploit writers evaluated feasibility specifically carried terms expressing exploit primitive behaviour program memory state transition functions section effectiveness utilized tool section correctly labelling exploit samples section thus accurately reconstructing wms concerned exploit primitives exploit primitives chosen based notion provide script level access native operations primitive first informally described snippet form description used aid building towards formal description finally formal Î´l definition provided takes form constraint prior w post transition states needs satisfied candidate primitives Ïƒ associated memory allocation primitive allocates chunk memory process heap c primitive described function call standard c library malloc function course tool intuition cases expected script level possible utilize allocated portion memory way programmer desires programming natively furthermore memory allocation could carried various ways even native level directly system call else calling custom memory managers consequently behaviour expressed abstract program state w def size allocated heap memory Î´memalloc p w w memory freeing primitive frees previously allocated chunk memory process heap expressed c call free behaviour expressed abstract program state w previous primitive fact behaviour exactly opposite defined Î´memf ree p w w execute crafted code primitive sets program counter address containing executable content executes c behaviour time requires description bit involved making use function pointer initialized address containing machine instructions dynamically extends original description follows v oi e x e c c r f e v oi f p r v oi r g e r p r e c e c l e c nt n c k e r c n r l l e c de f p r r g e r f p r understood already contains code execution prior primitives argument applies case requires disclosing predicted finally primitive requires presence memory error made available script level buffer overflow dangling pointer thus relates wm bytecode dangerous kind corresponding behaviour expressed abstract program state w def pc def expected codebase Î´execcraf ted p w w w pc refers program counter register expected codebase refers known memory regions containing browser code executable image sections heap memory reserved jit script engines call stack replacement primitive sets stack pointer memory location containing fabricated call stack corrupting flow execution return innermost function call thereafter c behaviour similar previous primitive two differences firstly presence fabricated call stack assumed rather executable content secondly stack pointer register time manipulated hence inline assembly performing stack pivot primitive also presupposes memory error description v oi c l l c k r e p l c e v oi r g e r p r e c e c l e c nt ai n h e f b r c e c l l c k asm v l l e mov r p r r g e r corresponding behaviour expressed abstract program state w def sp def expected call stack Î´callstackreplace p w w w sp refers stack pointer register expected call stack refers memory regions containing known call stacks application threads prototype implementation prototype tool developed windows explorer environment popular target dynamic binary analysis framework used tracing web browser instructions state transition monitoring well introspect cpu register values memory content program state derivation carried per basic instruction block script engine thread umbra extension also offers convenient way walk window process vad trees time filtering vad nodes heap memory manager information specifically concerning memory regions obtained vm extension command implementation setmarker resetmaker marker functions per fig provided inside script file requires inclusion within exploit files script preparation phase implementation makes use javascript alert function case internet explorer results call messageboxindirectw program instruction tracing call function arguments matching expected marker skipped relevant prior w post transition states computed accordingly known code call stack regions required exploit primitives computed execution reaches browser winmain entry point overall accuracy program state derivation implemented current prototype known possibly impacted well lack knowledge custom memory managers garbage collectors typical script engines case studies present exploit case studies including number previously defined exploit primitives ordered according sophistication case preanalysis markers labels shown superimposed manner corresponding script listings technical analysis exploits publicly available thus accuracy labelling could verified case study latest vulnerable version configurations used standard heap spray first case study taken heap spraying tutorial technique commonly used inject multiple instances malicious compiled code inside target vulnerable application environment win xp listing shows snippets exploit sample study number memalloc memfree primitives expected duly labelled lines specifically loop line identified sequence predominantly memory allocations interleaved frees memory memory clearly representing memory allocation freeing wm bytecodes respectively listing standard heap spray c r p r c r ke r j c r p c r p v r h e l l c e u n e c p e u v r b g b l c k u n e c p e u v r h e e r z e v r l c k h e e r z e h e l l c e l e n g h etm r k e r bigblock bi gbl oc k snip memalloc memfree snip n f snip snip w hil e b g b l c k l e n g h l c k b g b l c k b g b l c k v r f l l b l c k b g b l c k u b r n g l c k v r bl c k b g b l c k u b r n g b g b l c k l e n g h l c k w hil e bl c k l e n g h l c k bl c k bl c k bl c k f l l b l c k v r memory new r r f r etm r k e r h ell c e h e l l c e memalloc n f h e l l c e memalloc n f snip memory bl c k h e l l c e f r etm r k e r f ree f r e e memalloc n f f r e e memfree n f snip memory r e e tm r k e r c r p operation aurora exploit second case study taken technical blog analyses exploit used popular operation aurora cyberattack experimentation setup identical one used previous exploit case heap spay followed uaf exploit cve representative typical scenarios virtual function pointers get corrupted consequence multiple pointers used point object memory one pointers used free memory object reference counting pointers left referencing memory region get reused time thus virtual function table pointer overwritten subsequent behaviour left undefined listing shows snippets exploit sample lines identify entire function foverwrite valid wm bytecode executes crafted code particular information label line gives away line shown snippet sequence memory allocation freeing primitives inside function heapspray crafts code similar fashion previous case study yet lines fremove marker remains unlabelled even though memfree label expected happening memory region freed custom allocator underlying system heap memory manager impacting known limitation prototype listing operation aurora exploit c r p r c r ke r j c r p c r p snip f u n c n heapsp ray snip f u n c n fremove nl oa de nt heapsp ray etm r k e r fremove fremove eleme nt document c r e e e v e n b j e c nl oa de nt document g et el em e ntb spanid innerhtml etm r k e r fo v e rw rit e f v e r w rit e e x e c c r f e snip n f x snip window e n e r v l fo v e rw rit e r e e tm r k e r f u n c n f v e r w rit e b u f f e r snip f r r ra l e n g h r ra b u f f e r c r p snip p n spanid img r c bc g f nl fremove e v e n span snip cbutton uaf third case study obtained penetration testing framework chosen use programming metasploit framework ie cbutton uaf exploit rop technique rop recomposing existing executable content inside target browser thus able bypass data execution prevention dep mitigation renders segments exploits expecting thus rendered inert presence library loaded deterministic memory address base space layout randomization aslr enabled uaf exploit cve used direct execution instruction pivots stack location enabling execution instruction sequence effectively switches dep exploit resumes similar fashion previous case study sample shown listing executed win xp environment entire function called line constitutes wm bytecode whose semantics corresponds sequence callstackreplace execcrafted primitives addresses present labels respectively contents stack pointer program counter registers addresses memory locations allocated script execution trigger detection exploit primitives iterations would required zoom finer level analysis granularity order identify statements specifically causing type exploit primitive behaviour meantime gc markers lines respectively remain unlabelled due custom allocator issue already encountered previous case study hand prepare marker line properly labelled allocation sizes concerned indicate case internet explorer larger allocations likely get detected since affect underlying system heap manager else avoid involving custom allocator altogether listing cbu n uaf exploit ct p e html html xmlns u r n schemas c r f tim e head meta import name pace p l e e n n e f u l tim e c r p f u n c n stim e c oarg snip f u n c n h ell ow rl e f rm document g et el em e ntb fo rmelm e di v document g et el em e ntb di v elm etm r k e r c r e e b n c r e e b n f r document c r e e e l e e n b utt n e di v p p e n dc hil document c r e e e l e e n b utt n e di v f r c h l p pl el em e nt e f rm etm r k e r f r e e b n f r e e b n e di v innerhtml e di v p p e n dc hil document c r e e e l e e n body etm r k e r gc gc c l l e c g r b g e etm r k e r p r e p r e p r e p r e memalloc snip n f p u n e c p e f r p u n e c p e p u n e c p e snip f u n e c p e f r f f u n e c p e e l e f u n e c p e f p etm r k e r mstime mstime memalloc snip c l l c k r e p l c e snip e x e c c r f e n f snip x snip x stim e c h e l l c e fo h e pbl c k si z e b j myanim c r p body nl e v l h ell ow rl animatecolor myanim di v di v elm v fo rm fo rmelm html discussion research direction results obtained case studies demonstrate promise feasibility approaching exploit analysis wm reconstruction particular primitives along process followed defining show exploit primitives defined manner required wmrecon algorithm despite case studies based relatively less recent exploits targets mandated elevated sophistication recent ones nonetheless attain intent demonstrating applicability idea proposed therefore augur favourably towards exploration direction definitely one important outcome crucial requirement tools implementing wmrecon able accurately detect monitor custom memory managers substantial effort already devoted towards endeavour previous work significant success therefore solid starting point already place aspect dealt research proceed cover exploits case studies particular exploits leverage multiple features vulnerabilities targets possibly combining different parsing modules script engines web browser within individual steps exploit one specific leverages actionscript engine deterministic memory layout combined javascriptaccessible browser vulnerability able bypass aslrrandomized heaps leaking memory content separate memory error actionscript engine used subvert execution switching dep using rop process reconstructing wms exploits similar level sophistication entails defining exploit primitives memory reads well able separate program memory state transitions different application threads dynamic binary analysis longer term followed idea also cater assisting analysts marker placement process script specifically targeted aiding exploit analysis browser script exploit case studies well kernel exploit case studies respect latter research avenue interesting note kernel exploits similar script exploits sense script exploits utilize primitives access operations scriptlevel likewise kernel exploits access operations vi conclusions paper tackled problem difficulty analysing script exploits due increased sophistication approach taken cast exploit analysis problem weird machine wm reconstruction problem aims identify script statements used exploit primitives order take advantage emergent functionality inside target applications constituting wm valid bytecode novel idea explained length paper analysis script exploits nothing superficial semantics script statements rather program native operations aim attain quest program wm concept presented wmrecon wm reconstruction algorithm takes dynamic binary analysis approach order detect behaviour caused exploit primitives associating responsible script statements constitute valid wm bytecode associated exploit primitive behaviours provide corresponding semantics reconstructed wm none identified bytecode set experimentation exploit samples moderate sophistication demonstrates feasibility approach time results also point towards crucial requirement enhancing current prototype capability detect monitor customer memory managers handle exploits elevated level sophistication particular aiming exploits combine multiple script languages eventually also consider adding kernel exploits within scope proposes exploit analysts benefit automated identification individual exploit steps required knowledgeable exploit programming general therefore away learn details multitude web browser script engine implementations references marco cova christopher kruegel giovanni vigna detection analysis attacks malicious javascript code proceedings international conference world wide web pages acm corelan heap spraying demystified https accessed sergey bratus michael e locasto meredith l patterson len sassaman anna shubina exploit programming buffer overflows weird machines theory computation usenix login ms ie security vulnerabilities https product accessed len sassaman meredith l patterson sergey bratus patch postel robustness principle ieee security privacy julian bangert sergey bratus rebecca shapiro sean w smith weird machine lessons computation woot windows mitigation improvements https pdf accessed trend micro look adobe flash player attack http accessed andreas moser christopher kruegel engin kirda exploring multiple execution paths malware analysis security privacy sp ieee symposium pages ieee dawn song david brumley heng yin juan caballero ivan jager min gyung kang zhenkai liang james newsome pongsin poosankam prateek saxena bitblaze new approach computer security via binary analysis international conference information systems security pages springer sang kil cha thanassis avgerinos alexandre rebert david brumley unleashing mayhem binary code security privacy sp ieee symposium pages ieee yanzhen qu kelly hughes detecting metamorphic malware using aggregated signature internet security worldcis world congress pages ieee xunchao hu aravind prakash jinghan wang rundong zhou yao cheng heng yin dissection javascript exploits via dynamic analysis international symposium research attacks intrusions defenses pages springer fermin serna info leak era software exploitation https us serna leak era accessed stephen bradshaw heap spray exploit tutorial internet explorer use free aurora vulnerability http xi chen asia slowinska herbert bos membrush practical tool detect custom memory allocators c binaries reverse engineering wcre working conference pages ieee
border quarantine systems impact delta variant cameron freya david michael jodie james nicholas computing information systems university melbourne australia school population global health university melbourne australia peter doherty institute infection immunity royal melbourne hospital university melbourne australia infectious diseases alfred central clinical school monash university australia mathematics statistics university melbourne australia dated september sep abstract controlling transmission effectiveness border quarantine strategies key concern jurisdictions local prevalence disease immunity low settings like china australia new zealand rare outbreak events lead escalating epidemics trigger imposition large scale lockdown policies examine degree vaccination status incoming arrivals quarantine workforce allow relaxation quarantine requirements develop apply detailed model disease progression transmission taking account nuanced timing factors key among disease incubation periods progression infection detectability incubation using disease characteristics associated ancestral lineage benchmark level acceptable risk examine performance border quarantine system vaccinated arrivals examine disease transmission vaccine efficacy parameters wide range covering plausible values delta variant currently circulating globally results indicate threshold outbreak potential function vaccine efficacy time outbreak increasing two orders magnitude vaccine efficacy transmission increases parameters corresponding delta variant vaccination able maintain capacity quarantine systems reduce case importation outbreak risk counteracting pathogen increased infectiousness prevent outbreaks heightened vaccination border quarantine systems must combined mass vaccination ultimate success programs depend sensitively efficacy vaccines viral transmission introduction mitigation pandemics requires continuous analysis risk order respond proportionately efficiently border quarantine systems designed allow travel jurisdictions limiting risk disease transmission rigorously limiting disease transmission regions appropriate large differences exist pathogen prevalence strict border measures effective preventing disease incursions also costly operate reduce international travel trickle given enormous economic social costs associated international travel restrictions come stringent border quarantine policies systems used prevent catastrophic public health crisis pandemic border quarantine strategies implemented parts world various forms regions tightly controlled borders screening international travellers provided effective means limiting importation rate individuals infected facilitated success outbreak control strategies relying targeted ttiq responses combination approaches largely successful preventing widespread epidemics countries china new zealand australia australia meant many citizens abroad outset pandemic stranded overseas due quarantine capacity constraints also stressed higher education tourism sectors devastated airline industry design quarantine system needs balance benefits reducing risk importation associated costs order assess tradeoff analytical frameworks must incorporate emerging evidence pathogen characteristics provide accurate estimates risk associated alternative quarantine strategies two potential factors motivating revaluation quarantine stringency include changes properties pathogen changes deemed acceptable level breach risk case development rollout effective vaccines provided opportunity countries previously maintained stringent border controls contemplate future measures could relaxed however emergence delta variant produced need evaluate risk context virus exhibiting higher transmissibility higher clinical severity existing vaccines less effective shifting context role vaccination acceptable risk border quarantine breach events must emergence new variants broadly different disease characteristics viewed onset new pandemic therefore risk mitigation measures need assessed based information work evaluate efficacy border quarantine systems function following pathogen characteristics transmissibility efficacy vaccines transmission combination efficacy infection efficacy transmission breakthrough cases primary purpose estimate reduction transmission risk focus pathogen vaccine characteristics associated transmission efficacy vaccines preventing infection onward transmission primary consideration designing modified border quarantine pathways vaccinated travellers currently becoming widely adopted framework evaluate performance simulated border quarantine system consistent recommendations world health organization countries choose quarantine international arrivals includes minimum stay testing regime response strategy isolates confirmed cases contacts travellers quarantine figure figure chosen model reproduces general features adopted chinese australian new zealand border quarantine systems examine performance quarantine system range vaccine efficacy levels reproductive ratios relative unvaccinated baseline condition vaccine efficacy investigate risk outbreaks seeded quarantine breach events changes emergence transmissible strain delta variant outbreak scenarios examine effect varying levels vaccination coverage model ensemble results presented help guide adaptation border quarantine measures virus evolves vaccination coverage increases vaccine efficacy changes ii methods model overview structure inputs outputs simulate virus transmission case detection isolation response pathways within single quarantine facility capacity travellers facility staffed vaccinated workers intermittent contact quarantine individuals processed subject testing case isolation structure quarantine environment generic captures main principles typically applied border quarantine facilities output quarantine model used separate branching process model evaluate potential outbreaks community transmission schematic overall system shown figure population structured two distinct groups one comprising workers staff arrivals quarantine extension isolation community workers workers close contact groups days fig schematic quarantine system model arrivals enter quarantine groups four close contacts groups weak contact one another workforce case detected infected individual placed isolation contacts placed quarantine extension travellers extended quarantine still contact workforce groups within facility separate branching process model used evaluate potential outbreaks community based breach event statistics produced quarantine system model facility comprising quarantined travellers travellers move system indicated figure arriving close contact groups individuals travellers remain system days unless infection detected within group day minimum stay means typically travellers exit system week model used simulate border quarantine incorporates detailed description progression transmission captures following salient features lognormally distributed incubation period mean approx Âµ Ïƒ figure infectiousness increasing moment exposure peaking symptom onset declining recovery figure test sensitivity peak symptom onset followed gradual decline figure secondary case distribution figure features allow model capture two important effects quarantine environment first truncation naturally secondary case distribution due physical separation close contact groups second tendency false negative tests occur early stages infection detailed descriptions disease natural history test sensitivity models found supporting information detection infection occur due either positive tests conducted days symptom onset model assumes cases asymptomatic asymptomatic cases detected testing symptomatic cases may detected period detected end incubation period begin expressing symptoms symptomatic individuals treated confirmed cases case detection travellers results isolation period case well quarantine extension close contacts additional tests days extension period subsequent detection within group contacts results isolation cases incur additional extensions remaining contacts therefore maximum period individual remain system days would occur individual close contact case detected day initial stay detected case day extension period subsequently isolated additional days quarantine extension transmission dynamics altered isolation individuals may transmit infection individuals members close contact group discharged system replaced new group simulated quarantine facility workforce composed individuals come go day workers tested via day attend site worker attends days per week two days per week workers may become infected contact quarantined travellers contact infected force infection applied travellers workers reduced factor simulate infection control measures mask wearing limited contact hand force arrival first test results discharge test results day day day day extension infected individuals enter community breach events false negative discharge discharge susceptible infected undetected infected detected isolation days discharge day discharge day isolation days fig schematic event sequence arrivals entering quarantine testing isolation detected infections extension quarantine close contacts family groups eventual discharge quarantine false negative discharge tests lead infected individuals entering community infection workers reduced factor relative unmitigated contact accounts infection control higher levels mixing workers tested frequently infections typically detected period infected workers replaced susceptible ones either detection recovery note replacement recovery strictly realistic avoids eventual saturation recovered worker population long simulations b scenarios vaccine efficacy pathogen transmissibility scenarios selected designed determine risk associated quarantine breaches mitigated within pathway exclusive fully vaccinated travellers pathway would staffed exclusively vaccinated workers well vaccination coverage within system context examine performance wide range vaccine efficacy viral transmissibility parameters performance determined relative baseline scenario vaccine efficacy v e set disease transmission parameters aligned strains circulation prior emergence delta variant quarantine community transmission model systems vaccines play three important roles vaccination travellers prior departure reduces proportion infected arrivals factor v e base rate vaccination workers travellers limits transmission within quarantine reduces rate breach events mass vaccination prevents outbreaks community quarantine breach events occur efficacy vaccination transmission investigate range total efficacy quarantine model treats vaccine efficacy combination efficacy infection vi efficacy onward transmission breakthrough infections vt simplify single efficacy parameter scenarios investigated assume individuals system vaccinated note scenarios subset individuals vaccinated simplifying assumption would need relaxed account interactions involving combinations vaccinated unvaccinated individuals noted consider efficacy baseline accounting levels incursion risk existing vaccines became available efficacy levels indicative conditions existing ancestral lineage alpha variants previously circulation lower efficacy ranges account emergence variants capable higher levels breakthrough infection currently dominant delta variant emergence viral variants also requires us investigate broad range transmission rates transmissibility delta variant estimated approximately twice ancestral non voc lineages based outbreak china guangdong province may basic reproductive ratio delta variant estimated approximately therefore order understand scaling quarantine system performance disease transmissibility examine wide range possibilities model variations shorter incubation period baseline model sample viral incubation period time infection symptom onset described studies ancestral lineage estimate also influences model test sensitivity function time symptom onset see supporting information quarantine systems operating test release framework primarily designed prevent individuals infected elsewhere entering community timing considerations applied operational framework minimum stay designed exceed disease incubation period perspective emergence variants incubation periods different system designed expected alter system performance system performance general improve shorter incubation periods context recent reports suggest delta variant may shorter incubation period ancestral lineage however reports using data outbreak indicate incubation period delta variant changed substantially given preliminary evidence shorter incubation period performed sensitivity analysis key parameter see supporting information model outputs quarantine facility model produces timeseries breach events corresponds infected individual worker traveller interacting community outside quarantine infected traveller occur two reasons leaving case isolation still infectious isolation period leaving quarantine false negative test result recorded breach event accounts number days individual remain infectious leaving quarantine integrated force infection produced individual period infected workers recorded breach events account time infection either detection recovery integrated force infection period general community force infection produced breach event associated case given Î²i x tc Î² Î²i integrated force infection produced agent outside quarantine tc represents set discrete timepoints individual infectious community Î² force infection case discrete time step used simulation days breach events rare due effectiveness quarantine system particularly within vaccinated high efficacy generate large number breach events use comparing outbreak statistics scenarios simulation lasts days recall workers tested daily infections typically detected period infected workers replaced either detection recovery latter avoids eventual saturation recovered worker population long simulations different conditions breach events involving travellers workers produce qualitatively different breach statistics depend also vaccine efficacy figure details quarantine simulation model found supporting information evaluated effectiveness quarantine system examining integrated force infection introduced community due breach events value computed Î²tot xn Î²i n total number breach events simulated given scenario Î²i force infection community produced breach model parameters held constant see methods Î²tot useful representation relative performance system different combinations v e figure Î²tot computed set parameters shown relative value computed baseline scenario v e assume breakthrough cases contagious infections unvaccinated individuals assume vaccine acts primarily protect immunised number breach events travellers days infectious community number breach events workers traveller breach events worker breach events number breach events travellers days infectious community number breach events workers traveller breach events worker breach events number breach events travellers days infectious community number breach events workers traveller breach events worker breach events number breach events travellers days infectious community number breach events workers traveller breach events worker breach events b c fig distribution days infectious community produced breach event simulated four illustrative scenarios ancestral strain without vaccination b ancestral strain vaccination c delta strain without vaccination delta strain vaccination increased transmissibility decreased vaccine efficacy breach events occur infected travellers discharged quarantine still infectious also occur due infected workers detected asymptomatic due screening tests distribution days infectious community differs qualitatively traveller breach events subfigure corresponds different combination reproductive ratio vaccine efficacy v shaded black bars correspond breach events open red bars correspond breach events infection vt vi v e evidence reduced periods viral shedding vaccinated individuals peak viral loads appear similar therefore presented results based conservative assumption relaxed modified new evidence emerges see supporting information sensitivity analysis given alternate assumption vt v e vi influence quarantine system outbreak risk computed using distribution breach events produced quarantine simulation sample seeding events branching process model outbreak scenarios level vaccination varied assuming negligible level immunity results branching process model used estimate probability community outbreak given fixed volume travellers set infection prevalence produces absolute outbreak risk express time probability transmission cluster containing cases exceeds values interpreted means comparing alternate scenarios given fixed quantities incoming arrivals see supporting information details branching process model iii results summary results demonstrate quarantine system would perform different conditions vaccine efficacy viral transmissibility fixed assumptions respect details test schedules quarantine duration see supporting information quantify terms breach events produced set conditions breach events occur infected traveller quarantine worker comes contact general population first examine force infection produced breach events serves measure quarantine system performance independent community embedded examine potential outbreaks caused breach events taking account level vaccination coverage general population also investigate sensitivity model outcomes disease incubation period may shorter delta variant results analysis show shorter incubation periods make quarantine system effective overall infectious periods shorter ii test sensitivity increases quickly infection iii shorter delay symptom expression hastens detection false negative arrival tests finally examine sensitivity results choice vaccine efficacy decomposition treat disease transmission process first requiring infection subject efficacy term vi efficacy infection requiring onward transmission subject efficacy term vt efficacy onward transmission model overall efficacy transmission v e given v e vt vi means two extreme interpretations exist v e vi vt vt v e vi main results use first extreme see methods section detailed discussion choice investigate second extreme sensitivity analysis gives range results decomposition consistent equation may fall quarantine system breach risk interpreting Î²tot measure outbreak potential set conditions heatmap figure illustrates vaccine efficacy must increase offset rise outbreak potential produced increases baseline conditions v e following outermost contour delineated figure illustrates vaccine efficacy must exceed order baseline risk levels maintained must exceed required v e levels saturate high values efficacy sufficient maintain baseline risk levels even saturation occurs transmission within quarantine environment partially constrained grouping arrivals small cohorts family units constraint transmission contingent upon substantial reduction exposure risk outside close contact groups representative stringent infection control measures within facility community outbreak risk next simulate outbreaks based distribution quarantine breach events produced quarantine model scenarios investigate subset v e combinations corresponding plausible values delta variant investigated population outbreak characteristics v e varying mass vaccination coverage levels branching process scenarios fixed traveller arrival rate assumed infection prevalence differed inflow assumptions quarantine model travellers per week infection prevalence scaling factor used linearly adjust breach rate produced quarantine model fig integrated force infection relative baseline computed quarantine breach events simulated model heatmap contour demonstrates value scales vaccine efficacy v e basic reproductive ratio virus simulations incoming arrivals quarantine workers vaccinated susceptibility infection reduced factor indicated v e v e vi vt dotted blue box represents plausible values baseline condition ancestral lineage alpha variant dominant vaccines available green dotted box represents scenarios corresponding vaccinated quarantine pathways emergence delta variant yellow dashed box covers range values plausible delta variant scenarios see methods supporting information scaling approximation assumes linear dependence quarantine breach rate incoming arrival infection prevalence present values function vaccine coverage figure demonstrates effect mass vaccination outbreak risk combination v e results illustrate vaccine efficacy crucial determinant outbreak risk even high coverage vaccine efficacy sufficient dramatically reduce time required outbreaks occur hand possible threshold behaviour coverage observed high vaccine efficacy higher values increasing order magnitude high coverage levels threshold effect appears persist even high transmission rates figure sensitivity outbreak risk v e emphasise importance accurately estimating crucial parameter vaccine efficacy infection onward transmission sensitivity analysis incubation period sensitivity analysis incubation period demonstrated shorter incubation periods increase effectiveness quarantine system test sensitivity increases rapidly ii individuals infectious shorter periods time results emphasise shorter incubation periods make easier detect infections closed systems like quarantine facilities reduces risk community quarantine sensitivity analysis vaccine efficacy transmission breakthrough infections results demonstrated figure assume effect vaccination capacity vaccinated individuals become infected transmit virus vt vi v e alternate assumption efficacy onward transmission equivalent total v e represents plausible upper bound investigated sensitivity analysis vt v e vi results figure demonstrate alternate optimistic assumption vaccine efficacy required maintain baseline risk levels falls example would require effective vaccine order maintain baseline outbreak risk would require effective vaccine iv discussion vaccines developed remain highly effective preventing severe disease however efficacy infection decreased delta b c e f time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline fig time probability outbreak community reaches set scenarios corresponding potential delta variant parameter combinations vaccine coverage values correspond proportion individuals community outside quarantine vaccinated higher vaccine coverage efficacy reduces probability outbreak occurring given quarantine breach event possible threshold behaviour observed high coverage efficacy vaccine efficacy producing values increase one order magnitude coverage rises full vaccine coverage baseline scenario black line shows vaccination v e variant virus efficacy may deteriorate continued emergence new variants context border quarantine capacity limit transmission key consideration determining best manage new arrivals may infected asymptomatic primary purpose border quarantine system prevent infectious individuals entering community management clinical cases within quarantine system facilitated regular surveillance efficient case detection allocation medical resources therefore utility vaccination within context quarantine system equivalent utility mass vaccination context large outbreak large outbreaks efficacy clinical severity reduces hospital case loads deaths mitigating public health burden human cost even transmission continues however modern quarantine systems operational goal identify isolate cases limit transmission keep required duration quarantine minimum minimum stay commonly practiced pandemic implemented due long incubation period disease within days case arriving would likely display symptoms testing arrivals accelerates process case detection facilitates earlier management case detection efforts unsuccessful transmission within quarantine environment best leads extended stay conditions cases contacts worst leads discharge infectious individuals receive exit test early infection yet high enough viral load case confirmation therefore primary benefit vaccination context quarantine facilities limiting transmission context increased transmissibility decreased vaccine efficacy transmission associated delta variant requires risk results demonstrate vaccination may allow quarantine systems remain effective hand quarantine requirements vaccinated travellers must remain stringent due increased transmissibility virus emphasise implications result conditions remained consistent alpha variant v e figure indicates vaccination would decreased border quarantine breach risk baseline effect vaccinated quarantine pathway would allowed number arrivals increase factor approx assuming sufficient system capacity maintaining baseline community exposure levels existing circumstances analysis suggests quarantine policies vaccinated individuals need approximate used unvaccinated cohorts prior emergence delta variant unvaccinated cohorts travellers hand pose much greater risk quarantine breach events previously increased factor figure ultimately level stringency requirements quarantine new arrivals assessed function prevalence viral variants jurisdictions relative levels similar variants concern little justification limitations travel however emergence new variants quarantine systems must capable rapidly responding slow eliminate global diffusion variants particularly true variants increased transmissibility clinical severity delta variant primary example conclusion summarise results demonstrate context border quarantine systems used compensate low levels community vaccination delta variant true even individuals within quarantine environment vaccinated delta variant transmissible likely produce breakthrough infections individuals vaccinated ancestral lineage findings illustrate key aspect global battle mitigate public health crisis produced regions low community prevalence becoming confident international travel could increase vaccinated individuals virus changed become transmissible partially avoid immunity results show changes nullified prospective benefits quarantine systems terms international travel volumes however important emphasize alternative scenario vaccine become available prior emergence delta variant capacity existing border quarantine systems mitigate outbreaks would dramatically deteriorated currently comprehensive vaccination quarantine facilities allowing countries australia new zealand china continue allowing low levels international travel moving forward expansion quarantine systems focus preparing future variants ultimately future pandemics higher clinical severity infection fatality ratios revealed unprecedented capacity populations around world dramatically alter behaviour prevent disease spread quarantine systems amplify payoff responses limiting incursions coupling border quarantine measures elimination strategies buys critical time development vaccines effective clinical practices vi acknowledgements funding work directly funded australian government department health office health protection additional support provided national health medical research council australia centres research excellence spectrum investigator grant schemes jmcv principal research fellowship gnt mjl supported nhmrc project grant conflicts interest authors declare conflicts interest author contributions cz ng mcvernon designed model quarantine facility environments cz fs djp mccaw designed model disease progression test sensitivity mjl djp fs designed outbreak branching process model cz implemented individualbased models analysed outputs ml implemented outbreak model analysed outputs authors contributed manuscript composition study design vii source code data availability source code models raw data used produce figure available quarantine abm source code branching process model available data presented work reproduced source code also made available upon request corresponding author guan wang hallegatte davis sj huo j li et al global effects control measures nature human behaviour organization wh et al policy considerations implementing approach international travel context july world health organization wells cr sah p moghadas sm pandey shoukat wang et al impact international travel border control measures global spread novel coronavirus outbreak proceedings national academy sciences haug n geyrhofer l londei dervic e loreto v et al ranking effectiveness worldwide government interventions nature human behaviour steyn n plank mj james binny rn hendy sc lustig managing risk outbreak border arrivals journal royal society interface gostic k gomez ac mummah ro kucharski aj jo estimated effectiveness symptom risk screening prevent spread elife ashcroft p lehtinen angst dc low n bonhoeffer quantifying impact quarantine duration transmission elife lau h khosrawipour v kocbach p mikolajczyk schubert j bania j et al positive impact lockdown wuhan containing outbreak china journal travel medicine zachreson c mitchell l lydeamore mj rebuli n tomko geard risk mapping outbreaks australia using mobility data journal royal society interface baker mg kvalsvig verrall aj wellington new zealand elimination strategy med j aust summers j cheng hy lin hh barnard lt kvalsvig wilson n et al potential lessons taiwan new zealand health responses pandemic lancet regional pacific thatcher zhang todoroski h chau wang j liang predicting impact australian universities journal risk financial management tisdall l zhang zhang impacts general experiences governmental responses policy imperatives transport policy beck mj hensher da insights impact household travel activities early days restrictions transport policy fisman tuite progressive increase virulence novel variants ontario canada february june medrxiv zhang xiao j deng zhang zhuang hu et al transmission dynamics outbreak delta variant b province china china cdc weekly kang xin h yuan j ali st liang z zhang j et al transmission dynamics epidemiological characteristics delta variant infections china medrxiv dagpunar js interim estimates increased transmissibility growth rate reproduction number b variant concern united kingdom medrxiv brown cm outbreak infections including vaccine breakthrough infections associated large public county massachusetts july mmwr morbidity mortality weekly report chia py ong swx chiew cj ang lw chavatte jm mak tm et al virological serological kinetics delta variant infections cohort study medrxiv lopez bernal j andrews n gower c gallagher e simmons r thelwall et al effectiveness vaccines b delta variant new england journal medicine elliott p haw wang h eales walters c ainslie k et al round final report exponential growth high prevalence vaccine effectiveness associated delta variant england may july osama razai ms majeed vaccine passports access equity ethics british medical journal publishing group organization wh et al considerations quarantine contacts cases interim guidance june world health organization nasreen chung h brown ka gubbay jb buchan sa et al effectiveness vaccines variants concern canada medrxiv zachreson c chang sl cliff om prokopenko change lockdown requirements australia lancet regional health western pacific campbell f archer b h jinnai konings f batra n et al increased transmissibility global spread variants concern june eurosurveillance lauer sa grantz kh bi q jones fk zheng q meredith hr et al incubation period coronavirus disease publicly reported confirmed cases estimation application annals internal medicine hellewell j russell tw beale r kelly g houlihan c nastouli e et al estimating effectiveness routine asymptomatic pcr testing different frequencies detection infections bmc medicine riemersma kk grogan jeppson ge connor dh friedrich tc et al vaccinated unvaccinated individuals similar viral loads communities high prevalence delta variant medrxiv puranik lenehan pj silvert e niesen mj j horo jc et al comparison two mrna vaccines periods alpha delta variant prevalence medrxiv available https pouwels kb pritchard e matthews p stoesser nb eyre dw vihta kd et al impact delta viral burden vaccine effectiveness new infections uk medrxiv ferretti l wymant c kendall zhao l nurtay l et al quantifying transmission suggests epidemic control digital contact tracing science ferretti l ledda wymant c zhao l ledda v l et al timing transmission medrxiv jo schreiber sj kopp pe getz wm superspreading effect individual variation disease emergence nature madewell zj yang longini im halloran dean ne household transmission systematic review jama network open johansson quandelacy tm kada prasad pv steele brooks jt et al transmission people without symptoms jama network open r corman vm guggemos w seilmaier zange et al virological assessment hospitalized patients nature supporting information model details work utilised two distinct models disease transmission one abstract model implemented branching process approximate community transmission dynamics applied quantify tendency quarantine breach events initiate outbreaks characterise outbreaks model simulation describing disease progression transmission individual level implemented two scenarios one used calibration fundamental parameters investigation quarantine system efficacy calibration scenario homogeneous allows characterisation basic reproductive ratio secondary case rates timing transmission detection events effectively open system quarantine scenario designed reproduce general features controlled border screening environments implements defined population structure outbreak transmission branching process model simulate infectious individuals entering community potentially seeding outbreak use branching process community transmission model inhomogenous offspring distribution branching process models considered terms generations generation acts independently last term generation zero index case leaves quarantine transmission potential cases community define transmission potential represents expected number cases caused single case community transmission potential combines biological features virus vaccine status index case vaccination coverage wider community vaccine efficacy parameters break vaccine efficacy two components efficacy infection denoted vi efficacy onward transmission denoted vt overall reduction transmission given v vi vt given starting transmission potential effective transmission potential population pp given pp cv c proportion population vaccinated breach caused vaccinated traveller first generation transmission potential given pu cvi breach caused unvaccinated traveller first generation transmission potential given pv cvi vt secondary case distribution public health measures number secondary infections generated single case taken negative binomial distribution n samples probability success p p order match dispersion number secondary cases fixed expected number secondary cases calendar times infections occur drawn weibull distribution mean days standard deviation line literature estimates case index case thus quarantine infections occur individual left quarantine retained individual enters isolation point per worker protocols infections occur individual entered isolation retained future generations assumed quarantine proactive isolation applied probability breach becoming outbreak calculate probability single breach event becoming outbreak simulate breaches community index cases breaches chosen randomly quarantine model probability calculated separately travellers workers breach defined outbreak reaches least five cumulative cases extinction time significant breach event time breach events assumed occur frequency defined quarantine model scale time according number travellers prior probability arriving system infected construct scaling factor targeted number arrival targeted prevalence arrival country number arrivals modelled quarantine model prevalence infection assumed quarantine model time breaches obtained quarantine model divided breach determined outbreak according binomial distribution probability success defined probability causing outbreak traveller worker breach events chosen proportion occur quarantine model disease model model quarantine scenarios developed model disease transmission designed match three salient features distribution delays symptom onset primary case transmission secondary cases following definition used ferretti et refer quantity time onset symptoms transmission tost household secondary attack rate secondary case dispersion dependence test sensitivity time symptom onset matching distributions model required definition detailed model disease natural history level distribution incubation periods key ensemble statistic informs model dynamics see many possible implementations models could generate required ensemble statistics specific choices follow logic virus initially grows exponentially recognition host immune systems triggers onset symptoms end incubation period immune response produces exponential decline viral load recovery occurs time viral shedding possible sections detail specifics model basic reproductive number transmission rate scalar individual Î²max gamma Îº Î¸ controls transmission rate given transmission environment shape parameter Îº translates directly dispersion parameter derived secondary case distribution distributed negative binomial see scale parameter Î¸ function mean peak force infection hÎ²maxi proportional calibration model figure calibrate basic reproductive number performed systematic scan hÎ²maxi keeping parameters constant produce generic calibration basic reproductive number performed scan unstructured population n individuals simulated large ensemble single transmission generations without interaction effects n instances instance index case properties sampled parameter distributions specified transmission simulated recovery index case count secondary cases produced ignoring additional force infection produced secondary cases average values approximates observe linear relationship control parameter hÎ²maxi figure set value given scenario use line best fit determine corresponding value hÎ²maxi required produce desired value secondary case dispersion distribution secondary cases produced index case ensemble used compute conforms negative binomial distribution dispersion parameter r figure implemented follows index case independent transmission probabilities produce secondary case numbers transmissibility parameter index case Î²max sampled gamma distribution secondary case numbers aggregated basic reproductive ratio simulated linear fit frequency ntot number secondary cases n secondary case distribution b fig calibration basic reproductive number linear dependence global transmission scalar hÎ²maxi derived parameter b distribution secondary cases produced different values effectively drawn negative binomial distribution dispersion parameter number successes r mean index cases effectively drawn ensemble poisson distributions gammadistributed rate parameters gives negative binomial dispersion r Îº therefore model controls secondary case dispersion directly assigning Î²max random variable choice dispersion alter calibration describes average number secondary cases household secondary attack rate check parameterisation r produce reasonable correspondence observed household secondary attack rates ran calibration model setting population size n conditions number possible transmissions akin generic number household contacts n individuals high transmissibility restricted transmission potential calibration produces average household secondary attack rates range consistent observations transmission among household contacts figure low end range typical ancestral lineage increases consistently reaching probability secondary cases simulated k fit negative binomial mean dispersion fig secondary case distribution calibration model follows negative binomial mean dispersion parameter r controlled shape parameter Îº gamma distribution maximum force infection Î²max sampled individual corresponding delta variant secondary attack rate n r frequency ntot number secondary cases n b fig secondary attack rate values produced calibration model transmission within small groups n secondary attack rate function global transmission scalar hÎ²maxi values plotted correspond number secondary infections produced average divided number contacts n b frequency distributions secondary case numbers produced independent trials corresponding single index case single generation transmission four close contacts values hÎ²maxi chosen b correspond broadly estimates ancestral lineage hÎ²maxi delta variant hÎ²maxi disease transmission model model viral dynamics follows function precise form determined individual incubation period individual trajectory infectiousness function time exposure Î² illustrated figure function features initial exponential increase followed brief plateau subsequent exponential decline start exponential decline phase corresponds end individual incubation period onset symptoms note individuals become infectious immediately infected latent period preceding onset infectiousness model assume infected individuals never develop symptoms reduces probability detected within quarantine system model use functional form Î² describe infections regardless whether asymptomatic may asymptomatic individuals marginally less contagious case model would overestimate number secondary cases produce work opted conservative assumption difference exists dynamics implemented piecewise function plateau growth decay phases describing Î² infectiousness individual Î² Î²max vmax exp tinc tp Î²max tinc tp tinc Î²max exp tinc vmax tinc tinc incubation period individual tp duration infectiousness plateau set equal Î²max maximum infectiousness individual parameter vmax scaling factor controlling shape growth curve smaller values vmax produce broader growth decay functions higher values produce steeper growth decay rate parameters determined value vmax duration incubation periods ln vmax tinc tp ln vmax r tr time symptom onset recovery drawn uniformly random range approximately match duration viral shedding symptom onset interaction infected individual susceptible individual j probability transmission computed pij exp Î² force infection produced infected individual time since infection days duration discrete time step Ïƒij scaling factor incorporates effects contact frequency intensity given transmission event infected individual susceptible individual j Ïƒij fijh j fij transmission mitigation factor hj number contacts given type local mixing environment calibration model fij hj n full quarantine model fij given follows close contacts travellers group fij hj ni ni number close contacts group individual n initially decrease members moved isolation interactions travellers different close contact groups fij hj p ng number travellers quarantine system isolated group g individual interactions infected travellers susceptible workers fij hj nw nw number workers present facility time interactions infected workers susceptible travellers fij hj ntot ntot number travellers isolation interactions infected workers susceptible workers fij hj nw nw number workers present facility time force infection rescaled maximum time infection Î²max gamma k Î²max k Î²max Î² p e incubation period symptom onset incubation periods lognormal periods uniform Î²max fig example force infection produced infected individual function time infection force infection increases exponentially time infection start plateau point reaches maximum value plateau phase lasts end incubation period duration equal total incubation period incubation periods drawn distribution period infectiousness decreases exponentially reaches cutoff time recovery duration end plateau phase recovery drawn uniform distribution bounded days values Î²max drawn gamma distribution parameterised specified value described section b time onset symptoms transmission tost functional form used Î² developed match ensemble distributions time onset symptoms transmission tost reported ferretti et al comparison statistics produced calibration model distribution reported ferretti et al shown figure qualitative match model case statistics empirical tost distribution sensitive choice individual disease trajectory function probability density time onset symptoms transmission tost days empirical tost scaled ferretti et al simulated tost abm n trials n agents fig time onset symptoms transmission tost distributions produced calibration model n individuals homogeneous contact network tost distribution depend transmissibility disease matches closely model ferretti et al equations time onset symptoms detection tosd model test sensitivity discussed following subsections designed capture variability test sensitivity function time relative symptom onset models based study hellewell et al general objective describe test sensitivity piecewise sigmoid single breakpoint tc breakpoint sensitivity increases tc represents time infection breakpoint tc sensitivity decreases slowly case function expressed logistic regression parameter ci tc table parameter ranges used hellewell et describe progression test sensitivity infections healthcare workers model reported parameter ranges adjusted account individual variability incubation periods p exp tc exp tc Ï„ tc maximum test sensitivity depends exp initial growth sensitivity controlled decay sensitivity tc given parameter ranges credible intervals provided hellewell et al shown table parameter ranges shown table produced fitting ensemble data study examined timeseries tests test results cohort individuals aggregated timeseries order fit parameters model therefore parameter ranges suitable individual test sensitivity trajectories model translates specified functional form logistic function parameter ranges set trajectories describing test sensitivity function incubation period time infection symptom onset individual system reconcile ensemble characteristics observed hellewell et requirements individual trajectories model requirements specified follows individual may test positive infected peak test sensitivity must correspondence timing peak viral load peak infectiousness probability detection high first week symptoms requirements following implications model framework specified hellewell et al specified range tc fit trajectories incubation periods average incubation period days rate increase must higher individuals shorter incubation periods imposes correlation specifying individual trajectories address discrepancies relax parameter restrictions table set breakpoint position relative individual incubation period delay breakpoint tc onset symptoms tinc distributed range rationale choice based observation upper credible interval reported hellewell tc approximately equivalent median incubation period infer corresponds using incubation period upper limit tc additionally model correlates length delay incubation period agent quantile matching ensure tc always positive tc tinc denotes specific individual qi value incubation period cdf evaluated tinc range possible delays units days peak test sensitivity symptom onset provide better match ensemble statistics also chose impose negative correlation individual incubation periods term specifies growth rate test sensitivity peak along decay rate test sensitivity peak qi lower bound range values given table modified parameter ranges shown table samples individual trajectories shown figure comparison ensemble statistics shown figure hand parameter ci tc tinc table parameter ranges used order fit abm ensemble statistics reported hellewell et al parameters chosen uniformly random individual ranges specified model approximately matches proportion infections detected symptom onset given daily test estimated hellewell et al approx corresponding distribution time onset symptoms detection tosd shown figure c system daily testing detects approximately cases prior symptom onset relative infectiousness time infection test sensitivity relative infectiousness test sensitivity symptom onset peak test sensitivity relative infectiousness time infection test sensitivity relative infectiousness test sensitivity symptom onset peak test sensitivity relative infectiousness time infection test sensitivity relative infectiousness test sensitivity symptom onset peak test sensitivity b c fig individual trajectories test sensitivity force infection function time since exposure short incubation periods produce alignment peak test sensitivity peak infectiousness occur close onset symptoms b average incubation periods produce test sensitivity peak lags symptom onset peak infectiousness several days extend tail test sensitivity curve symptom onset c long incubation periods correspond longer lag times peak test sensitivity symptom onset extend tail test sensitivity trajectory test sensitivity time infection sample median n quantile quantile mean incubation period days median lower ci hellewell et al median upper ci hellewell et al test sensitivity time onset symptoms sample median n quantile quantile symptom onset probability density time onset symptoms detection cumulative probability p detect onset b c fig ensemble statistics test sensitivity function time infection aggregated agent based model test sensitivity function time infection grey dashed lines give credible intervals mean hellewell et solid black trace shows ensemble average produced samples model solid red traces give quantiles model b test sensitivity function time symptom onset produced model black trace gives ensemble average red traces give quantiles vertical dashed lines b represent onset symptoms c time onset symptoms detection given daily tests via derived model solid trace indicates cumulative distribution dashed lines indicate proportion cases detected one day prior symptom onset assuming test turnaround day corresponds proportion detected prior symptom onset model quarantine environment model quarantine system transmission occurs explicitly represents individual travellers quarantine workers describe model terms input layer filter layer output layer input layer arriving travellers characterised terms proportion arriving travellers infected proportion arriving travellers vaccinated set proportion infected arrivals proportion vaccinated additionally assumed infected arrivals either asymptomatic arrival time since infection sampled random individual incubation period traveller asymptomatic time since infection arrival sampled sum incubation period period filter layer travellers quarantined travellers structured groups quarantined together room results presented size groups set number travellers facility set travellers discharged system groups travellers group meet discharge criteria group removed new group generated replace workforce quarantine workforce also represented workforce model specifies weekly work schedule individual including days working days days days scheduled randomly work schedule configuration accepted model long least workers present day week transmission control assume rate transmission travellers belong different groups reduced factor compared travellers belong group similarly assume factor reduction transmission travellers workers factor reduction workers vaccination efficacy vaccination may varied reflect available evidence assume proportion workforce proportion arriving travellers vaccinated vaccine efficacy parameters varied reflect characteristics vaccines used particular source countries interest work assume individuals quarantine system vaccinated implement vaccination setting efficacy infection vi v e efficacy onward transmission vt choice significant computing transmission within quarantine system individuals assumed vaccinated however components vaccine efficacy could play significant role interpreting force infection produced breach events see sensitivity analysis testing testing workers scheduled varying frequencies daily every three days weekly workers tested days attend workplace results reported testing workforce performed daily long worker present model includes testing travellers scheduled occur given days quarantine period results reported travellers tested days entering quarantine calibrated test sensitivity specified represent detection via response positive test symptoms worker tests positive develops symptoms assume removed workforce replaced new worker irrespective whether attend work day traveller tests positive develops symptoms isolated removed quarantine facility health hotel hospital isolation period set days released positive test result traveller triggers quarantine extension travellers group resets testing schedule tests performed days extension output output quarantine simulation time series breach events corresponding characteristics individual leaves quarantine infected several properties recorded recorded properties depend whether infected individual worker traveller travellers recorded properties exposure days number days remain infectious days quarantine total number days spent quarantine system days extended quarantine number days quarantine extension detection case close contact days isolation number days spent isolation testing positive presenting symptoms incubation period period infection symptom onset time period symptom onset recovery time discharged timepoint individual released quarantine index case boolean flag indicating whether individual arrived infected infected quarantine symptomatic boolean flag indicating whether individual would express clinical symptoms incubation period vaccinated boolean flag indicting individual vaccination status Î²max maximum force infection individual force infection symptom onset Î²community integrated force infection period individual discharged quarantine summed produce Î²tot value simulation workers recorded properties exposure days number days infection detection recovery incubation period travellers see period travellers see tested positive boolean flag indicating whether individual removed testing positive expressed symptoms boolean flag indicating whether individual removed expressing symptoms time discharged timepoint individual removed facility symptomatic boolean travellers see vaccinated boolean travellers see Î²max travellers see Î²community force infection integrated period infection detection discharge output timeseries used generate input statistics index cases used branching process model sensitivity analysis incubation period estimate effect shorter incubation period used statistics reported china cdc outbreak delta variant may estimates incubation period may differ others represent lower bound important parameter demonstrate shorter incubation period affects transmission detection virus model system main differences without intervention slightly less transmission occurs prior symptom onset due rapid increase viral load detection cases typically occurs earlier probability density incubation period lognormal mean days median days lognormal mean days median days fig incubation period distributions used model black trace indicates distribution used main results red trace indicates distribution used sensitivity analysis quarantine model scenario shorter overall duration infection increases efficacy quarantine results demonstrate shorter incubation periods correspond enhanced capacity control transmission results caution use preliminary estimates incubation period statistics use models border quarantine systems demonstrate potentially effectiveness systems represent conservative assumptions viral dynamics investigate effect incubation period first base model using modified incubation period distribution figure calibration determined timing symptom onset relative transmission timing detection relative symptom onset given daily testing via homogeneous transmission network individuals figure applied modified calibration full quarantine simulation examine effectiveness quarantine v e parameter space results qualitatively similar produced original calibration average incubation period days show consistently lower levels breach risk measured Î²tot basic reproductive ratio simulated mean incubation period days linear fit simulated mean incubation period days linear fit fig calibration function global transmission scalar two different incubation periods probability density time onset symptoms transmission tost days empirical tost scaled ferretti et al simulated tost abm n trials n agents probability density time onset symptoms transmission tost days empirical tost scaled ferretti et al simulated tost abm n trials n agents b fig distribution tost two different incubation period distributions shows full distribution b zooms negative intervals corresponding transmission b elin e fig integrated force infection Î²tot relative baseline using incubation period mean days baseline denominator value taken alternate scenario incubation period days v e results shown function vaccine efficacy sensitivity analysis vaccine efficacy onward transmission results presented figure assumed vaccine efficacy onward transmission negligible values reported Î²tot represent differences breach statistics rather direct effects vaccine efficacy examine alternate extreme case efficacy transmission equivalent v equates multiplication Î²tot values figure factor v results correction applied force infection values fall linearly v e increases alternate assumption value vaccine efficacy required maintain baseline outbreak statistics lower magnitude difference increases ranging approximately approximately differences substantial represent largest possible deviation due efficacy transmission therefore results presented figure may overestimate vaccine efficacy required maintain baseline risk ratios magnitude overestimate exceed b elin e fig integrated force infection Î²tot relative baseline assuming vaccine efficacy onward transmission maximised vt v e vi baseline denominator value taken scenario v e results shown function vaccine efficacy
border quarantine systems impact delta variant cameron freya david michael jodie james nicholas computing information systems university melbourne australia school population global health university melbourne australia peter doherty institute infection immunity royal melbourne hospital university melbourne australia infectious diseases alfred central clinical school monash university australia mathematics statistics university melbourne australia dated september sep abstract controlling transmission effectiveness border quarantine strategies key concern jurisdictions local prevalence disease immunity low settings like china australia new zealand rare outbreak events lead escalating epidemics trigger imposition large scale lockdown policies examine degree vaccination status incoming arrivals quarantine workforce allow relaxation quarantine requirements develop apply detailed model disease progression transmission taking account nuanced timing factors key among disease incubation periods progression infection detectability incubation using disease characteristics associated ancestral lineage benchmark level acceptable risk examine performance border quarantine system vaccinated arrivals examine disease transmission vaccine efficacy parameters wide range covering plausible values delta variant currently circulating globally results indicate threshold outbreak potential function vaccine efficacy time outbreak increasing two orders magnitude vaccine efficacy transmission increases parameters corresponding delta variant vaccination able maintain capacity quarantine systems reduce case importation outbreak risk counteracting pathogen increased infectiousness prevent outbreaks heightened vaccination border quarantine systems must combined mass vaccination ultimate success programs depend sensitively efficacy vaccines viral transmission introduction mitigation pandemics requires continuous analysis risk order respond proportionately efficiently border quarantine systems designed allow travel jurisdictions limiting risk disease transmission rigorously limiting disease transmission regions appropriate large differences exist pathogen prevalence strict border measures effective preventing disease incursions also costly operate reduce international travel trickle given enormous economic social costs associated international travel restrictions come stringent border quarantine policies systems used prevent catastrophic public health crisis pandemic border quarantine strategies implemented parts world various forms regions tightly controlled borders screening international travellers provided effective means limiting importation rate individuals infected facilitated success outbreak control strategies relying targeted ttiq responses combination approaches largely successful preventing widespread epidemics countries china new zealand australia australia meant many citizens abroad outset pandemic stranded overseas due quarantine capacity constraints also stressed higher education tourism sectors devastated airline industry design quarantine system needs balance benefits reducing risk importation associated costs order assess tradeoff analytical frameworks must incorporate emerging evidence pathogen characteristics provide accurate estimates risk associated alternative quarantine strategies two potential factors motivating revaluation quarantine stringency include changes properties pathogen changes deemed acceptable level breach risk case development rollout effective vaccines provided opportunity countries previously maintained stringent border controls contemplate future measures could relaxed however emergence delta variant produced need evaluate risk context virus exhibiting higher transmissibility higher clinical severity existing vaccines less effective shifting context role vaccination acceptable risk border quarantine breach events must emergence new variants broadly different disease characteristics viewed onset new pandemic therefore risk mitigation measures need assessed based information work evaluate efficacy border quarantine systems function following pathogen characteristics transmissibility efficacy vaccines transmission combination efficacy infection efficacy transmission breakthrough cases primary purpose estimate reduction transmission risk focus pathogen vaccine characteristics associated transmission efficacy vaccines preventing infection onward transmission primary consideration designing modified border quarantine pathways vaccinated travellers currently becoming widely adopted framework evaluate performance simulated border quarantine system consistent recommendations world health organization countries choose quarantine international arrivals includes minimum stay testing regime response strategy isolates confirmed cases contacts travellers quarantine figure figure chosen model reproduces general features adopted chinese australian new zealand border quarantine systems examine performance quarantine system range vaccine efficacy levels reproductive ratios relative unvaccinated baseline condition vaccine efficacy investigate risk outbreaks seeded quarantine breach events changes emergence transmissible strain delta variant outbreak scenarios examine effect varying levels vaccination coverage model ensemble results presented help guide adaptation border quarantine measures virus evolves vaccination coverage increases vaccine efficacy changes ii methods model overview structure inputs outputs simulate virus transmission case detection isolation response pathways within single quarantine facility capacity travellers facility staffed vaccinated workers intermittent contact quarantine individuals processed subject testing case isolation structure quarantine environment generic captures main principles typically applied border quarantine facilities output quarantine model used separate branching process model evaluate potential outbreaks community transmission schematic overall system shown figure population structured two distinct groups one comprising workers staff arrivals quarantine extension isolation community workers workers close contact groups days fig schematic quarantine system model arrivals enter quarantine groups four close contacts groups weak contact one another workforce case detected infected individual placed isolation contacts placed quarantine extension travellers extended quarantine still contact workforce groups within facility separate branching process model used evaluate potential outbreaks community based breach event statistics produced quarantine system model facility comprising quarantined travellers travellers move system indicated figure arriving close contact groups individuals travellers remain system days unless infection detected within group day minimum stay means typically travellers exit system week model used simulate border quarantine incorporates detailed description progression transmission captures following salient features lognormally distributed incubation period mean approx Âµ Ïƒ figure infectiousness increasing moment exposure peaking symptom onset declining recovery figure test sensitivity peak symptom onset followed gradual decline figure secondary case distribution figure features allow model capture two important effects quarantine environment first truncation naturally secondary case distribution due physical separation close contact groups second tendency false negative tests occur early stages infection detailed descriptions disease natural history test sensitivity models found supporting information detection infection occur due either positive tests conducted days symptom onset model assumes cases asymptomatic asymptomatic cases detected testing symptomatic cases may detected period detected end incubation period begin expressing symptoms symptomatic individuals treated confirmed cases case detection travellers results isolation period case well quarantine extension close contacts additional tests days extension period subsequent detection within group contacts results isolation cases incur additional extensions remaining contacts therefore maximum period individual remain system days would occur individual close contact case detected day initial stay detected case day extension period subsequently isolated additional days quarantine extension transmission dynamics altered isolation individuals may transmit infection individuals members close contact group discharged system replaced new group simulated quarantine facility workforce composed individuals come go day workers tested via day attend site worker attends days per week two days per week workers may become infected contact quarantined travellers contact infected force infection applied travellers workers reduced factor simulate infection control measures mask wearing limited contact hand force arrival first test results discharge test results day day day day extension infected individuals enter community breach events false negative discharge discharge susceptible infected undetected infected detected isolation days discharge day discharge day isolation days fig schematic event sequence arrivals entering quarantine testing isolation detected infections extension quarantine close contacts family groups eventual discharge quarantine false negative discharge tests lead infected individuals entering community infection workers reduced factor relative unmitigated contact accounts infection control higher levels mixing workers tested frequently infections typically detected period infected workers replaced susceptible ones either detection recovery note replacement recovery strictly realistic avoids eventual saturation recovered worker population long simulations b scenarios vaccine efficacy pathogen transmissibility scenarios selected designed determine risk associated quarantine breaches mitigated within pathway exclusive fully vaccinated travellers pathway would staffed exclusively vaccinated workers well vaccination coverage within system context examine performance wide range vaccine efficacy viral transmissibility parameters performance determined relative baseline scenario vaccine efficacy v e set disease transmission parameters aligned strains circulation prior emergence delta variant quarantine community transmission model systems vaccines play three important roles vaccination travellers prior departure reduces proportion infected arrivals factor v e base rate vaccination workers travellers limits transmission within quarantine reduces rate breach events mass vaccination prevents outbreaks community quarantine breach events occur efficacy vaccination transmission investigate range total efficacy quarantine model treats vaccine efficacy combination efficacy infection vi efficacy onward transmission breakthrough infections vt simplify single efficacy parameter scenarios investigated assume individuals system vaccinated note scenarios subset individuals vaccinated simplifying assumption would need relaxed account interactions involving combinations vaccinated unvaccinated individuals noted consider efficacy baseline accounting levels incursion risk existing vaccines became available efficacy levels indicative conditions existing ancestral lineage alpha variants previously circulation lower efficacy ranges account emergence variants capable higher levels breakthrough infection currently dominant delta variant emergence viral variants also requires us investigate broad range transmission rates transmissibility delta variant estimated approximately twice ancestral non voc lineages based outbreak china guangdong province may basic reproductive ratio delta variant estimated approximately therefore order understand scaling quarantine system performance disease transmissibility examine wide range possibilities model variations shorter incubation period baseline model sample viral incubation period time infection symptom onset described studies ancestral lineage estimate also influences model test sensitivity function time symptom onset see supporting information quarantine systems operating test release framework primarily designed prevent individuals infected elsewhere entering community timing considerations applied operational framework minimum stay designed exceed disease incubation period perspective emergence variants incubation periods different system designed expected alter system performance system performance general improve shorter incubation periods context recent reports suggest delta variant may shorter incubation period ancestral lineage however reports using data outbreak indicate incubation period delta variant changed substantially given preliminary evidence shorter incubation period performed sensitivity analysis key parameter see supporting information model outputs quarantine facility model produces timeseries breach events corresponds infected individual worker traveller interacting community outside quarantine infected traveller occur two reasons leaving case isolation still infectious isolation period leaving quarantine false negative test result recorded breach event accounts number days individual remain infectious leaving quarantine integrated force infection produced individual period infected workers recorded breach events account time infection either detection recovery integrated force infection period general community force infection produced breach event associated case given Î²i x tc Î² Î²i integrated force infection produced agent outside quarantine tc represents set discrete timepoints individual infectious community Î² force infection case discrete time step used simulation days breach events rare due effectiveness quarantine system particularly within vaccinated high efficacy generate large number breach events use comparing outbreak statistics scenarios simulation lasts days recall workers tested daily infections typically detected period infected workers replaced either detection recovery latter avoids eventual saturation recovered worker population long simulations different conditions breach events involving travellers workers produce qualitatively different breach statistics depend also vaccine efficacy figure details quarantine simulation model found supporting information evaluated effectiveness quarantine system examining integrated force infection introduced community due breach events value computed Î²tot xn Î²i n total number breach events simulated given scenario Î²i force infection community produced breach model parameters held constant see methods Î²tot useful representation relative performance system different combinations v e figure Î²tot computed set parameters shown relative value computed baseline scenario v e assume breakthrough cases contagious infections unvaccinated individuals assume vaccine acts primarily protect immunised number breach events travellers days infectious community number breach events workers traveller breach events worker breach events number breach events travellers days infectious community number breach events workers traveller breach events worker breach events number breach events travellers days infectious community number breach events workers traveller breach events worker breach events number breach events travellers days infectious community number breach events workers traveller breach events worker breach events b c fig distribution days infectious community produced breach event simulated four illustrative scenarios ancestral strain without vaccination b ancestral strain vaccination c delta strain without vaccination delta strain vaccination increased transmissibility decreased vaccine efficacy breach events occur infected travellers discharged quarantine still infectious also occur due infected workers detected asymptomatic due screening tests distribution days infectious community differs qualitatively traveller breach events subfigure corresponds different combination reproductive ratio vaccine efficacy v shaded black bars correspond breach events open red bars correspond breach events infection vt vi v e evidence reduced periods viral shedding vaccinated individuals peak viral loads appear similar therefore presented results based conservative assumption relaxed modified new evidence emerges see supporting information sensitivity analysis given alternate assumption vt v e vi influence quarantine system outbreak risk computed using distribution breach events produced quarantine simulation sample seeding events branching process model outbreak scenarios level vaccination varied assuming negligible level immunity results branching process model used estimate probability community outbreak given fixed volume travellers set infection prevalence produces absolute outbreak risk express time probability transmission cluster containing cases exceeds values interpreted means comparing alternate scenarios given fixed quantities incoming arrivals see supporting information details branching process model iii results summary results demonstrate quarantine system would perform different conditions vaccine efficacy viral transmissibility fixed assumptions respect details test schedules quarantine duration see supporting information quantify terms breach events produced set conditions breach events occur infected traveller quarantine worker comes contact general population first examine force infection produced breach events serves measure quarantine system performance independent community embedded examine potential outbreaks caused breach events taking account level vaccination coverage general population also investigate sensitivity model outcomes disease incubation period may shorter delta variant results analysis show shorter incubation periods make quarantine system effective overall infectious periods shorter ii test sensitivity increases quickly infection iii shorter delay symptom expression hastens detection false negative arrival tests finally examine sensitivity results choice vaccine efficacy decomposition treat disease transmission process first requiring infection subject efficacy term vi efficacy infection requiring onward transmission subject efficacy term vt efficacy onward transmission model overall efficacy transmission v e given v e vt vi means two extreme interpretations exist v e vi vt vt v e vi main results use first extreme see methods section detailed discussion choice investigate second extreme sensitivity analysis gives range results decomposition consistent equation may fall quarantine system breach risk interpreting Î²tot measure outbreak potential set conditions heatmap figure illustrates vaccine efficacy must increase offset rise outbreak potential produced increases baseline conditions v e following outermost contour delineated figure illustrates vaccine efficacy must exceed order baseline risk levels maintained must exceed required v e levels saturate high values efficacy sufficient maintain baseline risk levels even saturation occurs transmission within quarantine environment partially constrained grouping arrivals small cohorts family units constraint transmission contingent upon substantial reduction exposure risk outside close contact groups representative stringent infection control measures within facility community outbreak risk next simulate outbreaks based distribution quarantine breach events produced quarantine model scenarios investigate subset v e combinations corresponding plausible values delta variant investigated population outbreak characteristics v e varying mass vaccination coverage levels branching process scenarios fixed traveller arrival rate assumed infection prevalence differed inflow assumptions quarantine model travellers per week infection prevalence scaling factor used linearly adjust breach rate produced quarantine model fig integrated force infection relative baseline computed quarantine breach events simulated model heatmap contour demonstrates value scales vaccine efficacy v e basic reproductive ratio virus simulations incoming arrivals quarantine workers vaccinated susceptibility infection reduced factor indicated v e v e vi vt dotted blue box represents plausible values baseline condition ancestral lineage alpha variant dominant vaccines available green dotted box represents scenarios corresponding vaccinated quarantine pathways emergence delta variant yellow dashed box covers range values plausible delta variant scenarios see methods supporting information scaling approximation assumes linear dependence quarantine breach rate incoming arrival infection prevalence present values function vaccine coverage figure demonstrates effect mass vaccination outbreak risk combination v e results illustrate vaccine efficacy crucial determinant outbreak risk even high coverage vaccine efficacy sufficient dramatically reduce time required outbreaks occur hand possible threshold behaviour coverage observed high vaccine efficacy higher values increasing order magnitude high coverage levels threshold effect appears persist even high transmission rates figure sensitivity outbreak risk v e emphasise importance accurately estimating crucial parameter vaccine efficacy infection onward transmission sensitivity analysis incubation period sensitivity analysis incubation period demonstrated shorter incubation periods increase effectiveness quarantine system test sensitivity increases rapidly ii individuals infectious shorter periods time results emphasise shorter incubation periods make easier detect infections closed systems like quarantine facilities reduces risk community quarantine sensitivity analysis vaccine efficacy transmission breakthrough infections results demonstrated figure assume effect vaccination capacity vaccinated individuals become infected transmit virus vt vi v e alternate assumption efficacy onward transmission equivalent total v e represents plausible upper bound investigated sensitivity analysis vt v e vi results figure demonstrate alternate optimistic assumption vaccine efficacy required maintain baseline risk levels falls example would require effective vaccine order maintain baseline outbreak risk would require effective vaccine iv discussion vaccines developed remain highly effective preventing severe disease however efficacy infection decreased delta b c e f time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline time outbreak probability days vaccine coverage proportion population baseline fig time probability outbreak community reaches set scenarios corresponding potential delta variant parameter combinations vaccine coverage values correspond proportion individuals community outside quarantine vaccinated higher vaccine coverage efficacy reduces probability outbreak occurring given quarantine breach event possible threshold behaviour observed high coverage efficacy vaccine efficacy producing values increase one order magnitude coverage rises full vaccine coverage baseline scenario black line shows vaccination v e variant virus efficacy may deteriorate continued emergence new variants context border quarantine capacity limit transmission key consideration determining best manage new arrivals may infected asymptomatic primary purpose border quarantine system prevent infectious individuals entering community management clinical cases within quarantine system facilitated regular surveillance efficient case detection allocation medical resources therefore utility vaccination within context quarantine system equivalent utility mass vaccination context large outbreak large outbreaks efficacy clinical severity reduces hospital case loads deaths mitigating public health burden human cost even transmission continues however modern quarantine systems operational goal identify isolate cases limit transmission keep required duration quarantine minimum minimum stay commonly practiced pandemic implemented due long incubation period disease within days case arriving would likely display symptoms testing arrivals accelerates process case detection facilitates earlier management case detection efforts unsuccessful transmission within quarantine environment best leads extended stay conditions cases contacts worst leads discharge infectious individuals receive exit test early infection yet high enough viral load case confirmation therefore primary benefit vaccination context quarantine facilities limiting transmission context increased transmissibility decreased vaccine efficacy transmission associated delta variant requires risk results demonstrate vaccination may allow quarantine systems remain effective hand quarantine requirements vaccinated travellers must remain stringent due increased transmissibility virus emphasise implications result conditions remained consistent alpha variant v e figure indicates vaccination would decreased border quarantine breach risk baseline effect vaccinated quarantine pathway would allowed number arrivals increase factor approx assuming sufficient system capacity maintaining baseline community exposure levels existing circumstances analysis suggests quarantine policies vaccinated individuals need approximate used unvaccinated cohorts prior emergence delta variant unvaccinated cohorts travellers hand pose much greater risk quarantine breach events previously increased factor figure ultimately level stringency requirements quarantine new arrivals assessed function prevalence viral variants jurisdictions relative levels similar variants concern little justification limitations travel however emergence new variants quarantine systems must capable rapidly responding slow eliminate global diffusion variants particularly true variants increased transmissibility clinical severity delta variant primary example conclusion summarise results demonstrate context border quarantine systems used compensate low levels community vaccination delta variant true even individuals within quarantine environment vaccinated delta variant transmissible likely produce breakthrough infections individuals vaccinated ancestral lineage findings illustrate key aspect global battle mitigate public health crisis produced regions low community prevalence becoming confident international travel could increase vaccinated individuals virus changed become transmissible partially avoid immunity results show changes nullified prospective benefits quarantine systems terms international travel volumes however important emphasize alternative scenario vaccine become available prior emergence delta variant capacity existing border quarantine systems mitigate outbreaks would dramatically deteriorated currently comprehensive vaccination quarantine facilities allowing countries australia new zealand china continue allowing low levels international travel moving forward expansion quarantine systems focus preparing future variants ultimately future pandemics higher clinical severity infection fatality ratios revealed unprecedented capacity populations around world dramatically alter behaviour prevent disease spread quarantine systems amplify payoff responses limiting incursions coupling border quarantine measures elimination strategies buys critical time development vaccines effective clinical practices vi acknowledgements funding work directly funded australian government department health office health protection additional support provided national health medical research council australia centres research excellence spectrum investigator grant schemes jmcv principal research fellowship gnt mjl supported nhmrc project grant conflicts interest authors declare conflicts interest author contributions cz ng mcvernon designed model quarantine facility environments cz fs djp mccaw designed model disease progression test sensitivity mjl djp fs designed outbreak branching process model cz implemented individualbased models analysed outputs ml implemented outbreak model analysed outputs authors contributed manuscript composition study design vii source code data availability source code models raw data used produce figure available quarantine abm source code branching process model available data presented work reproduced source code also made available upon request corresponding author guan wang hallegatte davis sj huo j li et al global effects control measures nature human behaviour organization wh et al policy considerations implementing approach international travel context july world health organization wells cr sah p moghadas sm pandey shoukat wang et al impact international travel border control measures global spread novel coronavirus outbreak proceedings national academy sciences haug n geyrhofer l londei dervic e loreto v et al ranking effectiveness worldwide government interventions nature human behaviour steyn n plank mj james binny rn hendy sc lustig managing risk outbreak border arrivals journal royal society interface gostic k gomez ac mummah ro kucharski aj jo estimated effectiveness symptom risk screening prevent spread elife ashcroft p lehtinen angst dc low n bonhoeffer quantifying impact quarantine duration transmission elife lau h khosrawipour v kocbach p mikolajczyk schubert j bania j et al positive impact lockdown wuhan containing outbreak china journal travel medicine zachreson c mitchell l lydeamore mj rebuli n tomko geard risk mapping outbreaks australia using mobility data journal royal society interface baker mg kvalsvig verrall aj wellington new zealand elimination strategy med j aust summers j cheng hy lin hh barnard lt kvalsvig wilson n et al potential lessons taiwan new zealand health responses pandemic lancet regional pacific thatcher zhang todoroski h chau wang j liang predicting impact australian universities journal risk financial management tisdall l zhang zhang impacts general experiences governmental responses policy imperatives transport policy beck mj hensher da insights impact household travel activities early days restrictions transport policy fisman tuite progressive increase virulence novel variants ontario canada february june medrxiv zhang xiao j deng zhang zhuang hu et al transmission dynamics outbreak delta variant b province china china cdc weekly kang xin h yuan j ali st liang z zhang j et al transmission dynamics epidemiological characteristics delta variant infections china medrxiv dagpunar js interim estimates increased transmissibility growth rate reproduction number b variant concern united kingdom medrxiv brown cm outbreak infections including vaccine breakthrough infections associated large public county massachusetts july mmwr morbidity mortality weekly report chia py ong swx chiew cj ang lw chavatte jm mak tm et al virological serological kinetics delta variant infections cohort study medrxiv lopez bernal j andrews n gower c gallagher e simmons r thelwall et al effectiveness vaccines b delta variant new england journal medicine elliott p haw wang h eales walters c ainslie k et al round final report exponential growth high prevalence vaccine effectiveness associated delta variant england may july osama razai ms majeed vaccine passports access equity ethics british medical journal publishing group organization wh et al considerations quarantine contacts cases interim guidance june world health organization nasreen chung h brown ka gubbay jb buchan sa et al effectiveness vaccines variants concern canada medrxiv zachreson c chang sl cliff om prokopenko change lockdown requirements australia lancet regional health western pacific campbell f archer b h jinnai konings f batra n et al increased transmissibility global spread variants concern june eurosurveillance lauer sa grantz kh bi q jones fk zheng q meredith hr et al incubation period coronavirus disease publicly reported confirmed cases estimation application annals internal medicine hellewell j russell tw beale r kelly g houlihan c nastouli e et al estimating effectiveness routine asymptomatic pcr testing different frequencies detection infections bmc medicine riemersma kk grogan jeppson ge connor dh friedrich tc et al vaccinated unvaccinated individuals similar viral loads communities high prevalence delta variant medrxiv puranik lenehan pj silvert e niesen mj j horo jc et al comparison two mrna vaccines periods alpha delta variant prevalence medrxiv available https pouwels kb pritchard e matthews p stoesser nb eyre dw vihta kd et al impact delta viral burden vaccine effectiveness new infections uk medrxiv ferretti l wymant c kendall zhao l nurtay l et al quantifying transmission suggests epidemic control digital contact tracing science ferretti l ledda wymant c zhao l ledda v l et al timing transmission medrxiv jo schreiber sj kopp pe getz wm superspreading effect individual variation disease emergence nature madewell zj yang longini im halloran dean ne household transmission systematic review jama network open johansson quandelacy tm kada prasad pv steele brooks jt et al transmission people without symptoms jama network open r corman vm guggemos w seilmaier zange et al virological assessment hospitalized patients nature supporting information model details work utilised two distinct models disease transmission one abstract model implemented branching process approximate community transmission dynamics applied quantify tendency quarantine breach events initiate outbreaks characterise outbreaks model simulation describing disease progression transmission individual level implemented two scenarios one used calibration fundamental parameters investigation quarantine system efficacy calibration scenario homogeneous allows characterisation basic reproductive ratio secondary case rates timing transmission detection events effectively open system quarantine scenario designed reproduce general features controlled border screening environments implements defined population structure outbreak transmission branching process model simulate infectious individuals entering community potentially seeding outbreak use branching process community transmission model inhomogenous offspring distribution branching process models considered terms generations generation acts independently last term generation zero index case leaves quarantine transmission potential cases community define transmission potential represents expected number cases caused single case community transmission potential combines biological features virus vaccine status index case vaccination coverage wider community vaccine efficacy parameters break vaccine efficacy two components efficacy infection denoted vi efficacy onward transmission denoted vt overall reduction transmission given v vi vt given starting transmission potential effective transmission potential population pp given pp cv c proportion population vaccinated breach caused vaccinated traveller first generation transmission potential given pu cvi breach caused unvaccinated traveller first generation transmission potential given pv cvi vt secondary case distribution public health measures number secondary infections generated single case taken negative binomial distribution n samples probability success p p order match dispersion number secondary cases fixed expected number secondary cases calendar times infections occur drawn weibull distribution mean days standard deviation line literature estimates case index case thus quarantine infections occur individual left quarantine retained individual enters isolation point per worker protocols infections occur individual entered isolation retained future generations assumed quarantine proactive isolation applied probability breach becoming outbreak calculate probability single breach event becoming outbreak simulate breaches community index cases breaches chosen randomly quarantine model probability calculated separately travellers workers breach defined outbreak reaches least five cumulative cases extinction time significant breach event time breach events assumed occur frequency defined quarantine model scale time according number travellers prior probability arriving system infected construct scaling factor targeted number arrival targeted prevalence arrival country number arrivals modelled quarantine model prevalence infection assumed quarantine model time breaches obtained quarantine model divided breach determined outbreak according binomial distribution probability success defined probability causing outbreak traveller worker breach events chosen proportion occur quarantine model disease model model quarantine scenarios developed model disease transmission designed match three salient features distribution delays symptom onset primary case transmission secondary cases following definition used ferretti et refer quantity time onset symptoms transmission tost household secondary attack rate secondary case dispersion dependence test sensitivity time symptom onset matching distributions model required definition detailed model disease natural history level distribution incubation periods key ensemble statistic informs model dynamics see many possible implementations models could generate required ensemble statistics specific choices follow logic virus initially grows exponentially recognition host immune systems triggers onset symptoms end incubation period immune response produces exponential decline viral load recovery occurs time viral shedding possible sections detail specifics model basic reproductive number transmission rate scalar individual Î²max gamma Îº Î¸ controls transmission rate given transmission environment shape parameter Îº translates directly dispersion parameter derived secondary case distribution distributed negative binomial see scale parameter Î¸ function mean peak force infection hÎ²maxi proportional calibration model figure calibrate basic reproductive number performed systematic scan hÎ²maxi keeping parameters constant produce generic calibration basic reproductive number performed scan unstructured population n individuals simulated large ensemble single transmission generations without interaction effects n instances instance index case properties sampled parameter distributions specified transmission simulated recovery index case count secondary cases produced ignoring additional force infection produced secondary cases average values approximates observe linear relationship control parameter hÎ²maxi figure set value given scenario use line best fit determine corresponding value hÎ²maxi required produce desired value secondary case dispersion distribution secondary cases produced index case ensemble used compute conforms negative binomial distribution dispersion parameter r figure implemented follows index case independent transmission probabilities produce secondary case numbers transmissibility parameter index case Î²max sampled gamma distribution secondary case numbers aggregated basic reproductive ratio simulated linear fit frequency ntot number secondary cases n secondary case distribution b fig calibration basic reproductive number linear dependence global transmission scalar hÎ²maxi derived parameter b distribution secondary cases produced different values effectively drawn negative binomial distribution dispersion parameter number successes r mean index cases effectively drawn ensemble poisson distributions gammadistributed rate parameters gives negative binomial dispersion r Îº therefore model controls secondary case dispersion directly assigning Î²max random variable choice dispersion alter calibration describes average number secondary cases household secondary attack rate check parameterisation r produce reasonable correspondence observed household secondary attack rates ran calibration model setting population size n conditions number possible transmissions akin generic number household contacts n individuals high transmissibility restricted transmission potential calibration produces average household secondary attack rates range consistent observations transmission among household contacts figure low end range typical ancestral lineage increases consistently reaching probability secondary cases simulated k fit negative binomial mean dispersion fig secondary case distribution calibration model follows negative binomial mean dispersion parameter r controlled shape parameter Îº gamma distribution maximum force infection Î²max sampled individual corresponding delta variant secondary attack rate n r frequency ntot number secondary cases n b fig secondary attack rate values produced calibration model transmission within small groups n secondary attack rate function global transmission scalar hÎ²maxi values plotted correspond number secondary infections produced average divided number contacts n b frequency distributions secondary case numbers produced independent trials corresponding single index case single generation transmission four close contacts values hÎ²maxi chosen b correspond broadly estimates ancestral lineage hÎ²maxi delta variant hÎ²maxi disease transmission model model viral dynamics follows function precise form determined individual incubation period individual trajectory infectiousness function time exposure Î² illustrated figure function features initial exponential increase followed brief plateau subsequent exponential decline start exponential decline phase corresponds end individual incubation period onset symptoms note individuals become infectious immediately infected latent period preceding onset infectiousness model assume infected individuals never develop symptoms reduces probability detected within quarantine system model use functional form Î² describe infections regardless whether asymptomatic may asymptomatic individuals marginally less contagious case model would overestimate number secondary cases produce work opted conservative assumption difference exists dynamics implemented piecewise function plateau growth decay phases describing Î² infectiousness individual Î² Î²max vmax exp tinc tp Î²max tinc tp tinc Î²max exp tinc vmax tinc tinc incubation period individual tp duration infectiousness plateau set equal Î²max maximum infectiousness individual parameter vmax scaling factor controlling shape growth curve smaller values vmax produce broader growth decay functions higher values produce steeper growth decay rate parameters determined value vmax duration incubation periods ln vmax tinc tp ln vmax r tr time symptom onset recovery drawn uniformly random range approximately match duration viral shedding symptom onset interaction infected individual susceptible individual j probability transmission computed pij exp Î² force infection produced infected individual time since infection days duration discrete time step Ïƒij scaling factor incorporates effects contact frequency intensity given transmission event infected individual susceptible individual j Ïƒij fijh j fij transmission mitigation factor hj number contacts given type local mixing environment calibration model fij hj n full quarantine model fij given follows close contacts travellers group fij hj ni ni number close contacts group individual n initially decrease members moved isolation interactions travellers different close contact groups fij hj p ng number travellers quarantine system isolated group g individual interactions infected travellers susceptible workers fij hj nw nw number workers present facility time interactions infected workers susceptible travellers fij hj ntot ntot number travellers isolation interactions infected workers susceptible workers fij hj nw nw number workers present facility time force infection rescaled maximum time infection Î²max gamma k Î²max k Î²max Î² p e incubation period symptom onset incubation periods lognormal periods uniform Î²max fig example force infection produced infected individual function time infection force infection increases exponentially time infection start plateau point reaches maximum value plateau phase lasts end incubation period duration equal total incubation period incubation periods drawn distribution period infectiousness decreases exponentially reaches cutoff time recovery duration end plateau phase recovery drawn uniform distribution bounded days values Î²max drawn gamma distribution parameterised specified value described section b time onset symptoms transmission tost functional form used Î² developed match ensemble distributions time onset symptoms transmission tost reported ferretti et al comparison statistics produced calibration model distribution reported ferretti et al shown figure qualitative match model case statistics empirical tost distribution sensitive choice individual disease trajectory function probability density time onset symptoms transmission tost days empirical tost scaled ferretti et al simulated tost abm n trials n agents fig time onset symptoms transmission tost distributions produced calibration model n individuals homogeneous contact network tost distribution depend transmissibility disease matches closely model ferretti et al equations time onset symptoms detection tosd model test sensitivity discussed following subsections designed capture variability test sensitivity function time relative symptom onset models based study hellewell et al general objective describe test sensitivity piecewise sigmoid single breakpoint tc breakpoint sensitivity increases tc represents time infection breakpoint tc sensitivity decreases slowly case function expressed logistic regression parameter ci tc table parameter ranges used hellewell et describe progression test sensitivity infections healthcare workers model reported parameter ranges adjusted account individual variability incubation periods p exp tc exp tc Ï„ tc maximum test sensitivity depends exp initial growth sensitivity controlled decay sensitivity tc given parameter ranges credible intervals provided hellewell et al shown table parameter ranges shown table produced fitting ensemble data study examined timeseries tests test results cohort individuals aggregated timeseries order fit parameters model therefore parameter ranges suitable individual test sensitivity trajectories model translates specified functional form logistic function parameter ranges set trajectories describing test sensitivity function incubation period time infection symptom onset individual system reconcile ensemble characteristics observed hellewell et requirements individual trajectories model requirements specified follows individual may test positive infected peak test sensitivity must correspondence timing peak viral load peak infectiousness probability detection high first week symptoms requirements following implications model framework specified hellewell et al specified range tc fit trajectories incubation periods average incubation period days rate increase must higher individuals shorter incubation periods imposes correlation specifying individual trajectories address discrepancies relax parameter restrictions table set breakpoint position relative individual incubation period delay breakpoint tc onset symptoms tinc distributed range rationale choice based observation upper credible interval reported hellewell tc approximately equivalent median incubation period infer corresponds using incubation period upper limit tc additionally model correlates length delay incubation period agent quantile matching ensure tc always positive tc tinc denotes specific individual qi value incubation period cdf evaluated tinc range possible delays units days peak test sensitivity symptom onset provide better match ensemble statistics also chose impose negative correlation individual incubation periods term specifies growth rate test sensitivity peak along decay rate test sensitivity peak qi lower bound range values given table modified parameter ranges shown table samples individual trajectories shown figure comparison ensemble statistics shown figure hand parameter ci tc tinc table parameter ranges used order fit abm ensemble statistics reported hellewell et al parameters chosen uniformly random individual ranges specified model approximately matches proportion infections detected symptom onset given daily test estimated hellewell et al approx corresponding distribution time onset symptoms detection tosd shown figure c system daily testing detects approximately cases prior symptom onset relative infectiousness time infection test sensitivity relative infectiousness test sensitivity symptom onset peak test sensitivity relative infectiousness time infection test sensitivity relative infectiousness test sensitivity symptom onset peak test sensitivity relative infectiousness time infection test sensitivity relative infectiousness test sensitivity symptom onset peak test sensitivity b c fig individual trajectories test sensitivity force infection function time since exposure short incubation periods produce alignment peak test sensitivity peak infectiousness occur close onset symptoms b average incubation periods produce test sensitivity peak lags symptom onset peak infectiousness several days extend tail test sensitivity curve symptom onset c long incubation periods correspond longer lag times peak test sensitivity symptom onset extend tail test sensitivity trajectory test sensitivity time infection sample median n quantile quantile mean incubation period days median lower ci hellewell et al median upper ci hellewell et al test sensitivity time onset symptoms sample median n quantile quantile symptom onset probability density time onset symptoms detection cumulative probability p detect onset b c fig ensemble statistics test sensitivity function time infection aggregated agent based model test sensitivity function time infection grey dashed lines give credible intervals mean hellewell et solid black trace shows ensemble average produced samples model solid red traces give quantiles model b test sensitivity function time symptom onset produced model black trace gives ensemble average red traces give quantiles vertical dashed lines b represent onset symptoms c time onset symptoms detection given daily tests via derived model solid trace indicates cumulative distribution dashed lines indicate proportion cases detected one day prior symptom onset assuming test turnaround day corresponds proportion detected prior symptom onset model quarantine environment model quarantine system transmission occurs explicitly represents individual travellers quarantine workers describe model terms input layer filter layer output layer input layer arriving travellers characterised terms proportion arriving travellers infected proportion arriving travellers vaccinated set proportion infected arrivals proportion vaccinated additionally assumed infected arrivals either asymptomatic arrival time since infection sampled random individual incubation period traveller asymptomatic time since infection arrival sampled sum incubation period period filter layer travellers quarantined travellers structured groups quarantined together room results presented size groups set number travellers facility set travellers discharged system groups travellers group meet discharge criteria group removed new group generated replace workforce quarantine workforce also represented workforce model specifies weekly work schedule individual including days working days days days scheduled randomly work schedule configuration accepted model long least workers present day week transmission control assume rate transmission travellers belong different groups reduced factor compared travellers belong group similarly assume factor reduction transmission travellers workers factor reduction workers vaccination efficacy vaccination may varied reflect available evidence assume proportion workforce proportion arriving travellers vaccinated vaccine efficacy parameters varied reflect characteristics vaccines used particular source countries interest work assume individuals quarantine system vaccinated implement vaccination setting efficacy infection vi v e efficacy onward transmission vt choice significant computing transmission within quarantine system individuals assumed vaccinated however components vaccine efficacy could play significant role interpreting force infection produced breach events see sensitivity analysis testing testing workers scheduled varying frequencies daily every three days weekly workers tested days attend workplace results reported testing workforce performed daily long worker present model includes testing travellers scheduled occur given days quarantine period results reported travellers tested days entering quarantine calibrated test sensitivity specified represent detection via response positive test symptoms worker tests positive develops symptoms assume removed workforce replaced new worker irrespective whether attend work day traveller tests positive develops symptoms isolated removed quarantine facility health hotel hospital isolation period set days released positive test result traveller triggers quarantine extension travellers group resets testing schedule tests performed days extension output output quarantine simulation time series breach events corresponding characteristics individual leaves quarantine infected several properties recorded recorded properties depend whether infected individual worker traveller travellers recorded properties exposure days number days remain infectious days quarantine total number days spent quarantine system days extended quarantine number days quarantine extension detection case close contact days isolation number days spent isolation testing positive presenting symptoms incubation period period infection symptom onset time period symptom onset recovery time discharged timepoint individual released quarantine index case boolean flag indicating whether individual arrived infected infected quarantine symptomatic boolean flag indicating whether individual would express clinical symptoms incubation period vaccinated boolean flag indicting individual vaccination status Î²max maximum force infection individual force infection symptom onset Î²community integrated force infection period individual discharged quarantine summed produce Î²tot value simulation workers recorded properties exposure days number days infection detection recovery incubation period travellers see period travellers see tested positive boolean flag indicating whether individual removed testing positive expressed symptoms boolean flag indicating whether individual removed expressing symptoms time discharged timepoint individual removed facility symptomatic boolean travellers see vaccinated boolean travellers see Î²max travellers see Î²community force infection integrated period infection detection discharge output timeseries used generate input statistics index cases used branching process model sensitivity analysis incubation period estimate effect shorter incubation period used statistics reported china cdc outbreak delta variant may estimates incubation period may differ others represent lower bound important parameter demonstrate shorter incubation period affects transmission detection virus model system main differences without intervention slightly less transmission occurs prior symptom onset due rapid increase viral load detection cases typically occurs earlier probability density incubation period lognormal mean days median days lognormal mean days median days fig incubation period distributions used model black trace indicates distribution used main results red trace indicates distribution used sensitivity analysis quarantine model scenario shorter overall duration infection increases efficacy quarantine results demonstrate shorter incubation periods correspond enhanced capacity control transmission results caution use preliminary estimates incubation period statistics use models border quarantine systems demonstrate potentially effectiveness systems represent conservative assumptions viral dynamics investigate effect incubation period first base model using modified incubation period distribution figure calibration determined timing symptom onset relative transmission timing detection relative symptom onset given daily testing via homogeneous transmission network individuals figure applied modified calibration full quarantine simulation examine effectiveness quarantine v e parameter space results qualitatively similar produced original calibration average incubation period days show consistently lower levels breach risk measured Î²tot basic reproductive ratio simulated mean incubation period days linear fit simulated mean incubation period days linear fit fig calibration function global transmission scalar two different incubation periods probability density time onset symptoms transmission tost days empirical tost scaled ferretti et al simulated tost abm n trials n agents probability density time onset symptoms transmission tost days empirical tost scaled ferretti et al simulated tost abm n trials n agents b fig distribution tost two different incubation period distributions shows full distribution b zooms negative intervals corresponding transmission b elin e fig integrated force infection Î²tot relative baseline using incubation period mean days baseline denominator value taken alternate scenario incubation period days v e results shown function vaccine efficacy sensitivity analysis vaccine efficacy onward transmission results presented figure assumed vaccine efficacy onward transmission negligible values reported Î²tot represent differences breach statistics rather direct effects vaccine efficacy examine alternate extreme case efficacy transmission equivalent v equates multiplication Î²tot values figure factor v results correction applied force infection values fall linearly v e increases alternate assumption value vaccine efficacy required maintain baseline outbreak statistics lower magnitude difference increases ranging approximately approximately differences substantial represent largest possible deviation due efficacy transmission therefore results presented figure may overestimate vaccine efficacy required maintain baseline risk ratios magnitude overestimate exceed b elin e fig integrated force infection Î²tot relative baseline assuming vaccine efficacy onward transmission maximised vt v e vi baseline denominator value taken scenario v e results shown function vaccine efficacy
statically delayed sampling probabilistic streams eric atkinson mit usa guillaume baudart inria Ã©cole normale supÃ©rieure psl university france louis mandel watson ai lab ibm research usa charles yuan mit usa michael carbin mit usa probabilistic programming languages aid developers performing bayesian inference languages provide programming constructs tools probabilistic modeling automated inference prior work introduced probabilistic programming language probzelus extend probabilistic programming functionality unbounded streams data work demonstrated delayed sampling inference algorithm could extended work streaming context probzelus showed delayed sampling could effectively deployed programs depending probabilistic model consideration delayed sampling guaranteed use bounded amount memory course execution program paper present conditions probabilistic program execution delayed sampling execute bounded memory two conditions dataflow properties core operations delayed sampling property unseparated paths property program executes bounded memory delayed sampling satisfies unseparated paths properties propose static analysis abstracts properties soundly ensure program passes analysis satisfies properties thus executes bounded memory delayed sampling ccs concepts theory computation program analysis streaming models software engineering data flow languages additional key words phrases probabilistic programming reactive programming streaming inference semantics program analysis acm reference format eric atkinson guillaume baudart louis mandel charles yuan michael carbin statically boundedmemory delayed sampling probabilistic streams proc acm program lang oopsla article october pages https introduction probabilistic programming languages aid developers performing bayesian inference atkinson et al bingham et al et al ge et al gelman et al goodman et al goodman stuhlmÃ¼ller gordon et al huang et al mansingkha et al milch et al narayanan et al nori et al pfeffer tran et al languages provide programming constructs tools probabilistic modeling automated inference researchers developed probabilistic programming languages several domains authors addresses eric atkinson mit usa guillaume baudart inria Ã©cole normale supÃ©rieure psl university france louis mandel watson ai lab ibm research usa charles yuan mit usa michael carbin mit usa permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed profit commercial advantage copies bear notice full citation first page copyrights components work must honored uses contact copyright held https proc acm program vol oopsla article publication date october sep eric atkinson guillaume baudart louis mandel charles yuan michael carbin including data science gelman et al machine learning bingham et al tran et al scientific simulation baydin et al control baudart et al probabilistic programming streams paper consider programs accept inputs compute outputs discrete time steps outputs step flowing environment affect future inputs program mathematically one model programs computations operate produce infinite streams computing streams common computational model applications control robotics avionics colaÃ§o et al example control airplane system implemented program transforming stream altitude measurements stream commands engine baudart et al introduced probabilistic programming language probzelus enable probabilistic programming domain computations streams key innovation probzelus demonstrate delayed sampling murray et al could extended work streams provide inference procedures delayed sampling inference algorithm combines exact approximate inference takes advantage exact inference efficient known solutions exist falls back approximate inference required specifically delayed sampling combines bayesian networks graphs encode exact distributions probabilistic models particle filtering del moral et al approximate inference algorithm challenge adapting delayed sampling computations streams computations run indefinite periods time often subject stringent limits resources memory baudart et al showed many cases finite number nodes delayed sampling graph data structures reachable given time rest could influence computation future could removed memory however behavior depends probabilistic model consideration delayed sampling guaranteed maintain bounded amount memory programs result though probabilistic programming languages designed hide complexities developing probabilistic inference algorithms certain combinations model inference algorithm result undesirable behaviors developer anticipate moreover developer means reason behaviors except inspecting implementation inference algorithm delayed sampling paper formalize semantic conditions applying delayed sampling probabilistic programs streams execute bounded memory two conditions dataflow properties core operations delayed sampling assume observe value respectively add new random variable delayed sampling graph observe random variable evaluate random variable produce sampled value consumed property states variables introduced assume eventually consumed observe value passed assumes resulting new variables unseparated path sequence random variables passed parameter assume operation next variable passed observe value operation unseparated paths property states variable maintained program state starts unseparated longer fixed bound ğ‘› program executes bounded memory delayed sampling satisfies unseparated paths properties static analysis propose static analysis checks unseparated paths properties soundly ensure program passes analysis satisfies properties thus executes bounded memory delayed sampling proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams contributions paper present following contributions introduce formalize unseparated paths properties show necessary sufficient program execution present static analysis check properties prove analysis sound implement analysis evaluate several probabilistic inference benchmarks results show eight nine benchmarks analysis determines whether semantic properties necessary execution satisfied identify precision limitation conservative static analysis remaining benchmark work brings probabilistic programming control settings new benefit static guarantees system resource consumption best knowledge work first develop resource analysis probabilistic program relation probabilistic programming system underlying inference algorithm remainder paper structured follows section give example program illustrate concepts paper section present syntax semantics language probabilistic programming streams adapted ğœ‡ğ¹ language baudart et al section review background delayed sampling based contributions murray et al baudart et al section present unseparated paths semantic properties sections present evaluate static analysis sections summarize related work present conclusions example figure presents example robot designed navigate desired position target using measurements obs noisy position sensor robot issues command u indicates acceleration apply change position robot estimates current position probabilistic model kalman uses estimate compute command u deterministic controller regulator sontag implementation elided simplicity present example ğœ‡ğ¹ purely functional core calculus probabilistic programming streams val kalman stream init step obs let x sample gaussian let observe gaussian x obs x x val robot stream init init controller infer kalman step c k obs target let k unfold k obs let u c unfold c target mean u c k fig ğœ‡ğ¹ program main stream function robot program set stream function definitions consist initializer step function given previous state input value produces output value new state mealy operators init infer instantiate stream function creating internal state stream function applied input stream generate output stream operator unfold applies step function using internal state input values unlike init step function instance created using infer performs probabilistic inference thus returns iteration distribution outputs distribution states main stream function robot state composed two stream function instances c deterministic controller k kalman probabilistic model robot initializer creates proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin two instances transition function instance k performs probabilistic inference infer distribution robot state updated instance k transition function instance c computes command u go toward destination target using statistics position distribution updated instance c transition function robot returns command u updated state probabilistic model stream function kalman specifies hidden markov model baum petrie common probabilistic model tracking applications goal estimate trajectory object given noisy measurements object position stream function state consists latent random variable denotes position robot previous iteration robot state latent robot unable directly observe position instead must leverage noisy measurement observation position infer probability distribution potential states inside definition kalman program models latent nature x sampling current position gaussian distribution centered around previous position program models observation taking observed sensor value input obs supplying input observe operator example observe specifies obs observation gaussian distribution centered around position x observe operator conditions program execution observed value adjusts distribution inferred x sequence diagrams figure illustrates evolution representation hidden markov model first four iterations program light grey node denotes latent random variable x given iteration dark grey node denotes observation given iteration solid black arrow signifies dependence random variables traditional bayesian network representation probabilistic graphical model koller friedman note observation iteration depends current position robot state given iteration depends position previous iteration inference delayed sampling kalman probabilistic model sufficient robot reason position instead robot must perform inference model compute posterior distribution x conditioned observations mentioned infer operator robot stream function applies inference probabilistic model receives input paper study delayed sampling baudart et al murray et al algorithmic implementation infer operator delayed sampling extension particle filtering algorithm leverages symbolic execution reason relationship random values perform exact inference possible particle filter estimates posterior distribution set particles independent executions model particle delayed sampling operates dynamically maintaining graph bayesian network records dependence relationships random variables program figure key idea rather sample concrete value random variable program x delayed sampling instead returns reference node graph node contains representation distribution sample operator sampled along distribution dependence random variables program symbolic computation fails delayed sampling fall back particle filter drawing concrete values random variables proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams x obs iteration x obs b iteration x obs c iteration x obs iteration fig evolution delayed sampling graph hidden markov model figure kalman implemented baudart et al node denotes either value dark gray distribution light gray plain arrow denotes dependency underlying bayesian network dotted arrow denotes pointer implementation delayed sampling graph label indicates program variable corresponds node node denotes node reachable program state delayed sampling key concern applying delayed sampling streams may execute indefinite number iterations size delayed sampling graph bounded fixed constant iterations program delayed sampling graph may consume bounded memory program may exhaust resources permitted execute indefinitely general bounding memory use challenging underlying bayesian network fact unbounded nevertheless delayed sampling implementation maintain bounded memory programs depending operation said programs subsection review delayed sampling implementation presented baudart et al execute bounded memory programs example figure shows delayed sampling maintains bounded memory program figure particle delayed sampling implementation must keep memory nodes reachable node referenced program state dashed lines figure visualize reachability relation node line points reachable node line points program evolves state changes variables state contains nodes delayed sampling graph may become unreachable marked figure shows delayed sampling graph first iteration graph consists two nodes one introduced sampling variable x one introduced observation obs end step program state reachable figure shows delayed sampling graph second iteration program added two nodes graph sampling x observing obs nodes left first iteration still graph longer reachable figures show delayed sampling graph iterations respectively case recently introduced nodes x obs reachable nodes previous iterations unreachable general program ensures iteration recently introduced nodes reachable rest unreachable two reachable nodes iterations inference executes bounded memory example figure presents example program execute bounded memory modified version kalman figure samples initial latent position gaussian distribution keeps reference random variable state figure shows program figure fails maintain bounded memory figure shows delayed sampling graph first iteration graph consists three reachable nodes introduced sampling variables x observation obs proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin val stream init true step first obs let first let sample gaussian else let x sample gaussian let observe gaussian x obs x false x fig model unbounded memory consumption x obs iteration x obs b iteration x obs c iteration x obs iteration fig evolution delayed sampling graph variant kalman probabilistic model figure nodes edges meaning figure f nil f obs f f obs iteration iteration fig depiction trace program figure figure depicts trace end iteration trace list primitive operations primitive operation sampling operation f observation operation obs diagram use xğ‘› yğ‘› refer random variables introduced iteration ğ‘› respectively sampling x observing obs figure figure shows delayed sampling graph second iteration program added two nodes graph sampling x observing obs since variable program state node x reachable figures show next iterations two new nodes introduced step one remains reachable primary observation note number introduced nodes increases every iteration therefore bound size delayed sampling graph hence program execute bounded memory analyzing delayed sampling paper present analysis show program figure maintains bounded memory program figure define two dataflow properties encode whether program executes bounded memory unseparated paths property property show properties verified using static analysis traces formalize dataflow properties properties traces trace recording important features program execution case trace records sampling observation operations program executed well variables involved operations figure illustrates trace execution program figure unseparated paths unseparated path trace sequence variables ğ‘¥ğ‘– trace specifies variable ğ‘¥ğ‘– sampled predecessor ğ‘¥ğ‘– observed proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams f nil f f obs f f obs iteration iteration false fig depiction trace program figure figure depicts trace value program state end iteration diagram use xğ‘› yğ‘› respectively refer random variable introduced sampling variable introduced iteration ğ‘› sampling x variable introduced iteration ğ‘› observing obs figure highlighted elements unseparated path ğ‘– green unseparated paths property states uniform bound ğ‘ iterations variable program state starts unseparated path ğ‘ variables figure illustrates trace program figure program carries variable program state trace specifies sampled sampled sequence unseparated path variables general iteration ğ‘› program figure maintains program state starts unseparated path length ğ‘› bound exist length path arbitrary number iterations program fails unseparated path property variable ğ‘š sampling operations away variable consumed observe statement property states uniform bound ğ‘š every variable introduced sampling operation ğ‘š ğ‘š note traces figures satisfy property every variable ğ‘¡ yğ‘¡ directly observed xğ‘¡ yğ‘¡ sampled xğ‘¡ yğ‘¡ variable sampled outlier benchmark presented section example program fails consumed property thus execute bounded memory program sometimes observes values close true latent state otherwise observes values outlier distribution program observes value outlier distribution fails observe dependencies latent state thus guarantee latent state time program performs latent state updates remain unobserved due program always observing outlier distribution lack guarantee results uniform bound ğ‘š latent state could analysis goal ultimately analyze whether given program executes bounded memory show section program execution maintains bounded memory satisfies unseparated path properties reduces problem analyzing behavior program analyzing dataflow properties analysis utilizes abstract delayed sampling graph formally defined section key aspects properties abstract graph maintains set variables introduced yet consumed unseparated paths maintains upper bound length example abstract graphs trace figure given figure proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin f nil f f obs f f obs iteration iteration unseparated paths fig depiction abstract graphs program figure trace figure operation depict abstract graph set nodes introduced consumed set empty end iteration program satisfies semantic property unseparated paths abstract graph mapping unseparated path graph endpoints length depict longest path mapping iteration longest path continues lengthen program satisfy unseparated paths semantic property language model section present semantics probabilistic programs streams using language ğœ‡ğ¹ adapted ğœ‡ğ¹ baudart et al core calculus probabilistic programs extended syntax explicit streams syntax syntax ğœ‡ğ¹ language defined according following grammar program ğ‘‘ ğ‘š ğ‘‘ val ğ‘ ğ‘’ val ğ‘“ fun ğ‘ ğ‘’ val ğ‘š stream init ğ‘’ step ğ‘ ğ‘ ğ‘’ ğ‘’ ğ‘£ op ğ‘£ ğ‘“ ğ‘£ ğ‘£ ğ‘’ else ğ‘’ let ğ‘ ğ‘’ ğ‘’ init ğ‘š unfold ğ‘¥ ğ‘£ sample ğ‘£ observe ğ‘£ ğ‘£ infer ğ‘š ğ‘£ ğ‘ ğ‘¥ ğ‘£ ğ‘£ ğ‘ ğ‘¥ ğ‘ ğ‘ program set value function stream function definitions followed name main stream function stream function ğ‘š composed initial state init transition function step given state input transition function returns output new state expression either value constant variable pair application primitive operator arithmetic operator distribution etc function call conditional local definition expression init ğ‘š creates instance stream function unfold ğ‘¥ ğ‘£ applies instance ğ‘¥ stream function input returns next element updated instance finally set expressions comprises probabilistic operators sample observe infer nested inference functions streams allowed language require arguments syntactic operators values simplify presentation semantics since new variables always introduced capture value expression choice reduce expressiveness language semantics execution program ğ‘ ğ‘‘ comprises three steps first declarations ğ‘‘ evaluated produce environment ğ›¾ contains definition main stream function ğ‘š second instance stream function ğ‘š created proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams ğ‘¥ ğ›¾ ğ‘¥ ğ‘“ fun ğ‘ ğ›¾ ğ‘“ ğœ†ğ‘£ ğ‘š stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ ğ‘š stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ ğ‘š let stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ let ğ‘ init ğ‘ init ğœ† ğ‘  ğ‘£ ğ‘’ deterministic ğ‘š let stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ let ğ‘ init ğ‘ init ğœ† ğ‘  ğ‘£ ğ‘’ ğ›¾ ğ‘’ probabilistic ğ‘¥ ğ‘£ let ğ‘£state ğ‘“ let ğ‘£output state ğ‘“ ğ‘£state ğ‘£output ğ‘£ state ğ‘“ ğ‘š let stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ let ğ‘ init ğ›¿ğ‘ init infer ğœ† ğ‘  ğ‘£ ğ‘’ ğ›¾ infer ğ‘“ ğœ† ğœ ğ‘£ let ğœ‡ ğœ†ğ‘ˆ ğ‘† ğœ ğ‘‘ğ‘  ğ‘“ ğ‘  ğ‘£ ğ‘ˆ let ğœˆ ğœ†ğ‘ˆ ğœ‡ ğ‘ˆ ğœˆ ğœˆ fig deterministic semantics ğœ‡ğ¹ complete definition figure third instance iteratively applied input stream ğ‘–ğ‘› produce output stream ğ‘œğ‘› defined following way ğ‘– ğ‘› ğ‘œğ‘› ğ‘ ğ‘‘ ğ›¾ ğ‘š ğ‘œğ‘› ğ‘ ğ‘› ğ‘–ğ‘› figure defines semantics declarations deterministic expressions declarations build evaluation environment ğ›¾ maps names values functions stream functions semantics deterministic expressions corresponds first order functional language new constructs handle streams infer operator complete definition given figure appendix expression init ğ‘š creates instance stream function ğ‘š pair corresponding current state transition function current state initialized value init field expression unfold ğ‘¥ ğ‘£ executes transition function instance ğ‘¥ current state input ğ‘£ expression produces pair composed transformed value updated instance ideal semantics ğœ‡ğ¹ probabilistic expressions semantics similar one presented staton complete definition given appendix given environment ğ›¾ expression interpreted measure ğ‘’ ğ›¾ Ïƒğ· function associates positive number measurable setğ‘ˆ Ïƒğ· Ïƒğ· denotes domain expression ğ· set measurable sets possible values sample ğ‘£ returns distribution observe weights execution paths using likelihood observation distribution distribution ğœ‡ denote probability density function ğœ‡pdf local definitions interpreted integration use dirac delta measure interpret deterministic expressions proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin ğ‘£ ğ›¾ ğœ†ğ‘” ğ‘¤ ğ‘” ğ‘¤ op ğ‘£ ğ›¾ ğœ†ğ‘” ğ‘¤ app op ğ‘” ğ‘¤ ğ‘“ ğ‘£ ğ›¾ ğœ†ğ‘” ğ‘¤ ğ›¾ ğ‘“ ğ‘” ğ‘¤ let ğ‘ ğ›¾ ğœ†ğ‘” ğ‘¤ let ğ›¾ ğ‘” ğ‘¤ ğ‘£ else ğ›¾ ğœ†ğ‘” ğ‘¤ let ğ‘ ğ‘”ğ‘ value ğ‘” ğ‘ ğ›¾ ğ‘”ğ‘ ğ‘¤ else ğ›¾ ğ‘”ğ‘ ğ‘¤ unfold ğ‘¥ ğ‘£ ğ›¾ ğœ†ğ‘” ğ‘¤ let ğ‘£state ğ‘“ let ğ‘£output state ğ‘“ ğ‘£state ğ‘” ğ‘¤ ğ‘£output ğ‘£ state ğ‘“ sample ğ‘£ ğ›¾ ğœ†ğ‘” ğ‘¤ let ğ‘‹ assume ğ‘” ğ‘‹ ğ‘¤ observe ğ›¾ ğœ†ğ‘” ğ‘¤ let ğ‘‹ ğ‘”ğ‘¥ assume ğ‘” let ğ‘£ ğ‘”ğ‘£ value ğ‘”ğ‘¥ let ğ‘” observe ğ‘‹ ğ‘£ ğ‘”ğ‘£ ğ‘¤ ğœ‡pdf ğ‘£ fig delayed sampling semantics probabilistic expressions functions graph weight triplet value graph weight infer ğ‘š operator creates instance probabilistic stream initial state dirac delta distribution initial state ğ‘š transition function infer ğ‘“ ğ‘“ transition function ğ‘š body ğ‘“ expression ğ‘’ interpreted probabilistic semantics defines measure pairs output values states function infer ğ‘“ takes arguments distribution states ğœ input ğ‘£ returns distribution outputs distribution new states two distributions obtained integrating transition function ğ‘“ along distribution ğœ possible states domain ğ‘† build measure ğœ‡ normalized build distribution ğœˆ pairs outputs states distribution ğœˆ split pair marginal distributions using pushforward ğœˆ across projections delayed sampling section present details delayed sampling underpin work new formalization results presented murray et al baudart et al delayed sampling algorithm combining exact inference exact computation fails approximate inference particle filtering del moral et al particle filter launches multiple executions model execution particle associated weight operational semantics sample ğ‘‘ statements draw samples corresponding distributions observe ğ‘¥ ğ‘‘ statements update weight reflect quality samples end executions results particles normalized according weights form categorical distribution approximates posterior distribution model delayed sampling particle contains graph random variables dependencies used compute distributions observations incorporated analytically conditioning network symbolic conditioning fails inference falls back particle filter drawing concrete samples required random variables proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams operational semantics definition infer figure makes use intractable integral delayed sampling semantics replaces integral discrete sum set particles particle filter compared traditional particle filtering delayed sampling performs exact computations possible thus extend valuesğ‘£ symbolic terms symbolic terms include random variables ğ‘‹ nodes delayed sampling graph applications operators ğ‘£ ğ‘‹ app op ğ‘£ semantics figure rely following operations update graph ğ‘£ value ğ‘£ ğ‘” samples random variables ğ‘£ produce concrete value ğ‘” observe ğ‘‹ ğ‘£ ğ‘” conditions graph fact random variable ğ‘‹ takes value ğ‘‹ assume ğ‘‘ ğ‘” adds returns new random variable ğ‘‹ distribution probabilistic semantics semantics probabilistic expressions defined figure semantics expression ğ‘’ ğ›¾ ğ‘” ğ‘¤ takes two additional arguments ğ‘” delayed sampling graph ğ‘¤ weight particle filter returns symbolic value updated graph updated weight operator application op ğ‘£ introduces symbolic expression app op ğ‘£ uses value operation sample concrete value condition sample ğ‘£ introduces new random variable graph distribution observe introduces fresh random variable ğ‘‹ distribution conditions graph fact ğ‘‹ takes value inference given transition function ğ‘“ distribution states ğœ previous iteration inputs ğ‘£ğ‘– infer operator computes distribution outputs new distribution states next iteration first inference draws ğ‘ states ğœ theses states ğ‘ ğ‘› associated delayed sampling graph ğ‘”ğ‘› second transition function ğ‘“ returns symbolic output value ğ‘£ğ‘› new state ğ‘  ğ‘› updated graph ğ‘” ğ‘› importance weight ğ‘¤ğ‘› third distribution ğ‘œğ‘› ğ‘› function returns distribution values without altering graph new distribution states dirac delta distribution pair ğ‘  ğ‘› ğ‘› finally results accumulated mixture distribution using weights ğ‘¤ğ‘› distribution split distribution values distribution next ğ‘š let stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ let ğ‘ init ğ›¿ ğ‘ init infer ğœ† ğ‘state ğ‘input ğ‘’ ğ›¾ infer ğ‘“ ğœ† ğœ ğ‘£ğ‘– let ğœ‡ ğœ†ğ‘ˆ Ã­ ğ‘ let ğ‘ ğ‘› ğ‘”ğ‘› draw ğœ let ğ‘œğ‘› ğ‘› ğ‘› ğ‘¤ğ‘› ğ‘“ ğ‘ ğ‘› ğ‘£ğ‘– ğ‘”ğ‘› let ğ‘‘ğ‘› distribution ğ‘œğ‘› ğ‘› ğ‘¤ğ‘› ğ‘‘ğ‘› ğ‘ˆ ğ›¿ğ‘  ğ‘› ğ‘› ğ‘ˆ ğœ‡ ğœ‡ graph manipulation describe graph manipulation functions required define operations value assume observe used semantics figure lundÃ©n murray et al provide detailed explanations operations notation section follow frv ğ‘£ denotes free random variables program value ğ‘£ set variables used symbolic expression ğ‘£ write ğ‘¤ğ‘– ğ‘¤ğ‘– Ã­ğ‘ ğ‘¤ğ‘– normalized weights proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin graph data structure delayed sampling graph ğ‘” defined tuple ğ‘‰ ğ¸ ğ‘ ğ‘‰ set vertices random variables ğ¸ set directed edges dependencies random variables ğ‘ relation mapping node state initialized marginalized realized node initialized ğ‘ğ‘‹ represents random variable ğ‘‹ conditional distribution ğ‘ğ‘‹ ğ‘Œ unique parent ğ‘‹ node marginalized ğ‘ğ‘‹ represents random variable ğ‘‹ marginal distribution ğ‘ğ‘‹ marginalized node one parent parent node distribution ğ‘ğ‘‹ incorporates distribution node realized ğ‘£ represents random variable ğ‘‹ associated concrete value ğ‘£ construction delayed sampling graph forest set trees node one parent value operation value ğ‘£ ğ‘” converts symbolic expression ğ‘£ concrete value sampling random variables ğ‘£ random variables become realized nodes graph distributions depending variables updated value ğ‘£ ğ‘” ğ‘£ ğ‘” ğ‘£ concrete value value app op ğ‘£ ğ‘” let ğ‘£ value ğ‘£ ğ‘” op ğ‘£ value ğ‘‹ ğ‘” let ğ‘‰ ğ¸ ğ‘ ğ‘” ğ‘ ğ‘‹ realized ğ‘£ ğ‘£ ğ‘” else let ğ‘‰ ğ‘‹ marginalized ğœ‡ graft ğ‘‹ ğ‘” let ğ‘£ draw ğœ‡ ğ‘£ ğ‘‰ ğ‘‹ realized ğ‘£ ğ‘£ already concrete value nothing ğ‘£ application operator value recursively samples concrete value argument applies operator value ifğ‘£ random variable ğ‘‹ already realized value returns corresponding value otherwise value calls graft function defined appendix c marginalize ğ‘‹ ancestors draws sample marginalized distribution returns value turns ğ‘‹ realized node note graft might realize nodes since marginalizes ancestors marginal node single marginalized child marginalization graft also removes edges marginalized nodes realized child assume operation assume ğ‘£ ğ‘” adds new random variable ğ‘‹ distribution ğ‘£ graph assume ğ‘£ ğ‘” let ğ‘‰ ğ¸ ğ‘ ğ‘” let ğ‘‹ fresh ğ‘‰ frv ğ‘£ ğ‘‹ ğ‘‰ ğ‘‹ ğ¸ ğ‘ ğ‘‹ marginalized ğ‘£ else frv ğ‘£ ğ‘Œ conj ğ‘£ ğ‘Œ ğ‘” ğ‘‹ ğ‘‰ ğ‘‹ ğ¸ ğ‘‹ ğ‘Œ ğ‘ ğ‘‹ initialized ğ‘£ else let ğ‘£ ğ‘‰ ğ¸ value ğ‘£ ğ‘‰ ğ‘‹ ğ¸ ğ‘ ğ‘‹ ğ‘‰ ğ‘‹ marginalized ğ‘£ distribution ğ‘£ symbolic expression marginal distribution depends random variables app bernoulli conditional distribution app bernoulli ğ‘Œ ğ‘Œ random variable ğ‘£ marginal distribution assume adds new marginalized node graph ğ‘£ conditional distribution assume tries keep track dependency ğ‘‹ random variable used ğ‘£ delayed sampling graph forest node one parent value ğ‘£ thus represents distribution ğ‘ğ‘‹ ğ‘‹ depends unique random variable ğ‘Œ distribution ğ‘ğ‘‹ ğ‘ğ‘Œ conjugate conj ğ‘£ ğ‘Œ ğ‘” app bernoulli ğ‘Œ ğ‘Œ beta ğ›¼ ğ›½ marginalization conditioning tractable operations assume adds edge proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams ğ‘Œ new initialized node ğ‘‹ graph otherwise symbolic computation possible assume calls value sample concrete value thus breaking dependency adds new independent marginalized node graph observe operation observe ğ‘‹ ğ‘£ ğ‘” assigns concrete value ğ‘£ ğ‘‹ updates distributions depending ğ‘‹ accordingly observe ğ‘‹ ğ‘£ ğ‘” let ğ‘‰ ğ¸ ğ‘ graft ğ‘‹ ğ‘” ğ‘‰ ğ¸ ğ‘ ğ‘‹ realized ğ‘£ similarly value observe operation uses function graft marginalize variable ğ‘‹ turns ğ‘‹ realized node associated value ğ‘£ memory usage baudart et al proposed implementation delayed sampling initialized node pointer parent marginalized node pointer unique marginalized realized child realized node pointers parent children garbage collection node delayed sampling graph safely removed none program variables depend value assume existence garbage collection routine deallocates nodes graph reachable soon possible definition reachability given set root variables ğ‘Ÿ delayed sampling graph ğ‘” ğ‘‰ ğ¸ ğ‘ set reachable variables written reachable ğ‘” ğ‘Ÿ defined follows ğ‘… ğ‘‹ ğ‘Œ ğ‘‹ ğ‘Œ ğ¸ ğ‘ ğ‘‹ ğ‘Œ ğ‘‹ ğ¸ ğ‘ ğ‘‹ marginalized ğ‘ ğ‘Œ marginalized ğ‘ ğ‘Œ realized reachable ğ‘” ğ‘Ÿ ğ‘Œ ğ‘… ğ‘‹ ğ‘Œ ğ‘‹ ğ‘Ÿ ğ‘Œ ğ‘‰ ğ‘… denotes reflexive transitive closure relation ğ‘… consider graph figure reachable ğ‘” x x example figure reachable ğ‘” x x gray node nodes reachability core property used definition define means program run bounded memory graph expansion operation increases size graph assume introduces new nodes operations value observe marginalize realize nodes ğ‘” graph resulting application value observe graph ğ‘” ğ‘” ğ‘” structure initialized nodes marginalized realized marginalized nodes realized reachability relation graph implies value observe reduce number dependencies delayed sampling graph reachable ğ‘” ğ‘Ÿ reachable ğ‘” ğ‘Ÿ initialized marginalized chains two patterns yield unbounded memory consumption first possible keep adding nodes without realizing via observation sampling thus forming initialized chains initialized chain sequence initialized nodes holds pointer parent thereby expands number random variables reachable second possible nodes indirectly used realize one children marginalized nodes form marginalized chains marginalized chain sequence marginalized nodes holds pointer child thus expands number random variables reachable last node marginalized chain may realized proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin semantic properties section define conditions delayed sampling executes bounded memory define conditions properties executions execution sequence pairs state delayed sampling graph ğ‘ ğ‘› ğ‘”ğ‘› state value defined section execution defines sequence states graphs model argument infer goes inference step function infer ğ‘“ ğ‘š may operate multiple executions ğ‘“ see section however infer ğ‘“ executes bounded memory every execution ğ‘“ infer ğ‘“ always updates state mapping ğ‘“ states graphs distribution previous iteration thus state graph distribution next iteration must come execution ğ‘“ executions ğ‘“ states graphs distribution must bounded memory formalized details appendix based notion execution introduce two notions executions delayed sampling semantic properties necessary sufficient boundedmemory execution section present definition bounded memory directly corresponds delayed sampling runtime executes section present alternative definition terms dataflow properties delayed sampling operators unseparated paths properties section show formulations equivalent particular section shows correspondence property bound length initialized chains well correspondence unseparated paths property bound length marginalized chains bounded memory program executes bounded memory delayed sampling graph maintains bounded number reachable variables time formalize follows definition execution ğ‘ ğ‘› ğ‘”ğ‘› model ğ‘”ğ‘› ğ‘ ğ‘› ğ‘˜ ğ‘ ğ‘› definition states iteration size set reachable nodes delayed sampling graph may constant multiple number free random variables state consider runtime violate bounded memory trivial case program state intrinsically unbounded ğ‘ ğ‘› unbounded program would execute bounded memory inference algorithm even particle filter would require unbounded memory store program state definitions section present alternative definition bounded memory easier reason definition terms dataflow properties delayed sampling operations formalized dataflow properties augmenting delayed sampling operations tracing trace defined follows ğœ ğœ nil ğ‘‹ f ğ‘‹ ğ‘‹ f nil eval x obs ğ‘‹ proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams assume ğ‘£ ğ‘” ğœ let ğ‘‹ assume ğ‘£ ğ‘” ğ‘‹ ğ‘” ğœ ğ‘‹ f nil frv ğ‘£ ğ‘‹ ğ‘” ğœ ğ‘‹ f ğ‘‹ ğ‘‹ frv ğ‘£ conj ğ‘£ ğ‘‹ ğ‘” ğ‘‹ ğ‘” ğœ eval frv ğ‘£ ğ‘‹ f nil otherwise value ğ‘£ ğ‘” ğœ let ğ‘£ value ğ‘£ ğ‘” ğ‘£ ğ‘” ğœ eval frv ğ‘£ observe ğ‘‹ ğ‘£ ğ‘” ğœ observe ğ‘‹ ğ‘£ ğ‘” ğœ obs ğ‘‹ fig tracing semantics delayed sampling operators trace list primitive operations primitive one assumption written ğ‘‹ f ğ‘‹ ğ‘‹ assumed another random variable ğ‘‹ ğ‘‹ f nil assumed without parent evaluation using eval keyword refers evaluating set random variables x observation using obs keyword refers observing random variable ğ‘‹ define augmented semantics operates pair delayed sampling graph trace figure defines augmented versions assume value observe operations full semantics written defined replacing operators figure traced counterparts figure property property used enforce every variable introduced assume eventually consumed either directly passed value observe transitively passed assume introduces variable also definition variable ğ‘‹ trace ğœ following circumstances ğ‘‹ observed evaluated ğœ eval ğ‘‹ ğ‘‹ x obs ğ‘‹ ğ‘‹ never used ğ‘‹ f ğ‘‹ eval ğ‘‹ obs ğ‘‹ ğœ ğ‘‹ passed assume statement introduces another variable ğ‘‹ ğ‘‹ f ğ‘‹ ğœ ğ‘‹ ğ‘š unseparated paths property unseparated paths property states existence sequence variables assumed previous variable sequence observed evaluated definition unseparated paths unseparated path inğœ sequence ğ‘‹ğ‘› assumed ğ‘‹ğ‘– f ğ‘‹ğ‘– ğœ ğ‘‹ğ‘– directly observed evaluated ğœ contain eval obs operations reference ğ‘‹ğ‘– bounded memory present bounded memory property property states variables must eventually must uniform bound across iterations length unseparated path starting program state variable definition program execution ğ‘ ğ‘› ğ‘”ğ‘› ğœğ‘› exists ğ‘š every iteration ğ‘› every variable introduced ğ‘› ğ‘‹ ğ‘‹ f ğ‘‹ ğ‘‹ f nil ğœğ‘› exists ğ‘› ğ‘› ğ‘› ğ‘› ğ‘‹ ğœğ‘› exists ğ‘ ğ‘› random variable referenced ğ‘ ğ‘› starts unseparated path ğœğ‘› length proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin equivalence definitions section show equivalence definitions showing properties equivalent delayed sampling graph uniform bound bound holds across iterations length initialized marginalized chains defined section bounded memory infinite chains lemma delayed sampling graph constructed using assume observe value operations random variable starts either initialized chain marginalized chain initialized chain followed marginalized chain proof assume observe value operations make following modifications delayed sampling graph ğ‘” add independent marginalized node creates marginalized chain length zero attach new initialized node ğ‘‹ node ğ‘Œ conjugate distribution means ğ‘Œ either initialized marginalized thus creates either longer initialized chain initialized chain followed marginalized chain perform graft ensures every ancestor node marginalized single marginalized child every variable either becomes realized operation preserves structure previous graph increase length chains convert marginalized node realized node break chain theorem program iff uniform boundğ‘š length initialized chain uniform bound ğ‘ length marginalized chain proof assuming uniform bound number variables bounded ğ‘ according lemma number reachable nodes graph bounded ğ‘ ğ‘ ğ‘š conversely uniform bound exists every potential bounds ğ‘ ğ‘š exists iteration ğ‘› chains may exceed bound ğ‘› execution even number root variables bounded ğ‘ reachable variables may exceed ğ‘ ğ‘ ğ‘š bounded memory infinite chains theorem soundness program execution infinite chains exist delayed sampling graphs proof initialized chains must shorter ğ‘š ğ‘š property variable descendant subject observe value variable becomes marginalized descendant ğ‘š variables away definition marginalized chains must shorter ğ‘ ğ‘ unseparated path property ğ‘š property lemma every marginalized chain must start either root initialized chain starts root unseparated path property ensures path root end chain contain ğ‘ variables observed valued variables become realized become end chain starts initialized chain reasoning chain length ğ‘š previous iteration marginalized chain started root length ğ‘ giving overall length ğ‘ ğ‘š lemma exists variable program produces graph iteration initialized chain length proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams proof variable definition must start assume chain length ğ‘š nodes chain must initialized therefore form initialized chain length ğ‘š lemma every variable exists variable starts unseparated path length ğ‘ ğ‘ ğ‘š exists iteration marginalized chain length least ğ‘ ğ‘š proof note firstğ‘ variables unseparated path must either marginalized realized otherwise would ğ‘š initialized variables tail unseparated path initialized would violate soundness let ğ‘‹ variable starts unseparated path ğ‘‹ last marginalized realized variable unseparated path consider iteration ğ‘› ğ‘‹ first marginalized must true ğ‘‹ program state iteration ğ‘› state current iteration ğ‘› ğ‘› marginalized chain runs ğ‘‹ ğ‘‹ thus ğ‘› marginalized chain length ğ‘ ğ‘š theorem completeness program execution boundedmemory delayed sampling graph either unbounded initialized chains marginalized chains proof execution either fails property unseparated path property fails property apply lemma otherwise apply lemma theorem program execution proof apply theorems analysis section develop analysis check ğœ‡ğ¹ program executes bounded memory approach problem developing two independent analyses within shared analysis framework one analysis checks property program checks unseparated paths property together ensure program executes bounded memory section shared analysis framework abstracts execution program execution abstract operations abstract graph abstract graph abstracts dynamic state program delayed sampling graph implement analysis framework means type system programs satisfy unseparated paths properties given analysis respective instantiation abstract graph typing judgment Î³ g ğ‘’ ğ‘¡ g asserts context Î³ abstract graph g expression ğ‘’ accesses random variables denoted type ğ‘¡ yields new abstract graph g parameter ğ›¼ either mc denote analysis denote unseparated paths write Î³ ğ‘’ ğ‘¡ shorthand Î³ g ğ‘’ ğ‘¡ g ğ‘’ effect graph types contexts type ğ‘¡ captures random variables expression could refer well shape primitive data product function stream instance ğ‘¡ f ğ‘Ÿ stream ğ‘¡ ğ‘  bounded ğ‘  f stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin type primitive expression reference set denoted ğ‘Ÿ specifies random variables expression refers distinguish two types stream instances checking first stream ğ‘¡ ğ‘  ğ‘¡ type current state ğ‘  step function representation described later second bounded representing instances passed bounded memory analysis hide inner structure reference sets reference set ğœ‡ğ¹ expression denoted ğ‘Ÿ specifies random variables affected expression observed evaluated presence branches define ğ‘Ÿ pair sets lb ub lower bound lb contains random variables must affected upper bound ub random variables may affected example constant value ğœ‡ğ¹ reference set references random variables program variables x correspond random variables ğ‘‹ ğ‘Œ respectively expression gaussian x specifying distribution two parameters reference set ğ‘‹ ğ‘Œ ğ‘‹ ğ‘Œ meaning observing observe random variables ğ‘‹ contexts context Î³ ğ‘¥ ğ‘¡ maps variable ğ‘¥ type ğ‘¡ ğœ‡ğ¹ syntactic patterns ğ‘ may variables pairs use shorthand Î³ ğ‘ ğ‘¡ define types variables ğ‘ structural correspondence ğ‘¡ defined first rule also define judgment ğ‘ ğ‘¡ synthesizes deterministic type ğ‘¡ pattern Î³ ğ‘’ ğ‘¡ Î³ ğ‘’ ğ‘¡ ğ‘¥ abstract graphs abstract graph g abstraction delayed sampling graph tracks random variables consumed active paths random variables properties relevant semantic properties analysis ğ›¼ exists abstract graph type g set operations form interface figure specifically analysis define g pair sets con respectively represent variables introduced graph underapproximation variables consumed observation sampling figure unseparated paths analysis define g set sep separators containing consumed random variables partial path function ğ‘ mapping pair random variables upper bound length unseparated path figure operations abstract graph manipulate random variables graphs reference sets function assume returns new graph random variable ğ‘‹ distribution reference set ğ‘Ÿ added g observe returns graph ğ‘‹ observed value reference set ğ‘Ÿ value returns graph expression reference set ğ‘Ÿ evaluated join operator represents conservative choice two graphs graph operations figure assumemc ğ‘‹ ğ‘Ÿ g marks random variable ğ‘‹ introduced cases lower bound random variables input marked consumed join two states union introduced variables intersect consumed variables unseparated paths graph operations figure observeup valueup mark input variables separators assumeup set length path new variable ğ‘‹ zero parent ğ‘‹ğ‘ separator set length path variable ğ‘‹ğ‘– ğ‘‹ one length ğ‘‹ğ‘– ğ‘‹ğ‘ join two states intersect separators take maximum length results two path functions defined otherwise proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams assumeğ›¼ rv ğ‘Ÿ g g observeğ›¼ rv ğ‘Ÿ g g valueğ›¼ ğ‘Ÿ g g g g g fig abstract graph interface g f ğ‘–ğ‘› rv con rv assumemc ğ‘‹ ğ‘Ÿ g ğ‘‹ ğ‘Ÿ observemc ğ‘‹ ğ‘Ÿ g ğ‘Ÿ ğ‘‹ valuemc ğ‘Ÿ g ğ‘Ÿ fig abstract graph operations g f ğ‘ rv rv n sep rv assumeup ğ‘‹ ğ‘Ÿ g ğ‘ ğ‘ ğ‘‹ ğ‘‹ ğ‘ ğ‘‹ğ‘– ğ‘‹ ğ‘‹ğ‘– ğ‘‹ğ‘ ğ‘‹ğ‘ ğ‘Ÿ ğ‘‹ğ‘– rv ğ‘ ğ‘‹ ğ‘Œ ğ‘‹ ğ‘Œ otherwise observeup ğ‘‹ ğ‘Ÿ g ğ‘Ÿ ğ‘‹ valueup ğ‘Ÿ g ğ‘Ÿ ğ‘ ğ‘ max fig unseparated paths abstract graph operations typing rules figure present typing rules relevant analyzing probabilistic streams full definition appendix constants reference random variables sample introduces fresh random variable sampled argument adds graph observe introduces intermediate random variable first argument mechanism sample observes evaluation second argument operators scalar folding use ğœ‡ğ¹ operators ğ‘œğ‘ describe probability distributions operations scalars assume scalar return values auxiliary judgment folds products stream instances scalars taking unions variable sets ğ‘Ÿ ğ‘Ÿ lb ub lb ub ğ‘¡ lb ub stream ğ‘¡ ğ‘  lb ub bounded sequencing sequencing using follows standard typing rule let also threads output graph evaluating ğ‘’ evaluation ğ‘’ ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡ lb ub lb ub fig join operator types conditionals join evaluate condition check branches parallel join resulting reference set graphs join operator figure representing conservative union two types unions upper bounds intersects lower bounds disallow ifbranching functions stream instances proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin Î³ ğ‘ Î³ ğ‘£ ğ‘Ÿ ğ‘‹ fresh g Î³ g sample ğ‘£ ğ‘‹ ğ‘‹ assumeğ›¼ ğ‘‹ ğ‘Ÿ g Î³ g sample ğ‘‹ ğ‘‹ g Î³ Î³ g observe observeğ›¼ ğ‘‹ valueğ›¼ g Î³ ğ‘£ ğ‘¡ ğ‘¡ ğ‘Ÿ Î³ op ğ‘£ ğ‘Ÿ Î³ g ğ‘’ ğ‘¡ g Î³ ğ‘ ğ‘¡ g ğ‘’ ğ‘¡ g Î³ g let ğ‘ ğ‘’ ğ‘’ ğ‘¡ g Î³ ğ‘£ ğ‘Ÿ g valueğ›¼ ğ‘Ÿ g Î³ g Î³ g Î³ g ğ‘£ else Î³ ğ‘š ğ‘¡ ğ‘  Î³ init ğ‘š stream ğ‘¡ ğ‘  Î³ ğ‘¥ stream ğ‘¡ stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ Î³ ğ‘£ ğ‘¡in Î³ğ‘’ ğ‘state ğ‘¡ ğ‘in ğ‘¡in g ğ‘’ ğ‘¡ ğ‘¡out g Î³ g unfold ğ‘¥ ğ‘£ ğ‘¡out stream ğ‘¡ stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ g Î³ ğ‘š bounded Î³ ğ‘š bounded Î³ infer ğ‘š bounded Î³ ğ‘¥ bounded Î³ ğ‘£ ğ‘¡ ğ‘¡ Î³ unfold ğ‘¥ ğ‘£ bounded fig delayed sampling type system streams inference facilitate typing stream functions define following auxiliary judgment computes stream function type initial state syntactic fragment step function Î³ ğ‘’ ğ‘¡init ğ‘¡init Î³ stream init ğ‘’ step ğ‘state ğ‘in ğ‘’ ğ‘¡init stepfn ğ‘state ğ‘in Î³ ğ‘’ correspondingly define context Î³ ğ‘š ğ‘¡init stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ map stream function name ğ‘š initial state type step function instances created init expose type internal state step function unfold rule applies step function current state yielding output instance new state ensures argument ğ‘£ compatible type step function infer expression marks entry point new new delayed sampling graph premises typing rule infer success conditions analyses must hold regardless ğ›¼ judgment Î³ ğ‘š bounded states stream function ğ‘š unfolded arbitrary number iterations satisfying property ğ›¼ starting empty delayed sampling graph instances created infer possess newly instantiated delayed sampling graph internal state contains delayed sampling graph bookkeeping information inference algorithm thus state hidden exterior instance assigned opaque type bounded unfold bounded type requires input output purely deterministic success condition conclude stream function passes analysis variables introduced consumed program introduced variable may take several stream iterations consumed repeatedly execute analysis proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams consume variables succeed reach fixed point fail define iteration judgment Î³ ğ‘› ğ‘š ğ‘¡ g ğ›¼ either ğ‘šğ‘ ğ‘¢ğ‘ follows Î³ ğ‘š ğ‘¡ stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ ğ‘in ğ‘¡in Î³ğ‘’ ğ‘in ğ‘¡in ğ‘state ğ‘¡ ğ‘’ ğ‘¡out ğ‘¡ g Î³ ğ‘š ğ‘¡ g Î³ ğ‘š ğ‘¡ stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ Î³ ğ‘š ğ‘¡ g ğ‘in ğ‘¡in Î³ğ‘’ ğ‘in ğ‘¡in ğ‘state ğ‘¡ g ğ‘’ ğ‘¡out ğ‘¡ g Î³ ğ‘› ğ‘š ğ‘¡ g iteration judgment applies appropriate type rule step function returns result using abstract graph previous iteration context step function rule initial iteration uses empty abstract graph context represented analysis specialize judgment Î³ ğ‘› ğ‘š ğ‘¡ g define rule continues iterating reaches success condition success condition states every variable introduced kept program state must used bounded number time steps formalize following type rule Î³ ğ‘š ğ‘¡ g ğ‘¡ ğ‘™ğ‘ ğ‘¢ğ‘ Î³ ğ‘› ğ‘š ğ‘¡ g ub Î³ ğ‘š bounded alternatively evaluating one iteration consume variables reach fixed point return failure since every iteration either consume variable reach fixed point analysis guaranteed terminate unseparated paths success condition like analysis unseparated paths analysis iterative may need repeat number iterations specialize iteration judgment defined previous section Î³ ğ‘› ğ‘š ğ‘¡ g define pair empty map empty set define path ğ‘¡ g ğ‘¡ lb ub length longest path random variable ub variable conclude program passes unseparated path analysis length longest path converges finite number iterations Î³ ğ‘› ğ‘š ğ‘¡ g Î³ path ğ‘¡ g ğ‘¡ ğ‘š ğ‘¡ g path ğ‘¡ g path ğ‘¡ g Î³ ğ‘š bounded implementation rule repeatedly computes new abstract graph starting previous iteration output exits longest path length current iteration equal longest path path ğ‘¡ g size ğ‘¡ additional iterations function size determines given type ğ‘¡ many values base type contained size ğ‘Ÿ size size size extra iterations ensure path length stabilized analysis safely conclude bound length longest unseparated path path length check fails implementation keeps iterating bound reached upon reaching bound implementation outputs analysis failure note analysis may imprecise reject correct programs bound sufficiently high proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin example type derivation section presents example type derivation used analysis confirm program figure satisfies property particular confirm stream function kalman passes analysis using ğ‘’ shorthand body step function derive following success condition kalman Î³ kalman ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ Î³ kalman ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ Î³ kalman bounded second fourth premises follow immediately definitions set operations derivation first third premises follows Î³ kalman stepfn obs Î³ğ‘’ ğ‘’ obs Î³ğ‘’ obs ğ‘’ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ Î³ kalman ğ‘‹ ğ‘‹ ğ‘‹ ğ‘‹ second premise follows definitions derivation first premise follows Î³ğ‘’ Î³ stream init step obs ğ‘’ stepfn obs Î³ğ‘’ ğ‘’ premises follow immediately finally let Î³ context Î³ğ‘’ obs ğ‘¡ type derivation third premise follows Î³ sample gaussian ğ‘¡ ğ‘‹ Î³ x ğ‘¡ ğ‘‹ let observe gaussian x obs x x ğ‘¡ ğ‘¡ ğ‘‹ ğ‘‹ Î³ ğ‘’ ğ‘¡ ğ‘¡ ğ‘‹ ğ‘‹ first premise follows typing rule sample second premise follows typing rule let follows Î³ x ğ‘¡ ğ‘‹ observe gaussian x obs ğ‘‹ ğ‘‹ Î³ x ğ‘¡ ğ‘‹ ğ‘‹ x x ğ‘¡ ğ‘¡ ğ‘‹ ğ‘‹ Î³ x ğ‘¡ ğ‘‹ let observe gaussian x obs x x ğ‘¡ ğ‘¡ ğ‘‹ ğ‘‹ first premise follows rule observe second rule pairs soundness outline show type system sound give overview approach details appendix entailment relations appendix establish several entailment relations relate semantic objects counterparts relations parameterized ğ›¼ either ğ‘šğ‘ relation ğ‘¢ğ‘ unseparated path relation write ğ‘£ ğ‘¡ mean value entails type write ğ›¾ Î³ mean environment entails type context write ğ‘£ ğ‘” ğœ ğ‘¡ g mean value traced graph see section definition traced graph entail type abstract graph write ğ›¾ ğ‘” ğœ Î³ g mean environment traced graph entail type context abstract graph proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams soundness following theorems establish soundness type system first theorem states type system soundly ascribes types values soundly updates abstract delayed sampling graph theorem unseparated path soundness ğ›¾ ğ‘” ğœ Î³ g Î³ g ğ‘’ ğ‘¡ g ğ‘’ ğ›¾ ğ‘” ğœ ğ‘¤ ğ‘£ ğ‘” ğœ ğ‘£ ğ‘” ğœ ğ‘¡ g next type system soundly ensures stream function maintains bounded memory theorem analysis soundness ğ›¾ Î³ Î³ ğ‘š bounded bounded prove theorems appendix implementation implemented analysis framework unseparated paths analyses ocaml implementation takes input ğœ‡ğ¹ program outputs either true false analysis also accepts parameter iteration bound unseparated paths analysis implementation goes beyond type system laid paper supporting functions probabilistic effects well interfaces list array operations ğœ‡ğ¹ programs compiled ocaml executed using probzelus delayed sampling runtime code available https evaluation evaluate ability analysis accept ğœ‡ğ¹ programs execute bounded memory executed several benchmarks reflective inference tasks research questions used implementation answer two research questions realistic probabilistic programs type system precisely verify properties required boundedmemory execution small iteration bound sufficient unseparated paths analysis methodology executed analysis example programs baudart et al originally written probzelus probabilistic programming language featuring probabilistic data streams delayed sampling manually translated ğœ‡ğ¹ reflect range realistic control problems different memory usage characteristics unseparated paths analysis set iteration count bound sufficient programs compared outputs analysis manual logical reasoning ability following programs execute bounded memory provide source code benchmarks appendix kalman simplified core model figure models agent estimates position noisy observations applying delayed sampling model equivalent kalman filter kalman particle returns exact solution kalman example figure reference output first iteration gaussian random walk simplification kalman observe true position effectively expressing gaussian random walk robot full example figure includes kalman core model well main stream function invokes controller based inferred position coin models agent estimates bias coin model chooses probability coin uniform distribution thereafter chooses observations flipping coin probability applying delayed sampling model equivalent exact inference conjugate model fink particle returns exact solution estimates mean variance gaussian distribution proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin table bounded memory analysis benchmark programs unsep paths bounded mem output actual output actual output actual kalman kalman gaussian random walk robot coin outlier mtt slam outlier adapted section minka models situation kalman benchmark sensor occasionally produce invalid readings model chooses probability invalid reading beta distribution invalid readings occur approximately time time step previously chosen probability model chooses observation either invalid distribution gaussian kalman model applying delayed sampling model equivalent particle filter doucet et al combining exact inference approximate particle filtering mtt tracker adapted murray schÃ¶n involves variable number targets motion models produce measurements position time step model randomly introduces targets poisson process deletes fixed probability step slam simultaneous localization mapping adapted doucet et al models agent estimates position grid also map environment associating cell black white robot uses inference decide next move motion commands noisy probability wheels may slip observations may also incorrectly reported analysis results table displays analysis outputs benchmark programs analysis output column result implementation actual column ground truth whether program satisfies semantic property according manual analysis bounded memory columns logical conjunction two semantic properties first six benchmarks analysis implementation yielded answer manual analysis whether program satisfies semantic properties thus permits execution bounded memory every case output implementation sound respect ground truth furthermore analyses converged within iterations kalman program every variable ğ‘š starts unseparated path length thus execute bounded memory kalman program every variable ğ‘š however analysis detects unseparated paths starting initial value x grow without bound fail converge iterations program execute bounded memory proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams gaussian random walk every unseparated path length however analysis detects noğ‘š variable variable ever observed evaluated program execute bounded memory robot every variable every separated path length analysis succeeds indicates program execute bounded memory coin every variable every unseparated path length analysis succeeds indicates program execute bounded memory every variable every separated path length analysis succeeds indicates program execute bounded memory outlier every unseparated path length however event samples indefinitely considered outliers observation occur causes variable xt consumed program execute bounded memory mtt every unseparated path length however random variables guaranteed consumed final observe operation executed based dynamic condition lengths two list data structures condition guaranteed met program execute bounded memory slam every unseparated path length analysis concludes environment map array consumed model makes random choices guaranteed cover entries map however manual examination shows entry map never covered random choice virtue never used thus analysis soundly imprecisely determines condition fails discussion outlier mtt benchmarks even though fail semantic property therefore guaranteed execute bounded memory almost certainly execute bounded memory example outlier way memory consumption model increase indefinitely particular random choice always takes one branch event general semantic properties analysis implementation reason absence program execution yields unbounded memory however practice almost certain execution may also useful property programs general analysis provide sound guarantee program executes bounded memory however saw slam always precise enough rejects program program must unbounded memory consumption example possible deliberately construct pathological programs requiring large number iterations unseparated paths analysis remaining limitations precision include common static analysis challenges path sensitivity due statements aliasing due complex data structures facing conditional branches analysis takes conservative approach may utilize statically available knowledge specifically determine certain branches taken entire input stream certain program paths valid multiple sequential branches analysis also accurately track variables stored complex data structures meaning mark consumed discuss challenges greater detail provide specific examples appendix related work resource analysis probabilistic programs static resource analysis capable automatically determining upper bounds resources time memory required execute probabilistic program ngo et al proposed approach determine expected memory usage probabilistic program bounds number loop iterations executed proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin number explicit memory allocation ticks encountered analysis hand extends static reasoning inherent memory usage inference algorithm reactive probabilistic programming gupta et al first introduced idea reactive probabilistic programming extend concurrent constraint language random variables contrast language based synchronous dataflow model focus resource analysis baudart et al developed probzelus reactive probabilistic programming language operates streams data supports inference stream iteration uses implementation delayed sampling designed provide inference class reactive probabilistic programs however probzelus provides static guarantee inference work define language used target compilation probzelus identify semantic conditions static analysis makes possible provide static guarantee delayed sampling inference mechanism delayed sampling probabilistic programs introduced murray et al implemented anglican birch programming languages neither supports inference streams delayed sampling form sequential monte carlo liu chen execute bounded memory automates construction particle filters doucet et al particularly efficient variant smc comparison markov chain monte carlo techniques generally execute bounded memory maintain sample full history program execution size grow without bound probabilistic stream variational inference extensions make amenable streaming broderick et al aware probabilistic programming system makes use programming languages hakaru narayanan et al use static program transformations accomplish goal deferring approximate inference much possible unclear transformations apply streaming context dynamic information necessary reflect evolution underlying model many iterations conclusion probabilistic programming augmented constructs perform inference unbounded iterations streams data underlying programming model delayed sampling combines benefits exact inference flexibility sampling paper introduce unseparated path semantic properties show delayed sampling execute bounded memory reactive probabilistic programs present sound static analysis verifies two properties type system abstract delayed sampling graph best knowledge work first develop resource analysis probabilistic program relation probabilistic programming system underlying inference algorithm hope work enable automatic inference mechanisms whose performance better understood model developers probabilistic programming languages acknowledgments would like thank cambridge yang alex renda jesse michel ben sherman provided feedback drafts paper work supported part watson ai lab office naval research onr opinions findings conclusions recommendations expressed material authors necessarily reflect views office naval research proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams references eric atkinson cambridge yang michael carbin verifying handcoded probabilistic inference procedures arxiv guillaume baudart louis mandel eric atkinson benjamin sherman marc pouzet michael carbin reactive probabilistic programming conference programming language design implementation leonard baum ted petrie statistical inference probabilistic functions finite state markov chains annals mathematical statistics atilim gÃ¼neÅŸ baydin lei shao wahid bhimji lukas heinrich lawrence meadows jialin liu andreas munk saeid naderiparizi bradley gilles louppe mingfei xiaohui zhao philip torr victor lee kyle cranmer prabhat frank wood etalumis bringing probabilistic programming scientific simulators scale proceedings international conference high performance computing networking storage analysis sc eli bingham jonathan chen martin jankowiak fritz obermeyer neeraj pradhan theofanis karaletsos rohit singh paul szerlip paul horsfall noah goodman pyro deep universal probabilistic programming journal machine learning research tamara broderick nicholas boyd andre wibisono ashia wilson michael jordan streaming variational bayes international conference neural information processing systems colaÃ§o bruno pagano marc pouzet scade formal language embedded critical software development invited paper tase ieee computer society marco f feras saad alexander k lew vikash k mansinghka gen probabilistic programming system programmable inference conference programming language design implementation pierre del moral arnaud doucet ajay jasra sequential monte carlo samplers royal statistical society series b statistical methodology arnaud doucet nando de freitas kevin murphy stuart russell particle filtering dynamic bayesian networks uai arnaud doucet nando de freitas kevin murphy stuart russell particle filtering dynamic bayesian networks conference uncertainty artificial intelligence daniel fink compendium conjugate priors hong ge kai xu zoubin ghahramani turing composable inference probabilistic programming international conference artificial intelligence statistics andrew gelman daniel lee jiqiang guo stan probabilistic programming language bayesian inference optimization journal educational behavioral statistics noah goodman vikash mansinghka daniel roy keith bonawitz joshua tenenbaum church language generative models conference uncertainty artificial intelligence noah goodman andreas stuhlmÃ¼ller design implementation probabilistic programming languages http accessed andrew gordon thore graepel nicolas rolland claudio russo johannes borgstrom john guiver tabular probabilistic programming language symposium principles programming languages vineet gupta radha jagadeesan vijay saraswat probabilistic concurrent constraint programming concur lecture notes computer science vol springer daniel huang tristan greg morisett compiling markov chain monte carlo algorithms probabilistic modeling conference programming language design implementation kalman new approach linear filtering prediction problems journal basic engineering daphne koller nir friedman probabilistic graphical models principles techniques mit press jun liu rong chen sequential monte carlo methods dynamic systems amer statist assoc daniel lundÃ©n delayed sampling probabilistic programming language anglican master thesis kth royal institute technology vikash mansingkha ulrich schaechtle shivam handa alexey radul yutian chen martin rinard probabilistic programming programmable inference conference programming language design implementation george mealy method synthesizing sequential circuits bell system technical journal brian milch bhaskara marthi stuart russell david sontag daniel ong andrey kolobov blog probabilistic models unknown objects statistical relational learning thomas minka expectation propagation approximate bayesian inference conference uncertainty artificial intelligence proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin lawrence murray daniel lundÃ©n jan kudlicka david broman thomas schÃ¶n delayed sampling automatic probabilistic programs international conference artificial intelligence statistics lawrence murray thomas schÃ¶n automated learning probabilistic programming language birch annual reviews control praveen narayanan jacques carette wren romano robert zinkov probabilistic inference program transformation hakaru system description international symposium functional logic programming van chan ngo quentin carbonneaux jan hoffmann bounded expectations resource analysis probabilistic programs conference programming language design implementation aditya nori sherjil ozair sriram rajamani deepak vijaykeerthy efficient synthesis probabilistic programs conference programming language design implementation avi pfeffer figaro probabilistic programming language vol eduardo sontag mathematical control theory deterministic finite dimensional systems vol springer science business media sam staton commutative semantics probabilistic programming european symposium programming dustin tran matthew hoffman rif saurous eugene brevdo kevin murphy david blei deep probabilistic programming international conference learning representations proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams ideal semantics section present complete semantics deterministic part ğœ‡ğ¹ figure ideal semantics probabilistic part figure probabilistic semantics figure semantics similar one presented staton given environment ğ›¾ expression interpreted measure ğ‘’ ğ›¾ Ïƒğ· function associates positive number measurable set ğ‘ˆ Ïƒğ· Ïƒğ· denotes domain expression ğ· set measurable sets possible values sample ğ‘£ returns distribution observe weights execution paths using likelihood observation distribution distribution ğœ‡ note ğœ‡pdf probability density function local definitions interpreted integration use dirac delta measure interpret deterministic expressions b core types ğœ‡ğ¹ section describes type system ğœ‡ğ¹ programs programs consider work must type check according system type system ensures expression ğ‘’ given probabilistic typing judgment Î³ ğ‘’ ğ‘‡ means ğ‘’ evaluated using probabilistic semantics ğ‘’ rather deterministic semantics type ğ‘‡ measurable space include nonmeasurable objects functions type system also prohibits nested inference types ğœ‡ğ¹ unit booleans reals functions pairs well probability distributions deterministic probabilistic stream functions stream instances ğ‘‡ unit bool real ğ‘‡ ğ‘‡ ğ‘‡ distr ğ‘‡ dstreamfn ğ‘‡ ğ‘‡ dstream ğ‘‡ ğ‘‡ pstreamfn ğ‘‡ ğ‘‡ pstream ğ‘‡ ğ‘‡ subset types may act support probability distributions denoted judgment measurable ğ‘‡ exclude function stream types measurable unit measurable bool measurable real measurable measurable measurable measurable ğ‘‡ measurable distr ğ‘‡ present full type system ğœ‡ğ¹ figures c definition graft section review definition graft murray et al preliminaries definition makes use alternative type marginalized node maintains marginal distribution well conditional distribution relates marginalized node unique marginalized child use notation marginalized ğœ‡marg ğœ‡cond refer marginalized node marginal distribution ğœ‡marg conditional distribution ğœ‡cond use notation ğ‘  marginalized mean node state ğ‘  marginalized node type two types marginalized nodes differ distributions store reachability memory consumption properties murray et al defines invariants delayed sampling runtimes namely specifies delayed sampling maintains nodes delayed sampling graph one proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin ğ‘¥ ğ›¾ ğ‘¥ ğ‘“ fun ğ‘ ğ›¾ ğ‘“ ğœ†ğ‘£ let ğ‘š stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ ğ‘š stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ ğ‘ ğ›¾ ğ‘¥ ğ‘£ op ğ‘£ ğ›¾ ğ‘“ ğ‘ let ğ‘£ ğ‘£ else else ğ‘š let stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ let ğ‘ init ğ‘ init ğœ† ğ‘  ğ‘£ ğ‘’ deterministic ğ‘š let stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ let ğ‘ init ğ‘ init ğœ† ğ‘  ğ‘£ ğ‘’ ğ›¾ ğ‘’ probabilistic ğ‘¥ ğ‘£ let ğ‘£state ğ‘“ let ğ‘£output state ğ‘“ ğ‘£state ğ‘£output ğ‘£ state ğ‘“ ğ‘š let stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ let ğ‘ init ğ›¿ğ‘ init infer ğœ† ğ‘  ğ‘£ ğ‘’ ğ›¾ infer ğ‘“ ğœ† ğœ ğ‘£ let ğœ‡ ğœ†ğ‘ˆ ğ‘† ğœ ğ‘‘ğ‘  ğ‘“ ğ‘  ğ‘£ ğ‘ˆ let ğœˆ ğœ†ğ‘ˆ ğœ‡ ğ‘ˆ ğœˆ ğœˆ fig deterministic semantics ğœ‡ğ¹ parent marginalized nodes graph one marginalized realized child following definitions use notation parent ğ‘‹ ğ¸ mean function returns unique parent ğ‘‹ edge set ğ¸ also use notation child ğ‘‹ ğ¸ mean function returns unique realized marginalized child marginalized node ğ‘‹ edge set definitions define graft function follows called initialized node graft recursively marginalizes every initialized ancestor given node means performs integration incorporate parent information distributions node initialized chain called marginalized node graft calls prune function proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams ğ‘£ ğ›¾ ğœ†ğ‘ˆ ğ‘ˆ op ğ‘£ ğ›¾ ğœ†ğ‘ˆ ğ›¿op ğ‘ˆ ğ‘“ ğ‘£ ğ›¾ ğœ†ğ‘ˆ ğ›¿ğ›¾ ğ‘“ ğ‘ˆ let ğ‘ ğ›¾ ğœ†ğ‘ˆ ğ‘‡ ğ›¾ ğ‘‘ğ‘¢ ğ‘ˆ ğ‘£ else ğ›¾ ğœ†ğ‘ˆ ğ›¾ ğ‘ˆ else ğ›¾ ğ‘ˆ unfold ğ‘¥ ğ‘£ ğ›¾ ğœ†ğ‘ˆ let ğ‘£state ğ‘“ let ğœ‡ ğ‘“ ğ‘£state ğœ‡ ğ‘‘ğ‘£output state ğ›¿ ğ‘£output ğ‘£ state ğ‘“ ğ‘ˆ sample ğ‘£ ğ›¾ ğœ†ğ‘ˆ ğ‘ˆ observe ğ›¾ ğœ†ğ‘ˆ let ğœ‡ ğœ‡pdf ğ›¿ ğ‘ˆ fig probabilistic semantics ğœ‡ğ¹ Î³ ğ‘’ ğ‘‡ Î³ val ğ‘ ğ‘’ Î³ ğ‘ ğ‘‡ Î³ ğ‘ ğ‘‡ ğ‘’ ğ‘‡ Î³ val ğ‘“ fun ğ‘ ğ‘’ Î³ ğ‘ ğ‘‡ ğ‘‡ Î³ Î³ Î³ Î³ Î³ Î³ Î³ ğ‘’init ğ‘‡state Î³ ğ‘state ğ‘input ğ‘‡state ğ‘’step ğ‘‡state Î³ val ğ‘š stream init ğ‘’init step ğ‘state ğ‘input ğ‘’step Î³ ğ‘š dstreamfn ğ‘‡input ğ‘‡out Î³ ğ‘’init ğ‘‡state Î³ ğ‘state ğ‘input ğ‘‡state ğ‘’step ğ‘‡state Î³ val ğ‘š stream init ğ‘’init step ğ‘state ğ‘input ğ‘’step Î³ ğ‘š pstreamfn ğ‘‡input ğ‘‡out fig typing rules programs ğœ‡ğ¹ judgment Î³ ğ‘‘ Î³ means ğœ‡ğ¹ declaration ğ‘‘ typed typing context Î³ produces typing context Î³ graft ğ‘‹ ğ‘” let ğ‘‰ ğ¸ ğ‘ ğ‘” ğ‘ ğ‘‹ initialized ğœ‡ let ğ‘‹par parent ğ‘‹ ğ¸ let ğœ‡prior ğ‘ ğ‘‹par marginalized ğœ‡par ğ‘ ğ‘‹par initialized ğœ‡par let ğ‘‰ graft ğ‘‹par ğ‘” let marginalized ğœ‡par ğ‘ ğ‘‹par ğœ‡par ğ‘‰ ğ‘‹par marginalized ğœ‡par ğœ‡ else ğ‘ ğ‘‹par realized ğ‘£ ğ›¿ ğ‘£ ğ‘‰ ğ¸ ğ‘‹ ğ‘‹par ğ‘ let ğœ‡ ğ‘‰ ğœ‡ dğœ‡prior ğ‘‰ ğ‘‹ marginalized ğœ‡ else ğ‘ ğ‘‹ marginalized ğœ‡ ğœ‡child prune ğ‘‹ ğ‘” else ğ‘” proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin Î³ unit ğ‘ true false Î³ ğ‘ bool ğ‘ r Î³ ğ‘ real Î³ Î³ Î³ Î³ ğ‘’ ğ‘‡ Î³ ğ‘’ ğ‘‡ Î³ ğ‘¥ ğ‘‡ ğ‘¥ ğ‘‡ Î³ ğ‘’ ğ‘‡ Î³ ğ‘“ ğ‘‡ ğ‘‡ Î³ ğ‘“ ğ‘’ ğ‘‡ Î³ bool Î³ ğ‘‡ Î³ ğ‘‡ Î³ else ğ‘‡ Î³ Î³ ğ‘ Î³ let ğ‘ Î³ ğ‘š dstreamfn ğ‘‡input ğ‘‡out Î³ init ğ‘š dstream ğ‘‡input ğ‘‡out Î³ ğ‘š pstreamfn ğ‘‡input ğ‘‡out Î³ infer ğ‘š pstream ğ‘‡input ğ‘‡out Î³ dstream ğ‘‡input ğ‘‡out Î³ ğ‘‡input Î³ unfold ğ‘‡out dstream ğ‘‡input ğ‘‡out Î³ pstream ğ‘‡input ğ‘‡out Î³ ğ‘‡input Î³ unfold distr ğ‘‡out pstream ğ‘‡input ğ‘‡out Î³ ğ‘’ ğ‘‡ measurable ğ‘‡ Î³ ğ‘’ ğ‘‡ Î³ ğ‘’ distr ğ‘‡ Î³ sample ğ‘’ ğ‘‡ Î³ distr ğ‘‡ Î³ ğ‘‡ Î³ observe unit fig deterministic probabilistic type systems ğœ‡ğ¹ typing judgment Î³ ğ‘’ ğ‘‡ means ğœ‡ğ¹ expression ğ‘’ context Î³ deterministic type ğ‘‡ judgment Î³ ğ‘’ ğ‘‡ means ğœ‡ğ¹ expression ğ‘’ context Î³ probabilistic type ğ‘‡ judgment Î³ ğ‘’ ğ‘‡ stands either deterministic probabilistic judgment ğ‘˜ instantiated ğ‘‘ğ‘’ğ‘¡ ğ‘ğ‘Ÿğ‘œğ‘ rules state sample observe used inside body probabilistic stream define prune function follows called marginalized node marginalized realized child function first recursively prunes child child marginalized node marginalized samples value node conditions current node child taking value child node realized function proceeds immediately condition current node child node value either case conditioning proceeds follows prune function first extracts probability density functions relevant measures using pdf function follows bayes rule multiplying prior conditional density functions normalizing result normalize function finally updates marginal distribution given node removes edge connecting node child proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams prune ğ‘‹ ğ‘” let ğ‘‰ ğ¸ ğ‘ ğ‘” ğ‘ ğ‘‹ marginalized ğœ‡ğ‘‹ ğœ‡ let ğ‘‹child child ğ‘‹ ğ¸ let ğ‘” prune ğ‘‹child ğ‘” ğ‘ ğ‘‹child marginalized ğœ‡child let ğ‘£ ğ‘‰ value ğ‘‹child let ğ‘ğ‘‹ ğ‘child pdf ğœ‡ğ‘‹ pdf ğœ‡ let ğœ‡ ğ‘‹ normalize ğ‘¥ ğ‘child let ğ‘ ğ‘ ğ‘‹child realized ğ‘£ ğ‘‹ marginalized ğœ‡ ğ‘‹ ğ‘‰ ğ‘‹ ğ‘‹child else ğ‘ ğ‘‹child realized ğ‘£ let ğ‘£ ğ‘‰ ğ‘” let ğ‘ğ‘‹ ğ‘child pdf ğœ‡ğ‘‹ pdf ğœ‡ let ğœ‡ ğ‘‹ normalize ğ‘¥ ğ‘child let ğ‘ ğ‘ ğ‘‹ marginalized ğœ‡ ğ‘‹ ğ‘‰ ğ‘‹child ğ‘‹ else ğ‘” else ğ‘” proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin complete analysis type system following complete definition typing judgment Î³ g ğ‘’ ğ‘¡ g describing types abstract graph transitions expressions Î³ ğ‘ Î³ ğ‘¥ ğ‘¡ ğ‘¥ ğ‘¡ Î³ ğ‘š ğ‘¡init stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ ğ‘š ğ‘¡init stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ Î³ ğ‘£ ğ‘Ÿ ğ‘‹ fresh g Î³ g sample ğ‘£ ğ‘‹ ğ‘‹ assumeğ›¼ ğ‘‹ ğ‘Ÿ g Î³ g sample ğ‘‹ ğ‘‹ g Î³ Î³ g observe observeğ›¼ ğ‘‹ valueğ›¼ g Î³ ğ‘£ ğ‘¡ ğ‘¡ ğ‘Ÿ Î³ op ğ‘£ ğ‘Ÿ Î³ g ğ‘’ ğ‘¡ g Î³ ğ‘ ğ‘¡ g ğ‘’ ğ‘¡ g Î³ g let ğ‘ ğ‘’ ğ‘’ ğ‘¡ g Î³ Î³ Î³ Î³ ğ‘£ ğ‘Ÿ g valueğ›¼ ğ‘Ÿ g Î³ g Î³ g Î³ g ğ‘£ else ğ‘ ğ‘¡ Î³ ğ‘ ğ‘¡ ğ‘’ ğ‘¡ Î³ fun ğ‘ ğ‘’ ğ‘¡ ğ‘¡ Î³ ğ‘“ ğ‘¡ ğ‘¡ Î³ ğ‘£ ğ‘¡ Î³ ğ‘“ ğ‘£ ğ‘¡ Î³ ğ‘š ğ‘¡ ğ‘  Î³ init ğ‘š stream ğ‘¡ ğ‘  Î³ ğ‘š bounded Î³ ğ‘š bounded Î³ infer ğ‘š bounded Î³ ğ‘¥ stream ğ‘¡ stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ Î³ ğ‘£ ğ‘¡in Î³ğ‘’ ğ‘state ğ‘¡ ğ‘in ğ‘¡in g ğ‘’ ğ‘¡ ğ‘¡out g Î³ g unfold ğ‘¥ ğ‘£ ğ‘¡out stream ğ‘¡ stepfn ğ‘state ğ‘in Î³ğ‘’ ğ‘’ g Î³ ğ‘¥ bounded Î³ ğ‘£ ğ‘¡ ğ‘¡ Î³ unfold ğ‘¥ ğ‘£ bounded ğœ‡ğ¹ programs consist series value function stream function declarations thus also define judgment Î³ ğ‘‘ program states ğœ‡ğ¹ program ğ‘‘ contains declarations proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams judgment defined follows Î³ ğœ– program Î³ g ğ‘’ ğ‘¡ g Î³ ğ‘ ğ‘¡ ğ‘‘ program Î³ val ğ‘ ğ‘’ ğ‘‘ program Î³ g fun ğ‘ ğ‘’ ğ‘¡ g Î³ ğ‘“ ğ‘¡ ğ‘‘ program Î³ val ğ‘“ fun ğ‘ ğ‘’ ğ‘‘ program Î³ stream init ğ‘’ step ğ‘state ğ‘in ğ‘’ ğ‘¡init stepfn ğ‘state ğ‘in Î³ ğ‘’ Î³ ğ‘š ğ‘¡init stepfn ğ‘state ğ‘in Î³ ğ‘’ ğ‘‘ program Î³ val ğ‘š stream init ğ‘’ step ğ‘state ğ‘in ğ‘’ ğ‘‘ program ğ‘‘ empty streams including main valid judgment holds trivially e soundness executions execution program constructs dynamically allocate memory sample observe add new node delayed sampling graph using assume operation two probabilistic constructs used model argument infer operator thus focus memory footprint infer transition function execution transition function infer infer comprises three steps see section draw set particles pairs state graph execute model particle extract distributions state outputs operation dynamically allocate memory second one delayed sampling graph altered iteration ğ‘› particle current pair state graph obtained succession application model transition function initial state empty graph step definition infer drop execution paths call sequence execution model following properties states boundedmemory execution possible infer function executes lemma execution sufficiency stream functions ğ‘š environments ğ›¾ let stream init ğ‘’init step ğ‘state ğ‘input ğ‘’ ğ›¾ let ğ‘ ğ‘š let ğ‘“ğ‘š ğœ† ğ‘  ğ‘£ ğ‘’ let ğ‘ ğ‘– ğ‘“ğ‘– ğ‘š say ğ‘“ğ‘– produces sequence distributions ğœ‡ğ‘› given input sequence ğ‘–ğ‘› ğ‘“ğ‘– ğœ‡ğ‘› ğ‘–ğ‘› ğœ”ğ‘› sequence output distributions ğœ”ğ‘› similarly say ğ‘“ğ‘š produces execution ğ‘”ğ‘› ğ‘ ğ‘› ğ‘“ğ‘š ğ‘ ğ‘› ğ‘–ğ‘› ğ‘”ğ‘› ğ‘œğ‘› ğ‘¤ğ‘› sequences outputs ğ‘œğ‘› weights ğ‘¤ğ‘› lemma states input sequences ğ‘–ğ‘› ğ‘“ğ‘– produces sequence ğœ‡ğ‘› ğ‘› ğ‘”ğ‘› ğ‘ ğ‘› support ğœ‡ğ‘› exists execution ğ‘” ğ‘› ğ‘› ğ‘” ğ‘› ğ‘”ğ‘› ğ‘  ğ‘› ğ‘ ğ‘› ğ‘“ğ‘š produces ğ‘” ğ‘› ğ‘› proof proceed induction ğ‘› ğ‘› distribution obtained execution ğ‘“ğ‘š particle initial state empty graph support obtained execution ğ‘“ğ‘š ğ‘› definition infer pair ğ‘”ğ‘› ğ‘ ğ‘› support distribution ğœ‡ğ‘› obtained application ğ‘“ğ‘š drawn distribution application induction hypothesis ğ‘”ğ‘– ğ‘ ğ‘– ğ‘› execution produced ğ‘“ğ‘š therefore ğ‘”ğ‘– ğ‘ ğ‘– also produced ğ‘“ğ‘š corollary executions ğ‘“ğ‘š input sequence ğ‘–ğ‘› execution ğ‘”ğ‘› ğ‘ ğ‘› ğ‘› every ğ‘”ğ‘› ğ‘ ğ‘› support ğœ‡ğ‘› ğ‘”ğ‘› ğ‘ ğ‘› bounded memory ğœ‡ğ‘› produced ğ‘“ğ‘– proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin type soundness section show type system sound first define relations referenced section prove soundness theorems stated section variable mappings delayed sampling type system use set fresh variable names label random variables type system delayed sampling execution may use different name conceptually random variable define association maps namespaces use notation â„“ refer function maps delayed sampling variable type system variable extension â„“ sets ğ‘‹Ë† â„“ ğ‘‹ ğ‘‹ ğ‘‹Ë† entailment establish means value entail type value entails type type accurately captures random variables value could refer well shape value whether value scalar pair stream function step function types include type contexts also establish means environment entail type context stream value entails bounded produces sequence states every delayed sampling graph bounded formalize follows given sequence inputs ğ‘–ğ‘› initial state say stream function ğ‘“ produces sequence state ğ‘ ğ‘› ğ‘– ğ‘“ ğ‘–ğ‘› ğ‘ ğ‘› ğ‘œğ‘› output sequence ğ‘œğ‘› say ğ‘  bounded every sequence delayed sampling graphs contained ğ‘  definition type entailment value ğ‘£ entails type ğ‘¡ written ğ‘£ â„“ ğ‘¡ following circumstances ğ‘ â„“ ub ğ‘‹ â„“ lb ub lb â„“ ğ‘‹ ub app op ğ‘£ â„“ lb ub lb frv ğ‘£ ub â„“ â„“ â„“ stream init ğ‘’init step ğ‘in ğ‘state ğ‘’state ğ›¾ğ‘’ â„“ ğ‘¡init stepfn ğ‘in ğ‘state Î³ğ‘’ ğ‘’state ğ‘’init â„“ ğ‘¡init â„“ Î³ğ‘’ ğ‘“ â„“ stream ğ‘¡init ğ‘† â„“ ğ‘¡init ğ‘“ â„“ ğ‘† ğ‘“ â„“ stepfn ğ‘in ğ‘state Î³ğ‘’ ğ‘’ ğ›¾ â„“ Î³ğ‘’ ğ‘“ ğœ† ğ‘  ğ‘£ ğ‘’ ğ›¾ â„“ Î³ ğ‘¡ ğ›¾ ğ‘¥ ğ‘£ ğ‘£ â„“ ğ‘¡ ğ‘“ bounded ğ‘“ produces ğ‘  ğ‘– ğ‘  bounded define version type entailment applies restricted set variables definition restricted type entailment value ğ‘£ entails type ğ‘¡ restricted variable set ğ‘‹Ë† written ğ‘£ â„“ ğ‘‹Ë† ğ‘¡ following circumstances ğ‘ â„“ ğ‘‹Ë† ub ğ‘‹ â„“ ğ‘‹Ë† lb ub ğ‘‹ ğ‘‹Ë† lb â„“ ğ‘‹ ub app op ğ‘£ â„“ ğ‘‹Ë† lb ub ğ‘‹ ğ‘‹Ë† lb frv ğ‘£ ub proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams rules values similar definition pass set ğ‘‹Ë† unchanged recursive definitions fold operation designed generate scalar type encapsulates free variables value disregarding shape lemma fold entailment ğ‘£ â„“ ğ‘¡ ğ‘¡ lb ub lb frv ğ‘£ ub traced graph entails abstract graph abstract graph soundly approximates variables used definition graph entailment traced graph ğ‘” ğœ entails abstract graph g written ğ‘” ğœ â„“ mc g every variable ğ‘‹ every â„“ ğ‘‹ used ğœ traced graph entails abstract graph path function soundly approximates unseparated paths traced graph separator set soundly approximates set variables observed valued definition unseparated path graph entailment graph ğ‘” ğœ entails abstract graph g written ğ‘” ğœ â„“ g every referenced ğœ â„“ â„“ least length unseparated path ğœ ğ‘‹ referenced ğœ â„“ ğ‘‹ true ğ‘‹ separator entailment section define entailment relations referenced section definitions defined terms relevant definitions section variable map â„“ existentially quantified ğ‘£ ğ‘¡ ğ‘£ â„“ ğ‘¡ ğ›¾ Î³ ğ›¾ â„“ Î³ ğ‘£ ğ‘” ğœ ğ‘¡ g ğ‘£ â„“ ğ‘¡ ğ‘” ğœ â„“ ğ›¼ g ğ›¾ ğ‘” ğœ Î³ g ğ›¾ â„“ Î³ ğ‘” ğœ â„“ ğ›¼ g extend definitions incorporate restricted variable set ğ‘‹Ë† ğ‘£ ğ‘‹Ë† ğ‘¡ ğ‘£ â„“ ğ‘‹Ë† ğ‘¡ ğ›¾ ğ‘‹Ë† Î³ ğ›¾ â„“ ğ‘‹Ë† Î³ ğ‘£ ğ‘” ğœ ğ‘‹Ë† ğ‘¡ g ğ‘£ â„“ ğ‘‹Ë† ğ‘¡ ğ‘” ğœ â„“ ğ›¼ g ğ›¾ ğ‘” ğœ ğ‘‹Ë† Î³ g ğ›¾ â„“ ğ‘‹Ë† Î³ ğ‘” ğœ â„“ ğ›¼ g soundness theorems type judgment sound abstracts property semantics according entailment relations special case theorem type soundness ğ›¾ ğ‘” ğœ Î³ g Î³ g ğ‘’ ğ‘¡ g ğ‘’ ğ›¾ ğ‘” ğœ ğ‘¤ ğ‘£ ğ‘” ğœ ğ‘£ ğ‘” ğœ ğ‘¡ g proof structural induction derivations proving soundness judgment producing bounded type requires strengthening theorem work partial traces meaning abstract graph applies tail end trace rather whole trace using notation mean trace appended formalize follows proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin lemma soundness partial traces ğ›¾ ğ‘” Î³ g Î³ g ğ‘’ ğ‘¡ g ğ‘’ ğ›¾ ğ‘” ğ‘¤ ğ‘£ ğ‘” ğœ ğœ ğœ ğ‘£ ğ‘” ğœ ğ‘¡ g proof structural induction derivations individual steps previous theorem except also use associativity type judgment sound abstracts unseparated path property semantics according entailment relations special case theorem unseparated path type soundness ğ›¾ ğ‘” ğœ Î³ g Î³ g ğ‘’ ğ‘¡ g ğ‘’ ğ›¾ ğ‘” ğœ ğ‘¤ ğ‘£ ğ‘” ğœ ğ‘£ ğ‘” ğœ ğ‘¡ g also strengthen theorem aid proving soundness bounded judgment lemma unseparated paths soundness partial traces ğ›¾ ğ‘” frv Î³ g Î³ g ğ‘’ ğ‘¡ g ğ‘’ ğ›¾ ğ‘” ğ‘¤ ğ‘£ ğ‘” ğœ ğœ ğœ ğ‘£ ğ‘” ğœ frv ğ‘¡ g proof structural induction derivations individual steps previous theorem except also use associativity theorem analysis soundness ğ›¾ Î³ Î³ ğ‘š bounded bounded proof first show execution stream function ğ‘š satisfying Î³ ğ‘š bounded satisfies semantic property show execution stream function ğ‘š satisfying Î³ ğ‘š bounded satisfies unseparated paths semantic property theorem lemma ğ‘š satisfies properties calling infer ğ‘š must bounded show execution stream functionğ‘š satisfying Î³ ğ‘š bounded satisfies semantic property show using definition let ğ‘”ğ‘– ğœğ‘– ğ‘–th step execution lemma g captures variables introduced time ğ‘– also lemma g captures variables guaranteed consumed ğ‘– ğ‘– ğ‘› thus variable introduced time step ğ‘– must either consumed within ğ‘› steps ğ‘› static bound must stored program state consumed variable future time steps ğ‘š ğ‘› times constant bound based number sample statements stream function stored program state never used therefore always unseparated paths proceed contradiction assume ğ‘ ğ‘– ğ‘”ğ‘– ğœğ‘– ğ‘– execution violates unseparated paths semantic property time step ğ‘— execution must add variable delayed sampling graph way increases unseparated path starting variable graph b store variable starting increased path otherwise execution would easily satisfy property according lemma must iteration abstract graph also variable starting increased path reference ğ‘Ÿ contained type ğ‘¡ references variable letting ğ‘…Ë† set possible references ğ‘Ÿ pidgeonhole principle ğ‘˜ size ğ‘¡ size ğ‘¡ longest path abstract graph starting variable referenced element ğ‘…Ë† must increased least similarly ğ‘› path ğ‘¡ g instances pattern longest path abstract graph starting variable referenced ğ‘…Ë† must increased least path g ğ‘¡ thus longest graph starting state variable contradicts termination condition path ğ‘¡ g path ğ‘¡ g equality size ğ‘¡ size ğ‘¡ enforced type rules figure appendix b proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams f benchmarks benchmarks followed main stream serves entry point program val main stream init infer f step f args unfold f args kalman val f stream init step obs let x sample gaussian let observe gaussian x obs x x kalman val kalman stream init true step first obs let first let sample gaussian else let x sample gaussian let observe gaussian x obs x false x gaussian random walk val f stream init true step first x let x first sample gaussian else sample gaussian x x false x coin val f stream init true step first xt yobs let xt first sample beta else xt let observe bernoulli xt yobs xt false xt proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin outlier val f stream init true step first xt yobs let xt first sample gaussian sample beta else sample gaussian xt let sample bernoulli let observe gaussian yobs else observe gaussian xt yobs xt false xt mtt val f stream init true step first inp cmd let let fun eval sample bernoulli let sample poisson let fun sample bernoulli let let fun tr sample bernoulli tr let obs fun tr bernoulli tr let sub inp obs let observe poisson let clutter fun bernoulli tr let sample shuffle obs clutter let lt fun var value observe gaussian var value inp else false slam val f stream init true step first x map obs cmd let map first fun sample bernoulli else map let sample bernoulli proc acm program vol oopsla article publication date october statically delayed sampling probabilistic streams let x first else x else plus x cmd let map x let observe bernoulli ite obs x map false x map g precision limitations precision analysis limited path complex sensitivity two common challenges static analysis analysis overly conservative facing conditional branches example following snippet let x sample bernoulli let sample gaussian let x observe gaussian else let x else observe gaussian according analysis consumed branch separately conservatively judged consume even though path unobserved sophisticated analysis reasons actual values affected variables would precise similarly analysis imprecise presence complex data tuples consider following snippet let x sample gaussian let sample gaussian let b sample bernoulli gaussian x gaussian else gaussian gaussian x let observe let observe b x like previous example x considered consumed even though path observe analysis determine b may reference x neither alone must knowledge b taken pair lost stored tuple case kind alias shape analysis might recover relationship fields tuple without executing multiple iterations analysis would occasionally conservative due requiring variables used end current iteration step function consider stream init step obs let observe gaussian obs let x sample gaussian x x proc acm program vol oopsla article publication date october eric atkinson guillaume baudart louis mandel charles yuan michael carbin example every sample eventually consumed subsequent iteration step function analysis considered one iteration would reject example allow introduced variables consumed multiple iterations allows example pass analysis examples require significant number iterations unseparated paths analysis converge however analysis may fail detect convergence programs many variables iteration bound parameter low following program requires four iterations stream init step obs let x sample gaussian let observe gaussian x x program longest unseparated path increases four iterations variables start dropped state maximum length converges suggest parameter set comfortably larger number variables statements program avoid issue since iteration fast run cause performance degradation finally analysis could incorporate functions though would hard analyze statically storage chains closures built many iterations could violate bound memory usage proc acm program vol oopsla article publication date october
differentiable programming julia frank schÃ¤fer department physics university basel switzerland mohamed tarek usa unsw canberra australia mohamed lyndon white invenia labs cambridge uk chris rackauckas massachusetts institute technology usa julia computing usa usa crackauc abstract single automatic differentiation ad system optimal choice problems means informed selection ad system combinations variable greatly impact performance julia programming language major ad systems target input thus theory compose hitherto switching ad packages julia language required familiarize api respective packages furthermore implementing new usable ad package required ad package developers write boilerplate code define convenience api functions response issues present automatized generation extensive unified api ad package splitting complexity ad users ad developers ad package developers need implement one two primitive definitions support various utilities ad users like jacobians hessians lazy product operators native primitives pullbacks pushforwards thus removing tedious far inevitable boilerplate code enabling easy switching composing ad implementations introduction differentiable programming ability differentiate general computer program structures enabled efficient combination existing packages scientific computation machine learning raissi et rackauckas et de avila et machine learning approaches flexible require large amount data incorporating scientific knowledge structure problem via reduces amount data needed allows learning task simplified example focusing learning parts model missing rackauckas et dandekar et already many examples differentiable frameworks provided performance accuracy advantages approaches machine learning including limited alquraishi ingraham et fluid dynamics schenck fox robotics schenck fox quantum control schÃ¤fer et commonly realized automatic differentiation ad family techniques efficiently accurately differentiate numeric functions expressed computer programs generally besides preprint review sep ad two main ad branches many software implementations different pros cons exist ad software implementations work lower level code representation possibly mixing compiler passes fully optimize scalar operations revels et moses churavy others perform transformations higher level keep linear algebra operations intact optimal usage blas primitives innes et paszke et goal make best choice ad system every part program without requiring users extensively contort code differing apis ad landscape julia programming language developed manner composability ad systems possible many automatic differentiation systems require specific formulations code example pytorch using alternative implementation numpy api known paszke et similarly jax bradbury et differing original numpy oliphant api subtle ways different numerical properties julia ad systems generally act directly standard julia syntax standard library array implementation standard gpu acceleration tools besard et previously shown allow packages julia developed without knowledge ad systems fully differentiable without modification multiple different tools rackauckas et furthermore julia common ground differentiation rules defined white et shared amongst ad packages empowers idea glue ad system rackauckas software library authors define chainrules overloads add domain insight automatic differentiation process without tying one particular ad system however switching one backend another user side still tedious user learn adapt code towards api new ad package similarly author ad package defining extensive api supporting every possible differentiation use case requires lot boilerplate code define jacobian function product hessian product etc defining functions ad implementation tedious unnecessary since relationship functions abstract therefore theory switching ad systems trivially done practice competing apis various ad mechanisms limited use throughout language ecosystem julia language bezanson et dozen automatic differentiation packages white different packages different user interfaces offer different tradeoffs popular systems include revels et ad implementation many years extensive use thus high reliability revels ad implementation featuring several optimizations innes et ad implementation source code transformation generate derivative code function code operating level julia intermediate representation zygote therefore able handle arbitrary julia code unable handle mutation moses churavy ad implementation runs source code transformation llvm level excellent performance scalar operations present lesser performance large matrix operations fischer new ad package promising high performance scalar code detailed summary strengths limitations different ad packages given appendix ad systems many others unique set advantages disadvantages additionally define api functions subset possible differentiation use cases often requiring users implementations quantities like product product needed beside existing stable ad implementations new implementation may may mature enough handle perturbation confusion properly siskind pearlmutter manzyuk et prevents one general ad correctly simple workaround compose various ad packages level differentiation giving rise applications changing ad mechanisms increasingly common ad systems different pros cons software author want change ad systems depending problem available hardware resources see appendix b however challenging might seem changing ad systems results forking code even though nominal value software using ad remains give examples changed using innes et resulted fork created viz want use old ad system even though conceptually flux neural network library abstracted away ad created attempt move theano et used salvatier et using tensorflow abadi et attempt eventually abandoned favor keeping theano adding jax bradbury et backend pymc development team code need forked overall attempt successful admittedly particularly complex case beyond ad tensorflow theano general computational frameworks ad one feature work present aims ensure changing ad system accessible providing consistent abstractions author algorithm implementation use similar complex problem solved legat et provides common abstractions across constrained mathematical optimizers ipopt wachter cbc forrest et gurobi gurobi optimization llc turn used mathematical optimization frameworks including jump dunning et udell et different mathematical optimizers unique internal set abstractions exposes way additional complication supports different kinds problems must exposed still classes problems different kind mathematical transformation mathoptinterface exposes extensible system bridges automatically perform reformulations system considerably complicated setting every ad system perform operations varying degrees efficiency mathoptinterface system proven successful supports idea kind abstraction valuable practically realized light authors believe necessary interface provide objects like function value gradient hessian etc well combining ad implementations together ad interface help us avoid combinatorial explosion code supporting every differentiation package julia every piece software requiring gradients hessians especially important derivatives one combine two differentiation backends create new backend generally k th order derivative amount code required support n differentiation packages algorithm implementations n k paper present tarek et al package defines abstract extensive api differentiation julia enabling development algorithms requiring first derivatives way using single unified interface reducing code complexity n k n automatically defines extensive api new ad package one two primitive api function definitions thus making easier ad package developer support every possible use case without great deal boilerplate code levels abstraction julia ad ecosystem figure overview levels abstraction julia ad ecosystem presented bottom level libraries differentiation rules https https https specific functions rules either defined ad developers basic julia constructs ad users specific functions known analytic derivatives sitting top library rules ad package implementations level numerous design decisions optimizations made giving variety different ad package implementations different tradeoffs ad package developer define minimal set primitives backend type extending minimal definitions enable automatically define extensive set api functions ad users use derivative jacobian hessian product product etc top level ad users use relevant part api implement algorithms requiring abstraction design amount code needed support n ad packages algorithms requiring k th order derivatives n significant reduction n k without additionally ad users developers need add unnecessary boilerplate code extend ad package api anymore since automatically figure levels abstraction julia ad ecosystem api description installation loading registered julia package installed julia package manager package loaded alternatively import abstractdifferentiation ad using abstractdifferentiation note exports ad alias abstractdifferentiation module alias allows us conveniently access names within via ad instead typing full package name backends primitives backends functionalities implemented based ab type ad package developer ad user necessary first constructs backend instance subtypes ab ab ab subtypes ab example backends support defined follows forwarddiff struct forwarddiffbackend end const forwarddiffbackend zygote struct zygotebackend end const zygotebackend adding fields backend struct control configurations differentiation package chunk sizes compilation flags method choices use finite differencing method central grid points implemented package write finitedifferences struct fdmbackend alg end denotes order derivative estimate fdmbackend fdmbackend backends compute derivatives may desirable combine different backends provide implement backends let automatic differentiation backend let automatic differentiation backend construct backend automatic differentiation one defines analogously backend automatic differentiation constructed via jacobian pushforward pullback primitive operation addition definition backend ad package developer needs define one following primitive operations ad primitive function jacobian ab f xs return end ad primitive function ab f xs return end ad primitive function ab f xs return end generates two primitive functions instance ad package developer specify native primitive operation zygote ad primitive function ab f xs return function vs supports single output back f xs vs isa abstractvector return back vs else vs isa tuple assert length vs return back vs end end end case operator overloading ad implementations require additionally definition returning primal value forward pass automatically provided functions preparatory steps automatically defines various functions ad users making use primitives defined important api functions provided presented following refer reader package documentation details tarek et derivative gradient jacobian hessian ds ab f xs gs ab f xs js ab f xs h ab f x value derivative gradient jacobian hessian v ds ab f xs v gs ab f xs v js ab f xs v h ab f x v g h ab f x lazy operators finally implemented lazy versions derivative gradient jacobian hessian ld ab f xs lg ab f xs lj ab f xs lh ab f x interest iterative solvers example compute product multiplying single transposed vector tuple appropriate shape left lazy jacobian operator use cases example many numerical algorithms require computation constructs ones described section table presents rough summary linking widely adopted routines across different domains quantities used respective iterative update steps example present simple implementation gaussnewton algorithm solve least squares problems appendix also expect specifically handy future ad package like computing constructs like jacobians hessians technically possible yet part public api due abstractions naming conventions made package algorithms required quantities root finding jacobian newton krylov products optimization adam gradient newton gradient hessian jacobian jacobian differential equations stiff ode solvers jacobian stiff ode solvers products forward sensitivity methods products adjoint sensitivity methods product table algorithms requiring derivatives gradients jacobians hessians vectorjacobian products products commonly computed ad packages summary future work ability straightforwardly combine different packages one workflow one versatile key features julia switching different ad packages combining derivatives useful feature selecting best ad implementation specific application presented package makes switching combining ad implementations painless possible also reducing amount necessary boilerplate code per ad package support differentiation use cases future aim support ad packages julia remove lots boilerplate code popular julia packages sciml turinglang organizations heavily employ ad references abadi agarwal barham brevdo chen citro corrado davis j dean devin ghemawat goodfellow harp irving isard jia jozefowicz kaiser kudlur levenberg manÃ© monga moore murray olah schuster shlens steiner sutskever talwar tucker vanhoucke vasudevan viÃ©gas vinyals warden wattenberg wicke yu zheng tensorflow largescale machine learning heterogeneous systems url https software available alain almahairi angermueller bahdanau ballas bastien bayer belikov belopolsky bengio bergeron bergstra bisson bleecher snyder bouchard bouthillier de brÃ©bisson breuleux carrier cho chorowski christiano cooijmans cÃ´tÃ© cÃ´tÃ© courville dauphin delalleau demouth desjardins dieleman dinh ducoffe dumoulin ebrahimi kahou erhan z fan firat germain glorot goodfellow graham gulcehre hamel harlouchet heng hidasi honari jain jean jia korobov kulkarni lamb lamblin larsen laurent lee lefrancois lemieux lÃ©onard lin j livezey lorenz lowin manzagol mastropietro mcgibbon memisevic van merriÃ«nboer michalski mirza orlandi pal pascanu pezeshki raffel renshaw rocklin romero roth sadowski salvatier savard schlÃ¼ter schulman schwartz serban serdyuk shabanian simon spieckermann subramanyam sygnowski tanguay van tulder turian urban vincent visin de vries webb willson xu xue yao zhang zhang theano python framework fast computation mathematical expressions arxiv may url http alquraishi differentiable learning protein structure biorxiv doi url https besard foket b de sutter effective extensible programming unleashing julia gpus ieee transactions parallel distributed systems issn doi bezanson karpinski shah edelman julia fast dynamic language technical computing arxiv preprint bradbury frostig hawkins johnson leary maclaurin necula paszke vanderplas zhang jax composable transformations programs url http chen rubanova bettencourt duvenaud neural ordinary differential equations arxiv preprint dandekar rackauckas barbastathis machine global diagnostic comparative tool assess effect quarantine control spread patterns de avila smith allen tenenbaum j kolter differentiable physics learning control advances neural information processing systems dunning huchette lubin jump modeling language mathematical optimization siam review fischer compiler transformations presence dynamic dispatch url https forrest ralphs vigerske louhafer kristjansson jpfasano edwinstraver lubin santos rlougee saltzman version july url https gurobi optimization llc gurobi optimizer reference manual url https ingraham riesselman sander marks learning protein structure differentiable simulator international conference learning representations innes edelman fischer rackauckus saba shah tebbutt zygote differentiable programming system bridge machine learning scientific computing arxiv preprint url https legat dowson garcia lubin mathoptinterface data structure mathematical optimization problems url https manzyuk b pearlmutter radul rush siskind perturbation confusion forward automatic differentiation functions journal functional programming moses churavy instead rewriting foreign code machine learning automatically synthesize fast gradients larochelle ranzato hadsell balcan lin editors advances neural information processing systems volume pages curran associates url https oliphant guide numpy volume trelgol publishing usa paszke gross chintala chanan yang devito lin desmaison antiga lerer automatic differentiation pytorch rackauckas glue ad full language differentiable programming url http rackauckas dixit guo innes revels nyberg ivaturi comparison automatic differentiation continuous sensitivity analysis derivatives differential equation solutions arxiv preprint rackauckas edelman fischer innes saba shah tebbutt generalized learning differentiable programming aaai spring symposium mlps rackauckas martensen warner zubov supekar skinner ramadhan universal differential equations scientific machine learning arxiv preprint raissi perdikaris karniadakis neural networks deep learning framework solving forward inverse problems involving nonlinear partial differential equations journal computational physics revels url http revels lubin papamarkou automatic differentiation julia arxiv preprint salvatier wiecki fonnesbeck probabilistic programming python using peerj computer science apr doi url https schÃ¤fer agnostic code url https schÃ¤fer kloc bruder lÃ¶rch differentiable programming method quantum control machine learning science technology schÃ¤fer sekatski koppenhÃ¶fer bruder kloc control stochastic quantum dynamics differentiable programming machine learning science technology schenck fox spnets differentiable fluid dynamics deep neural networks conference robot learning pages pmlr siskind b pearlmutter perturbation confusion referential transparency correct functional implementation ad srajer kukelova fitzgibbon benchmark selected algorithmic differentiation tools problems computer vision machine learning optimization methods software tarek schÃ¤fer contributers url https pymc development team future theano dead long live theano url https udell mohan zeng hong diamond boyd convex optimization julia workshop high performance technical computing dynamic languages wachter interior point algorithm nonlinear optimization applications process engineering phd thesis carnegie mellon university white juliadiff website url https white zgubic abbott revels arslan axen schaub robinson dhingra tebbutt heim rosemberg schmitz rackauckas widmann heintzmann schÃ¤fer fischer robson brzezinski zhabinski besanÃ§on vertechi gowda fitzgibbon lucibello vogt gandhi chorney url https summary current state ad packages julia september table table summarizes current state popular julia ad packages september scalar refers scalar operations support including defining custom rules functions scalars refers native support construct including ability define custom differentiation rules functions functions similarly first class struct support refers native support julia structs construct including ability define custom differentiation rules functions functions structs gpu refers ability differentiate functions returning gpu arrays gc refers supporting functions call julia garbage collector mutation refers ability support mutating arrays structs runtime branches refers ability support functions control flow path function takes ultimately structure mathematical function differentiated depends values inputs function maturity refers subjective measure mature package eyes community well feature maturity package package scalar vector tensor first class struct support gpu gc mutation runtime branches maturity forwarddiff high reversediff slow limited high reversediff compiled tape limited high tracker slow limited high zygote slow high enzyme limited wip wip wip low diffractor low table summarizes current state popular ad packages julia ecosystem time writing paper b ad performance well know function f r n r n independent input variables dependent output variables ad preferred build jacobian n ad preferred n one increases number inputs within problem ad mode eventually overtake ad performance investigated depth differential equations applied models relevant biopharmacology alongside various adjoint options rackauckas et work shows sufficiently small odes odes parameters ad via efficient method comparing analytical techniques adjoint techniques using size increased stiff partial differential equation shown products mixed specific adjoint method efficient outperforming techniques long follows demonstrate two additional examples choice specific reversemode ad package may also significantly impact performance srajer et examples show compiled mode outperforming certain circumstances however compatible gpus shown performance competitive potential equations scientific computing applications allows efficient together shows one application ad systems could potentially optimal choice depending user inputs package code establishes optimal choice ad mechanism rather complex users package developers thus decreasing cost performing benchmarks value many scientists example model figure benchmark model cases use checkpointed interpolating adjoint method rackauckas et compute local sensitivities false true indicate tape precompiled suppose instantaneous objective l x x model Î±x Î²xy Î³xy Î´y initial conditions x let Î¾ denote parameters Î± Î² Î³ Î´ interested sensitivities p l x ti ti respect equally spaced time grid grid spacing figure shows violin plot runtimes four choices internally used ad system demonstrates products use static compilation ode function compilation enabled vastly outperform choices small odes lot scalar indexing common feature many nonlinear physical biochemical models note adjoint techniques shown outperformed example elsewhere rackauckas et example still confirms many scalar indexing cases system perform rather poorly example neural ode example spiral neural ode chosen neural ordinary differential equations manuscript chen et ode defined neural network applied cubed states system nn u nn u multilayer perceptron one hidden layer size tanh activation function u r figure shows violin plot runtimes four choices internally used ad system results show direct differentiation cpus reversediffvjp compiled tape efficient method however many caveats one caveat form applicable code branching thus would incompatible activation functions like relu additionally testing various sizes hidden layers established rtx super gpu outperformed ryzen cpu hidden layer size reached approximately note crossover point could potentially lot smaller many scenarios neural network deeper since first last layer sizes matching dimensionality u around size neural networks strategies gpus become efficient one restricted cpus two examples addition prior research clearly demonstrate internal ad system must carefully chosen based problem hardware resources hand figure benchmark spiral neural ode model cases use checkpointed interpolating adjoint method rackauckas et compute local sensitivities false true indicate tape precompiled c implementation algorithm appendix use implementation algorithm solving nonlinear least squares problems schÃ¤fer algorithm iteratively finds value n variables x xn minimizing sum squares residuals fm x x fi x p starting initial guess minimum method runs iterations x x k Î±k j j j f x k p residuals f x k p depend current step x k parameters j jacobian matrix x k Î±k step length determined via line search subroutine scheme function gaussnewton xs x p backend maxiter x step x p backend push xs x end return xs x end function step x p backend deepcopy x done x p condition first return value dfdx second return value dfdp j backend f x p j j j f x p copyto x end return end switching different ad systems easily accomplished passing different backends input gaussnewton function
differentiable programming julia frank schÃ¤fer department physics university basel switzerland mohamed tarek usa unsw canberra australia mohamed lyndon white invenia labs cambridge uk chris rackauckas massachusetts institute technology usa julia computing usa usa crackauc abstract single automatic differentiation ad system optimal choice problems means informed selection ad system combinations variable greatly impact performance julia programming language major ad systems target input thus theory compose hitherto switching ad packages julia language required familiarize api respective packages furthermore implementing new usable ad package required ad package developers write boilerplate code define convenience api functions response issues present automatized generation extensive unified api ad package splitting complexity ad users ad developers ad package developers need implement one two primitive definitions support various utilities ad users like jacobians hessians lazy product operators native primitives pullbacks pushforwards thus removing tedious far inevitable boilerplate code enabling easy switching composing ad implementations introduction differentiable programming ability differentiate general computer program structures enabled efficient combination existing packages scientific computation machine learning raissi et rackauckas et de avila et machine learning approaches flexible require large amount data incorporating scientific knowledge structure problem via reduces amount data needed allows learning task simplified example focusing learning parts model missing rackauckas et dandekar et already many examples differentiable frameworks provided performance accuracy advantages approaches machine learning including limited alquraishi ingraham et fluid dynamics schenck fox robotics schenck fox quantum control schÃ¤fer et commonly realized automatic differentiation ad family techniques efficiently accurately differentiate numeric functions expressed computer programs generally besides preprint review sep ad two main ad branches many software implementations different pros cons exist ad software implementations work lower level code representation possibly mixing compiler passes fully optimize scalar operations revels et moses churavy others perform transformations higher level keep linear algebra operations intact optimal usage blas primitives innes et paszke et goal make best choice ad system every part program without requiring users extensively contort code differing apis ad landscape julia programming language developed manner composability ad systems possible many automatic differentiation systems require specific formulations code example pytorch using alternative implementation numpy api known paszke et similarly jax bradbury et differing original numpy oliphant api subtle ways different numerical properties julia ad systems generally act directly standard julia syntax standard library array implementation standard gpu acceleration tools besard et previously shown allow packages julia developed without knowledge ad systems fully differentiable without modification multiple different tools rackauckas et furthermore julia common ground differentiation rules defined white et shared amongst ad packages empowers idea glue ad system rackauckas software library authors define chainrules overloads add domain insight automatic differentiation process without tying one particular ad system however switching one backend another user side still tedious user learn adapt code towards api new ad package similarly author ad package defining extensive api supporting every possible differentiation use case requires lot boilerplate code define jacobian function product hessian product etc defining functions ad implementation tedious unnecessary since relationship functions abstract therefore theory switching ad systems trivially done practice competing apis various ad mechanisms limited use throughout language ecosystem julia language bezanson et dozen automatic differentiation packages white different packages different user interfaces offer different tradeoffs popular systems include revels et ad implementation many years extensive use thus high reliability revels ad implementation featuring several optimizations innes et ad implementation source code transformation generate derivative code function code operating level julia intermediate representation zygote therefore able handle arbitrary julia code unable handle mutation moses churavy ad implementation runs source code transformation llvm level excellent performance scalar operations present lesser performance large matrix operations fischer new ad package promising high performance scalar code detailed summary strengths limitations different ad packages given appendix ad systems many others unique set advantages disadvantages additionally define api functions subset possible differentiation use cases often requiring users implementations quantities like product product needed beside existing stable ad implementations new implementation may may mature enough handle perturbation confusion properly siskind pearlmutter manzyuk et prevents one general ad correctly simple workaround compose various ad packages level differentiation giving rise applications changing ad mechanisms increasingly common ad systems different pros cons software author want change ad systems depending problem available hardware resources see appendix b however challenging might seem changing ad systems results forking code even though nominal value software using ad remains give examples changed using innes et resulted fork created viz want use old ad system even though conceptually flux neural network library abstracted away ad created attempt move theano et used salvatier et using tensorflow abadi et attempt eventually abandoned favor keeping theano adding jax bradbury et backend pymc development team code need forked overall attempt successful admittedly particularly complex case beyond ad tensorflow theano general computational frameworks ad one feature work present aims ensure changing ad system accessible providing consistent abstractions author algorithm implementation use similar complex problem solved legat et provides common abstractions across constrained mathematical optimizers ipopt wachter cbc forrest et gurobi gurobi optimization llc turn used mathematical optimization frameworks including jump dunning et udell et different mathematical optimizers unique internal set abstractions exposes way additional complication supports different kinds problems must exposed still classes problems different kind mathematical transformation mathoptinterface exposes extensible system bridges automatically perform reformulations system considerably complicated setting every ad system perform operations varying degrees efficiency mathoptinterface system proven successful supports idea kind abstraction valuable practically realized light authors believe necessary interface provide objects like function value gradient hessian etc well combining ad implementations together ad interface help us avoid combinatorial explosion code supporting every differentiation package julia every piece software requiring gradients hessians especially important derivatives one combine two differentiation backends create new backend generally k th order derivative amount code required support n differentiation packages algorithm implementations n k paper present tarek et al package defines abstract extensive api differentiation julia enabling development algorithms requiring first derivatives way using single unified interface reducing code complexity n k n automatically defines extensive api new ad package one two primitive api function definitions thus making easier ad package developer support every possible use case without great deal boilerplate code levels abstraction julia ad ecosystem figure overview levels abstraction julia ad ecosystem presented bottom level libraries differentiation rules https https https specific functions rules either defined ad developers basic julia constructs ad users specific functions known analytic derivatives sitting top library rules ad package implementations level numerous design decisions optimizations made giving variety different ad package implementations different tradeoffs ad package developer define minimal set primitives backend type extending minimal definitions enable automatically define extensive set api functions ad users use derivative jacobian hessian product product etc top level ad users use relevant part api implement algorithms requiring abstraction design amount code needed support n ad packages algorithms requiring k th order derivatives n significant reduction n k without additionally ad users developers need add unnecessary boilerplate code extend ad package api anymore since automatically figure levels abstraction julia ad ecosystem api description installation loading registered julia package installed julia package manager package loaded alternatively import abstractdifferentiation ad using abstractdifferentiation note exports ad alias abstractdifferentiation module alias allows us conveniently access names within via ad instead typing full package name backends primitives backends functionalities implemented based ab type ad package developer ad user necessary first constructs backend instance subtypes ab ab ab subtypes ab example backends support defined follows forwarddiff struct forwarddiffbackend end const forwarddiffbackend zygote struct zygotebackend end const zygotebackend adding fields backend struct control configurations differentiation package chunk sizes compilation flags method choices use finite differencing method central grid points implemented package write finitedifferences struct fdmbackend alg end denotes order derivative estimate fdmbackend fdmbackend backends compute derivatives may desirable combine different backends provide implement backends let automatic differentiation backend let automatic differentiation backend construct backend automatic differentiation one defines analogously backend automatic differentiation constructed via jacobian pushforward pullback primitive operation addition definition backend ad package developer needs define one following primitive operations ad primitive function jacobian ab f xs return end ad primitive function ab f xs return end ad primitive function ab f xs return end generates two primitive functions instance ad package developer specify native primitive operation zygote ad primitive function ab f xs return function vs supports single output back f xs vs isa abstractvector return back vs else vs isa tuple assert length vs return back vs end end end case operator overloading ad implementations require additionally definition returning primal value forward pass automatically provided functions preparatory steps automatically defines various functions ad users making use primitives defined important api functions provided presented following refer reader package documentation details tarek et derivative gradient jacobian hessian ds ab f xs gs ab f xs js ab f xs h ab f x value derivative gradient jacobian hessian v ds ab f xs v gs ab f xs v js ab f xs v h ab f x v g h ab f x lazy operators finally implemented lazy versions derivative gradient jacobian hessian ld ab f xs lg ab f xs lj ab f xs lh ab f x interest iterative solvers example compute product multiplying single transposed vector tuple appropriate shape left lazy jacobian operator use cases example many numerical algorithms require computation constructs ones described section table presents rough summary linking widely adopted routines across different domains quantities used respective iterative update steps example present simple implementation gaussnewton algorithm solve least squares problems appendix also expect specifically handy future ad package like computing constructs like jacobians hessians technically possible yet part public api due abstractions naming conventions made package algorithms required quantities root finding jacobian newton krylov products optimization adam gradient newton gradient hessian jacobian jacobian differential equations stiff ode solvers jacobian stiff ode solvers products forward sensitivity methods products adjoint sensitivity methods product table algorithms requiring derivatives gradients jacobians hessians vectorjacobian products products commonly computed ad packages summary future work ability straightforwardly combine different packages one workflow one versatile key features julia switching different ad packages combining derivatives useful feature selecting best ad implementation specific application presented package makes switching combining ad implementations painless possible also reducing amount necessary boilerplate code per ad package support differentiation use cases future aim support ad packages julia remove lots boilerplate code popular julia packages sciml turinglang organizations heavily employ ad references abadi agarwal barham brevdo chen citro corrado davis j dean devin ghemawat goodfellow harp irving isard jia jozefowicz kaiser kudlur levenberg manÃ© monga moore murray olah schuster shlens steiner sutskever talwar tucker vanhoucke vasudevan viÃ©gas vinyals warden wattenberg wicke yu zheng tensorflow largescale machine learning heterogeneous systems url https software available alain almahairi angermueller bahdanau ballas bastien bayer belikov belopolsky bengio bergeron bergstra bisson bleecher snyder bouchard bouthillier de brÃ©bisson breuleux carrier cho chorowski christiano cooijmans cÃ´tÃ© cÃ´tÃ© courville dauphin delalleau demouth desjardins dieleman dinh ducoffe dumoulin ebrahimi kahou erhan z fan firat germain glorot goodfellow graham gulcehre hamel harlouchet heng hidasi honari jain jean jia korobov kulkarni lamb lamblin larsen laurent lee lefrancois lemieux lÃ©onard lin j livezey lorenz lowin manzagol mastropietro mcgibbon memisevic van merriÃ«nboer michalski mirza orlandi pal pascanu pezeshki raffel renshaw rocklin romero roth sadowski salvatier savard schlÃ¼ter schulman schwartz serban serdyuk shabanian simon spieckermann subramanyam sygnowski tanguay van tulder turian urban vincent visin de vries webb willson xu xue yao zhang zhang theano python framework fast computation mathematical expressions arxiv may url http alquraishi differentiable learning protein structure biorxiv doi url https besard foket b de sutter effective extensible programming unleashing julia gpus ieee transactions parallel distributed systems issn doi bezanson karpinski shah edelman julia fast dynamic language technical computing arxiv preprint bradbury frostig hawkins johnson leary maclaurin necula paszke vanderplas zhang jax composable transformations programs url http chen rubanova bettencourt duvenaud neural ordinary differential equations arxiv preprint dandekar rackauckas barbastathis machine global diagnostic comparative tool assess effect quarantine control spread patterns de avila smith allen tenenbaum j kolter differentiable physics learning control advances neural information processing systems dunning huchette lubin jump modeling language mathematical optimization siam review fischer compiler transformations presence dynamic dispatch url https forrest ralphs vigerske louhafer kristjansson jpfasano edwinstraver lubin santos rlougee saltzman version july url https gurobi optimization llc gurobi optimizer reference manual url https ingraham riesselman sander marks learning protein structure differentiable simulator international conference learning representations innes edelman fischer rackauckus saba shah tebbutt zygote differentiable programming system bridge machine learning scientific computing arxiv preprint url https legat dowson garcia lubin mathoptinterface data structure mathematical optimization problems url https manzyuk b pearlmutter radul rush siskind perturbation confusion forward automatic differentiation functions journal functional programming moses churavy instead rewriting foreign code machine learning automatically synthesize fast gradients larochelle ranzato hadsell balcan lin editors advances neural information processing systems volume pages curran associates url https oliphant guide numpy volume trelgol publishing usa paszke gross chintala chanan yang devito lin desmaison antiga lerer automatic differentiation pytorch rackauckas glue ad full language differentiable programming url http rackauckas dixit guo innes revels nyberg ivaturi comparison automatic differentiation continuous sensitivity analysis derivatives differential equation solutions arxiv preprint rackauckas edelman fischer innes saba shah tebbutt generalized learning differentiable programming aaai spring symposium mlps rackauckas martensen warner zubov supekar skinner ramadhan universal differential equations scientific machine learning arxiv preprint raissi perdikaris karniadakis neural networks deep learning framework solving forward inverse problems involving nonlinear partial differential equations journal computational physics revels url http revels lubin papamarkou automatic differentiation julia arxiv preprint salvatier wiecki fonnesbeck probabilistic programming python using peerj computer science apr doi url https schÃ¤fer agnostic code url https schÃ¤fer kloc bruder lÃ¶rch differentiable programming method quantum control machine learning science technology schÃ¤fer sekatski koppenhÃ¶fer bruder kloc control stochastic quantum dynamics differentiable programming machine learning science technology schenck fox spnets differentiable fluid dynamics deep neural networks conference robot learning pages pmlr siskind b pearlmutter perturbation confusion referential transparency correct functional implementation ad srajer kukelova fitzgibbon benchmark selected algorithmic differentiation tools problems computer vision machine learning optimization methods software tarek schÃ¤fer contributers url https pymc development team future theano dead long live theano url https udell mohan zeng hong diamond boyd convex optimization julia workshop high performance technical computing dynamic languages wachter interior point algorithm nonlinear optimization applications process engineering phd thesis carnegie mellon university white juliadiff website url https white zgubic abbott revels arslan axen schaub robinson dhingra tebbutt heim rosemberg schmitz rackauckas widmann heintzmann schÃ¤fer fischer robson brzezinski zhabinski besanÃ§on vertechi gowda fitzgibbon lucibello vogt gandhi chorney url https summary current state ad packages julia september table table summarizes current state popular julia ad packages september scalar refers scalar operations support including defining custom rules functions scalars refers native support construct including ability define custom differentiation rules functions functions similarly first class struct support refers native support julia structs construct including ability define custom differentiation rules functions functions structs gpu refers ability differentiate functions returning gpu arrays gc refers supporting functions call julia garbage collector mutation refers ability support mutating arrays structs runtime branches refers ability support functions control flow path function takes ultimately structure mathematical function differentiated depends values inputs function maturity refers subjective measure mature package eyes community well feature maturity package package scalar vector tensor first class struct support gpu gc mutation runtime branches maturity forwarddiff high reversediff slow limited high reversediff compiled tape limited high tracker slow limited high zygote slow high enzyme limited wip wip wip low diffractor low table summarizes current state popular ad packages julia ecosystem time writing paper b ad performance well know function f r n r n independent input variables dependent output variables ad preferred build jacobian n ad preferred n one increases number inputs within problem ad mode eventually overtake ad performance investigated depth differential equations applied models relevant biopharmacology alongside various adjoint options rackauckas et work shows sufficiently small odes odes parameters ad via efficient method comparing analytical techniques adjoint techniques using size increased stiff partial differential equation shown products mixed specific adjoint method efficient outperforming techniques long follows demonstrate two additional examples choice specific reversemode ad package may also significantly impact performance srajer et examples show compiled mode outperforming certain circumstances however compatible gpus shown performance competitive potential equations scientific computing applications allows efficient together shows one application ad systems could potentially optimal choice depending user inputs package code establishes optimal choice ad mechanism rather complex users package developers thus decreasing cost performing benchmarks value many scientists example model figure benchmark model cases use checkpointed interpolating adjoint method rackauckas et compute local sensitivities false true indicate tape precompiled suppose instantaneous objective l x x model Î±x Î²xy Î³xy Î´y initial conditions x let Î¾ denote parameters Î± Î² Î³ Î´ interested sensitivities p l x ti ti respect equally spaced time grid grid spacing figure shows violin plot runtimes four choices internally used ad system demonstrates products use static compilation ode function compilation enabled vastly outperform choices small odes lot scalar indexing common feature many nonlinear physical biochemical models note adjoint techniques shown outperformed example elsewhere rackauckas et example still confirms many scalar indexing cases system perform rather poorly example neural ode example spiral neural ode chosen neural ordinary differential equations manuscript chen et ode defined neural network applied cubed states system nn u nn u multilayer perceptron one hidden layer size tanh activation function u r figure shows violin plot runtimes four choices internally used ad system results show direct differentiation cpus reversediffvjp compiled tape efficient method however many caveats one caveat form applicable code branching thus would incompatible activation functions like relu additionally testing various sizes hidden layers established rtx super gpu outperformed ryzen cpu hidden layer size reached approximately note crossover point could potentially lot smaller many scenarios neural network deeper since first last layer sizes matching dimensionality u around size neural networks strategies gpus become efficient one restricted cpus two examples addition prior research clearly demonstrate internal ad system must carefully chosen based problem hardware resources hand figure benchmark spiral neural ode model cases use checkpointed interpolating adjoint method rackauckas et compute local sensitivities false true indicate tape precompiled c implementation algorithm appendix use implementation algorithm solving nonlinear least squares problems schÃ¤fer algorithm iteratively finds value n variables x xn minimizing sum squares residuals fm x x fi x p starting initial guess minimum method runs iterations x x k Î±k j j j f x k p residuals f x k p depend current step x k parameters j jacobian matrix x k Î±k step length determined via line search subroutine scheme function gaussnewton xs x p backend maxiter x step x p backend push xs x end return xs x end function step x p backend deepcopy x done x p condition first return value dfdx second return value dfdp j backend f x p j j j f x p copyto x end return end switching different ad systems easily accomplished passing different backends input gaussnewton function
draft version september typeset using latex twocolumn style galactic archaeology program overview target selection survey properties sanjib sharma dennis stello joel zinn joss institute astronomy school physics university sydney nsw australia centre excellence sky astrophysics three dimensions physics university new south wales sydney nsw australia astrophysics centre department physics astronomy aarhus university aarhus c denmark abstract nasa mission targets proposed guest observer programs among galactic archaeology program devoted measuring asteroseismic signals giant stars inform studies galaxy observed targets allocated program provide overview program discuss detail target selection procedure provide python code implements selection function additionally discuss detection completeness asteroseismic parameters Î½max broadly speaking targets selected based color j finely tuned adjustments campaign making use selection function compare observed distribution asteroseismic masses theoretical predictions median asteroseismic mass higher compared predictions additionally number seismic detections average lower expected provide mock catalog stars based synthetic model galaxy community used subsequent analyses data set keywords galaxy disc galaxy evolution galaxy formation galaxy kinematics dynamics introduction use asteroseismology inform studies milky way proposed decade ago miglio et al became possible first time detect oscillations hundreds even thousands distant stars using continuous photometric data missions particularly corot kepler de ridder et al stello et al however early missions far ideal studying galaxy whole indeed never designed mind sharma et al main reasons limited sky coverage lack target selection function well understood selection function fundamental make meaningful comparisons observed stellar populations sharma et al studies play important role making robust inferences galactic stellar populations decade ago primary nasa kepler mission targetted single field cygnus lyra constellations four years compromised satellite new mission stare days time different directions along ecliptic figure mission able probe stellar populations many directions covering much galaxy achieved earlier missions included halo bulge thin thick disks vastly different galactic radii heights plane take advantage opportunity galactic archaeology program formed around international collaboration aim detecting oscillations thousands red giants along ecliptic primary goal establish robust stellar ages major galactic stellar components rendle et al sharma et al significantly improve possible esa gaia spectroscopic survey data alone et al achieved devising reproducible target selection eliminate limitations previous spacebased seismic observations maximize synergy galactic spectroscopic surveys total provided observing campaigns fuel ran spacecraft retired end survey already published proof concept study stello et al along succession welltested data products data release containing seismic results campaign stello et al data release containing seismic results zinn et al final data release results campaigns one homogeneous catalog zinn et al addition science sep sharma et al galactic longitude degree galactic latitude degree kepler right ascension degree declination degree b figure footprint different campaigns galactic equatorial coordinates campaigns suitable studies shown green first three follow well defined selection seismic detections results published rendle et al sharma et al zinn et al overarching vision seismic data always combined complementary data many stellar surveys emerged decade recognition potential several large spectroscopic surveys targetted fields surveys largest overlap apogee lamost show synergy proved effective determining improved stellar ages thousands stars important goal galactic archaeology freeman paper report target selection campaign detail discuss detection completeness asteroseismic parameters Î½max oscillating target selection j ks ks stars j ks b max stars figure color absolute magnitude distribution stars observed minute cadence gaia parallax absolute magnitude estimated using gaia parallax vertical line j marks color selection number stars bin indicated color bar b subset stars asteroseismic detection Î½max stars Î½max detections j stars Î½max detected mks either incorrect Î½max parallax vjk giant fraction j ks giants mks degree figure fraction stars proposed giants function apparent magnitude vjk different campaigns stars satisfy selection function given table giants identified based absolute magnitude mks mks estimated using gaia parallaxes giants make detailed comparison observed distribution stars Î½max vjk Îºm selectionmatched mock catalogs finally discuss implications results asteroseismic relations galactic archaeology method primary target selection strategy target selection strategy designed easily reproducible aids study ensembles rather individual stars especially important galactic archaeology need fit galactic models observational data taking target selection account sharma et al also useful exoplanet population studies necessary first step selecting targets input catalog well understood reliable photometry covers regions sky interested mind adopt catalog robust photometry completeness magnitude range targeting vjk color limit j ks adopted throughout survey designed focus red giants primary asteroseismic targets seen figure stars detect oscillations j mks stars j typically dwarfs mks oscillation frequencies large detected cadence color limit j ks excludes giants blue extension red clump stars horizontal branch predominantly rare although reduced proper motions used separate dwarfs giants past avoided multiple reasons first introduces kinematic bias undesirable galactic archaeology secondly proper motions available ucac time selection significant uncertainties finally dwarfs interested desirable exoplanet studies simple selection function would also benefit summary simplest color based selection criteria found best suited galactic archaeology exoplanet population studies addition color stars restricted apparent magnitude brightness lower upper limit lower bright limit chosen avoid overly saturated stars upper faint limit chosen avoid observing ensembles low yield oscillating giants first campaigns used h magnitude select brightness however later campaigns adopted vjk j exp j approximation v band magnitude measured j k bands shown sharma et al formula accurate dex stars adopted vjk later campaigns collects data k p band significantly bluer h band additionally spectroscopic surveys like sharma et al lamost following targets observe v band bright magnitude limit vjk h adopted however faint limit different sharma et al ra deg dec deg deg radius broken ccd ccd figure field view typical campaign shown campaign solid lines outline ccds arranged modules broken modules shown red green circle shows degree radius field view hermes spectrograph note module numbers defined us similar official module numbers numbering starts exclude four corner modules two broken modules campaign typical limit vjk limit campaign determined weighing potential scientific return versus drop yield oscillating giants going towards fainter magnitudes drop yield oscillating giants going fainter due couple reasons first galaxy overall fraction stars giants given apparent magnitude drops go fainter magnitudes shown figure secondly fainter stars lower ratio hinders ability detect oscillations based simulations incompleteness observations predicted set around vjk see section details prompted us propose targets general faint field view certain studies important know completeness observed sample well foot print field view field view square degrees comprising mosaic ccd modules made two pixel ccds arcsec pixel scale slight gaps two ccds modules see figure although actual area module square degrees proposed stars confined square degrees likely due buffer pixels introduced python package mullally et al used select targets certain campaigns high target density proposed stars degree circles located center selected ccd modules make spectroscopic followup easier see figure circle photosensitive area square degrees circle area given size maximum possible photosensitive area among circle placements catalog targets provide master catalog targets observed file construct catalog start list observed targets kepler science website also contains campaign names campaign convert integer cno list includes targets selected programs proposed first cross matched epic catalog based added columns supplement photometric information cross match instead relying information provided epic catalog huber et al epic catalog missing entries targets spite targets stars moreover columns mflg prox incorrect majority stars epic flags among others used select stars good quality photometry table catalog contains targets rest paper exclusively focus targets rest targets like asteroids planets moons base catalog added two additional columns provide information targets target list total amounts observed targets stars also include serendipitous ones selected programs target list remove serendipitous targets create sample referred complete following procedure described section majority complete targets follow strict color magnitude selection function identified python module provided mission team identify target within field view https http fits http target selection table selection function targets campaign first column campaign number selection given last column eighth columns two seven list number stars given data set set right subset set left second column lists stars observed third column lists stars observed target list fourth column lists stars complete meaning excludes serendipitous observations targets programs fifth column lists stars satisfy strict selection function given eighth column sixth column lists completeness fraction stars fifth column seventh column lists stars Î½max measurement range Âµhz finally eighth column selection function stars effectively j due quality cuts c gap gap gap fcomp Î½max selection function sf obs obs com sf sf sf j j h j h c j h h c j vjk j vjk j vjk j vjk c vjk c j vjk j vjk j vjk j vjk j vjk vjk c vjk c vjk c j vjk j vjk vjk c vjk c vjk c vjk c j vjk j vjk vjk c vjk c vjk c vjk c j vjk j vjk vjk c vjk c j vjk circular pointing identifier c shown figure campaign numbers greater equal ccd module corresponding c broken table quality selection criteria fflag description criterion criterion qflag bbb aaa j h k photometric quality bflag blend flag cflag contamination flag xflag ext source aflag solar system object prox arcsec arcsec distance nearest star peculiarities certain campaigns due late change roll angle actual field view slightly shifted compared one provided software observations meant proposed targets unobservable later permanent failure one ccd modules marked figure occurring observations target selection locked resulted selected stars falling module partly observed affected campaigns campaigns unique little seismic detections conducted fulllength engineering test prove viability sharma et al figure distribution stars observed campaigns stars selected lie one degree radius circles campaign one degree circles numbered located centers ccd module excluding two broken ccd modules table priority order selecting targets order description criterion used campaigns apogee j logg rave j logg j logg misc miscellaneous special targets segue g r logg r snr nnnnn Î½max stars Î½max measurements previous campaigns primary j sdss g r r lcolor sdss Âµreduced g r r Âµreduced Âµreduced j vjk Âµreduced secondary j vjk circles c clist k sion fine tune observational setup pointing choice aperture size dedicated gravitational microlensing studies hence community targets sought light curves shorter duration observations terminated days due low fuel targets observed found serendipitous selections hence selection function known observations lasted target selection fraction observed fraction observed b fraction observed c row fraction observed figure fraction stars observed function row list targets proposed sharp fall fraction marks row number sample complete campaigns completeness typically high greater slightly lower completeness respectively completeness low due roll angle error due extra targets proposed broken ccd module also slightly lower completeness due extra targets proposed broken ccd module shows fall fraction cause clear days spacecraft ran fuel campaign also suffered erratic pointing proposed targets describe procedure adopted creating proposed target list separate target lists created campaign general stars selected good quality photometry defined table targets list sorted based priority list various priority classes order given table classes order less stars known giants either spectroscopy asteroseismology special targets included stars existing spectroscopy surveys apogee rave segue previous experience kepler known seismic detections possible logg given spectrocopic logg uncertainties order dex criterion logg adopted spectroscopic sample lower limit logg adopted stars logg classes order number greater equal stars selected based photometry make proposed sample class order number used campaigns provided bulk targets stars selected simply based color magnitude priority sorted magnitude class order number makes use color lcolor defined term u g r band sdss magnitude classes order numbers additionally made use reduced proper motion Âµreduced q Âµ ra dec arcsec rsdss defined term proper motion Âµra Âµdec r band sdss magnitude general stars proposed entire field view see section however certain campaigns look plane galactic disc stars proposed one degree circles located center ccd modules done make spectroscopic followup easier final target list uploaded spacecraft observation prepared nasa contained targets different proposals hence proposed targets serendipitous selections selection based proposals happened also target list serendipitous targets therefore follow proposed priority order guided figure devised procedure exclude targets figure shows average fraction stars selected list function list row number see fraction high almost constant small row numbers abruptly falls low value remains low rest list sharp fall fraction marks special row number sample selection complete beyond serendipitous targets identifying special row number sample selection complete change point sharma et al r kpc z kpc kpc p b r xhelio kpc yhelio kpc c kpc p figure spatial distribution oscillating giants using parallax information gaia panels b show distribution galactocentric cylindrical coordinates r z away plane radial coverage r extends way kpc kpc however close plane radial extent quite limited panels c show distribution heliocentric cartesian coordinates xhelio yhelio distance detection problem propose novel algorithm quantifying change point given argmax x si fc si binary state variable star selected otherwise procedure identifies row number completeness f changes greater fc less fc fc free tunable parameter set actual change point sensitive exact choice fc using procedure total found free serendipitous targets refer complete sample sample identify stars color magnitude complete following selection function listed table asteroseismic parameters giants paper use two seismic quantities frequency maximum oscillation power Î½max frequency separation overtone oscillation modes values use syd results also adopted reyes et al submitted catalog zinn et al used associate detection probabilities pÎ½max based hon et al based reyes et al submitted target assumed invalid target pÎ½max assumed invalid Î½max applying definitions total targets valid Î½max total targets valid note stars observed multiple campaigns means multiple targets hence results correspond star consistent sharma et al use syd results stello et al comparing kepler total targets valid Î½max results spatial distribution oscillating giants one main advantages mission kepler mission wider coverage galaxy seen figure shows spatial distribution oscillating giants galaxy giants span wide region r z plane kepler giants target selection mks x e e c tio n p r b bilit vjk kepler figure probability detecting Î½max function absolute magnitude mks probability measured ratio stars Î½max detections number stars observed bin mks average probability range mks kepler max hz n n max campaign figure fraction stars Î½max detections also detections fined small range around r r specially useful studying formation evolution galaxy away plane radial coverage r extends way kpc kpc figure blue curve however close plane radial extent quite limited figure z kpc heliocentric x projection giants seen four quadrants lower half defined yhelio figure although giants extend distance kpc sun stars within distance kpc figure green curve probability detect Î½max bright stars mission expected detect oscillations stars lower limit Î½max due duration observations upper limit due min cadence data absolute magnitude example mks increases increasing Î½max hence stars Î½max measurements confined range mks suggests mks used estimate overall detection probability seen figure plot ratio stars Î½max measurement number observed stars function mks probability range mks approximately constant falls either end stars mks Î½max high measurable stars mks Î½max low average probability range mks found kepler represents overall probability detect Î½max probability kepler slightly higher likely due higher snr resulting light curves times longer kepler high detection probability zone extends lower values mks expected due kepler light curves significantly longer restrict analysis bright stars vjk fainter stars low progressively makes harder detect Î½max specially stars high Î½max lower oscillation amplitudes lowering bright limit vjk found effect detection probability profile shown figure probability detect given Î½max figure show probability detecting given Î½max detection campaign shown separately probability computed fraction stars Î½max detection also detection fraction shows undulating behaviour two peaks arise global smooth hill shape peaks Î½max local dip near Î½max global shape drop towards lower Î½max due lower limit set day duration light curve becomes harder resolve drop towards higher Î½max Î½max approaches nyquist frequency dip Î½max corresponds location red clump rc stars shows generally harder detect clump stars asteroseismic completeness pipeline results function mass radius considered zinn et al comparing observed asteroseismic data galactic model predictions one main aims study formation evolution milky way important step process compare observed asteroseismic data predictions current galactic model help identify major issues need addressed fine tuning model campaign unique characteristics light curve duration pointing accuracy crowding varying campaign campaign hence important highlight sharma et al max hz b c max hz e f g h max hz j k l max hz n p max hz q r max hz u v w x max hz z aa ab max hz ac ad ae af vjk mag max hz ag kepler vjk mag ah kepler vjk mag ai vjk mag aj nobs nobs figure distribution observed first third columns stars Î½max vjk plane different campaigns results kepler shown panel ag combined results campaigns except shown ai panels second fourth columns plot ratio observed predicted oscillating giants bin average recovery rate shown top right panel predictions based simulations using galaxia dashed line represents equation Î½max vjk upper right region dashed line indicates detect oscillations due low target selection campaigns way problematic example observations agree model predictions campaigns others strong evidence problematic campaigns described selection function detection completeness proceed performing model comparison begin creating synthetic catalog stars accordance galactic model satisfy selection function observed data available download next compare predicted observed distribution various stellar properties apparent magnitude vjk Î½max Îºm latter seismic mass proxy includes Î½max sample data prescribed galactic model use code sharma et al uses galactic model initially based besanÃ§on model robin et al crucial modifications described sharma et al one significant change shift mean effective metallicity thick disc model metal rich thick disc hereafter referred galaxia mr main steps creating synthetic catalog follows using galaxia create magnitude limited samples j campaign circular area degree radius stars filtered accordance selection function color magnitude angular coordinates described table provide python next synthetic stars without replacement match total number observed stars campaign follow selection function column table reality reduce poisson noise oversample synthetic stars factor reference purposes also show results kepler mission selection function adopt kepler given equations sharma et al full details reproduce keplerselection function found sharma et al seismic quantities Î½max synthetic stars estimated effective temperature teff surface gravity g density Ï using following asteroseismic scaling relations brown et al kjeldsen bedding ulrich Î½max Î½max g g teff teff Ï Ï correction factor derived sharma et al analyzing theoretical oscillation frequencies http http https gyre townsend teitler stellar models generated mesa paxton et al used code sharma et al computes correction factor function metallicity z initial mass evolutionary state estate pre post helium ignition teff logg random scatter based median observed uncertainty campaign added estimated values Î½max discussed earlier section expect detect oscillations range however probability measure Î½max constant range oscillation amplitude general decreases Î½max overall noise extracted power spectrum increases increasing apparent magnitude means fainter magnitudes high Î½max stars less likely show detectable oscillations model seismic detection probability follow scheme presented chaplin et al campante et al exact procedure adopted given section sharma et al short oscillation amplitude estimated based stellar luminosity mass temperature apparent magnitude used compute instrumental noise power spectrum combined granulation noise gave total noise mean oscillation power total noise used derive probability detecting oscillations less possibility false alarm stars detection probability greater assumed detectable distribution stars Î½max vjk plane figure shows distribution observed stars vjk Î½max plane different campaigns first third columns results kepler panel ag combination campaigns panel ai also shown heat maps second fourth columns show number ratio observed predicted giants see Î½max measured stars faint vjk however efficiency seems decrease beyond vjk dark region figure seen lack observed stars upper right corner red dashed line red dashed line roughly identifies threshold beyond theory predicts oscillations would hard detect low oscillation amplitude high Î½max high noise faint stars ratio observed predicted number stars varies campaign campaign typically averaged campaigns ratio section figure know giants expected missing extra missing giants likely due fact model overpredicts http sharma et al number giants stars mks compared dwarfs stars j needs investigation could also due turnoff stars bluer model hence getting excluded j ks cut used select stars campaign unusually low numbers observed stars compared prediction ratio could related data quality doubtful couple reasons firstly due error initial roll angle correction applied days campaign result campaign split two segments secondly pointing towards galactic bulge highest stellar density amongst campaigns analyzed due high stellar density pipelines used extracting light curves well subsequent asteroseismic analysis likely operating outside nominal design range severely hamper quality derived asteroseismic parameters following two sections look distributions shown figure collapsed onto either axis distribution apparent magnitude figure show distribution apparent magnitude vjk giants Î½max detections shows good agreement model data good match primarily reflection fact model correctly reproduces number giants function magnitude good match vjk sense necessary condition embark detailed comparison model predictions observations number observed predicted giants listed panel seen model overpredicts number oscillating giants discuss detail later distribution Î½max figure show observed distribution Î½max alongside model predictions distribution shows peak around Î½max Âµhz corresponding rc stars peak observed stars significantly shallower compared prediction could due uncertainty Î½max underestimated model model inaccurate could also due rc stars preferentially escaping detection observed peak systematically shifted lower Î½max compared predictions except interestingly point towards direction suggesting model requires changes distribution stars Î½max Îºm plane turn Îºm Î½max Î½max b c e f g h j k l n p vjk mag q kepler vjk mag r galaxia mr observed figure magnitude distribution observed oscillating giants along predictions galaxia model mr number stars Î½max detections observed sample predicted model also listed panel essentially seismic proxy stellar mass mass one useful asteroseismic quantities helps us determine stellar age hence comparing observed distribution Îºm theoretical models central theme galactic archaeology begin studying distribution stars Î½max Îºm plane plane also useful study properties rc red giant branch rgb stars separately sharma et al showed used segregate rc rgb stars rc stars show sharp edge plane feature used li et al measure intrinsic scatter asteroseismic scaling relations figure shows Î½max Îºm distribution stars top row kepler sample third row target selection b p c p e f p g h j p k l n p p max hz kepler q max hz r galaxia mr observed figure probability distribution Î½max observed predicted oscillating giants dashed line Î½max Âµhz shows approximate location peak distribution predicted stars peak corresponds location rc giants panel q shows distributions kepler panel r shows combined data campaigns observed peak systematically lower compared predictions except point towards direction model predictions kepler shown second fourth rows respectively distributions rc middle column rgb right column stars also shown separately rgb stars distributed wide range Î½max Îºm however rc stars form diagonal sequence lying narrow region marked two solid curves curves designed sharma et al segregate rc rgb aid eye comparing distributions different panels sharp right edge rc distribution clear density rgb distribution due stars partly overlaps location majority rc stars distributions kepler similar however rc sequence slightly sharper kepler likely due precise Î½max Îºm overall model predictions match well observed distributions comparison panel b panels middle column shows significant number stars right rightmost solid curve neither predicted model figure present kepler data figure suggests rgb stars misclassified rc stars unexpected given observations relatively short making seismic distinction uncertain hon et al rc stars high Î½max high Îºm secondary clump stars models figure k suggest upper limit around Âµhz Î½max kepler see stars way till Âµhz however data seems relatively fewer models also predict second sequence low Î½max stars end helium core burning agb clump stars seen data finally models location offset respect observations model location shifted lower Î½max known problem contemporary stellar evolution models silva aguirre et al distribution stars Îºm distribution Îºm one sensitive tests galactic models related mass turn related age hence distribution Îºm effectively age distribution stars sensitive star formation history radial migration galaxy sharma et al know given age mass star correlated metallicity hence distribution Îºm indirectly also probes age metallicity relation studies using kepler showed models predict number low Îºm stars sharma et al however doubts reproducibility complicated selection function kepler prevented us drawing strong conclusions problem alleviated simple selection function using data four campaigns sharma et al showed discrepancy due metallicity thick disc low models figure repeat analysis using campaigns distributions rgb hrgb rc rgb lrgb stars shown separately done probability detect varies stellar type figure suggesting systematic effects different stellar types stars split categories based location Î½max Îºm plane see figure hrgb left leftmost solid curve rc two solid curves lrgb right sharma et al figure distribution stars Îºm Î½max plane panels b c show result stars panels e f show theoretical predictions panels g h show results kepler stars panels j k l show theoretical predictions kepler left columns show results stars middle columns show results rc stars right columns show results rgb stars solid lines two curves horizontal line drawn aid eye comparing distributions different panels two curves sharma et al designed roughly identify rc stars target selection table ratio observed median Îºm predicted galaxia mr different giant classes uncertainties computed ratio also listed outlier excluded averaging campaigns campaign hrgb rc lrgb kepler solid curve results confirm findings sharma et al figure shows lrgb stars observed Îºm distribution good agreement predictions agreement also good hrgb stars models seems slightly predict number low mass stars however rc models seem significantly predict number low mass stars seen clearly figure combine results campaigns boost sample size predicted distribution old galaxia model metal poor thick disc also shown comparison even reproduce Îºm distribution lrgb stars detailed quantitative comparison given table list ratio observed predicted median Îºm different campaigns simply reinforce qualitative trends discussed mismatch observed predicted distribution rc stars table could due model inaccurate example inaccuracies galactic model underlying stellar models inaccuracies predicting asteroseismic parameters modelled sample however given fails measure significant number rc stars figure possible low mass stars preferentially evade measurement circumstantial evidence support kepler incompleteness also see discrepancy model predictions asteroseismic scaling relations galactic archaeology asteroseismology provide ages giant stars hence promising tool studying galactic structure evolution however proven difficult check accuracy ages masses estimated asteroseismology due shortage independent estimates mass age earlier studies indicated asteroseismology overestimated masses found comparing expected mass metal poor giants kepler sample epstein et al dynamical mass measurements binary systems gaulme et al based stello et al sharma et al showed theoretically motivated corrections scaling relation important take account corrections enough resolve discrepancy metal poor giants noticed epstein et al however situation regrading eclipsing binaries complicated gaulme et al suggested overestimation mass spite corrections work brogaard et al suggested good match dynamical masses least binaries population galactic models provide indirect way validate asteroseismic estimates assuming models sufficiently accurate models constructed independently asteroseismology built satisfy number observations photometric star counts kinematics stellar abundances spectroscopic surveys mentioned previous section studies using kepler mission revealed models predict many low mass stars compared observed mass distributions giants sharma et al subgiants sharma et al raised doubts accuracy asteroseismic scaling relations galactic models selection function sharma et al revisited analyzing asteroseismic data four campaigns mission well defined selection function showed metallicity distribution galactic models updated match measurements recent spectroscopic surveys distribution asteroseismic masses low luminosity giants good agreement model predictions mentioned previous section result confirmed using data campaigns number new interesting developments happened since analysis sharma et al sharma et al updated metallicity galactic model based results latest data release metallicity thick disc stars lower dex make models overpredict number low mass stars recent results sharma et al b suggest thick disc model adopted galaxia sharma et al p hrgb b rc c lrgb p hrgb e rc f lrgb p g hrgb h rc lrgb p j hrgb k rc l lrgb p hrgb n rc lrgb p p hrgb q rc r lrgb p hrgb rc u lrgb p v hrgb w rc x lrgb p hrgb z rc aa lrgb p ab hrgb ac rc ad lrgb p ae hrgb af rc ag lrgb p ah hrgb ai rc aj lrgb p ak hrgb al rc lrgb p hrgb ao rc ap lrgb p aq hrgb ar rc lrgb p hrgb au rc av lrgb p aw kepler hrgb ax kepler rc ay kepler lrgb galaxia mr observed figure distribution Îºm different campaigns kepler distributions three different stellar classes rgb rc low luminosity rgb stars shown separately classification done using two solid curves figure panel number observed predicted stars listed right hand side bottom row shows distributions kepler target selection p hrgb b rc c lrgb p kepler hrgb e kepler rc f kepler lrgb galaxia mp galaxia mr observed figure distribution Îºm oscillating giants kepler distributions rgb rc low luminosity rgb stars shown separately predictions based galaxia metal poor mp metal rich mr model also shown panel tic results suggest distinct thick disc instead whole disc considered continuous sequence stars age natural boundary thick thin discs stellar abundances shown function stellar age birth radius radial migration playing crucial role moving stars place birth effect new model distribution stellar masses expected small still needs tested sharma et al showed kinematics used estimate age ensemble stars hence test asteroseismic scaling relations concluded asteroseismic ages kepler stars underestimated least mass overestimated however correction required exact reason systematic difference kepler yet clear however clear systematic due light curve significantly shorter zinn et al demonstrate figure kepler data shortened time baselines leads underestimation Î½max hence mass good agreement findings sharma et al consistent results lrgb stars shown table shows mass overestimated kepler words masses lower kepler another interesting systematic associated asteroseismic mass age given warfield et al suggest ages high stars underestimated stellar models excellent agreement sharma et al traditionally salaris cassisi formula used account enhancement assuming solar composition increasing metallicity warfield et al suggests approach sufficient conclude kepler results taking systematic due light curve length account suggest discrepancy observed predicted masses observed masses higher discussion conclusions paper provided overview motivation guest observer program whose main aim study galaxy asteroseismology giants program designed select stars easily reproducible selection function total targets proposed accounting stellar targets observed amongst stars follow well defined selection one important contributions work providing rigorous selection function criteria campaign tabular form python code implementing selection function also provided also provide catalog stars observed along flags identify stars belonging sharma et al gram stars strictly satisfy prescribed selection criteria order facilitate comparison predictions theoretical galactic models also provide selectionmatched mock catalogs generated using galaxia present simple efficient change point identification algorithm used screen stars proposed serendipitously selected nasa guest observer programs work provides useful guidelines designing future astronomy surveys quite often know targets want based property targets however lack decisive data measures property cases tempting design overly sophisticated approaches cases lead marginal increase efficiency selecting right targets show situations possible adopting holistic approach greatly simplify selection function applied simple color criteria focus giants inevitably led dwarfs sample useful asteroseismology cadence however recognizing fact useful exoplanet studies effort made exclude greatly simplified selection function show asteroseismic giants span wide range r galaxy offering significant advantage galactic studies compared kepler also contains significantly older stars kepler useful probe early history galaxy however wider coverage comes price light curves shorter duration consequently lower making use gaia parallaxes identify giants bright enough show oscillations appreciable snr use study Î½max measurement completeness find giants Î½max measured exact cause known requires investigation unlike kepler stars Î½max measurements measurement probability detect maximum around Î½max Âµhz falls higher lower values Î½max due lower snr frequency resolution compared kepler makes detection harder additionally results suggest difficult detect rc star compared rgb star likely due oscillation power spectra rc stars complex campaign compare observed distribution various asteroseismic parameters predictions galactic model using galaxia comparison useful test model theory also useful check quality data especially important collected data various campaigns unique technical difficulties challenges full course mission campaigns observed number giants Î½max measurements roughly agreement predictions ratio stars however ratio exceptionally low investigations suggest could due roll angle error shortened light curve particular field distribution stars Î½max Îºm plane shows good match model predictions rgb rc stars however differences could also seen rc sequence sharp kepler due higher uncertainty Î½max Îºm compared kepler location lower Î½max models compared observations expected shortcomings stellar evolution models silva aguirre et al rgb stars found classified rc also seems lack secondary rc stars observations compared model predictions kepler results compare observed Îºm distribution model predictions find low luminosity giants observed median Îºm higher predicted observed rc high luminosity giant distributions differ significantly predictions likely due significant incompleteness measurements low luminosity kepler giants observed median Îºm higher predicted hence general masses lower compared kepler agreement findings sharma et al based stellar kinematics discussed zinn et al see figure systematic offset due shorter time baseline compared kepler hence data kepler suggest asteroseismic masses higher compared model predictions discrepancy could due inaccurate modelling enhanced stars warfield et al could due inaccuracies modelling galactic disc sharma et al b future improvement stellar models galactic models required data availability datasets used available download http python code selection function available https acknowledgements would like thank entire community supporting gap ss funded senior fellowship university sydney arc centre excellence sky astrophysics dimensions research fellowship jbh laureate fellowship australian research council arc jbh supported arc target selection tralian laureate fellowship funding stellar astrophysics centre provided danish national research foundation grant agreement parts research conducted australian research council centre excellence sky astrophysics dimensions astro project number publication makes use data products two micron sky survey joint project university massachusetts infrared processing analysis institute technology funded national aeronautics space administration nasa national science foundation nsf paper includes data collected kepler mission mission funding kepler mission mission provided nasa science mission directorate work made use data european space agency esa mission gaia https gaia processed gaia data processing analysis consortium dpac https funding dpac provided national institutions particular institutions participating gaia multilateral agreement research made use vizier catalogue access tool cds strasbourg france doi original description vizier service published research made use following software python numpy harris et al matplotlib hunter references sharma et al mnras doi brogaard hansen miglio et al mnras doi brown gilliland noyes ramsey apj doi campante schofield kuszlewicz et al apj doi chaplin kjeldsen bedding et al apj doi de ridder barban baudin et al nature doi epstein elsworth johnson j et al apjl doi freeman j ara doi gaulme mckeever jackiewicz et al apj doi harris millman van der walt et al nature hon stello yu j mnras doi hon stello zinn apj doi huber bryson haas et al apjs doi hunter computing science engineering kjeldsen bedding li bedding stello et al mnras doi miglio montalbÃ¡n baudin et al doi mullally barclay barentsen field view software nasa mission http paxton bildsten dotter et al apjs doi paxton cantiello arras et al apjs doi rendle miglio chiappini et al mnras doi robin reylÃ© derriÃ¨re picaud doi salaris cassisi evolution stars stellar populations john wiley sons sharma johnston binney j apj doi sharma hayden j mnras doi sharma stello huber bedding apj doi sharma stello huber bedding apj doi sharma binney et al apj doi sharma stello buder et al mnras doi sharma stello et al mnras doi sharma hayden et al arxiv https arxiv https mnras doi silva aguirre cassisi et al doi sharma et al stello chaplin basu elsworth bedding mnras doi stello huber bedding et al apjl doi stello huber sharma et al apjl doi stello zinn elsworth et al apj doi townsend teitler mnras doi ulrich apjl doi warfield zinn pinsonneault et al aj doi zinn stello elsworth et al apjs doi arxiv https
draft version september typeset using latex twocolumn style galactic archaeology program overview target selection survey properties sanjib sharma dennis stello joel zinn joss institute astronomy school physics university sydney nsw australia centre excellence sky astrophysics three dimensions physics university new south wales sydney nsw australia astrophysics centre department physics astronomy aarhus university aarhus c denmark abstract nasa mission targets proposed guest observer programs among galactic archaeology program devoted measuring asteroseismic signals giant stars inform studies galaxy observed targets allocated program provide overview program discuss detail target selection procedure provide python code implements selection function additionally discuss detection completeness asteroseismic parameters Î½max broadly speaking targets selected based color j finely tuned adjustments campaign making use selection function compare observed distribution asteroseismic masses theoretical predictions median asteroseismic mass higher compared predictions additionally number seismic detections average lower expected provide mock catalog stars based synthetic model galaxy community used subsequent analyses data set keywords galaxy disc galaxy evolution galaxy formation galaxy kinematics dynamics introduction use asteroseismology inform studies milky way proposed decade ago miglio et al became possible first time detect oscillations hundreds even thousands distant stars using continuous photometric data missions particularly corot kepler de ridder et al stello et al however early missions far ideal studying galaxy whole indeed never designed mind sharma et al main reasons limited sky coverage lack target selection function well understood selection function fundamental make meaningful comparisons observed stellar populations sharma et al studies play important role making robust inferences galactic stellar populations decade ago primary nasa kepler mission targetted single field cygnus lyra constellations four years compromised satellite new mission stare days time different directions along ecliptic figure mission able probe stellar populations many directions covering much galaxy achieved earlier missions included halo bulge thin thick disks vastly different galactic radii heights plane take advantage opportunity galactic archaeology program formed around international collaboration aim detecting oscillations thousands red giants along ecliptic primary goal establish robust stellar ages major galactic stellar components rendle et al sharma et al significantly improve possible esa gaia spectroscopic survey data alone et al achieved devising reproducible target selection eliminate limitations previous spacebased seismic observations maximize synergy galactic spectroscopic surveys total provided observing campaigns fuel ran spacecraft retired end survey already published proof concept study stello et al along succession welltested data products data release containing seismic results campaign stello et al data release containing seismic results zinn et al final data release results campaigns one homogeneous catalog zinn et al addition science sep sharma et al galactic longitude degree galactic latitude degree kepler right ascension degree declination degree b figure footprint different campaigns galactic equatorial coordinates campaigns suitable studies shown green first three follow well defined selection seismic detections results published rendle et al sharma et al zinn et al overarching vision seismic data always combined complementary data many stellar surveys emerged decade recognition potential several large spectroscopic surveys targetted fields surveys largest overlap apogee lamost show synergy proved effective determining improved stellar ages thousands stars important goal galactic archaeology freeman paper report target selection campaign detail discuss detection completeness asteroseismic parameters Î½max oscillating target selection j ks ks stars j ks b max stars figure color absolute magnitude distribution stars observed minute cadence gaia parallax absolute magnitude estimated using gaia parallax vertical line j marks color selection number stars bin indicated color bar b subset stars asteroseismic detection Î½max stars Î½max detections j stars Î½max detected mks either incorrect Î½max parallax vjk giant fraction j ks giants mks degree figure fraction stars proposed giants function apparent magnitude vjk different campaigns stars satisfy selection function given table giants identified based absolute magnitude mks mks estimated using gaia parallaxes giants make detailed comparison observed distribution stars Î½max vjk Îºm selectionmatched mock catalogs finally discuss implications results asteroseismic relations galactic archaeology method primary target selection strategy target selection strategy designed easily reproducible aids study ensembles rather individual stars especially important galactic archaeology need fit galactic models observational data taking target selection account sharma et al also useful exoplanet population studies necessary first step selecting targets input catalog well understood reliable photometry covers regions sky interested mind adopt catalog robust photometry completeness magnitude range targeting vjk color limit j ks adopted throughout survey designed focus red giants primary asteroseismic targets seen figure stars detect oscillations j mks stars j typically dwarfs mks oscillation frequencies large detected cadence color limit j ks excludes giants blue extension red clump stars horizontal branch predominantly rare although reduced proper motions used separate dwarfs giants past avoided multiple reasons first introduces kinematic bias undesirable galactic archaeology secondly proper motions available ucac time selection significant uncertainties finally dwarfs interested desirable exoplanet studies simple selection function would also benefit summary simplest color based selection criteria found best suited galactic archaeology exoplanet population studies addition color stars restricted apparent magnitude brightness lower upper limit lower bright limit chosen avoid overly saturated stars upper faint limit chosen avoid observing ensembles low yield oscillating giants first campaigns used h magnitude select brightness however later campaigns adopted vjk j exp j approximation v band magnitude measured j k bands shown sharma et al formula accurate dex stars adopted vjk later campaigns collects data k p band significantly bluer h band additionally spectroscopic surveys like sharma et al lamost following targets observe v band bright magnitude limit vjk h adopted however faint limit different sharma et al ra deg dec deg deg radius broken ccd ccd figure field view typical campaign shown campaign solid lines outline ccds arranged modules broken modules shown red green circle shows degree radius field view hermes spectrograph note module numbers defined us similar official module numbers numbering starts exclude four corner modules two broken modules campaign typical limit vjk limit campaign determined weighing potential scientific return versus drop yield oscillating giants going towards fainter magnitudes drop yield oscillating giants going fainter due couple reasons first galaxy overall fraction stars giants given apparent magnitude drops go fainter magnitudes shown figure secondly fainter stars lower ratio hinders ability detect oscillations based simulations incompleteness observations predicted set around vjk see section details prompted us propose targets general faint field view certain studies important know completeness observed sample well foot print field view field view square degrees comprising mosaic ccd modules made two pixel ccds arcsec pixel scale slight gaps two ccds modules see figure although actual area module square degrees proposed stars confined square degrees likely due buffer pixels introduced python package mullally et al used select targets certain campaigns high target density proposed stars degree circles located center selected ccd modules make spectroscopic followup easier see figure circle photosensitive area square degrees circle area given size maximum possible photosensitive area among circle placements catalog targets provide master catalog targets observed file construct catalog start list observed targets kepler science website also contains campaign names campaign convert integer cno list includes targets selected programs proposed first cross matched epic catalog based added columns supplement photometric information cross match instead relying information provided epic catalog huber et al epic catalog missing entries targets spite targets stars moreover columns mflg prox incorrect majority stars epic flags among others used select stars good quality photometry table catalog contains targets rest paper exclusively focus targets rest targets like asteroids planets moons base catalog added two additional columns provide information targets target list total amounts observed targets stars also include serendipitous ones selected programs target list remove serendipitous targets create sample referred complete following procedure described section majority complete targets follow strict color magnitude selection function identified python module provided mission team identify target within field view https http fits http target selection table selection function targets campaign first column campaign number selection given last column eighth columns two seven list number stars given data set set right subset set left second column lists stars observed third column lists stars observed target list fourth column lists stars complete meaning excludes serendipitous observations targets programs fifth column lists stars satisfy strict selection function given eighth column sixth column lists completeness fraction stars fifth column seventh column lists stars Î½max measurement range Âµhz finally eighth column selection function stars effectively j due quality cuts c gap gap gap fcomp Î½max selection function sf obs obs com sf sf sf j j h j h c j h h c j vjk j vjk j vjk j vjk c vjk c j vjk j vjk j vjk j vjk j vjk vjk c vjk c vjk c j vjk j vjk vjk c vjk c vjk c vjk c j vjk j vjk vjk c vjk c vjk c vjk c j vjk j vjk vjk c vjk c j vjk circular pointing identifier c shown figure campaign numbers greater equal ccd module corresponding c broken table quality selection criteria fflag description criterion criterion qflag bbb aaa j h k photometric quality bflag blend flag cflag contamination flag xflag ext source aflag solar system object prox arcsec arcsec distance nearest star peculiarities certain campaigns due late change roll angle actual field view slightly shifted compared one provided software observations meant proposed targets unobservable later permanent failure one ccd modules marked figure occurring observations target selection locked resulted selected stars falling module partly observed affected campaigns campaigns unique little seismic detections conducted fulllength engineering test prove viability sharma et al figure distribution stars observed campaigns stars selected lie one degree radius circles campaign one degree circles numbered located centers ccd module excluding two broken ccd modules table priority order selecting targets order description criterion used campaigns apogee j logg rave j logg j logg misc miscellaneous special targets segue g r logg r snr nnnnn Î½max stars Î½max measurements previous campaigns primary j sdss g r r lcolor sdss Âµreduced g r r Âµreduced Âµreduced j vjk Âµreduced secondary j vjk circles c clist k sion fine tune observational setup pointing choice aperture size dedicated gravitational microlensing studies hence community targets sought light curves shorter duration observations terminated days due low fuel targets observed found serendipitous selections hence selection function known observations lasted target selection fraction observed fraction observed b fraction observed c row fraction observed figure fraction stars observed function row list targets proposed sharp fall fraction marks row number sample complete campaigns completeness typically high greater slightly lower completeness respectively completeness low due roll angle error due extra targets proposed broken ccd module also slightly lower completeness due extra targets proposed broken ccd module shows fall fraction cause clear days spacecraft ran fuel campaign also suffered erratic pointing proposed targets describe procedure adopted creating proposed target list separate target lists created campaign general stars selected good quality photometry defined table targets list sorted based priority list various priority classes order given table classes order less stars known giants either spectroscopy asteroseismology special targets included stars existing spectroscopy surveys apogee rave segue previous experience kepler known seismic detections possible logg given spectrocopic logg uncertainties order dex criterion logg adopted spectroscopic sample lower limit logg adopted stars logg classes order number greater equal stars selected based photometry make proposed sample class order number used campaigns provided bulk targets stars selected simply based color magnitude priority sorted magnitude class order number makes use color lcolor defined term u g r band sdss magnitude classes order numbers additionally made use reduced proper motion Âµreduced q Âµ ra dec arcsec rsdss defined term proper motion Âµra Âµdec r band sdss magnitude general stars proposed entire field view see section however certain campaigns look plane galactic disc stars proposed one degree circles located center ccd modules done make spectroscopic followup easier final target list uploaded spacecraft observation prepared nasa contained targets different proposals hence proposed targets serendipitous selections selection based proposals happened also target list serendipitous targets therefore follow proposed priority order guided figure devised procedure exclude targets figure shows average fraction stars selected list function list row number see fraction high almost constant small row numbers abruptly falls low value remains low rest list sharp fall fraction marks special row number sample selection complete beyond serendipitous targets identifying special row number sample selection complete change point sharma et al r kpc z kpc kpc p b r xhelio kpc yhelio kpc c kpc p figure spatial distribution oscillating giants using parallax information gaia panels b show distribution galactocentric cylindrical coordinates r z away plane radial coverage r extends way kpc kpc however close plane radial extent quite limited panels c show distribution heliocentric cartesian coordinates xhelio yhelio distance detection problem propose novel algorithm quantifying change point given argmax x si fc si binary state variable star selected otherwise procedure identifies row number completeness f changes greater fc less fc fc free tunable parameter set actual change point sensitive exact choice fc using procedure total found free serendipitous targets refer complete sample sample identify stars color magnitude complete following selection function listed table asteroseismic parameters giants paper use two seismic quantities frequency maximum oscillation power Î½max frequency separation overtone oscillation modes values use syd results also adopted reyes et al submitted catalog zinn et al used associate detection probabilities pÎ½max based hon et al based reyes et al submitted target assumed invalid target pÎ½max assumed invalid Î½max applying definitions total targets valid Î½max total targets valid note stars observed multiple campaigns means multiple targets hence results correspond star consistent sharma et al use syd results stello et al comparing kepler total targets valid Î½max results spatial distribution oscillating giants one main advantages mission kepler mission wider coverage galaxy seen figure shows spatial distribution oscillating giants galaxy giants span wide region r z plane kepler giants target selection mks x e e c tio n p r b bilit vjk kepler figure probability detecting Î½max function absolute magnitude mks probability measured ratio stars Î½max detections number stars observed bin mks average probability range mks kepler max hz n n max campaign figure fraction stars Î½max detections also detections fined small range around r r specially useful studying formation evolution galaxy away plane radial coverage r extends way kpc kpc figure blue curve however close plane radial extent quite limited figure z kpc heliocentric x projection giants seen four quadrants lower half defined yhelio figure although giants extend distance kpc sun stars within distance kpc figure green curve probability detect Î½max bright stars mission expected detect oscillations stars lower limit Î½max due duration observations upper limit due min cadence data absolute magnitude example mks increases increasing Î½max hence stars Î½max measurements confined range mks suggests mks used estimate overall detection probability seen figure plot ratio stars Î½max measurement number observed stars function mks probability range mks approximately constant falls either end stars mks Î½max high measurable stars mks Î½max low average probability range mks found kepler represents overall probability detect Î½max probability kepler slightly higher likely due higher snr resulting light curves times longer kepler high detection probability zone extends lower values mks expected due kepler light curves significantly longer restrict analysis bright stars vjk fainter stars low progressively makes harder detect Î½max specially stars high Î½max lower oscillation amplitudes lowering bright limit vjk found effect detection probability profile shown figure probability detect given Î½max figure show probability detecting given Î½max detection campaign shown separately probability computed fraction stars Î½max detection also detection fraction shows undulating behaviour two peaks arise global smooth hill shape peaks Î½max local dip near Î½max global shape drop towards lower Î½max due lower limit set day duration light curve becomes harder resolve drop towards higher Î½max Î½max approaches nyquist frequency dip Î½max corresponds location red clump rc stars shows generally harder detect clump stars asteroseismic completeness pipeline results function mass radius considered zinn et al comparing observed asteroseismic data galactic model predictions one main aims study formation evolution milky way important step process compare observed asteroseismic data predictions current galactic model help identify major issues need addressed fine tuning model campaign unique characteristics light curve duration pointing accuracy crowding varying campaign campaign hence important highlight sharma et al max hz b c max hz e f g h max hz j k l max hz n p max hz q r max hz u v w x max hz z aa ab max hz ac ad ae af vjk mag max hz ag kepler vjk mag ah kepler vjk mag ai vjk mag aj nobs nobs figure distribution observed first third columns stars Î½max vjk plane different campaigns results kepler shown panel ag combined results campaigns except shown ai panels second fourth columns plot ratio observed predicted oscillating giants bin average recovery rate shown top right panel predictions based simulations using galaxia dashed line represents equation Î½max vjk upper right region dashed line indicates detect oscillations due low target selection campaigns way problematic example observations agree model predictions campaigns others strong evidence problematic campaigns described selection function detection completeness proceed performing model comparison begin creating synthetic catalog stars accordance galactic model satisfy selection function observed data available download next compare predicted observed distribution various stellar properties apparent magnitude vjk Î½max Îºm latter seismic mass proxy includes Î½max sample data prescribed galactic model use code sharma et al uses galactic model initially based besanÃ§on model robin et al crucial modifications described sharma et al one significant change shift mean effective metallicity thick disc model metal rich thick disc hereafter referred galaxia mr main steps creating synthetic catalog follows using galaxia create magnitude limited samples j campaign circular area degree radius stars filtered accordance selection function color magnitude angular coordinates described table provide python next synthetic stars without replacement match total number observed stars campaign follow selection function column table reality reduce poisson noise oversample synthetic stars factor reference purposes also show results kepler mission selection function adopt kepler given equations sharma et al full details reproduce keplerselection function found sharma et al seismic quantities Î½max synthetic stars estimated effective temperature teff surface gravity g density Ï using following asteroseismic scaling relations brown et al kjeldsen bedding ulrich Î½max Î½max g g teff teff Ï Ï correction factor derived sharma et al analyzing theoretical oscillation frequencies http http https gyre townsend teitler stellar models generated mesa paxton et al used code sharma et al computes correction factor function metallicity z initial mass evolutionary state estate pre post helium ignition teff logg random scatter based median observed uncertainty campaign added estimated values Î½max discussed earlier section expect detect oscillations range however probability measure Î½max constant range oscillation amplitude general decreases Î½max overall noise extracted power spectrum increases increasing apparent magnitude means fainter magnitudes high Î½max stars less likely show detectable oscillations model seismic detection probability follow scheme presented chaplin et al campante et al exact procedure adopted given section sharma et al short oscillation amplitude estimated based stellar luminosity mass temperature apparent magnitude used compute instrumental noise power spectrum combined granulation noise gave total noise mean oscillation power total noise used derive probability detecting oscillations less possibility false alarm stars detection probability greater assumed detectable distribution stars Î½max vjk plane figure shows distribution observed stars vjk Î½max plane different campaigns first third columns results kepler panel ag combination campaigns panel ai also shown heat maps second fourth columns show number ratio observed predicted giants see Î½max measured stars faint vjk however efficiency seems decrease beyond vjk dark region figure seen lack observed stars upper right corner red dashed line red dashed line roughly identifies threshold beyond theory predicts oscillations would hard detect low oscillation amplitude high Î½max high noise faint stars ratio observed predicted number stars varies campaign campaign typically averaged campaigns ratio section figure know giants expected missing extra missing giants likely due fact model overpredicts http sharma et al number giants stars mks compared dwarfs stars j needs investigation could also due turnoff stars bluer model hence getting excluded j ks cut used select stars campaign unusually low numbers observed stars compared prediction ratio could related data quality doubtful couple reasons firstly due error initial roll angle correction applied days campaign result campaign split two segments secondly pointing towards galactic bulge highest stellar density amongst campaigns analyzed due high stellar density pipelines used extracting light curves well subsequent asteroseismic analysis likely operating outside nominal design range severely hamper quality derived asteroseismic parameters following two sections look distributions shown figure collapsed onto either axis distribution apparent magnitude figure show distribution apparent magnitude vjk giants Î½max detections shows good agreement model data good match primarily reflection fact model correctly reproduces number giants function magnitude good match vjk sense necessary condition embark detailed comparison model predictions observations number observed predicted giants listed panel seen model overpredicts number oscillating giants discuss detail later distribution Î½max figure show observed distribution Î½max alongside model predictions distribution shows peak around Î½max Âµhz corresponding rc stars peak observed stars significantly shallower compared prediction could due uncertainty Î½max underestimated model model inaccurate could also due rc stars preferentially escaping detection observed peak systematically shifted lower Î½max compared predictions except interestingly point towards direction suggesting model requires changes distribution stars Î½max Îºm plane turn Îºm Î½max Î½max b c e f g h j k l n p vjk mag q kepler vjk mag r galaxia mr observed figure magnitude distribution observed oscillating giants along predictions galaxia model mr number stars Î½max detections observed sample predicted model also listed panel essentially seismic proxy stellar mass mass one useful asteroseismic quantities helps us determine stellar age hence comparing observed distribution Îºm theoretical models central theme galactic archaeology begin studying distribution stars Î½max Îºm plane plane also useful study properties rc red giant branch rgb stars separately sharma et al showed used segregate rc rgb stars rc stars show sharp edge plane feature used li et al measure intrinsic scatter asteroseismic scaling relations figure shows Î½max Îºm distribution stars top row kepler sample third row target selection b p c p e f p g h j p k l n p p max hz kepler q max hz r galaxia mr observed figure probability distribution Î½max observed predicted oscillating giants dashed line Î½max Âµhz shows approximate location peak distribution predicted stars peak corresponds location rc giants panel q shows distributions kepler panel r shows combined data campaigns observed peak systematically lower compared predictions except point towards direction model predictions kepler shown second fourth rows respectively distributions rc middle column rgb right column stars also shown separately rgb stars distributed wide range Î½max Îºm however rc stars form diagonal sequence lying narrow region marked two solid curves curves designed sharma et al segregate rc rgb aid eye comparing distributions different panels sharp right edge rc distribution clear density rgb distribution due stars partly overlaps location majority rc stars distributions kepler similar however rc sequence slightly sharper kepler likely due precise Î½max Îºm overall model predictions match well observed distributions comparison panel b panels middle column shows significant number stars right rightmost solid curve neither predicted model figure present kepler data figure suggests rgb stars misclassified rc stars unexpected given observations relatively short making seismic distinction uncertain hon et al rc stars high Î½max high Îºm secondary clump stars models figure k suggest upper limit around Âµhz Î½max kepler see stars way till Âµhz however data seems relatively fewer models also predict second sequence low Î½max stars end helium core burning agb clump stars seen data finally models location offset respect observations model location shifted lower Î½max known problem contemporary stellar evolution models silva aguirre et al distribution stars Îºm distribution Îºm one sensitive tests galactic models related mass turn related age hence distribution Îºm effectively age distribution stars sensitive star formation history radial migration galaxy sharma et al know given age mass star correlated metallicity hence distribution Îºm indirectly also probes age metallicity relation studies using kepler showed models predict number low Îºm stars sharma et al however doubts reproducibility complicated selection function kepler prevented us drawing strong conclusions problem alleviated simple selection function using data four campaigns sharma et al showed discrepancy due metallicity thick disc low models figure repeat analysis using campaigns distributions rgb hrgb rc rgb lrgb stars shown separately done probability detect varies stellar type figure suggesting systematic effects different stellar types stars split categories based location Î½max Îºm plane see figure hrgb left leftmost solid curve rc two solid curves lrgb right sharma et al figure distribution stars Îºm Î½max plane panels b c show result stars panels e f show theoretical predictions panels g h show results kepler stars panels j k l show theoretical predictions kepler left columns show results stars middle columns show results rc stars right columns show results rgb stars solid lines two curves horizontal line drawn aid eye comparing distributions different panels two curves sharma et al designed roughly identify rc stars target selection table ratio observed median Îºm predicted galaxia mr different giant classes uncertainties computed ratio also listed outlier excluded averaging campaigns campaign hrgb rc lrgb kepler solid curve results confirm findings sharma et al figure shows lrgb stars observed Îºm distribution good agreement predictions agreement also good hrgb stars models seems slightly predict number low mass stars however rc models seem significantly predict number low mass stars seen clearly figure combine results campaigns boost sample size predicted distribution old galaxia model metal poor thick disc also shown comparison even reproduce Îºm distribution lrgb stars detailed quantitative comparison given table list ratio observed predicted median Îºm different campaigns simply reinforce qualitative trends discussed mismatch observed predicted distribution rc stars table could due model inaccurate example inaccuracies galactic model underlying stellar models inaccuracies predicting asteroseismic parameters modelled sample however given fails measure significant number rc stars figure possible low mass stars preferentially evade measurement circumstantial evidence support kepler incompleteness also see discrepancy model predictions asteroseismic scaling relations galactic archaeology asteroseismology provide ages giant stars hence promising tool studying galactic structure evolution however proven difficult check accuracy ages masses estimated asteroseismology due shortage independent estimates mass age earlier studies indicated asteroseismology overestimated masses found comparing expected mass metal poor giants kepler sample epstein et al dynamical mass measurements binary systems gaulme et al based stello et al sharma et al showed theoretically motivated corrections scaling relation important take account corrections enough resolve discrepancy metal poor giants noticed epstein et al however situation regrading eclipsing binaries complicated gaulme et al suggested overestimation mass spite corrections work brogaard et al suggested good match dynamical masses least binaries population galactic models provide indirect way validate asteroseismic estimates assuming models sufficiently accurate models constructed independently asteroseismology built satisfy number observations photometric star counts kinematics stellar abundances spectroscopic surveys mentioned previous section studies using kepler mission revealed models predict many low mass stars compared observed mass distributions giants sharma et al subgiants sharma et al raised doubts accuracy asteroseismic scaling relations galactic models selection function sharma et al revisited analyzing asteroseismic data four campaigns mission well defined selection function showed metallicity distribution galactic models updated match measurements recent spectroscopic surveys distribution asteroseismic masses low luminosity giants good agreement model predictions mentioned previous section result confirmed using data campaigns number new interesting developments happened since analysis sharma et al sharma et al updated metallicity galactic model based results latest data release metallicity thick disc stars lower dex make models overpredict number low mass stars recent results sharma et al b suggest thick disc model adopted galaxia sharma et al p hrgb b rc c lrgb p hrgb e rc f lrgb p g hrgb h rc lrgb p j hrgb k rc l lrgb p hrgb n rc lrgb p p hrgb q rc r lrgb p hrgb rc u lrgb p v hrgb w rc x lrgb p hrgb z rc aa lrgb p ab hrgb ac rc ad lrgb p ae hrgb af rc ag lrgb p ah hrgb ai rc aj lrgb p ak hrgb al rc lrgb p hrgb ao rc ap lrgb p aq hrgb ar rc lrgb p hrgb au rc av lrgb p aw kepler hrgb ax kepler rc ay kepler lrgb galaxia mr observed figure distribution Îºm different campaigns kepler distributions three different stellar classes rgb rc low luminosity rgb stars shown separately classification done using two solid curves figure panel number observed predicted stars listed right hand side bottom row shows distributions kepler target selection p hrgb b rc c lrgb p kepler hrgb e kepler rc f kepler lrgb galaxia mp galaxia mr observed figure distribution Îºm oscillating giants kepler distributions rgb rc low luminosity rgb stars shown separately predictions based galaxia metal poor mp metal rich mr model also shown panel tic results suggest distinct thick disc instead whole disc considered continuous sequence stars age natural boundary thick thin discs stellar abundances shown function stellar age birth radius radial migration playing crucial role moving stars place birth effect new model distribution stellar masses expected small still needs tested sharma et al showed kinematics used estimate age ensemble stars hence test asteroseismic scaling relations concluded asteroseismic ages kepler stars underestimated least mass overestimated however correction required exact reason systematic difference kepler yet clear however clear systematic due light curve significantly shorter zinn et al demonstrate figure kepler data shortened time baselines leads underestimation Î½max hence mass good agreement findings sharma et al consistent results lrgb stars shown table shows mass overestimated kepler words masses lower kepler another interesting systematic associated asteroseismic mass age given warfield et al suggest ages high stars underestimated stellar models excellent agreement sharma et al traditionally salaris cassisi formula used account enhancement assuming solar composition increasing metallicity warfield et al suggests approach sufficient conclude kepler results taking systematic due light curve length account suggest discrepancy observed predicted masses observed masses higher discussion conclusions paper provided overview motivation guest observer program whose main aim study galaxy asteroseismology giants program designed select stars easily reproducible selection function total targets proposed accounting stellar targets observed amongst stars follow well defined selection one important contributions work providing rigorous selection function criteria campaign tabular form python code implementing selection function also provided also provide catalog stars observed along flags identify stars belonging sharma et al gram stars strictly satisfy prescribed selection criteria order facilitate comparison predictions theoretical galactic models also provide selectionmatched mock catalogs generated using galaxia present simple efficient change point identification algorithm used screen stars proposed serendipitously selected nasa guest observer programs work provides useful guidelines designing future astronomy surveys quite often know targets want based property targets however lack decisive data measures property cases tempting design overly sophisticated approaches cases lead marginal increase efficiency selecting right targets show situations possible adopting holistic approach greatly simplify selection function applied simple color criteria focus giants inevitably led dwarfs sample useful asteroseismology cadence however recognizing fact useful exoplanet studies effort made exclude greatly simplified selection function show asteroseismic giants span wide range r galaxy offering significant advantage galactic studies compared kepler also contains significantly older stars kepler useful probe early history galaxy however wider coverage comes price light curves shorter duration consequently lower making use gaia parallaxes identify giants bright enough show oscillations appreciable snr use study Î½max measurement completeness find giants Î½max measured exact cause known requires investigation unlike kepler stars Î½max measurements measurement probability detect maximum around Î½max Âµhz falls higher lower values Î½max due lower snr frequency resolution compared kepler makes detection harder additionally results suggest difficult detect rc star compared rgb star likely due oscillation power spectra rc stars complex campaign compare observed distribution various asteroseismic parameters predictions galactic model using galaxia comparison useful test model theory also useful check quality data especially important collected data various campaigns unique technical difficulties challenges full course mission campaigns observed number giants Î½max measurements roughly agreement predictions ratio stars however ratio exceptionally low investigations suggest could due roll angle error shortened light curve particular field distribution stars Î½max Îºm plane shows good match model predictions rgb rc stars however differences could also seen rc sequence sharp kepler due higher uncertainty Î½max Îºm compared kepler location lower Î½max models compared observations expected shortcomings stellar evolution models silva aguirre et al rgb stars found classified rc also seems lack secondary rc stars observations compared model predictions kepler results compare observed Îºm distribution model predictions find low luminosity giants observed median Îºm higher predicted observed rc high luminosity giant distributions differ significantly predictions likely due significant incompleteness measurements low luminosity kepler giants observed median Îºm higher predicted hence general masses lower compared kepler agreement findings sharma et al based stellar kinematics discussed zinn et al see figure systematic offset due shorter time baseline compared kepler hence data kepler suggest asteroseismic masses higher compared model predictions discrepancy could due inaccurate modelling enhanced stars warfield et al could due inaccuracies modelling galactic disc sharma et al b future improvement stellar models galactic models required data availability datasets used available download http python code selection function available https acknowledgements would like thank entire community supporting gap ss funded senior fellowship university sydney arc centre excellence sky astrophysics dimensions research fellowship jbh laureate fellowship australian research council arc jbh supported arc target selection tralian laureate fellowship funding stellar astrophysics centre provided danish national research foundation grant agreement parts research conducted australian research council centre excellence sky astrophysics dimensions astro project number publication makes use data products two micron sky survey joint project university massachusetts infrared processing analysis institute technology funded national aeronautics space administration nasa national science foundation nsf paper includes data collected kepler mission mission funding kepler mission mission provided nasa science mission directorate work made use data european space agency esa mission gaia https gaia processed gaia data processing analysis consortium dpac https funding dpac provided national institutions particular institutions participating gaia multilateral agreement research made use vizier catalogue access tool cds strasbourg france doi original description vizier service published research made use following software python numpy harris et al matplotlib hunter references sharma et al mnras doi brogaard hansen miglio et al mnras doi brown gilliland noyes ramsey apj doi campante schofield kuszlewicz et al apj doi chaplin kjeldsen bedding et al apj doi de ridder barban baudin et al nature doi epstein elsworth johnson j et al apjl doi freeman j ara doi gaulme mckeever jackiewicz et al apj doi harris millman van der walt et al nature hon stello yu j mnras doi hon stello zinn apj doi huber bryson haas et al apjs doi hunter computing science engineering kjeldsen bedding li bedding stello et al mnras doi miglio montalbÃ¡n baudin et al doi mullally barclay barentsen field view software nasa mission http paxton bildsten dotter et al apjs doi paxton cantiello arras et al apjs doi rendle miglio chiappini et al mnras doi robin reylÃ© derriÃ¨re picaud doi salaris cassisi evolution stars stellar populations john wiley sons sharma johnston binney j apj doi sharma hayden j mnras doi sharma stello huber bedding apj doi sharma stello huber bedding apj doi sharma binney et al apj doi sharma stello buder et al mnras doi sharma stello et al mnras doi sharma hayden et al arxiv https arxiv https mnras doi silva aguirre cassisi et al doi sharma et al stello chaplin basu elsworth bedding mnras doi stello huber bedding et al apjl doi stello huber sharma et al apjl doi stello zinn elsworth et al apj doi townsend teitler mnras doi ulrich apjl doi warfield zinn pinsonneault et al aj doi zinn stello elsworth et al apjs doi arxiv https
sinkhorn distributionally robust optimization jie wang school industrial systems engineering georgia institute technology atlanta ga rui gao department information risk operations management university texas austin austin tx yao xie school industrial systems engineering georgia institute technology atlanta ga study distributionally robust optimization sinkorn variant wasserstein distance based entropic regularization derive convex programming dual reformulations nominal distribution empirical distribution general distribution respectively compared wasserstein dro computationally tractable larger class loss functions distribution reasonable solve dual reformulation propose efficient batch gradient descent bisection search algorithm finally provide various numerical examples using synthetic real data demonstrate competitive performance key words wasserstein distributionally robust optimization sinkhorn distance duality theory introduction problems uncertainty broad applications operations research machine learning engineering economics data involves uncertainty due measurement error insufficient sample size contamination anomalies model misspecification distributionally robust optimization dro promising approach optimization seeking minimax robust optimal decision minimizes expected loss adverse distribution within given set relevant distributions called ambiguity set provides principled framework produce solution promising performance traditional sample average approximation saa method stochastic programming refer recent survey dro core dro choice ambiguity set ideally good ambiguity set take account properties practical applications maintaining computational tractability resulted dro formulation rich enough contain distributions relevant time include unnecessary distributions lead overly conservative decisions various dro formulations proposed literature among ambiguity set based wasserstein distance recently received much attention wasserstein distance incorporates geometry sample space thereby suitable comparing distributions supports hedging data perturbations nice statistical performance guarantees established wasserstein dro asymptotically empirically variety applications operations research machine learning stochastic control etc see references therein discussions also provide detailed literature survey end section hand current wasserstein dro framework without limitation first computational efficiency perspective tractability wasserstein dro usually available somewhat stringent conditions loss function dual formulation involves subproblem requires global supremum regularized loss function sample space particular dro convex reformulation known loss function expressed sep pointwise maximum finitely many concave functions efficient algorithm proposed special loss functions logistic loss dro efficient algorithms developed smooth loss functions sufficiently small radius equivalently sufficiently large lagrangian multiplier involved subproblem becomes strongly convex second modeling perspective wasserstein dro nominal distribution finitely supported usually empirical distribution distribution shown discrete distribution despite underlying true distribution many practical applications may well continuous raises concern whether wasserstein dro hedges right family distribution whether causes potentially performance address potential issues maintaining advantages wasserstein dro paper propose sinkhorn dro hedges distributions close nominal distribution sinkhorn distance sinkhorn distance viewed smoothed wasserstein distance defined cheapest transport cost two distributions associated optimal transport problem entropic regularization see definition section far know paper first study dro formulation using sinkhorn distance main contributions summarized follows derive strong duality reformulation sinkhorn dro theorem nominal distribution empirical distribution section nominal distribution arbitrary distribution section sinkhorn dual objective smooths maximization subproblem wasserstein dual objective converges wasserstein dual objective entropic regularization parameter goes zero remark moreover dual objective sinkhorn dro upper bounded dro nominal distribution kernel density estimator remark ii byproduct duality proof characterize distribution sinkhorn dro remark absolutely continuous respect reference measure lebesgue counting measure compared wasserstein dro distribution sinkhorn dro necessarily finitely supported even nominal distribution finitely supported distribution indicates sinkhorn dro flexible modeling choice many applications iii algorithmic aspect propose computationally efficient method solving sinkhorn dro problem section based batch gradient descent bisection search convergence guarantees also developed compared wasserstein dro dual problem sinkhorn dro computationally tractable measurable loss functions iv provide experiments section validate performance proposed sinkhorn dro model context newsvendor problem portfolio optimization learning using synthetic real data sets numerical results demonstrate superior performances compared several benchmarks including saa wasserstein dro dro related literature dro models construction ambiguity sets plays key role performance dro models generally two ways construct ambiguity sets literature first ambiguity sets defined using descriptive statistics support information moment conditions shape constraints marginal distributions second recently popular approach makes full use available data consider distributions within statistical distance nominal distribution usually chosen empirical distribution samples commonly used statistical distances used literature include wasserstein distance maximum mean discrepancy proposed sinkhorn dro viewed variant wasserstein dro literature wasserstein dro besides computational tractability regularization effects statistical inference also investigated particular shown wasserstein dro asymptotically equivalent statistical learning problem variation regularization radius chosen properly loss wasserstein dro serves upper confidence bound true loss variants wasserstein dro explored combining information moment information marginal distributions finally remark recent work distributionally robust optimization given marginals share somewhat similar spirit work start dual formulation propose replace supremum subproblem smooth penalization dualize dual problem obtain primal problem penalizes entropy distribution main differences formulation impose marginal distribution constraints primal formulation ii entropic regularization transport plan joint distribution nominal distribution candidate distribution ambiguity set entropic penalty imposed candidate distributions ambiguity set iii dual formulation smooths supremum subproblem function covered considered family penalizations sinkhorn distance sinkhorn distance proposed improve computational complexity wasserstein distance regularizing original mass transportation problem relative entropy penalty transport mapping particular distance computed dual form optimizing two blocks decision variables alternatively requires simple matrixvector products therefore significantly improves computation speed approach first aroused areas economics survey statistics convergence analysis attributed mathematician sinkhorn gives name sinkhorn distance recent work designs accelerated algorithm compute sinkhorn distance time using sinkhorn distance wasserstein distance demonstrated beneficial lower computational cost various applications including domain adaptations generative modeling dimensionality reduction etc best knowledge study sinkhorn distance distributionally robust optimization new literature rest paper organized follows section describe main formulation sinkhorn dro model section develop strong dual reformulation section propose optimization algorithm solves reformulation efficiently report several numerical results section conclude paper section omitted proofs found appendix model setup notation assume logarithm function log taken base ğ‘’ positive integer ğ‘ write ğ‘ ğ‘ measurable set z denote z set measures necessarily probability measures z p z set probability measures z given probability distribution â„™ measure ğœ‡ denote supp â„™ support â„™ write â„™ ğœ‡ â„™ absolutely continuous respect ğœ‡ given element ğ‘¥ denote ğ›¿ğ‘¥ probability distribution supported ğ‘¥ denote â„™ â„š product measure two probability distributions â„™ denote ğ›¾ ğ›¾ first second marginal distributions ğ›¾ respectively given set ğ´ define characteristic function ğ‘¥ ğ‘¥ ğ‘¥ ğ´ otherwise ğ‘¥ define indicator function ğœğ´ ğ‘¥ ğœğ´ ğ‘¥ ğ‘¥ ğ´ otherwise ğœğ´ ğ‘¥ define distance two sets ğ´ ğµ euclidean space dist ğ´ ğµ supğ‘¥ kğ‘¥ first review definition sinkhorn distance definition sinkhorn distance let z measurable set consider distributions â„™ â„š p z let ğœ‡ ğœˆ z two reference measures â„™ ğœ‡ â„š ğœˆ regularization parameter ğœ– sinkhorn distance two distributions â„™ â„š defined wğœ– â„™ â„š inf ğ›¾ â„™ â„š ğ”¼ ğ‘‹ ğ‘Œ ğ‘ ğ‘‹ ğ‘Œ ğ›¾ ğœ‡ Î³ â„™ â„š denotes set joint distributions whose first second marginal distributions â„™ â„š respectively ğ‘ ğ‘¥ ğ‘¦ denotes cost function ğ» ğ›¾ ğœ‡ denotes relative entropy ğ›¾ respect product measure ğœ‡ ğ» ğ›¾ ğœ‡ log dğ›¾ ğ‘¥ ğ‘¦ dğœ‡ ğ‘¥ dğœˆ ğ‘¦ dğ›¾ ğ‘¥ ğ‘¦ remark variants sinkhorn distance sinkhorn distance definition based general reference measures ğœ‡ ğœˆ special forms distance investigated literature instance reference measures ğœ‡ ğœˆ chosen â„™ â„š marginal distributions ğ›¾ respectively section relative entropy regularization term also considered variant optimal transport problem discussed definition winfo ğ‘… â„™ â„š inf ğ›¾ â„™ â„š ğ”¼ ğ‘‹ ğ‘Œ ğ‘ ğ‘‹ ğ‘Œ ğ» ğ›¾ â„™ â„š ğ‘… ğ‘… quantifies upper bound relative entropy distributions ğ›¾ â„™ â„š another variant optimal transport problem consider negative entropy regularization equation went ğœ– â„™ â„š inf ğ›¾ â„™ â„š ğ”¼ ğ‘‹ ğ‘Œ ğ‘ ğ‘‹ ğ‘Œ ğ›¾ ğ» ğ›¾ log dğ›¾ ğ‘¥ ğ‘¦ dğ‘¥ dğ‘¦ dğ›¾ ğ‘¥ ğ‘¦ dğ‘¥ dğ‘¦ lebesgue measures corresponding marginal distributions continuous counting measures marginal distributions discrete given â„™ â„š two regularized optimal transport distances equivalent constant paper study sinkhorn dro model given loss function ğ‘“ nominal distribution â„™b sinkhorn radius ğœŒ primal form expectation problem sinkhorn dro given ğ‘‰ sup ğœ– â„™b ğ‘“ ğ‘§ ğ”¹ğœŒ ğœ– â„™b â„™ wğœ– â„™b â„™ ğœŒ sinkhorn dro ğ”¹ğœŒ ğœ– â„™b sinkhorn ball radius ğœŒ centered nominal distribution â„™b due convex entropic regularizer wğœ– â„™b â„™ sinkhorn distance wğœ– â„™b â„™ convex â„™ sinkhorn ball convex set therefore problem sinkhorn dro convex program remark choice reference measures discuss choices two references measures ğœ‡ ğœˆ definition reference measure ğœ‡ observe definition relative entropy law probability see regularization term wğœ– â„™b â„™ written ğ» ğ›¾ ğœ‡ log dğ›¾ ğ‘¥ ğ‘¦ dâ„™b ğ‘¥ dğœˆ ğ‘¦ log â„™b ğ‘¥ dğœ‡ ğ‘¥ dğ›¾ ğ‘¥ ğ‘¦ log dğ›¾ ğ‘¥ ğ‘¦ dâ„™b ğ‘¥ dğœˆ ğ‘¦ dğ›¾ ğ‘¥ ğ‘¦ log â„™b ğ‘¥ dğœ‡ ğ‘¥ dâ„™b ğ‘¥ therefore choice reference measure ğœ‡ satisfying â„™b ğœ‡ equivalent constant simplicity sequel take ğœ‡ â„™b reference measure ğœˆ observe solution â„™ sinkhorn dro satisfy â„™ ğœˆ since otherwise entropic regularization definition undefined consequence choose ğœˆ underlying true distribution absolutely continuous respect typical choices include lebesgue measure gaussian measure continuous random variables counting measure discrete measures see section construction general reference measure following sections first derive tractable formulation sinkhorn dro model develop efficient method solve finally examine performance several numerical examples strong duality reformulation problem sinkhorn dro optimization problem probability distributions obtain tractable form section derive strong duality result sinkhorn dro main goal derive strong dual problem ğ‘‰d inf ğœ†ğœŒ ğœ†ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– dâ„™b ğ‘¥ dual dual decision variable ğœ† corresponds sinkhorn distance constraint sinkhorn dro convention define dual objective evaluated ğœ† limit objective values ğœ† equals essential supremum objective function respect measure ğœˆ define constant ğœŒ ğœŒ log ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ dâ„™b ğ‘¥ kernel probability distribution dâ„šğ‘¥ ğœ– ğ‘§ ğ‘’ ğ‘¥ ğ‘§ ğ‘’ ğ‘¥ ğ‘¢ dğœˆ ğ‘¢ dğœˆ ğ‘§ make primal sinkhorn dro dual dual problems introduce following assumptions cost function ğ‘ reference measure ğœˆ loss function ğ‘“ assumption ğœˆ ğ‘§ ğ‘ ğ‘¥ ğ‘§ every ğ‘¥ ii ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ every ğ‘¥ iii z measurable space function ğ‘“ z â„ measurable assumption ensures sinkhorn distance assumption ii satisfied sinkhorn ball ğ”¹ğœŒ ğœ– â„™b p z problem sinkhorn dro simple optimal value ğ‘‰ ğ‘“ ğ‘§ assumption iii ensures expected loss ğ‘“ ğ‘§ lower bounded distribution â„™ appendix present sufficient conditions assumption easy verify distinguish cases ğ‘‰ğ· ğ‘‰ğ· introduce following condition ğ‘“ condition exists ğœ† ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– every ğ‘¥ main result section follows theorem strong duality let â„™b p z assume assumption force following holds primal problem sinkhorn dro feasible ğœŒ ii whenever ğœŒ holds ğ‘‰ iii addition condition holds ğ‘‰ otherwise ğ‘‰ remark ğœŒ convention ğ‘‰ ğ‘‰ğ· well lemma section therefore ğ‘‰ long assumption holds discussions present proof theorem would like make several remarks remark connection wasserstein dro regularization parameter ğœ– dual objective sinkhorn dro converges dual formulation wasserstein dro problem theorem ğœ†ğœŒ sup ğ‘§ ğ‘“ ğ‘§ ğ‘¥ ğ‘§ dâ„™b ğ‘¥ proof given appendix essentially follows fact function smooth approximation supremum several advantages sinkhorn dro demonstrate section sinkhorn dro tractable large class loss functions empirical nominal distribution loss evaluated efficiently measurable loss function ğ‘“ contrast main computational difficulty wasserstein dro solve maximization problem inside integration fact dro shown tractable loss function expressed pointwise maximum finitely many concave functions theorem dro shown tractable loss function smooth radius ambiguity set sufficiently small theorem ii strong duality sinkhorn dro holds even general setting essentially requirements space z nominal distribution â„™b measurability contrast strong duality wasserstein dro theorem theorem requires nominal distribution â„™b borel probability measure set z polish space remark sinkorn dro wasserstein dro result different conditions finite values condition see sinkhorn dro finite condition ğ‘“ wasserstein dro theorem finite iff loss function satisfies growth condition ğ‘“ ğ‘§ ğ¿ğ‘ ğ‘§ ğ‘€ z constants ğ¿ ğ‘€ z remark connection using jensen inequality see dual objective function sinkhorn dro model upper bounded ğœ†ğœŒ ğœ†ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– dâ„™b ğ‘¥ corresponds dual objective function following dro sup â„™ ğ‘“ ğ‘§ ğ·kl â„™kâ„™ â„™ satisfies dâ„™ ğ‘§ ğ‘¥ dâ„šğ‘¥ ğœ– ğ‘§ dâ„™b ğ‘¥ viewed kernel density estimation constructed â„™b particularly â„™b ğ‘› pğ‘› ğ›¿ğ‘¥Ë†ğ‘– z â„ğ‘‘ ğ‘ ğ‘¥ ğ‘¦ kğ‘¥ â„™ kernel density estimator gaussian kernel bandwidth ğœ– dâ„™ ğ‘§ dğ‘§ ğ‘› ğ¾ğœ– ğ‘§ ğ‘§ â„ ğ‘‘ ğ¾ğœ– ğ‘¥ exp k represents gaussian kernel decomposing ğ›¾ ğ‘¥ ğ‘§ â„™b ğ‘¥ ğ‘§ similar proof section sinkhorn dro reformulated generalized dro problem ğ‘‰ sup ğ›¾ğ‘¥ z ğ‘“ ğ‘§ dâ„™b ğ‘¥ ğ·kl ğ›¾ğ‘¥ kâ„šğ‘¥ dâ„™b ğ‘¥ using divergence inequality theorem see sinkhorn dro ğœŒ reduced following saa model based distribution â„™ ğ‘‰ ğ‘“ ğ‘§ ğ”¼â„šğ‘¥ ğœ– ğ‘“ ğ‘§ dâ„™b ğ‘¥ statistics optimal bandwidth minimize estimated distribution underlying true one rate ğœ– ğ‘› theorem however optimal choice kernel density estimator may optimal choice optimizing performance sinkhorn dro numerical experiments section select ğœ– based let us illustrate result linear loss function ğ‘“ turns equivalent simple optimization problem example suppose ğ‘“ ğ‘§ ğ‘ ğ‘§ z â„ğ‘‘ ğœˆ corresponding lebesgue measure cost function mahalanobis distance ğ‘ ğ‘¥ ğ‘¦ ğ‘¥ tÏ‰ ğ‘¥ Ï‰ positive definite matrix case reference measure â„šğ‘¥ ğœ– n ğ‘¥ ğœ–Ï‰ consequence dual problem written ğ‘‰d inf ğœ† ğœ†ğœŒ ğœ†ğœ– Î»ğ‘¥ ğœ† dâ„™b ğ‘¥ Î»ğ‘¥ ğœ† log ğ”¼ ğ‘¥ h ğ‘’ ğ‘ ğœ†ğœ– ğ‘ ğ‘¥ ğœ†ğœ– ğ‘ tÏƒğ‘ therefore ğ‘‰d ğ‘ tğ”¼â„™b ğ‘¥ ğ‘ ğ”¼â„™b ğ‘ ğ‘¥ indicates sinkhorn dro equivalent empirical risk minimization norm regularization solved using efficiently using algorithms cone program following first show ğ‘‰ â„™b empirical distribution supported ğ‘› points relatively straightforward prove show results hold â„™b general distribution provides insights distribution proof empirical nominal distribution given data points ğ‘¥Ë†ğ‘– ğ‘– ğ‘› denote ğ‘› pğ‘› ğ›¿ğ‘¥Ë†ğ‘– corresponding empirical distribution subsection discuss dual reformulation provided nominal distribution â„™b taken form although strong duality result holds arbitrary nominal distribution still interesting case proof relatively simple â„™b often chosen empirical distribution practice key proof write primal problem lagrangian form apply minimax inequality obtain weak dual observe primal reformulated generalized dro problem hence leveraging strong duality result existing dro model minimax inequality incur duality gap proof theorem â„™b ğ‘› pğ‘› ğ›¿ğ‘¥Ë†ğ‘– based definition reformulate ğ‘‰ ğ‘‰ sup ğ›¾ ğ”¼â„™ ğ‘“ ğ‘§ ğ”¼ğ›¾ ğ‘ ğ‘¥ ğ‘§ log dğ›¾ ğ‘¥ ğ‘§ dâ„™b ğ‘¥ dğœˆ ğ‘§ ğœŒ disintegration theorem represent joint distribution ğ›¾ ğ‘› pğ‘› ğ›¿ğ‘¥Ë†ğ‘– ğ›¾ğ‘– conditional distribution ğ›¾ given first marginal ğ›¾ equals ğ‘¥Ë†ğ‘– thereby constraint equivalent ğ‘› ğ”¼ğ›¾ğ‘– ğ‘ ğ‘¥Ë†ğ‘– ğ‘§ log dğ›¾ğ‘– ğ‘§ dğœˆ ğ‘§ ğœŒ ğ›¾ğ‘– p z ğ‘– ğ‘› remark feasible solution ğ›¾ satisfies ğ›¾ â„™b ğœˆ hence ğ›¾ğ‘– consequently term log dğ›¾ğ‘– ğ‘§ dğœˆ ğ‘§ notational simplicity write â„šğ‘– â„šğ‘¥Ë†ğ‘– ğœ– based identity log dğ›¾ğ‘– ğ‘§ dğœˆ ğ‘§ log dâ„šğ‘– ğ‘§ dğœˆ ğ‘§ log dğ›¾ğ‘– ğ‘§ dâ„šğ‘– ğ‘§ expression â„šğ‘– constraint reformulated ğ‘› ğ”¼ğ›¾ğ‘– ğ‘ ğ‘¥Ë†ğ‘– ğ‘§ log ğ‘’ ğ‘¥ ğ‘§ ğ‘’ ğ‘¥ ğ‘¢ dğœˆ ğ‘¢ log dğ›¾ğ‘– ğ‘§ dâ„šğ‘– ğ‘§ ğœŒ ğ›¾ğ‘– p z ğ‘– ğ‘› combining first two terms within expectation term substituting expression ğœŒ equivalent ğœ– ğ‘› ğ”¼ğ›¾ğ‘– log dğ›¾ğ‘– ğ‘§ dâ„šğ‘– ğ‘§ ğœŒ ğ›¾ğ‘– p z ğ‘– ğ‘› similarly objective function sinkhorn dro written ğ‘› pğ‘› ğ”¼ğ›¾ğ‘– ğ‘“ ğ‘§ consequently primal problem sinkhorn dro reformulated generalized dro problem ğ‘‰ sup ğ›¾ğ‘– z ğ‘– ğ‘› ğ‘› ğ”¼ğ›¾ğ‘– ğ‘“ ğ‘§ ğœ– ğ‘› ğ·kl ğ›¾ğ‘– kâ„šğ‘– ğœŒ theorem holds based introducing lagrange multiplier ğœ† associated constraint reformulate sinkhorn dro ğ‘‰ sup ğ›¾ğ‘– z ğ‘– ğ‘› inf ğœ†ğœŒ ğ‘› ğ”¼ğ›¾ğ‘– ğ‘“ ğ‘§ log dğ›¾ğ‘– ğ‘§ dâ„šğ‘– ğ‘§ interchanging supremum infimum operators ğ‘‰ inf ğœ†ğœŒ sup ğ›¾ğ‘– z ğ‘– ğ‘› ğ‘› ğ”¼ğ›¾ğ‘– ğ‘“ ğ‘§ log dğ›¾ğ‘– ğ‘§ dâ„šğ‘– ğ‘§ since optimization ğ›¾ğ‘– ğ‘– ğ‘› separable defining ğ‘– ğ‘£ğ‘– ğœ† sup ğ›¾ğ‘– z ğ”¼ğ›¾ğ‘– ğ‘“ ğ‘§ log dğ›¾ğ‘– ğ‘§ dâ„šğ‘– ğ‘§ holds ğ‘‰ inf ğœ†ğœŒ ğ‘› ğ‘£ğ‘– ğœ† condition holds leveraging results entropy regularized linear optimization lemma see ğ‘£ğ‘– ğœ† ğœ†ğœ– log ğ”¼â„šğ‘– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– hence obtain weak duality ğ‘‰ ğ‘‰d otherwise ğœ† exists index ğ‘– ğ”¼â„šğ‘– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– also obtain ğ‘‰ ğ‘‰d weak duality still holds next prove strong duality recall primal problem generalized dro problem leveraging strong duality result minimax inequality incur duality gap ğœŒ ğœŒ since ğ·kl ğ›¾ğ‘– kâ„šğ‘– ğ›¾ğ‘– â„šğ‘– one see ğ‘‰ ğ‘› ğ”¼â„šğ‘– ğ‘“ ğ‘§ hand denote â„ ğœ† objective function dual problem inequality ğ‘‰d lim â„ ğœ† ğ‘› ğ”¼â„šğ‘– ğ‘“ ğ‘§ together weak duality result completes proof theorem ii theorem iii also follows based discussion finiteness ğ‘‰d sample space z finite following result presents conic programming reformulation corollary conic reformulation finite sample space suppose sample space contains ğ¿ elements z ğ‘§â„“ ğ¿ condition holds ğœŒ dual problem dual formulated following conic optimization ğ‘‰d min ğ‘  ğœ†ğœŒ ğ‘› ğ‘ ğ‘– ğœ†ğœ– ğ¿ ğ‘ğ‘– â„“ğ‘ğ‘– â„“ ğ‘– ğ‘› ğœ†ğœ– ğ‘ğ‘– â„“ ğ‘“ ğ‘§â„“ kexp ğ‘– ğ‘› â„“ ğ¿ ğ‘ğ‘– â„“ ğœ– ğ‘§ ğ‘§â„“ distribution â„šğ‘¥Ë†ğ‘– ğœ– defined kexp denotes exponential cone kexp ğœˆ ğœ† ğ›¿ â„ exp problem convex program minimizes linear function respect linear conic constraints solved using interior point algorithms develop customized optimization algorithm section able solve general problem without finite sample space proof general nominal distribution subsection outline proof theorem â„™b arbitrary nominal distribution discuss distribution feasibility result theorem easily shown using reformulation show ğ‘‰ easy show weak duality result following similar argument section replacing integration respect â„™b condition holds prove strong duality constructing distribution first show existence dual minimizer lemma build corresponding optimality condition lemma lemma results help us construct primal optimal solution sinkhorn dro shares optimal value ğ‘‰d completes first part theorem iii condition hold construct sequence dro problems finite optimal values converging ğ‘‰ consequently ğ‘‰ completes second part theorem iii putting two parts together imply theorem ii lemma weak duality assume assumption holds ğ‘‰ ğ‘‰d provide proof first part theorem iii case ğœŒ condition defer proofs degenerate cases appendix prove strong duality construct feasible solution sinkhorn dro whose loss coincides ğ‘‰d end first show dual minimizer exists lemma existence dual minimizer suppose ğœŒ condition satisfied dual minimizer ğœ† exists either equals satisfies condition separate two cases ğœ† ğœ† corresponding whether sinkhorn distance constraint sinkhorn dro binding lemma presents necessary sufficient condition dual minimizer ğœ† corresponding case sinkhorn distance constraint sinkhorn dro binding lemma necessary sufficient condition ğœ† suppose ğœŒ condition satisfied dual minimizer ğœ† following conditions hold ess sup ğœˆ ğ‘“ inf ğ‘¡ ğœˆ ğ‘“ ğ‘§ ğ‘¡ ii ğœŒ ğœŒ log ğ”¼â„šğ‘¥ ğœ– dâ„™b ğ‘¥ ğ´ ğ‘§ ğ‘“ ğ‘§ ess sup ğœˆ ğ‘“ recall convention dual objective evaluated ğœ† equals ess sup ğœˆ ğ‘“ thus condition ensures dual objective function evaluated minimizer finite minimizer ğœ† sinkhorn ball large enough contain least one distribution objective value ess sup ğœˆ ğ‘“ condition ii characterizes lower bound lemma considers optimality condition dual minimizer ğœ† obtained simply setting derivative dual objective function zero lemma optimality condition ğœ† suppose ğœŒ condition satisfied assume dual minimizer ğœ† ğœ† satisfies ğœ† ğœŒ log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ† ğœ– dâ„™b ğ‘¥ ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ† ğœ– ğ‘“ ğ‘§ ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ† dâ„™b ğ‘¥ ready prove theorem proof theorem iii condition ğœŒ proof separated two cases ğœ† ğœ† case prove constructing primal approximate optimal solution ğœ† take probability measure ğ‘¥ ğ‘§ exp ğœ™ ğœ† ğ‘¥ ğ‘§ ğœ† exp ğœ™ ğœ† ğ‘¥ ğ‘¢ ğœ† dğœˆ ğ‘¢ dğœˆ ğ‘§ dâ„™b ğ‘¥ ğœ™ ğœ† ğ‘¥ ğ‘§ ğ‘“ ğ‘§ ğ‘¥ ğ‘§ also define primal approximate optimal distribution recall expression sinkhorn distance definition one verify wğœ– â„™b inf ğ›¾ â„™b ğ”¼ğ›¾ ğ‘ ğ‘¥ ğ‘§ log dğ›¾ ğ‘¥ ğ‘§ dâ„™b ğ‘¥ dğœˆ ğ‘§ ğ‘ ğ‘¥ ğ‘§ log ğ‘¥ ğ‘§ dâ„™b ğ‘¥ dğœˆ ğ‘§ ğ‘ ğ‘¥ ğ‘§ log exp ğœ™ ğœ† ğ‘¥ ğ‘§ ğœ† exp ğœ™ ğœ† ğ‘¥ ğ‘¢ ğœ† dğœˆ ğ‘¢ Âª ğœ† ğ‘“ ğ‘§ exp ğœ™ ğœ† ğ‘¥ ğ‘§ ğœ† exp ğœ™ ğœ† ğ‘¥ ğ‘§ ğœ† dğœˆ ğ‘§ dğœˆ ğ‘§ dâ„™b ğ‘¥ ğœ– log exp ğœ™ ğœ† ğ‘¥ ğ‘¢ ğœ† dğœˆ ğ‘¢ dâ„™b ğ‘¥ second relation feasible solution Î³ â„™b third fourth relation substituting expression since ğœŒ dual minimizer ğœ† optimality condition holds implies wğœ– â„™b ğœŒ distribution primal feasible problem sinkhorn dro moreover see primal optimal value lower bounded dual optimal value ğ‘‰ ğ‘“ ğ‘§ ğ‘“ ğ‘§ ğ‘¥ ğ‘§ ğ‘“ ğ‘§ ğ‘¥ ğ‘§ dâ„™b ğ‘¥ dğœˆ ğ‘§ dğœˆ ğ‘§ dâ„™b ğ‘¥ ğ‘“ ğ‘§ exp ğœ™ ğœ† ğ‘¥ ğ‘§ ğœ† exp ğœ™ ğœ† ğ‘¥ ğ‘¢ ğœ† dğœˆ ğ‘¢ dğœˆ ğ‘§ dâ„™b ğ‘¥ ğœŒ log exp ğœ™ ğœ† ğ‘¥ ğ‘§ ğœ† dğœˆ ğ‘§ dâ„™b ğ‘¥ third equality based optimality condition lemma together weak duality result completes proof ğœ† ğœ† optimality condition lemma holds construct primal approximate solution satisfies ğ‘¥ ğ‘§ dğ›¾ ğ‘¥ ğ‘§ dâ„™b ğ‘¥ dğ›¾ ğ‘¥ ğ‘¦ ğ‘§ ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ ğ‘’ ğ‘¥ ğ‘¢ dğœˆ ğ‘¢ ğ‘§ ğ´ verify easily primal solution feasible based optimality condition ğœŒ lemma moreover check primal optimal value lower bounded dual optimal value ğ‘‰ ğ‘“ ğ‘§ ğ‘¥ ğ‘§ ğ‘“ ğ‘§ dğ›¾ ğ‘¥ ğ‘§ dâ„™b ğ‘¥ ess sup ğœˆ ğ‘“ dğ›¾ ğ‘¥ ğ‘§ dâ„™b ğ‘¥ ess sup ğœˆ ğ‘“ second equality ğ‘§ ğ´ ğ‘“ ğ‘§ ess sup ğœˆ ğ‘“ together weak duality result completes proof ğœ† remark distribution proof presented observe ğœ† distribution sinkhorn dro expressed ğ‘§ ğ‘¥ ğ‘’ ğ‘“ ğ‘§ ğœ† ğœ– dâ„šğ‘¥ ğœ– ğ‘§ ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ† dâ„™b ğ‘¥ see distribution shares support measure ğœˆ particularly â„™b empirical distribution ğ‘› pğ‘› ğ›¿ğ‘¥Ë†ğ‘– ğœˆ continuous distribution â„ğ‘‘ distribution supported entire â„ğ‘‘ contrast distribution wasserstein dro supported ğ‘› points another difference advantage possibly sinkhorn dro compared wasserstein dro indeed many practical problems underlying distribution modeled continuous distribution distribution wasserstein dro often finitely supported raising concern whether hedges wrong family distributions thus results suboptimal solutions numerical results section demonstrate empirical advantages sinkhorn dro efficient algorithm sinkhorn robust learning section consider sinkhorn robust learning problem seek optimal decision minimize risk inf ğœƒ sup ğœ– â„™b ğ‘“ğœƒ ğ‘§ feasible set Î¸ contains possible candidates decision vector ğœƒ take â„™b empirical distribution corresponding sample points ğ‘¥Ë†ğ‘– ğ‘– ğ‘› based strong dual dual reformulate inf ğœƒ ğ¹ ğœ† ğœƒ ğœ†ğœŒ ğ‘› ğœ†ğœ– log ğ”¼â„šğ‘¥Ë†ğ‘– ğœ– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– constant ğœŒ distribution â„šğ‘¥Ë†ğ‘– ğœ– defined respectively example seen instance get expression integration general expression available following present algorithm solve problem discuss alternatives section observe objective function involves nonlinear transformation expectation thus unbiased gradient estimate could challenging â„šğ‘¥Ë†ğ‘– ğœ– general probability distribution propose solve following approximation inf ğœƒ ğ¹Ë† ğ‘š ğœ† ğœƒ ğœ†ğœŒ ğ‘› ğœ†ğœ– log ğ”¼â„šË†ğ‘š ğ‘– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– â„šË†ğ‘š ğ‘– ğ‘š pğ‘š ğ›¿ğ‘§Ë†ğ‘– ğ‘— denotes empirical distribution constructed ğ‘§Ë†ğ‘– ğ‘— ğ‘š independent identically distributed samples â„šğ‘¥Ë†ğ‘– ğœ– many cases generating samples â„šğ‘¥Ë†ğ‘– ğœ– easy instance choosing cost function ğ‘ k z â„ğ‘‘ distribution â„šğ‘¥Ë†ğ‘– ğœ– becomes gaussian distribution n ğ‘¥Ë†ğ‘– ğœ–ğ¼ğ‘‘ otherwise generate samples example method brief summary proposed method first simulate batch samples approximate original sinkhorn dro dual objective function use projected algorithm batch gradient descent bisection search solving require interval ğœ†ğ‘™ ğœ†ğ‘¢ ğœ†ğ‘™ ğœ† ğœ†ğ‘¢ ğœ† optimal dual variable terminating tolerance Î´ ğ‘¡ ğ‘‡ ğœ†ğ‘™ ğœ†ğ‘¢ solve subproblem get compute ğ‘ ğ¹Ë† ğ‘š terminate iteration ğ‘ ğœ†ğ‘¢ Î´ let ğ‘¡ğ‘¢ ğ‘ let ğ‘¡ğ‘™ ğ‘ end return gradient descent bisection search solve approximated problem hence method named batch gradient descent bisection search function ğ‘“ğœƒ ğ‘§ convex ğœƒ problem finite convex programming second term objective function ğ¹Ë† ğ‘š ğœ† ğœƒ perspective transformation section function composition convex function develop customized batch gradient descent bisection search method solve problem efficiently gradient objective function calculated ğ¹Ë† ğ‘š ğœ† ğœƒ ğ‘› ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– ğ‘“ğœƒ ğ‘§ ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– ğ¹Ë† ğ‘š ğœ† ğœƒ ğœŒ ğœ– ğ‘› log ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– ğ‘› ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– ğ‘“ğœƒ ğ‘§ ğœ†ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– fixed ğœ† denote ğ¹Ë† ğ‘š ğœ† optimal value following problem ğ¹Ë† ğ‘š ğœ† ğœ†ğœŒ inf ğœƒ ğ‘› ğœ†ğœ– log ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– convexity ğ¹Ë† ğ‘š ğœ† ğœƒ function ğ¹Ë† ğ‘š ğœ† convex ğœ† together fact ğ¹Ë† ğ‘š ğœ† respect ğœ† motivates us use bisection search method algorithm solve problem particular iteration first find optimal solution problem fixed ğœ† use bisection method search optimal ğœ† gradient ğ‘“ğœƒ ğ‘§ bounded ğœƒ ğ‘§ solved using projected gradient method convergence rate ğ‘‚ ğ‘€ ğ‘€ denotes number inner iterations theorem also argue iteration points algorithm converge optimal solution ğ¹Ë† ğ‘š ğœ† linear rate proposition suppose function ğ‘“ğœƒ ğ‘§ convex ğœƒ iteration points ğœ† ğ‘¡ ğ‘¡ algorithm converge linearly ğ‘¡ ğœ† optimal solution ğ¹Ë† ğ‘š ğœ† last result section establishes consistency monte carlo approximation proposition let ğ‘‰ set optimal solutions corresponding optimal value problem respectively let ğ‘š ğ‘‰ ğ‘š set optimal solutions optimal value problem respectively assume function ğ‘“ğœƒ ğ‘§ random lower convex ğœƒ set Î¸ closed convex contains interior ii value function ğ¹ ğœ† ğœƒ defined lower exists point ğœ† Î¾ ğ¹ ğœ† ğœƒ ğœ† ğœƒ neighborhood ğœ† iii set bounded ğ‘š ğ‘‰ ğ‘š almost surely dist ğ‘š almost surely indicates obtain solution sinkhorn dro arbitrarily small gap long increase number simulation times monte carlo approximation proof leverages results key difference objective function studied paper involves nonlinear transform expectation existing result applied directly detailed proof found appendix alternative algorithmic choices subsection discuss possibilities designing algorithm solve objective involves composition two expectations natural idea solve problem design algorithms leveraging techniques stochastic compositional optimization problem applied directly assume inner independent randomness outer expectation inner expectation objective depends samples ğ‘¥Ë†ğ‘– ğ‘– ğ‘› recent conditional stochastic compositional csco optimization aims minimize composition two functions inner expectation taken respect conditional distribution also opens door designing efficient algorithms solving although objective written csco problem naturally fits structure dual variable ğœ† fixed however find takes relatively long time obtain optimal variable ğœƒ ğœ† fixed lack smoothness structure objective makes csco algorithm bsgd difficult converge empirically since need optimize variables ğœ† ğœƒ jointly global convergence csco problem even challenging extensive simulations omit find proposed method solves sinkhorn dro problem efficiently csco algorithm standard projected gradient descent without bisection search algorithm optimize ğœƒ fixed ğœ† alternative would optimize ğœ† ğœƒ jointly however pointed ğœ† small value variance gradient estimate objective function respect ğœ† unstable hence develop bisection method update ğœ† outer iterations algorithm moreover observe inner iteration solving computationally expansive step obtain gradient ğ¹Ë† ğ‘š ğœ† complexity ğ‘‚ ğ‘›ğ‘š statistical learning problems therefore promising use projected stochastic gradient method instead projected gradient descent solve condition guarantees convergence restrictive topic future study problems one also write problem standard conic optimization form use interior point method solve worth mentioning strategy applied obtain unbiased gradient estimate expectation term presence logarithm makes easy use standard stochastic gradient descent unbiased gradient estimate optimization instead use monte carlo samples problem approximate promising use numerical integration techniques carlo method wavelet method approximate objective efficiently research interest future study applications section apply methodology three applications newsvendor model meanrisk portfolio optimization learning examine performance sinkhorn dro model comparing three benchmarks classical sample average approximation saa model ii wasserstein dro model iii dro model unless otherwise specified cost function chosen ğ‘ k reference measure ğœˆ sinkhorn distance chosen lebesgue measure three applications ğ‘› training samples select pair ğœ– ğœŒ using method ğ¾ since grid search optimal pair costly search single first tune ğœ– fixing ğœŒ corresponds saa problem chosen ğœ– tune sinkhorn radius ğœŒ run repeated experiments times section section measure performance solution ğœƒ relative performance gap ğ½ ğœƒ ğ½ ğ½ denotes true optimal value true distribution known exactly ğ½ ğœƒ expected loss solution ğœƒ true distribution estimated saa objective value testing samples thus smaller relative performance gap better performance solution details included appendix newsvendor model consider following distributionally robust newsvendor model min ğœƒ max ğœ– â„™b ğ”¼â„™ ğ‘˜ğœƒ min ğœƒ ğ‘§ random variable ğ‘§ stands random demand empirical distribution â„™b consists ğ‘› independent samples exponential distribution density ğ‘“ ğ‘¥ ğ‘  ğ‘  exp ğ‘¥ ğ‘  ğ‘  decision variable ğœƒ represents inventory level ğ‘˜ ğ‘¢ constants corresponding overage underage costs respectively values recorded table see optimal entropic regularization parameter ğœ– increases distribution scale parameter ğ‘  increases distribution larger value ğ‘  larger variance achieve better performance larger entropic regularization parameter ğœ– needed encourage larger spread probability mass table values selected newsvendor problem parameter ğ‘  regularization ğœ– sinkhorn radius ğœŒ wasserstein radius ğœŒ radius ğœ‚ report violin plots box plots shapes formed kernel density estimation relative performance gap across different approaches fig find sinkhorn dro best performance figures stable performance indicated concentrated violin plot wasserstein dro one hand comparable performance saa ğ‘  small small radius ğœŒ indicated table even worse saa large ğ‘  large ğœŒ indicated table small ğœŒ wasserstein robust solution coincides saa solution thus regularizer problem similar observation made remark support â„ whereas large ğœŒ hedges distributions extreme puts positive probability mass zero demand leading saa sinkhorn wasserstein method relative performance gap n saa sinkhorn wasserstein method relative performance gap n saa sinkhorn wasserstein method relative performance gap n saa sinkhorn wasserstein method relative performance gap n saa sinkhorn wasserstein method relative performance gap n saa sinkhorn wasserstein method relative performance gap n figure performances newsvendor model parameters ğ‘  fixed sample size ğ‘› overly conservative solution moreover dro much improvement compared saa model likely induced distribution shares support empirical distribution portfolio optimization consider following distributionally robust portfolio optimization problem min ğœƒ max ğœ– â„™b ğ‘§ ğœš ğ‘§ ğœƒ Î¸ ğœƒ â„ ğ‘‘ ğœƒ random vector ğ‘§ â„ğ‘‘ stands returns assets decision variable ğœƒ Î¸ represents portfolio strategy invests certain percentage ğœƒğ‘– available capital asset term ğ‘§ quantifies conditional average ğ›¼ worst portfolio losses distribution â„™ follow similar setup specifically set ğ›¼ ğœš random asset ğ‘§ decomposed systematic risk factor ğœ“ â„ idiosyncratic risk factors ğœ– â„ğ‘‘ ğ‘§ğ‘– ğ‘– ğ· ğœ“ n ğœ–ğ‘– n ğ‘– ğ‘– fixed training sample size ğ‘› vary number assets ğ· solve problem using algorithm projected gradient descent step update ğœƒ follows implementation project onto probability simplex Î¸ violin plots relative performance gap across different approaches reported fig similar finding section wasserstein dro dro models outperform saa method much sinkhorn dro best performance plots indicated smallest well concentrated violin plots contrast apparent dimension ğ· large saa sinkhorn wasserstein method relative performance gap n saa sinkhorn wasserstein method relative performance gap n saa sinkhorn wasserstein method relative performance gap n figure performances portfolio optimization problem dimension ğ· fixed sample size ğ‘› learning last example learning task following similar setup suppose training data set dğ‘› ğ‘‹ğ‘– ğ‘Œğ‘– ğ‘› ğ‘Œğ‘– denotes label observation additionally set unlabeled observations ğ‘‹ğ‘– ğ‘ build set eğ‘ ğ‘‹ğ‘– ğ‘ ğ‘‹ğ‘– ğ‘ means replicate unlabeled data point twice recognizing missing label two available alternatives formulate empirical distribution consisting samples set xğ‘ dğ‘› eğ‘ denoted â„™b considering following distributionally robust formulation min ğœƒ max ğœ– â„™b ğ”¼â„™ â„“ ğœƒ ğ‘‹ ğ‘Œ â„“ ğœƒ ğ‘‹ ğ‘Œ log exp ğœƒ tğ‘‹ also solve task using three benchmark models cost function subsection set ğ‘ ğ‘¥ ğ‘¦ ğ‘¥ kğ‘¥ k ğ‘¦ ğ‘¦ parameter ğœ… means labeling error case duality result sinkhorn dro need robustify feature vectors ğ‘‹ consider three performance measures obtained classifiers training error samples known labels ii training error samples unknown labels iii testing error new observations experiment conducted using binary classification real data sets uci machine learning data base repeated experiments data set randomly partition collected samples training testing data sets classification results different approaches reported table first number entry represents average classification error second number entry represents confidence interval detailed parameters settings task choices reported appendix observe though sinkhorn dro best performance indicated training error samples known labels best performance data sets indicated smallest training error samples unknown labels smallest testing error concluding remarks paper investigated new distributionally robust optimization framework based sinkhorn distance developing strong dual reformulation customized batch gradient descent bisection search algorithm shown resulting dro problem tractable table classification results real datasets learning task experiment repeated independent trials confidence intervals classification errors reported different approaches saa sinkhorn wasserstein breast cancer train labeled train unlabeled test error magic train labeled train unlabeled test error qsar bio train labeled train unlabeled test error spambase train labeled train unlabeled test error mild assumptions greatly spans tractability wasserstein dro analysis distribution indicates sinkhorn dro hedges reasonable set adverse scenarios thus less conservative compared wasserstein dro demonstrated via extensive numerical experiments based theoretical numerical findings conclude sinkhorn distance promising candidate modeling distributional ambiguities uncertainty perspective computational tractability modeling rationality performance meantime several topics worth investigating left future works interesting design efficient algorithms sinkhorn dro nominal distribution arbitrary loss function decision variable moreover meaningful research question choice optimal sinkhorn dro radius ambiguity set ğœŒ entropic regularization parameters ğœ– reference measures ğœˆ paper focuses regularizing wasserstein distance entropic regularization sinkhorn distance extensions types regularization possible exploring discovering benefits sinkhorn dro types applications may lead future research directions appendix sufficient condition assumption proposition assumption holds exists ğ‘ following conditions satisfied ğ‘¥ ğ‘¦ ğ‘§ z ğ‘ ğ‘¥ ğ‘¦ ğ‘ ğ‘¥ ğ‘¦ ğ‘ ğ‘¥ ğ‘§ ğ‘ ğ‘§ ğ‘¦ ii nominal distribution â„™b finite mean denoted ğ‘¥ moreover ğœˆ ğ‘§ ğ‘ ğ‘¥ ğ‘§ pr ğ‘ ğ‘¥ ğ‘¥ iii exists ğœ† ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘’ ğ‘ ğ‘¥ ğ‘§ dğœˆ ğ‘§ make remarks sufficient conditions listed first condition satisfied taking cost function power metric defined z ğ‘ second condition requires nominal distribution â„™b finite almost surely subguassian distribution respect cost function ğ‘ combining three conditions together levering concentration arguments completes proof proposition references abdullah ren h ammar hb milenkovic v luo r zhang wang j wasserstein robust reinforcement learning arxiv preprint agrawal ding saberi ye price correlations stochastic optimization operations research altschuler j weed j rigollet p time approximation algorithms optimal transport via sinkhorn iteration advances neural information processing systems aps mosek modeling cookbook https html asmussen glynn pw stochastic simulation algorithms analysis volume springer science business media aziz haq f et al comparative study numerical integration based haar wavelets hybrid functions computers mathematics applications bacharach estimating nonnegative matrices marginal data international economic review bai wu x ozgur information constrained optimal transport talagrand marton cover ieee international symposium information theory isit bayraksan g love dk stochastic programming using operations research revolution informs den hertog de waegenaere melenberg b rennen g robust solutions optimization problems affected uncertain probabilities management science bertsimas natarajan k teo cp persistence discrete optimization data uncertainty mathematical programming bertsimas sim zhang adaptive distributionally robust optimization management science blanchet j chen l zhou xy distributionally robust portfolio selection wasserstein distances arxiv preprint blanchet j glynn pw yan j zhou z multivariate distributionally robust convex regression absolute error loss advances neural information processing systems volume blanchet j kang learning based distributionally robust optimization data analysis applications blanchet j kang murthy k robust wasserstein profile inference applications machine learning journal applied probability blanchet j murthy k quantifying distributional model risk via optimal transport mathematics operations research blanchet j murthy k nguyen va statistical analysis wasserstein distributionally robust estimators arxiv preprint blanchet j murthy k si n confidence regions wasserstein distributionally robust estimation arxiv preprint blanchet j murthy k zhang f optimal transport based distributionally robust optimization structural properties iterative schemes arxiv preprint blanchet jh glynn pw unbiased monte carlo optimization functions expectations via randomization winter simulation conference wsc boyd vandenberghe l convex optimization cambridge university press chang jt pollard conditioning disintegration statistica neerlandica chen r paschalidis ic robust learning approach regression models based distributionally robust optimization journal machine learning research chen r paschalidis ic selecting optimal decisions via distributionally robust regression advances neural information processing systems chen li w natural gradient wasserstein statistical manifold arxiv preprint chen ye x projection onto simplex arxiv preprint chen z kuhn wiesemann w chance constrained programs wasserstein balls arxiv preprint chen z sim xu h distributionally robust optimization infinitely constrained ambiguity sets operations research cherukuri cortÃ©s j cooperative distributionally robust optimization ieee transactions automatic control courty n flamary r habrard rakotomamonjy joint distribution optimal transportation domain adaptation advances neural information processing systems courty n flamary r tuia domain adaptation regularized optimal transport joint european conference machine learning knowledge discovery databases courty n flamary r tuia rakotomamonjy optimal transport domain adaptation ieee transactions pattern analysis machine intelligence cover tm thomas ja elements information theory cuturi sinkhorn distances lightspeed computation optimal transport advances neural information processing systems volume delage e ye distributionally robust optimization moment uncertainty application problems operations research deming stephan ff least squares adjustment sampled frequency table expected marginal totals known annals mathematical statistics derman e mannor distributional robustness regularization reinforcement learning arxiv preprint doan xv natarajan k complexity nonoverlapping multivariate marginal bounds probabilistic combinatorial optimization problems operations research dua graff c uci machine learning repository online available http duchi jc glynn pw namkoong h statistics robust optimization generalized empirical likelihood approach mathematics operations research eckstein kupper pohl robust risk aggregation neural networks mathematical finance frÃ©chet sur les tableaux dont les marges et des bornes sont donnÃ©es revue de l institut international de statistique gao r guarantees wasserstein distributionally robust optimization breaking curse dimensionality arxiv preprint gao r chen x kleywegt aj wasserstein distributionally robust optimization variation regularization arxiv preprint gao r kleywegt aj distributionally robust stochastic optimization wasserstein distance arxiv preprint gao r kleywegt aj robust optimization known marginal distributions working paper available https gao r kleywegt aj distributionally robust stochastic optimization dependence structure arxiv preprint genevay cuturi peyrÃ© g bach f stochastic optimization optimal transport advances neural information processing systems volume genevay peyre g cuturi learning generative models sinkhorn divergences proceedings international conference artificial intelligence statistics volume proceedings machine learning research pmlr ghadimi ruszczynski wang single timescale stochastic approximation method nested stochastic optimization siam journal optimization goh j sim distributionally robust optimization tractable approximations operations research grant boyd cvx matlab software disciplined convex programming version http hÃ¤rdle w applied nonparametric regression cambridge university press hu chen x n sample complexity sample average approximation conditional stochastic optimization siam journal optimization hu zhang chen x n biased stochastic methods conditional stochastic optimization applications meta learning advances neural information processing systems volume hu z hong lj divergence constrained distributionally robust optimization optimization online preprint optimization huang lai l riemannian block coordinate descent method computing projection robust wasserstein distance proceedings international conference machine learning jain p kar p optimization machine learning foundations trends machine learning kruithof j telefoonverkeersrekening de ingenieur kuhn esfahani pm nguyen va wasserstein distributionally robust optimization theory applications machine learning operations research management science age analytics informs li j huang amc algorithmic framework wasserstein distributionally robust logistic regression proceedings international conference neural information processing systems li w montufar g natural gradient via optimal transport arxiv preprint lin fan c ho n cuturi jordan projection robust wasserstein distance riemannian optimization advances neural information processing systems volume luise g rudi pontil ciliberto c differential properties sinkhorn approximation learning wasserstein distance advances neural information processing systems luo f mehrotra decomposition algorithm distributionally robust optimization using wasserstein metric application class regression models european journal operational research mohajerin esfahani p kuhn distributionally robust optimization using wasserstein metric performance guarantees tractable reformulations mathematical programming namkoong h duchi jc stochastic gradient methods distributionally robust optimization advances neural information processing systems volume natarajan k song teo cp persistency model applications choice modeling management science nemirovski lectures modern convex optimization society industrial applied mathematics siam nesterov nemirovskii polynomial algorithms convex programming siam nguyen va si n blanchet j robust bayesian classification using optimistic score ratio international conference machine learning nguyen va zhang f blanchet j delage e ye robustifying conditional portfolio decisions via optimal transport arxiv preprint niederreiter h random number generation carlo methods siam patrini g van den berg r forre p carioni bhargav welling genewein nielsen f sinkhorn autoencoders uncertainty artificial intelligence petzka h fischer lukovnikov regularization wasserstein gans international conference learning representations peyre g cuturi computational optimal transport applications data science foundations trends machine learning pflug g wozabal ambiguity portfolio selection quantitative finance pichler shapiro mathematical foundations distributionally robust multistage optimization arxiv preprint popescu semidefinite programming approach bounds convex classes distributions mathematics operations research rahimian h mehrotra distributionally robust optimization review arxiv preprint rockafellar rt uryasev et al optimization conditional journal risk scarf h solution inventory problem studies mathematical theory inventory production kuhn esfahani pm regularization via mass transportation journal machine learning research shafieezadeh abadeh mohajerin esfahani pm kuhn distributionally robust logistic regression advances neural information processing systems volume shapiro dentcheva ruszczyÅ„ski lectures stochastic programming modeling theory siam singh zhang tight bounds class distributionally robust risk measures arxiv preprint singh zhang distributionally robust profit opportunities operations research letters sinha namkoong h duchi j certifiable distributional robustness principled adversarial training international conference learning representations sinkhorn r relationship arbitrary positive matrices doubly stochastic matrices annals mathematical statistics smirnova e dohmatob e mary j distributionally robust reinforcement learning arxiv preprint staib jegelka distributionally robust optimization generalization kernel methods advances neural information processing systems taskesen b nguyen va kuhn blanchet j distributionally robust approach fair classification arxiv preprint van parys bp goulart pj kuhn generalized gauss inequalities via semidefinite programming mathematical programming vandenberghe l boyd semidefinite programming siam review wang c gao r qiu f wang j xin l distributionally robust optimal power flow dynamic line rating ieee transactions power systems wang j gao r xie test using projected wasserstein distance ieee international symposium information theory isit wang j gao r xie test kernel projected wasserstein distance arxiv preprint wang j gao r zha h reliable evaluation reinforcement learning arxiv preprint wang j jia z yin h yang inferred adaptive recoding batched network coding ieee international symposium information theory isit wang fang ex liu h stochastic compositional gradient descent algorithms minimizing compositions functions mathematical programming wang z glynn pw ye likelihood robust optimization problems computational management science wiesemann w kuhn sim distributionally robust convex optimization operations research wozabal framework optimization ambiguity annals operations research xie w distributionally robust chance constrained programs wasserstein distance mathematical programming yang convex optimization approach distributionally robust markov decision processes wasserstein distance ieee control systems letters yang wasserstein distributionally robust stochastic control approach ieee transactions automatic control yang wang fang ex multilevel stochastic gradient methods nested composition optimization siam journal optimization yule gu methods measuring association two attributes journal royal statistical society zhao c guan stochastic optimization wasserstein metric operations research letters zhu j jitkrittum w diehl schÃ¶lkopf b kernel distributionally robust optimization generalized duality theorem stochastic approximation proceedings international conference artificial intelligence statistics zymler kuhn rustem b distributionally robust joint chance constraints moment information mathematical programming supplementary sinkhorn distributionally robust optimization appendix detailed experiment setup experiments preformed macbook pro laptop memory running python candidates dro models listed follows experiment pick regularization term ğœ– spaced exponentially increasing steps sinkhorn radius ğœŒ chosen spaced exponentially increasing steps wasserstein radius ğœŒ radius ğœ‚ chosen spaced exponentially increasing steps second third experiments reported table table respectively obtain monte carlo approximated objective function sinkhorn dro model take nominal distribution â„™b empirical distribution based collected samples inner batch size ğ‘š use projected gradient descent method solve subproblem portfolio optimization problems try step size ğœ‚â„“ inner iteration otherwise try step size ğœ‚â„“ inner iteration denote objâ„“ objective function obtained iteration inner iteration terminated k kobjâ„“ k saa wasserstein dro dro models solved exactly based interior point solver mosek particular based corollary wasserstein dro formulation newsvendor problem section becomes min ğœƒ ğœ† ğ‘  ğ›¾ ğœ†ğœŒ ğ‘› ğ‘ ğ‘– ğ‘˜ ğœƒ ğ‘ ğ‘– ğ‘– ğ‘› ğ‘˜ğœƒ ğ‘ ğ‘– ğ‘– ğ‘› ğœ† ğ‘– ğ‘› ğœ† ğ‘– ğ‘› ğ›¾ ğ‘§Ë†ğ‘› denotes collected samples eq see wasserstein dro formulation portfolio optimization problem becomes min ğœƒ ğœ ğœ† ğ‘  ğœ†ğœŒ ğ‘› ğ‘ ğ‘– ğœƒ Î¸ ğ‘ğ‘—ğœ ğ‘§Ë†ğ‘–i ğ‘ ğ‘– ğ‘– ğ‘› ğ‘— ğ» kğ‘ğ‘—ğœƒ ğœ† ğ‘— ğ» recall dro problem radius ğœ‚ following tractable formulation min ğœƒ n ğœ†ğœ‚ ğœ† log ğ”¼â„™b h ğ‘’ ğ‘“ğœƒ ğ‘§ table values selected portfolio optimization problem dimension ğ· regularization ğœ– sinkhorn radius ğœŒ wasserstein radius ğœŒ radius ğœ‚ table values classification parameters dro models breast cancer magic qsar bio spambase number predictors train size labeled train size unlabeled test size sinkhorn para ğœŒ ğœ– wasserstein para ğœŒ para ğœ‚ appendix proofs technical results section order show strong duality result theorem â„™b empirical distribution present following technical lemma lemma fixed ğœ reference probability distribution â„š p z consider optimization problem ğ‘£ ğœ sup z ğ”¼â„™ ğ‘“ ğ‘§ log dâ„™ dâ„š ğ‘§ ğœ ğ‘£ ess sup â„š ğ‘“ inf ğ‘¡ â„ pr ğ‘“ ğ‘§ ğ‘¡ ii ğœ ğ”¼â„š h ğ‘’ ğ‘“ ğ‘§ holds ğ‘£ ğœ ğœ log ğ”¼â„š h ğ‘’ ğ‘“ ğ‘§ limğœ ğ‘£ ğœ ğ‘£ optimal solution expression dâ„™ ğ‘§ ğ‘’ ğ‘“ ğ‘§ ğ‘’ ğ‘“ ğ‘¢ dâ„š ğ‘¢ dâ„š ğ‘§ iii ğœ ğ”¼â„š h ğ‘’ ğ‘“ ğ‘§ ğ‘£ ğœ proof lemma reformulate ğ‘£ ğœ based importance sampling trick ğ‘£ ğœ sup ğ¿ ğ‘“ ğ‘§ ğ¿ ğ‘§ ğ‘§ logğ¿ ğ‘§ dâ„š ğ‘§ ğ¿ ğ‘§ dâ„š ğ‘§ remaining part follows discussion section proof corollary introduce variables ğ‘ ğ‘– ğ‘– ğ‘› reformulate ğ‘‰d ğ‘‰d inf ğ‘ ğ‘– ğœ†ğœŒ ğ‘› ğ‘ ğ‘– ğœ†ğœ– log ğ”¼â„šğ‘– ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘ ğ‘– fixed ğ‘– constraint reformulated n exp ğ‘ ğ‘– ğœ†ğœ– ğ”¼â„šğ‘– ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ”¼â„šğ‘– ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğœ†ğœ– ğ”¼â„šğ‘– ğœ– ğœ†ğœ–ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğœ†ğœ– ğ¿ â„šğ‘– ğœ– ğ‘§â„“ ğ‘ğ‘– â„“ ğ‘ğ‘– â„“ ğœ†ğœ– exp ğ‘“ ğ‘§â„“ ğœ†ğœ– second constraint set formulated ğœ†ğœ– ğ‘ğ‘– â„“ ğ‘“ ğ‘§â„“ kexp substituting expression ğ‘‰d completes proof appendix proof technical result section proof remark reformulate dual objective function ğ‘£ ğœ† ğœ– ğœ†ğœŒ ğœ†ğœ– log exp ğ‘“ ğ‘§ ğ‘¥ ğ‘§ ğœ†ğœ– dğœˆ ğ‘§ dâ„™b ğ‘¥ take limit second term ğ‘£ ğœ† ğœ– obtain lim ğœ†ğœ– log exp ğ‘“ ğ‘§ ğ‘¥ ğ‘§ ğœ†ğœ– dğœˆ ğ‘§ dâ„™b ğ‘¥ lim ğœ† ğ›½ log exp ğ‘“ ğ‘§ ğ‘¥ ğ‘§ ğ›½ ğœ† dğœˆ ğ‘§ dâ„™b ğ‘¥ lim exp ğ‘“ ğ‘§ ğ‘¥ ğ‘§ ğ›½ ğœ† dğœˆ ğ‘§ dâ„™b ğ‘¥ lim exp ğ‘“ ğ‘§ ğ‘¥ ğ‘§ ğ›½ ğœ† ğ‘“ ğ‘§ ğ‘¥ ğ‘§ dğœˆ ğ‘¦ exp ğ‘“ ğ‘§ ğ‘¥ ğ‘§ ğ›½ ğœ† dğœˆ ğ‘¦ dâ„™b ğ‘¥ sup ğ‘§ ğ‘“ ğ‘§ ğ‘¥ ğ‘§ dâ„™b ğ‘¥ hence conclude dual objective function sinkhorn dro problem converges wasserstein dro problem appendix proofs technical results section proof lemma recall remark primal problem ğ‘‰ reformulated ğ‘‰ sup ğ›¾ğ‘¥ z ğ”¼ğ›¾ğ‘¥ ğ‘“ ğ‘§ dâ„™b ğ‘¥ ğœ– ğ”¼ğ›¾ğ‘¥ log dğ›¾ğ‘¥ ğ‘§ dâ„šğ‘– ğ‘§ dâ„™b ğ‘¥ ğœŒ introducing lagrange multiplier ğœ† associated constraint reformulate ğ‘‰ ğ‘‰ sup ğ›¾ğ‘¥ z inf ğœ†ğœŒ ğ”¼ğ›¾ğ‘¥ ğ‘“ ğ‘§ log dğ›¾ğ‘¥ ğ‘§ dâ„šğ‘¥ ğœ– ğ‘§ dâ„™b ğ‘¥ interchanging order supremum infimum operators ğ‘‰ inf ğœ†ğœŒ sup ğ›¾ğ‘¥ z ğ”¼ğ›¾ğ‘¥ ğ‘“ ğ‘§ log dğ›¾ğ‘¥ ğ‘§ dâ„šğ‘¥ ğœ– ğ‘§ dâ„™b ğ‘¥ since optimization ğ›¾ğ‘¥ separable ğ‘¥ defining ğ‘£ğ‘¥ ğœ† sup ğ›¾ğ‘¥ z ğ”¼ğ›¾ğ‘¥ ğ‘“ ğ‘§ log dğ›¾ğ‘¥ ğ‘§ dâ„šğ‘¥ ğœ– ğ‘§ swap supremum integration obtain ğ‘‰ inf ğœ†ğœŒ ğ‘£ğ‘¥ ğœ† dâ„™b ğ‘¥ exists ğœ† condition holds leveraging reformulation entropy regularized linear optimization lemma see almost surely ğ‘£ğ‘¥ ğœ† ğœ†ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– substituting expression implies ğ‘‰ ğ‘‰d suppose contrary ğœ† pr n ğ‘¥ ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– intermediately obtain ğ‘‰ ğ‘‰d weak duality still holds proof lemma first show ğœ† denote ğ‘£ ğœ† objective function dual problem ğ‘£ ğœ† ğœ†ğœŒ ğœ†ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– dâ„™b ğ‘¥ integrability condition dominated convergence theorem satisfied implies lim ğœ†ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– dâ„™b ğ‘¥ lim ğœ– ğ›½ log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ›½ ğ‘“ ğ‘§ dâ„™b ğ‘¥ lim log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ›½ ğ‘“ ğ‘§ dâ„™b ğ‘¥ lim ğœ– ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ›½ ğ‘“ ğ‘§ ğ”¼â„šğ‘¥ ğœ– ğ‘“ ğ‘§ ğœ– ğ‘’ ğ›½ ğ‘“ ğ‘§ dâ„™b ğ‘¥ ğ”¼â„šğ‘¥ ğœ– ğ‘“ ğ‘§ dâ„™b ğ‘¥ first equality follows technique ğ›½ second equality follows l hospital rule third last equality follows dominated convergence theorem consequence long ğœŒ lim ğ‘£ ğœ† take ğœ† satisfying condition ğ‘£ ğœ† guarantees existence dual minimizer hence ğœ† implies either ğœ† ğœ† satisfies condition proof lemma suppose dual minimizer ğœ† taking limit dual objective function gives lim ğ‘£ ğœ† ğ» ğ‘¢ ğ‘¥ dâ„™b ğ‘¥ ğ» ğ‘¢ ğ‘¥ inf ğ‘¡ â„šğ‘¥ ğœ– ğ‘“ ğ‘§ ğ‘¡ ess sup â„šğ‘¥ ğœ– ğ‘“ notational simplicity take ğ» ğ‘¢ ess sup ğœˆ ğ‘“ one check ğ» ğ‘¢ ğ‘¥ ğ» ğ‘¢ ğ‘¥ supp â„™b ğ‘¡ â„šğ‘¥ ğœ– ğ‘“ ğ‘§ ğ‘¡ ğ‘“ ğ‘§ ğ‘¡ ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ together fact ğœˆ ğ‘ ğ‘¥ ğ‘§ fixed ğ‘¥ implies ğ‘“ ğ‘§ ğ‘¡ dğœˆ ğ‘§ contrary ğ‘¡ ğœˆ ğ‘“ ğ‘§ ğ‘¡ ğ‘“ ğ‘§ ğ‘¡ ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ ğ‘“ ğ‘§ ğ‘¡ dğœˆ ğ‘§ second inequality ğœˆ ğ‘ ğ‘¥ ğ‘§ consequence â„šğ‘¥ ğœ– ğ‘“ ğ‘§ ğ‘¡ hence assert ğ» ğ‘¢ ğ‘¥ ğ» ğ‘¢ ğ‘¥ supp â„™b implies lim ğ‘£ ğœ† ğ» ğ‘¢ show almost surely ğ‘¥ ğ”¼â„šğ‘¥ ğœ– ğ´ ğ‘§ ğ‘“ ğ‘§ ğ» ğ‘¢ denote ğ· collection samples ğ‘¥ ğ”¼â„šğ‘¥ ğœ– assume condition hold means â„™b ğ· ğœ ğ‘¥ ğ· exists ğ» ğ‘™ ğ‘¥ ğ» ğ‘¢ ğ”¥ğ‘¥ ğ”¼â„šğ‘¥ ğœ– ğ‘¥ ğœ ğµ ğ‘¥ ğ‘§ ğ» ğ‘™ ğ‘¥ ğ‘“ ğ‘§ ğ» ğ‘¢ define ğ» gap ğ‘¥ ğ» ğ‘¢ ğ‘™ ğ‘¥ ğ”¥ ğ‘ ğ‘¥ ğ”¥ğ‘¥ find ğ‘¥ ğ· ğ‘£ğ‘¥ ğœ† ğœ†ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘¥ ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘¥ ğ‘ ğ» ğ‘¢ ğœ†ğœ– log ğ”¥ğ‘¥ gap ğ‘¥ ğœ†ğœ– ğ”¥ ğ‘ ğ‘¥ since â„™b ğ· dual objective function ğœ† upper bounded ğ‘£ ğœ† ğœ†ğœŒ ğ‘£ğ‘¥ ğœ† dâ„™b ğ‘¥ ğ» ğ‘¢ ğœ†ğœŒ ğœ†ğœ– ğ· log ğ”¥ğ‘¥ gap ğ‘¥ ğœ†ğœ– ğ”¥ ğ‘ ğ‘¥ dâ„™b ğ‘¥ see lim ğœ†ğœŒ ğœ†ğœ– ğ· log ğ”¥ğ‘¥ gap ğ‘¥ ğœ†ğœ– ğ”¥ ğ‘ ğ‘¥ dâ„™b ğ‘¥ lim ğœ†ğœŒ ğœ†ğœ– ğ· log ğ”¥ğ‘¥ gap ğ‘¥ ğœ†ğœ– ğ”¥ ğ‘ ğ‘¥ dâ„™b ğ‘¥ ğ· log ğ”¥ğ‘¥ dâ„™b ğ‘¥ log ğœ â„™b ğ· second inequality taking constant ğœ exp ğœ–â„™b ğ· hence exists ğœ† ğ‘£ ğœ† ğ» ğ‘¢ ğœ†ğœŒ ğœ†ğœ– ğ· log ğ”¥ğ‘¥ gap ğ‘¥ ğœ†ğœ– ğ”¥ ğ‘ ğ‘¥ dâ„™b ğ‘¥ ğ‘£ contradicts optimality ğœ† result almost surely ğ‘¥ ğ”¼â„šğ‘¥ ğœ– show second condition dual objective function ğœ† ğ‘£ ğœ† ğœ†ğœŒ ğœ†ğœ– h log ğ”¼â„šğ‘¥ ğœ– ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğ‘¢ ğœ†ğœ– dâ„™b ğ‘¥ ğ‘¢ gradient ğ‘£ ğœ† becomes ğœ† ğœŒ h log ğ”¼â„šğ‘¥ ğœ– ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğ‘¢ ğœ†ğœ– dâ„™b ğ‘¥ ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğ‘¢ ğœ†ğœ– ğ» ğ‘¢ ğ‘“ ğ‘§ ğœ† ğ”¼â„šğ‘¥ ğœ– ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– dâ„™b ğ‘¥ see ğœ† ğœŒ take ğ‘¥ ğœ† ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğ‘¢ ğœ†ğœ– ğ‘¥ ğœ† ğ‘¥ ğœ† take ğ‘¥ ğœ† ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğ‘¢ ğœ†ğœ– ğ» ğ‘¢ ğ‘“ ğ‘§ ğœ† ğ”¼â„šğ‘¥ ğœ– ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘¥ ğœ† ğ‘¥ ğœ† follows lim ğœ† ğœŒ log ğ”¼â„šğ‘¥ ğœ– dâ„™b ğ‘¥ ğœŒ hence last condition violated based mean value theorem find ğœ† ğœ† contradicts optimality ğœ† show converse direction ğœ† find ğœ† ğœŒ log ğ”¼â„šğ‘¥ ğœ– ğ‘¥ ğœ† dâ„™b ğ‘¥ ğ‘¥ ğœ† dâ„™b ğ‘¥ fixed ğ‘¥ ğ”¼â„šğ‘¥ ğœ– see ğ‘¥ ğœ† ğ‘¥ ğœ† ğœŒ log ğ”¼â„šğ‘¥ ğœ– ğ‘¥ ğœ† ğ‘¥ ğœ† ğœŒ ğ”¼â„šğ‘¥ ğœ– see ğ‘¥ ğœ† ğ‘¥ ğœ† ğœŒ log ğ”¼â„šğ‘¥ ğœ– ğ‘¥ ğœ† ğ‘¥ ğœ† ğœŒ log ğ”¼â„šğ‘¥ ğœ– ğœŒ therefore ğœ† ğœ† convexity ğ‘£ ğœ† conclude dual minimizer ğœ† proof lemma since ğœ† based optimality condition dual problem ğœ†ğœŒ ğœ†ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– dâ„™b ğ‘¥ equivalently log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ† ğœ– dâ„™b ğ‘¥ ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ† ğœ– ğ‘“ ğ‘§ ğœ† ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ† dâ„™b ğ‘¥ term completes proof proof theorem feasibility result theorem easily shown considering reformulation ğ‘‰ ğœŒ one see ğ‘‰d lim ğœ†ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– dâ„™b ğ‘¥ ğ‘“ ğ‘§ therefore strong duality result holds case proof ğœŒ found main context remains show second part theorem iii consider sequence real numbers ğ‘…ğ‘— ğ‘— ğ‘…ğ‘— take objective function ğ‘“ğ‘— ğ‘§ ğ‘“ ğ‘§ ğ‘§ ğ‘…ğ‘— hence exists ğœ† satisfying pr ğ‘¥ ğ”¼â„šğ‘¥ ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– according necessary condition lemma corresponding dual minimizer ğœ† ğ‘— sufficiently large index ğ‘— apply duality result first part theorem iii show sufficiently large ğ‘— holds sup ğœ– â„™b ğ‘“ğ‘— ğ‘§ ğœ† ğ‘— ğœŒ ğœ† ğ‘— ğœ– log ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ğ‘— ğ‘§ ğœ†ğœ– dâ„™b ğ‘¥ taking ğ‘— sides implies ğ‘‰ completes proof appendix proofs technical results section proof proposition fixed denote optimal solution problem argue ğ‘ ğ¹Ë† ğ‘š ğ‘ subgradient ğ¹Ë† ğ‘š ğœ† ğœ† ğœ† let ğœƒ ğœ† optimal solution ğ¹Ë† ğ‘š ğœ† see ğ¹Ë† ğ‘š ğœ† ğ¹Ë† ğ‘š ğœ† ğœƒ ğœ† ğ¹Ë† ğ‘š ğœ† ğ‘š ğœƒ ğœ† ğ¹Ë† ğ‘š ğœ† ğ‘š denotes subdifferential ğ¹Ë† ğ‘š respect ğœƒ first inequality convexity ğ¹Ë† ğ‘š ğœ† ğœƒ respect ğœ† ğœƒ second inequality optimality condition ğ‘ immediately obtain ğ‘š means minimizer ğ¹Ë† ğ‘š ğœ† otherwise algorithm update interval ğ‘ ğœ† ğœ† within claim interval contain suppose contrary ğ‘ convexity ğ¹Ë† ğ‘š ğ¹Ë† ğ‘š ğ¹Ë† ğ‘š ğ¹Ë† ğ‘š contradicts optimality result interval length ğ‘™ğ‘¡ ğœ†ğ‘¢ iteration algorithm vanishes rate ğ‘™ğ‘¡ ğ‘¡ indicates algorithm converge optimal solution ğ¹Ë† ğ‘š ğœ† linearly proof proposition notational simplicity write ğ‘  ğœ† ğœƒ Î¾ Î¸ first show second part theorem begin introduce following functions ğ‘  ğ¹Ë† ğ‘š ğ‘  ğ‘  ğ‘  ğ¹ ğ‘  ğ‘  build pointwise law large numbers lln strong law large numbers lln ğ‘– every ğœ† ğœƒ Î¾ ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– ğ”¼â„šğ‘– ğœ– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– continuous mapping theorem ğ‘– every ğœ† ğœƒ Î¾ ğœ†ğœ– log ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– ğœ†ğœ– log ğ”¼â„šğ‘– ğœ– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– therefore using addition scalar multiplication rule almost sure convergence every ğœ† ğœƒ Î¾ holds ğ‘› ğœ†ğœ– log ğ”¼â„šË†ğ‘š ğ‘¥Ë†ğ‘– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– ğ‘› ğœ†ğœ– log ğ”¼â„šğ‘– ğœ– h ğ‘’ ğ‘“ğœƒ ğ‘§ ğœ†ğœ– reveals ğ¹Ë† ğ‘š ğ‘  ğ¹ ğ‘  ğ‘  Î¾ implies corresponding lln ğ‘  take compact subset ğ¶ contained interior ğ¶ set exists bounded denote set minimizers ğ¶ lower together pointwise lln find large ğ‘š implies set large ğ‘š show dist almost surely let ğœ” ğ‘§ğ‘– ğ‘— ğ‘– ğ‘— ğœ” ğ‘’ event holds almost surely ğœ” suppose contrary ğ‘š exists minimizer ğœ” ğ¶ dist ğœ€ due compactness ğ¶ exists ğ‘— converges point ğ‘  ğ¶ ğ‘  hand argue ğ‘  arg minğ‘  ğ‘  applying proposition obtain contradiction show ğ‘š large ğ‘š convexity assumption minimizer ğ¶ lies inside interior ğ¶ also optimal solution problem hence large ğ‘š ğ‘š together fact dist implies dist ğ‘š moreover suffices restrict feasible set compact set ğ¶ Î¾ convexity ğ¹ ğ‘  ğ‘  ğ¹Ë† ğ‘š ğ¹ holds uniformly ğ¶ Î¾ consequence first part proposition proved applying proposition appendix proof technical result appendix first present useful technical lemma showing proposition lemma first condition proposition ğ‘¥ z holds ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ ğ‘’ ğ‘ ğ‘¥ ğ‘¥ ğ‘’ ğ‘ ğ‘¥ ğ‘§ dğœˆ ğ‘§ proof lemma based inequality ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ see ğ‘ ğ‘¥ ğ‘§ ğ‘ ğ‘¦ ğ‘§ ğ‘§ ğ‘¦ ğ‘ ğ‘ ğ‘¦ ğ‘§ ğ‘§ ğ‘¦ ğ‘¦ ğ‘§ z since ğ‘ ğ‘¥ ğ‘§ ğ‘ ğ‘¥ ğ‘§ ğ‘¥ ğ‘¥ see ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ exp ğ‘ ğ‘¥ ğ‘¥ ğ‘’ ğ‘ ğ‘¥ ğ‘§ dğœˆ ğ‘§ proof completed proof proposition one see ğ‘¥ supp â„™b holds ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘’ ğ‘¥ ğ‘§ ğ‘’ ğ‘¥ ğ‘¢ dğœˆ ğ‘¢ dğœˆ ğ‘§ ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘’ ğ‘¥ ğ‘§ ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ dğœˆ ğ‘§ ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘’ ğ‘ ğ‘¥ ğ‘§ ğ‘’ ğ‘ ğ‘¥ ğ‘¥ ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ dğœˆ ğ‘§ ğ‘’ ğ‘ ğ‘¥ ğ‘¥ ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘’ ğ‘ ğ‘¥ ğ‘§ dğœˆ ğ‘§ first inequality based lower bound lemma second inequality based triangular inequality ğ‘ ğ‘¥ ğ‘§ ğ‘ ğ‘¥ ğ‘§ ğ‘¥ ğ‘¥ note almost surely ğ‘¥ supp â„™b ğ‘ ğ‘¥ ğ‘¥ moreover ğ‘’ ğ‘ ğ‘¥ ğ‘§ dğœˆ ğ‘§ ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ lower bound ğ‘ ğ‘¥ ğ‘§ almost surely ğ‘§ upper bound ğ‘ ğ‘¥ ğ‘§ almost surely ğ‘§ based observations ğ”¼â„šğ‘¥ ğœ– h ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘’ ğ‘ ğ‘¥ ğ‘¥ ğ‘’ ğ‘¥ ğ‘§ dğœˆ ğ‘§ ğ‘’ ğ‘“ ğ‘§ ğœ†ğœ– ğ‘’ ğ‘ ğ‘¥ ğ‘§ dğœˆ ğ‘§ almost surely ğ‘¥ â„™b
